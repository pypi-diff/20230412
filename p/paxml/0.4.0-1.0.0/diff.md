# Comparing `tmp/paxml-0.4.0-py3-none-any.whl.zip` & `tmp/paxml-1.0.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,80 +1,80 @@
-Zip file size: 290175 bytes, number of entries: 78
--rw-r--r--  2.0 unx    28747 b- defN 23-Mar-31 07:01 paxml/automl.py
--rw-r--r--  2.0 unx    15951 b- defN 23-Mar-31 07:01 paxml/automl_interfaces.py
--rw-r--r--  2.0 unx    35471 b- defN 23-Mar-31 07:01 paxml/automl_test.py
--rw-r--r--  2.0 unx     4810 b- defN 23-Mar-31 07:01 paxml/base_experiment.py
--rw-r--r--  2.0 unx     3105 b- defN 23-Mar-31 07:01 paxml/base_inference_runner.py
--rw-r--r--  2.0 unx     3026 b- defN 23-Mar-31 07:01 paxml/base_inference_runner_test.py
--rw-r--r--  2.0 unx    15688 b- defN 23-Mar-31 07:01 paxml/base_metrics.py
--rw-r--r--  2.0 unx     5204 b- defN 23-Mar-31 07:01 paxml/base_metrics_test.py
--rw-r--r--  2.0 unx     1106 b- defN 23-Mar-31 07:01 paxml/base_task.py
--rw-r--r--  2.0 unx    10867 b- defN 23-Mar-31 07:01 paxml/checkpoint_managers.py
--rw-r--r--  2.0 unx    21807 b- defN 23-Mar-31 07:01 paxml/checkpoint_managers_test.py
--rw-r--r--  2.0 unx     1310 b- defN 23-Mar-31 07:01 paxml/checkpoint_version.py
--rw-r--r--  2.0 unx    27845 b- defN 23-Mar-31 07:01 paxml/checkpoints.py
--rw-r--r--  2.0 unx     3643 b- defN 23-Mar-31 07:01 paxml/checkpoints_test.py
--rw-r--r--  2.0 unx    72697 b- defN 23-Mar-31 07:01 paxml/eval_lib.py
--rw-r--r--  2.0 unx     1659 b- defN 23-Mar-31 07:01 paxml/experiment_imports_all_test.py
--rw-r--r--  2.0 unx     5025 b- defN 23-Mar-31 07:01 paxml/experiment_imports_test_helper.py
--rw-r--r--  2.0 unx     6707 b- defN 23-Mar-31 07:01 paxml/experiment_registry.py
--rw-r--r--  2.0 unx     4770 b- defN 23-Mar-31 07:01 paxml/experiment_registry_test.py
--rw-r--r--  2.0 unx     4213 b- defN 23-Mar-31 07:01 paxml/experiment_utils.py
--rw-r--r--  2.0 unx    13122 b- defN 23-Mar-31 07:01 paxml/io_utils.py
--rw-r--r--  2.0 unx     5537 b- defN 23-Mar-31 07:01 paxml/io_utils_test.py
--rw-r--r--  2.0 unx    23525 b- defN 23-Mar-31 07:01 paxml/learners.py
--rw-r--r--  2.0 unx    27456 b- defN 23-Mar-31 07:01 paxml/learners_test.py
--rw-r--r--  2.0 unx    18494 b- defN 23-Mar-31 07:01 paxml/main.py
--rw-r--r--  2.0 unx     4842 b- defN 23-Mar-31 07:01 paxml/metric_tracker_utils.py
--rw-r--r--  2.0 unx     1839 b- defN 23-Mar-31 07:01 paxml/metric_tracker_utils_test.py
--rw-r--r--  2.0 unx    10151 b- defN 23-Mar-31 07:01 paxml/metric_utils.py
--rw-r--r--  2.0 unx    11334 b- defN 23-Mar-31 07:01 paxml/metric_utils_test.py
--rw-r--r--  2.0 unx    46957 b- defN 23-Mar-31 07:01 paxml/partitioning.py
--rw-r--r--  2.0 unx     1863 b- defN 23-Mar-31 07:01 paxml/partitioning_test.py
--rw-r--r--  2.0 unx      923 b- defN 23-Mar-31 07:01 paxml/preemption.py
--rw-r--r--  2.0 unx     3038 b- defN 23-Mar-31 07:01 paxml/profiling.py
--rw-r--r--  2.0 unx    27709 b- defN 23-Mar-31 07:01 paxml/programs.py
--rw-r--r--  2.0 unx     4515 b- defN 23-Mar-31 07:01 paxml/programs_test.py
--rw-r--r--  2.0 unx    74969 b- defN 23-Mar-31 07:01 paxml/seqio_input.py
--rw-r--r--  2.0 unx    41569 b- defN 23-Mar-31 07:01 paxml/seqio_input_test.py
--rw-r--r--  2.0 unx     3252 b- defN 23-Mar-31 07:01 paxml/setup_jax.py
--rw-r--r--  2.0 unx    12213 b- defN 23-Mar-31 07:01 paxml/sgf.py
--rw-r--r--  2.0 unx    25668 b- defN 23-Mar-31 07:01 paxml/summary_utils.py
--rw-r--r--  2.0 unx    11514 b- defN 23-Mar-31 07:01 paxml/summary_utils_test.py
--rw-r--r--  2.0 unx    61313 b- defN 23-Mar-31 07:01 paxml/tasks_lib.py
--rw-r--r--  2.0 unx    27063 b- defN 23-Mar-31 07:01 paxml/tasks_lib_test.py
--rw-r--r--  2.0 unx      793 b- defN 23-Mar-31 07:01 paxml/test_helper.py
--rw-r--r--  2.0 unx    48224 b- defN 23-Mar-31 07:01 paxml/train.py
--rw-r--r--  2.0 unx     2070 b- defN 23-Mar-31 07:01 paxml/train_states.py
--rw-r--r--  2.0 unx    46376 b- defN 23-Mar-31 07:01 paxml/trainer_lib.py
--rw-r--r--  2.0 unx    34972 b- defN 23-Mar-31 07:01 paxml/tuning_lib.py
--rw-r--r--  2.0 unx    31238 b- defN 23-Mar-31 07:01 paxml/tuning_lib_test.py
--rw-r--r--  2.0 unx     7590 b- defN 23-Mar-31 07:01 paxml/contrib/gpu/scripts_gpu/configs.py
--rw-r--r--  2.0 unx      784 b- defN 23-Mar-31 07:01 paxml/contrib/gpu/scripts_gpu/download_lambada.py
--rw-r--r--  2.0 unx      777 b- defN 23-Mar-31 07:01 paxml/contrib/gpu/scripts_gpu/download_the_pile.py
--rw-r--r--  2.0 unx     5881 b- defN 23-Mar-31 07:01 paxml/contrib/gpu/scripts_gpu/tasks.py
--rw-r--r--  2.0 unx     5431 b- defN 23-Mar-31 07:01 paxml/contrib/gpu/scripts_gpu/tfds_lambada.py
--rw-r--r--  2.0 unx     7376 b- defN 23-Mar-31 07:01 paxml/contrib/gpu/scripts_gpu/tfds_pile.py
--rw-r--r--  2.0 unx      597 b- defN 23-Mar-31 07:01 paxml/tasks/lm/__init__.py
--rw-r--r--  2.0 unx    17202 b- defN 23-Mar-31 07:01 paxml/tasks/lm/input_generator.py
--rw-r--r--  2.0 unx     4032 b- defN 23-Mar-31 07:01 paxml/tasks/lm/input_generator_test.py
--rw-r--r--  2.0 unx    35228 b- defN 23-Mar-31 07:01 paxml/tasks/lm/model_params.py
--rw-r--r--  2.0 unx     6532 b- defN 23-Mar-31 07:01 paxml/tasks/lm/params/bert.py
--rw-r--r--  2.0 unx    29826 b- defN 23-Mar-31 07:01 paxml/tasks/lm/params/c4.py
--rw-r--r--  2.0 unx     3612 b- defN 23-Mar-31 07:01 paxml/tasks/lm/params/c4_test.py
--rw-r--r--  2.0 unx    10315 b- defN 23-Mar-31 07:01 paxml/tasks/lm/params/lm_cloud.py
--rw-r--r--  2.0 unx     4919 b- defN 23-Mar-31 07:01 paxml/tasks/lm/params/nvidia.py
--rw-r--r--  2.0 unx     2972 b- defN 23-Mar-31 07:01 paxml/tasks/lm/params/optimal_scaling.py
--rw-r--r--  2.0 unx     1124 b- defN 23-Mar-31 07:01 paxml/tasks/test/synthetic.py
--rw-r--r--  2.0 unx     5371 b- defN 23-Mar-31 07:01 paxml/tasks/vision/input_generator.py
--rw-r--r--  2.0 unx     1611 b- defN 23-Mar-31 07:01 paxml/tasks/vision/input_generator_test.py
--rw-r--r--  2.0 unx     7002 b- defN 23-Mar-31 07:01 paxml/tasks/vision/resnet_preprocessing.py
--rw-r--r--  2.0 unx     8792 b- defN 23-Mar-31 07:01 paxml/tasks/vision/params/imagenet_resnets.py
--rw-r--r--  2.0 unx     7305 b- defN 23-Mar-31 07:01 paxml/tools/dump_hparams.py
--rw-r--r--  2.0 unx     1590 b- defN 23-Mar-31 07:01 paxml/tools/dump_input_specs.py
--rw-r--r--  2.0 unx     3834 b- defN 23-Mar-31 07:01 paxml/tools/dump_input_specs_lib.py
--rw-r--r--  2.0 unx    11357 b- defN 23-Mar-31 07:07 paxml-0.4.0.dist-info/LICENSE
--rw-r--r--  2.0 unx     1069 b- defN 23-Mar-31 07:07 paxml-0.4.0.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 23-Mar-31 07:07 paxml-0.4.0.dist-info/WHEEL
--rw-r--r--  2.0 unx        6 b- defN 23-Mar-31 07:07 paxml-0.4.0.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     6567 b- defN 23-Mar-31 07:07 paxml-0.4.0.dist-info/RECORD
-78 files, 1094984 bytes uncompressed, 279919 bytes compressed:  74.4%
+Zip file size: 289831 bytes, number of entries: 78
+-rw-r--r--  2.0 unx    28747 b- defN 23-Apr-12 18:21 paxml/automl.py
+-rw-r--r--  2.0 unx    15951 b- defN 23-Apr-12 18:21 paxml/automl_interfaces.py
+-rw-r--r--  2.0 unx    35471 b- defN 23-Apr-12 18:21 paxml/automl_test.py
+-rw-r--r--  2.0 unx     4810 b- defN 23-Apr-12 18:21 paxml/base_experiment.py
+-rw-r--r--  2.0 unx     3105 b- defN 23-Apr-12 18:21 paxml/base_inference_runner.py
+-rw-r--r--  2.0 unx     3026 b- defN 23-Apr-12 18:21 paxml/base_inference_runner_test.py
+-rw-r--r--  2.0 unx    15688 b- defN 23-Apr-12 18:21 paxml/base_metrics.py
+-rw-r--r--  2.0 unx     5204 b- defN 23-Apr-12 18:21 paxml/base_metrics_test.py
+-rw-r--r--  2.0 unx     1106 b- defN 23-Apr-12 18:21 paxml/base_task.py
+-rw-r--r--  2.0 unx    10825 b- defN 23-Apr-12 18:21 paxml/checkpoint_managers.py
+-rw-r--r--  2.0 unx    21585 b- defN 23-Apr-12 18:21 paxml/checkpoint_managers_test.py
+-rw-r--r--  2.0 unx     1310 b- defN 23-Apr-12 18:21 paxml/checkpoint_version.py
+-rw-r--r--  2.0 unx    27824 b- defN 23-Apr-12 18:21 paxml/checkpoints.py
+-rw-r--r--  2.0 unx     3643 b- defN 23-Apr-12 18:21 paxml/checkpoints_test.py
+-rw-r--r--  2.0 unx    72624 b- defN 23-Apr-12 18:21 paxml/eval_lib.py
+-rw-r--r--  2.0 unx     1659 b- defN 23-Apr-12 18:21 paxml/experiment_imports_all_test.py
+-rw-r--r--  2.0 unx     5025 b- defN 23-Apr-12 18:21 paxml/experiment_imports_test_helper.py
+-rw-r--r--  2.0 unx     6707 b- defN 23-Apr-12 18:21 paxml/experiment_registry.py
+-rw-r--r--  2.0 unx     4770 b- defN 23-Apr-12 18:21 paxml/experiment_registry_test.py
+-rw-r--r--  2.0 unx     4213 b- defN 23-Apr-12 18:21 paxml/experiment_utils.py
+-rw-r--r--  2.0 unx    13122 b- defN 23-Apr-12 18:21 paxml/io_utils.py
+-rw-r--r--  2.0 unx     5537 b- defN 23-Apr-12 18:21 paxml/io_utils_test.py
+-rw-r--r--  2.0 unx    23525 b- defN 23-Apr-12 18:21 paxml/learners.py
+-rw-r--r--  2.0 unx    27456 b- defN 23-Apr-12 18:21 paxml/learners_test.py
+-rw-r--r--  2.0 unx    18494 b- defN 23-Apr-12 18:21 paxml/main.py
+-rw-r--r--  2.0 unx     4842 b- defN 23-Apr-12 18:21 paxml/metric_tracker_utils.py
+-rw-r--r--  2.0 unx     1839 b- defN 23-Apr-12 18:21 paxml/metric_tracker_utils_test.py
+-rw-r--r--  2.0 unx    10151 b- defN 23-Apr-12 18:21 paxml/metric_utils.py
+-rw-r--r--  2.0 unx    11334 b- defN 23-Apr-12 18:21 paxml/metric_utils_test.py
+-rw-r--r--  2.0 unx    48890 b- defN 23-Apr-12 18:21 paxml/partitioning.py
+-rw-r--r--  2.0 unx     1863 b- defN 23-Apr-12 18:21 paxml/partitioning_test.py
+-rw-r--r--  2.0 unx      923 b- defN 23-Apr-12 18:21 paxml/preemption.py
+-rw-r--r--  2.0 unx     3038 b- defN 23-Apr-12 18:21 paxml/profiling.py
+-rw-r--r--  2.0 unx    27709 b- defN 23-Apr-12 18:21 paxml/programs.py
+-rw-r--r--  2.0 unx     4525 b- defN 23-Apr-12 18:21 paxml/programs_test.py
+-rw-r--r--  2.0 unx    74705 b- defN 23-Apr-12 18:21 paxml/seqio_input.py
+-rw-r--r--  2.0 unx    39897 b- defN 23-Apr-12 18:21 paxml/seqio_input_test.py
+-rw-r--r--  2.0 unx     3252 b- defN 23-Apr-12 18:21 paxml/setup_jax.py
+-rw-r--r--  2.0 unx    12213 b- defN 23-Apr-12 18:21 paxml/sgf.py
+-rw-r--r--  2.0 unx    25668 b- defN 23-Apr-12 18:21 paxml/summary_utils.py
+-rw-r--r--  2.0 unx    11514 b- defN 23-Apr-12 18:21 paxml/summary_utils_test.py
+-rw-r--r--  2.0 unx    61313 b- defN 23-Apr-12 18:21 paxml/tasks_lib.py
+-rw-r--r--  2.0 unx    27063 b- defN 23-Apr-12 18:21 paxml/tasks_lib_test.py
+-rw-r--r--  2.0 unx      793 b- defN 23-Apr-12 18:21 paxml/test_helper.py
+-rw-r--r--  2.0 unx    47710 b- defN 23-Apr-12 18:21 paxml/train.py
+-rw-r--r--  2.0 unx     2070 b- defN 23-Apr-12 18:21 paxml/train_states.py
+-rw-r--r--  2.0 unx    46376 b- defN 23-Apr-12 18:21 paxml/trainer_lib.py
+-rw-r--r--  2.0 unx    34972 b- defN 23-Apr-12 18:21 paxml/tuning_lib.py
+-rw-r--r--  2.0 unx    31238 b- defN 23-Apr-12 18:21 paxml/tuning_lib_test.py
+-rw-r--r--  2.0 unx     7540 b- defN 23-Apr-12 18:21 paxml/contrib/gpu/scripts_gpu/configs.py
+-rw-r--r--  2.0 unx      784 b- defN 23-Apr-12 18:21 paxml/contrib/gpu/scripts_gpu/download_lambada.py
+-rw-r--r--  2.0 unx      777 b- defN 23-Apr-12 18:21 paxml/contrib/gpu/scripts_gpu/download_the_pile.py
+-rw-r--r--  2.0 unx     5881 b- defN 23-Apr-12 18:21 paxml/contrib/gpu/scripts_gpu/tasks.py
+-rw-r--r--  2.0 unx     5431 b- defN 23-Apr-12 18:21 paxml/contrib/gpu/scripts_gpu/tfds_lambada.py
+-rw-r--r--  2.0 unx     7376 b- defN 23-Apr-12 18:21 paxml/contrib/gpu/scripts_gpu/tfds_pile.py
+-rw-r--r--  2.0 unx      597 b- defN 23-Apr-12 18:21 paxml/tasks/lm/__init__.py
+-rw-r--r--  2.0 unx    17202 b- defN 23-Apr-12 18:21 paxml/tasks/lm/input_generator.py
+-rw-r--r--  2.0 unx     4032 b- defN 23-Apr-12 18:21 paxml/tasks/lm/input_generator_test.py
+-rw-r--r--  2.0 unx    35228 b- defN 23-Apr-12 18:21 paxml/tasks/lm/model_params.py
+-rw-r--r--  2.0 unx     6532 b- defN 23-Apr-12 18:21 paxml/tasks/lm/params/bert.py
+-rw-r--r--  2.0 unx    29826 b- defN 23-Apr-12 18:21 paxml/tasks/lm/params/c4.py
+-rw-r--r--  2.0 unx     3612 b- defN 23-Apr-12 18:21 paxml/tasks/lm/params/c4_test.py
+-rw-r--r--  2.0 unx    10315 b- defN 23-Apr-12 18:21 paxml/tasks/lm/params/lm_cloud.py
+-rw-r--r--  2.0 unx     4919 b- defN 23-Apr-12 18:21 paxml/tasks/lm/params/nvidia.py
+-rw-r--r--  2.0 unx     2972 b- defN 23-Apr-12 18:21 paxml/tasks/lm/params/optimal_scaling.py
+-rw-r--r--  2.0 unx     1124 b- defN 23-Apr-12 18:21 paxml/tasks/test/synthetic.py
+-rw-r--r--  2.0 unx     5371 b- defN 23-Apr-12 18:21 paxml/tasks/vision/input_generator.py
+-rw-r--r--  2.0 unx     1611 b- defN 23-Apr-12 18:21 paxml/tasks/vision/input_generator_test.py
+-rw-r--r--  2.0 unx     7002 b- defN 23-Apr-12 18:21 paxml/tasks/vision/resnet_preprocessing.py
+-rw-r--r--  2.0 unx     8792 b- defN 23-Apr-12 18:21 paxml/tasks/vision/params/imagenet_resnets.py
+-rw-r--r--  2.0 unx     7305 b- defN 23-Apr-12 18:21 paxml/tools/dump_hparams.py
+-rw-r--r--  2.0 unx     1590 b- defN 23-Apr-12 18:21 paxml/tools/dump_input_specs.py
+-rw-r--r--  2.0 unx     3834 b- defN 23-Apr-12 18:21 paxml/tools/dump_input_specs_lib.py
+-rw-r--r--  2.0 unx    11357 b- defN 23-Apr-12 18:31 paxml-1.0.0.dist-info/LICENSE
+-rw-r--r--  2.0 unx     1302 b- defN 23-Apr-12 18:31 paxml-1.0.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Apr-12 18:31 paxml-1.0.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx        6 b- defN 23-Apr-12 18:31 paxml-1.0.0.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     6567 b- defN 23-Apr-12 18:31 paxml-1.0.0.dist-info/RECORD
+78 files, 1094302 bytes uncompressed, 279575 bytes compressed:  74.5%
```

## zipnote {}

```diff
@@ -213,23 +213,23 @@
 
 Filename: paxml/tools/dump_input_specs.py
 Comment: 
 
 Filename: paxml/tools/dump_input_specs_lib.py
 Comment: 
 
-Filename: paxml-0.4.0.dist-info/LICENSE
+Filename: paxml-1.0.0.dist-info/LICENSE
 Comment: 
 
-Filename: paxml-0.4.0.dist-info/METADATA
+Filename: paxml-1.0.0.dist-info/METADATA
 Comment: 
 
-Filename: paxml-0.4.0.dist-info/WHEEL
+Filename: paxml-1.0.0.dist-info/WHEEL
 Comment: 
 
-Filename: paxml-0.4.0.dist-info/top_level.txt
+Filename: paxml-1.0.0.dist-info/top_level.txt
 Comment: 
 
-Filename: paxml-0.4.0.dist-info/RECORD
+Filename: paxml-1.0.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## paxml/checkpoint_managers.py

```diff
@@ -45,15 +45,15 @@
 def _get_checkpoint_version(
     checkpoint_type: CheckpointType, directory: epath.Path, step: int
 ) -> float:
   """Gets checkpoint version from saved metadata."""
   checkpoint_step_dir = checkpoints.make_checkpoint_step_dir(
       directory, step, checkpoint_type=checkpoint_type
   )
-  version = 0.0
+  version = 0.
   # Necessary because some checkpoints do not conform to Orbax directory
   # structure. Could rely exclusively on actual version if all checkpoints
   # conformed.
   if checkpoints.metadata_exists(checkpoint_step_dir):
     version = checkpoints.restore_metadata(checkpoint_step_dir)[
         checkpoints.get_version_key()
     ]
@@ -86,15 +86,14 @@
 
   Attributes:
     todelete_subdir: If set, checkpoints to be deleted will be only renamed into
       a subdirectory with the provided string. Otherwise, they will be directly
       deleted from the file system. Useful if checkpoint deletion is time
       consuming. By default, delete the checkpoint assets.
   """
-
   todelete_subdir: Optional[str] = None
 
 
 class _CheckpointManagerImpl(orbax.checkpoint.CheckpointManager):
   """Provides Pax-specific logic for orbax.checkpoint.CheckpointManager.
 
   Pax only supports a single checkpointable item (TrainState) and checkpoints
@@ -124,26 +123,22 @@
     # specific version may impact the checkpoint format, so it must be known in
     # advance of any operations.
     self._directory = epath.Path(directory)
     if self._directory.exists():
       steps = self.all_steps(read=True)
       if steps:
         with concurrent.futures.ThreadPoolExecutor(
-            max_workers=len(steps)
-        ) as pool:
+            max_workers=len(steps)) as pool:
           versions = list(
               pool.map(
                   functools.partial(
                       _get_checkpoint_version,
                       self._checkpoint_type,
-                      self._directory,
-                  ),
-                  steps,
-              )
-          )
+                      self._directory),
+                  steps))
         if not all(v == versions[0] for v in versions):
           raise ValueError('Expected all checkpoints to have the same version.')
         self._version = versions[0]
 
     super().__init__(directory, *args, **kwargs)
     # Set to 1 if not provided or set to 0.
     self._options.save_interval_steps = self._options.save_interval_steps or 1
@@ -159,26 +154,24 @@
 
   def should_save(self, step: int) -> bool:
     """Indicates whether there is a need to save a checkpoint."""
     # Whether to save an on-demand checkpoint due to preemption
     if preemption.reached_preemption_sync_point(step):
       return True
     last_checkpoint_step = (
-        self._last_checkpoint.step if self._last_checkpoint else None
-    )
+        self._last_checkpoint.step if self._last_checkpoint else None)
     # Ensure current step is between the last step and next step (accounting for
     # save interval). The `last_checkpoint_step` may not be initialized, in
     # which case we should save. Otherwise, step must fall on the specified
     # save interval. This condition accounts for the possibility of saving
     # on preemption, in which case we want to maintain the same save period as
     # if preemption had not happened.
     return last_checkpoint_step is None or (
-        last_checkpoint_step < step
-        and step % self._options.save_interval_steps == 0
-    )
+        last_checkpoint_step < step and
+        step % self._options.save_interval_steps == 0)
 
   def _get_save_directory(
       self,
       step: int,
       directory: epath.Path,
       key_name: Optional[str] = None,
       tmp_directory: Optional[epath.Path] = None,
@@ -300,15 +293,15 @@
 
   def restore(
       self,
       step: int,
       train_state: Any,
       train_input_pipeline: Optional[base_input.BaseInput] = None,
       restore_kwargs: Optional[Any] = None,
-  ) -> Any:
+  ) -> Union[Any, Mapping[str, Any]]:
     """See superclass documentation."""
     # Propagate version to CheckpointHandler.
     restore_kwargs = _update_args_with_version(restore_kwargs, self.version)
     items = _create_items_dict_with_metadata(train_state, self.version)
     # Train input checkpoint may not exist if input checkpointing wasn't
     # previously enabled
     if train_input_pipeline and self._train_checkpoint_exists(step):
```

## paxml/checkpoint_managers_test.py

```diff
@@ -56,18 +56,16 @@
       name = f'{CHECKPOINT_PREFIX}{step:08d}'
     results.append(name)
   return results
 
 
 def _actual_checkpoint_filenames(directory: str) -> List[str]:
   return [
-      os.path.basename(v)
-      for v in tf.io.gfile.glob(
-          os.path.join(directory, f'{CHECKPOINT_PREFIX}*')
-      )
+      os.path.basename(v) for v in tf.io.gfile.glob(
+          os.path.join(directory, f'{CHECKPOINT_PREFIX}*'))
   ]
 
 
 def create_train_state(step: int = 0):
   mdl_vars = orbax.checkpoint.test_utils.setup_pytree()
   global_mesh = Mesh(np.asarray(jax.devices()), ('x',))
   axes = jax.sharding.PartitionSpec(
@@ -296,49 +294,44 @@
       (None, CheckpointType.GDA),
       (None, CheckpointType.FLAX),
       (2, CheckpointType.GDA),
       (2, CheckpointType.FLAX),
   )
   def test_save_max_to_keep(self, max_to_keep, checkpoint_type):
     options = checkpoint_managers.CheckpointManagerOptions(
-        save_interval_steps=1000, max_to_keep=max_to_keep
-    )
+        save_interval_steps=1000, max_to_keep=max_to_keep)
     checkpoint_manager = self.create_checkpoint_manager(
-        options, checkpoint_type=checkpoint_type
-    )
+        options, checkpoint_type=checkpoint_type)
     steps = list(range(0, 10000, 1000))
     for step in steps:
       self.save(checkpoint_manager, step, self.train_state)
 
     if max_to_keep is None:
       expected_steps = steps
     else:
       expected_steps = steps[-max_to_keep:]
 
     self.assertSameElements(
         _expected_checkpoint_filenames(
-            expected_steps, checkpoint_type=checkpoint_type
-        ),
-        _actual_checkpoint_filenames(self.directory),
-    )
+            expected_steps, checkpoint_type=checkpoint_type),
+        _actual_checkpoint_filenames(self.directory))
     self.assertSameElements(expected_steps, checkpoint_manager.all_steps())
 
   @parameterized.parameters((CheckpointType.GDA,), (CheckpointType.FLAX,))
   def test_save_checkpoint_keep_interval_timedelta(self, checkpoint_type):
     tz = datetime.timezone.utc
     current_datetime = datetime.datetime.now(tz=tz)
     zero_datetime = datetime.datetime.fromtimestamp(0, tz=tz)
     with mock.patch('datetime.datetime', autospec=True) as dt:
       dt.now.return_value = current_datetime
       dt.fromtimestamp.return_value = zero_datetime
       options = checkpoint_managers.CheckpointManagerOptions(
           save_interval_steps=1000,
           max_to_keep=2,
-          keep_time_interval=datetime.timedelta(hours=2),
-      )
+          keep_time_interval=datetime.timedelta(hours=2))
       checkpoint_manager = self.create_checkpoint_manager(
           options, checkpoint_type=checkpoint_type
       )
 
     steps = list(range(0, 10000, 1000))
     checkpoint_datetimes = []
     for step in steps:
@@ -349,68 +342,59 @@
         checkpoint_datetimes.append(current_datetime)
         current_datetime += datetime.timedelta(hours=1)
 
     saved_steps = [0, 2000, 4000, 6000, 8000, 9000]
 
     self.assertSameElements(
         _expected_checkpoint_filenames(
-            saved_steps, checkpoint_type=checkpoint_type
-        ),
-        _actual_checkpoint_filenames(self.directory),
-    )
+            saved_steps, checkpoint_type=checkpoint_type),
+        _actual_checkpoint_filenames(self.directory))
     self.assertSameElements(saved_steps, checkpoint_manager.all_steps())
 
   @parameterized.parameters((CheckpointType.GDA,), (CheckpointType.FLAX,))
   def test_save_restore_manager_case_1_default(self, checkpoint_type):
     tz = datetime.timezone.utc
     current_datetime = datetime.datetime.now(tz=tz)
     zero_datetime = datetime.datetime.fromtimestamp(0, tz=tz)
 
     options = checkpoint_managers.CheckpointManagerOptions(
-        save_interval_steps=2000, max_to_keep=4
-    )
+        save_interval_steps=2000, max_to_keep=4)
     checkpoint_manager = self.create_checkpoint_manager(
-        options, checkpoint_type=checkpoint_type
-    )
+        options, checkpoint_type=checkpoint_type)
 
     steps = list(range(0, 10000, 1000))
     for step in steps:
       self.save(checkpoint_manager, step, self.train_state)
 
     saved_steps = [2000, 4000, 6000, 8000]
 
     self.assertSameElements(
         _expected_checkpoint_filenames(
-            saved_steps, checkpoint_type=checkpoint_type
-        ),
-        _actual_checkpoint_filenames(self.directory),
-    )
+            saved_steps, checkpoint_type=checkpoint_type),
+        _actual_checkpoint_filenames(self.directory))
     self.assertSameElements(saved_steps, checkpoint_manager.all_steps())
 
     del checkpoint_manager
     with mock.patch('datetime.datetime', autospec=True) as dt:
       dt.now.return_value = current_datetime
       dt.fromtimestamp.return_value = zero_datetime
       options = checkpoint_managers.CheckpointManagerOptions(
           save_interval_steps=3000,
           max_to_keep=6,
-          keep_time_interval=datetime.timedelta(hours=3),
-      )
+          keep_time_interval=datetime.timedelta(hours=3))
       checkpoint_manager = self.create_checkpoint_manager(
           options, checkpoint_type=checkpoint_type
       )
 
     saved_steps_2_init = [2000, 4000, 6000, 8000]
 
     self.assertSameElements(
         _expected_checkpoint_filenames(
-            saved_steps_2_init, checkpoint_type=checkpoint_type
-        ),
-        _actual_checkpoint_filenames(self.directory),
-    )
+            saved_steps_2_init, checkpoint_type=checkpoint_type),
+        _actual_checkpoint_filenames(self.directory))
     self.assertSameElements(saved_steps_2_init, checkpoint_manager.all_steps())
 
     steps_2 = list(range(10000, 20000, 1000))
     for step in steps_2:
       with mock.patch('datetime.datetime', autospec=True) as dt:
         dt.now.return_value = current_datetime
         dt.fromtimestamp.return_value = zero_datetime
@@ -418,87 +402,74 @@
         current_datetime += datetime.timedelta(hours=1)
 
     # expect saved steps at multipliers of 3000.
     saved_steps_2 = saved_steps_2_init + [12000, 15000, 18000]
 
     self.assertSameElements(
         _expected_checkpoint_filenames(
-            saved_steps_2, checkpoint_type=checkpoint_type
-        ),
-        _actual_checkpoint_filenames(self.directory),
-    )
+            saved_steps_2, checkpoint_type=checkpoint_type),
+        _actual_checkpoint_filenames(self.directory))
     self.assertSameElements(saved_steps_2, checkpoint_manager.all_steps())
 
   @parameterized.parameters((CheckpointType.GDA,), (CheckpointType.FLAX,))
   def test_save_restore_manager_case_2_mutant(self, checkpoint_type):
     options = checkpoint_managers.CheckpointManagerOptions(
-        save_interval_steps=100, max_to_keep=None
-    )
+        save_interval_steps=100, max_to_keep=None)
     checkpoint_manager = self.create_checkpoint_manager(
-        options, checkpoint_type=checkpoint_type
-    )
+        options, checkpoint_type=checkpoint_type)
 
     steps = list(range(0, 10000, 1000))
     for step in steps:
       self.save(checkpoint_manager, step, self.train_state)
 
     saved_steps = steps
 
     self.assertSameElements(
         _expected_checkpoint_filenames(
-            saved_steps, checkpoint_type=checkpoint_type
-        ),
-        _actual_checkpoint_filenames(self.directory),
-    )
+            saved_steps, checkpoint_type=checkpoint_type),
+        _actual_checkpoint_filenames(self.directory))
     self.assertSameElements(saved_steps, checkpoint_manager.all_steps())
 
     del checkpoint_manager
     max_to_keep = 5
     options = checkpoint_managers.CheckpointManagerOptions(
-        save_interval_steps=1000, max_to_keep=max_to_keep
-    )
+        save_interval_steps=1000, max_to_keep=max_to_keep)
     checkpoint_manager = self.create_checkpoint_manager(
-        options, checkpoint_type=checkpoint_type
-    )
+        options, checkpoint_type=checkpoint_type)
 
     step = 10000
     steps.append(step)
     self.save(checkpoint_manager, step, self.train_state)
 
     saved_steps_2 = steps[-max_to_keep:]
 
     self.assertSameElements(
         _expected_checkpoint_filenames(
-            saved_steps_2, checkpoint_type=checkpoint_type
-        ),
-        _actual_checkpoint_filenames(self.directory),
-    )
+            saved_steps_2, checkpoint_type=checkpoint_type),
+        _actual_checkpoint_filenames(self.directory))
     self.assertSameElements(saved_steps_2, checkpoint_manager.all_steps())
 
   def test_save_on_preemption(self):
     options = checkpoint_managers.CheckpointManagerOptions(
-        save_interval_steps=1000, max_to_keep=None
-    )
+        save_interval_steps=1000, max_to_keep=None)
     checkpoint_manager = self.create_checkpoint_manager(options)
 
     save_step = 3
     jax.config.update('jax_coordination_service', True)
     multihost_utils.reached_preemption_sync_point = (
-        lambda step_id: step_id == save_step
-    )
+        lambda step_id: step_id == save_step)
 
     for step in range(save_step + 1):
       self.save(checkpoint_manager, step, self.train_state)
 
     saved_steps = [0, save_step]
 
     self.assertSameElements(
         _expected_checkpoint_filenames(saved_steps),
-        _actual_checkpoint_filenames(self.directory),
-    )
+        _actual_checkpoint_filenames(self.directory))
     self.assertSameElements(saved_steps, checkpoint_manager.all_steps())
 
   def test_cleanup(self):
     def _fake_on_commit_callback(*args, **kwargs):
       del args, kwargs
       pass  # Do nothing to simulate failure of finalization.
 
@@ -528,48 +499,42 @@
         _actual_checkpoint_filenames(checkpoint_manager.directory),
     )
     self.assertSameElements([0], checkpoint_manager.all_steps())
 
   @parameterized.parameters((CheckpointType.GDA,), (CheckpointType.FLAX,))
   def test_todelete_subdir(self, checkpoint_type):
     options = checkpoint_managers.CheckpointManagerOptions(
-        max_to_keep=2, todelete_subdir='archive'
-    )
+        max_to_keep=2, todelete_subdir='archive')
     checkpoint_manager = self.create_checkpoint_manager(
-        options, checkpoint_type=checkpoint_type
-    )
+        options, checkpoint_type=checkpoint_type)
 
     for step in range(4):
       self.save(checkpoint_manager, step, self.train_state)
 
     self.assertSameElements(
         _expected_checkpoint_filenames([0, 1], checkpoint_type=checkpoint_type),
-        _actual_checkpoint_filenames(os.path.join(self.directory, 'archive')),
-    )
+        _actual_checkpoint_filenames(os.path.join(self.directory, 'archive')))
     self.assertSameElements(
         _expected_checkpoint_filenames([2, 3], checkpoint_type=checkpoint_type),
-        _actual_checkpoint_filenames(os.path.join(self.directory)),
-    )
+        _actual_checkpoint_filenames(os.path.join(self.directory)))
     self.assertIn('archive', tf.io.gfile.listdir(self.directory))
     self.assertSameElements([2, 3], checkpoint_manager.all_steps())
 
   @parameterized.parameters((CheckpointType.GDA,), (CheckpointType.FLAX,))
   def test_reinitialize(self, checkpoint_type):
     options = checkpoint_managers.CheckpointManagerOptions(max_to_keep=2)
     checkpoint_manager = self.create_checkpoint_manager(
-        options, checkpoint_type=checkpoint_type
-    )
+        options, checkpoint_type=checkpoint_type)
 
     for step in range(3):
       self.save(checkpoint_manager, step, self.train_state)
     self.assertSameElements([1, 2], checkpoint_manager.all_steps())
 
     new_checkpoint_manager = self.create_checkpoint_manager(
-        options, checkpoint_type=checkpoint_type
-    )
+        options, checkpoint_type=checkpoint_type)
     self.assertSameElements([1, 2], new_checkpoint_manager.all_steps())
     self.save(new_checkpoint_manager, 3, self.train_state)
     self.assertSameElements([2, 3], new_checkpoint_manager.all_steps())
 
   @parameterized.parameters((CheckpointType.GDA,), (CheckpointType.FLAX,))
   def test_restore_legacy_format(self, checkpoint_type):
     checkpoint_manager = self.create_checkpoint_manager(
```

## paxml/checkpoints.py

```diff
@@ -38,16 +38,15 @@
 CHECKPOINT_PREFIX = 'checkpoint_'
 STATE_ITEM_NAME = 'state'
 INPUT_ITEM_NAME = 'train_input'
 METADATA_ITEM_NAME = orbax.checkpoint.checkpoint_manager.METADATA_ITEM_NAME
 TMP_PREFIX = 'tmp_'
 CHECKPOINT_PATTERN_RE = re.compile(rf'{CHECKPOINT_PREFIX}[\d]+$')
 TMP_CHECKPOINT_PATTERN_RE = re.compile(
-    rf'{TMP_PREFIX}[\d]+.{CHECKPOINT_PREFIX}[\d]+$'
-)
+    rf'{TMP_PREFIX}[\d]+.{CHECKPOINT_PREFIX}[\d]+$')
 # Large value to disable flax-specific checkpoint management.
 _MAX_CHECKPOINT_FLAX = 1000000
 get_version_key = checkpoint_version.get_version_key
 get_version = checkpoint_version.get_version
 
 JTensorOrPartitionSpec = pytypes.JTensorOrPartitionSpec
 PyTree = Any
@@ -116,15 +115,15 @@
 ) -> Tuple[float, epath.Path]:
   return get_version(), checkpoint_step_dir / STATE_ITEM_NAME
 
 
 def get_version_and_restore_dir(
     checkpoint_step_dir: epath.Path,
 ) -> Tuple[float, epath.Path]:
-  version = 0.0
+  version = 0.
   if metadata_exists(checkpoint_step_dir):
     version = restore_metadata(checkpoint_step_dir)[get_version_key()]
   if version > 0:
     restore_dir = checkpoint_step_dir / STATE_ITEM_NAME
   else:
     restore_dir = checkpoint_step_dir
   return version, restore_dir
@@ -151,16 +150,16 @@
 
 
 def get_step_from_checkpoint_asset(checkpoint_dir: epath.PathLike) -> int:
   checkpoint_dir = epath.Path(checkpoint_dir)
   if _is_gda_version_subdir(checkpoint_dir):
     return int(checkpoint_dir.name)
   if is_tmp_checkpoint_asset(checkpoint_dir):
-    return int(checkpoint_dir.suffix[len(CHECKPOINT_PREFIX) :])
-  return int(checkpoint_dir.stem[len(CHECKPOINT_PREFIX) :])
+    return int(checkpoint_dir.suffix[len(CHECKPOINT_PREFIX):])
+  return int(checkpoint_dir.stem[len(CHECKPOINT_PREFIX):])
 
 
 def maybe_update_checkpoint_type(
     user_specified_type: CheckpointType,
     checkpoint_path_with_step: epath.Path,
 ) -> CheckpointType:
   """Returns the GDA checkpoint type that matches the provided path.
@@ -177,16 +176,16 @@
     return user_specified_type
   if _is_gda_version_subdir(checkpoint_path_with_step):
     return CheckpointType.GDA_VERSION_SUBDIR
   return CheckpointType.GDA
 
 
 def retrieve_checkpoint_type(
-    maybe_use_persistence_checkpointing, task_p: base_task.BaseTask.HParams
-) -> CheckpointType:
+    maybe_use_persistence_checkpointing,
+    task_p: base_task.BaseTask.HParams) -> CheckpointType:
   """Retrieves the CheckpointType given the input arguments."""
   using_pjit = task_p.model.mesh_shape is not None  # pytype: disable=attribute-error
   if using_pjit or py_utils.pmap_use_tensorstore():
     if maybe_use_persistence_checkpointing:
       return CheckpointType.PERSISTENCE
     else:
       return CheckpointType.GDA
@@ -233,15 +232,16 @@
       checkpoint_dir, step, checkpoint_type=checkpoint_type
   )
   version, checkpoint_save_dir = get_version_and_save_dir(checkpoint_step_dir)
   if checkpoint_type == CheckpointType.GDA:
     if async_checkpointer is not None:
       async_checkpointer.save(checkpoint_save_dir, train_state, version=version)
     else:
-      checkpointer = orbax.checkpoint.Checkpointer(PaxCheckpointHandler())
+      checkpointer = orbax.checkpoint.Checkpointer(
+          PaxCheckpointHandler())
       checkpointer.save(checkpoint_save_dir, train_state, version=version)
   elif checkpoint_type == CheckpointType.FLAX:
     checkpointer = FlaxCheckpointer(FlaxCheckpointHandler())
     checkpointer.save(
         checkpoint_save_dir, train_state, force=overwrite, version=version
     )
   else:
@@ -267,22 +267,20 @@
       v
       for v in checkpoint_dir.iterdir()
       if is_checkpoint_asset(v) and not is_tmp_checkpoint_asset(v)
   ]
   if not checkpoint_assets:
     return None
   checkpoint_assets = sorted(
-      checkpoint_assets, key=get_step_from_checkpoint_asset
-  )
+      checkpoint_assets, key=get_step_from_checkpoint_asset)
   return checkpoint_dir / checkpoint_assets[-1]
 
 
 def retrieve_latest_checkpoint_step(
-    checkpoint_dir: epath.Path,
-) -> Optional[int]:
+    checkpoint_dir: epath.Path) -> Optional[int]:
   """Retrieves the latest checkpoint step if any.
 
   Note that this broadcasts the checkpoint step from host 0 to ensure that all
   processes get the exact same checkpoint step.
 
   Args:
     checkpoint_dir: The base directory from where to retrieve checkpoints.
@@ -295,19 +293,17 @@
   else:
     latest_checkpoint_path = latest_checkpoint(checkpoint_dir)
     if latest_checkpoint_path is None:
       checkpoint_step = -1
     else:
       checkpoint_step = get_step_from_checkpoint_asset(latest_checkpoint_path)
   np_checkpoint_step = multihost_utils.broadcast_one_to_all(
-      np.array(checkpoint_step)
-  )
-  multihost_utils.assert_equal(
-      np_checkpoint_step, "checkpoint_steps across hosts don't match."
-  )
+      np.array(checkpoint_step))
+  multihost_utils.assert_equal(np_checkpoint_step,
+                               "checkpoint_steps across hosts don't match.")
   step = int(np_checkpoint_step.item())
   if step == -1:
     return None
   return step
 
 
 def restore_checkpoint(
@@ -385,62 +381,54 @@
     return
   orbax.checkpoint.type_handlers.register_standard_handlers_with_options(
       metadata_key=tensorstore_metadata_key
   )
 
 
 def _extract_nested_prefix_names(
-    state: train_states.TrainState,
-) -> train_states.TrainState:
+    state: train_states.TrainState) -> train_states.TrainState:
   """Extracts prefix names from a TrainState data structure."""
   # CNS doesn't support square bracket in filenames.
   key_separator = '.'
   left_separator = '_'
   right_separator = ''
   return train_states.TrainState(
       step=py_utils.extract_prefixed_keys_from_nested_map(
           state.step,
           'step',
           key_separator=key_separator,
           left_separator=left_separator,
-          right_separator=right_separator,
-      ),
+          right_separator=right_separator),
       mdl_vars=py_utils.extract_prefixed_keys_from_nested_map(
           state.mdl_vars,
           'mdl_vars',
           key_separator=key_separator,
           left_separator=left_separator,
-          right_separator=right_separator,
-      ),
+          right_separator=right_separator),
       opt_states=py_utils.extract_prefixed_keys_from_nested_map(
           state.opt_states,
           'opt_states',
           key_separator=key_separator,
           left_separator=left_separator,
           right_separator=right_separator,
-          is_leaf=py_utils.is_optax_masked_node,
-      ),
-  )
+          is_leaf=py_utils.is_optax_masked_node))
 
 
 def _masked_node_to_none(mask: Any, value: Any) -> Any:
   """Return value when `mask` is not a MaskedNode, or MaskedNode otherwise."""
   if py_utils.is_optax_masked_node(mask):
     return optax.MaskedNode()
   return value
 
 
 def _tensorstore_prepare(
     train_state: train_states.TrainState,
-    state_specs: Optional[train_states.TrainState] = None,
-) -> Tuple[
-    Sequence[JTensorOrPartitionSpec],
-    Sequence[str],
-    Optional[Sequence[JTensorOrPartitionSpec]],
-]:
+    state_specs: Optional[train_states.TrainState] = None
+) -> Tuple[Sequence[JTensorOrPartitionSpec], Sequence[str],
+           Optional[Sequence[JTensorOrPartitionSpec]]]:
   """Prepares data prior to saving/restoring it from/to TensorStore.
 
   Args:
     train_state: A partitioned train_state that is a Pytree of
       GlobalDeviceArray.
     state_specs: [optional] The partition specs corresponding to this TrainState
       instance, when it is used for checkpoint restoring.
@@ -463,16 +451,15 @@
       is_leaf=py_utils.is_optax_masked_node,
   )
   if state_specs is not None:
     state_specs_none = jax.tree_map(
         _masked_node_to_none,
         train_state,
         state_specs,
-        is_leaf=py_utils.is_optax_masked_node,
-    )
+        is_leaf=py_utils.is_optax_masked_node)
   # ... that are filtered out when calling jax.tree_util.tree_flatten() here.
   flattened_train_state, _ = jax.tree_util.tree_flatten(train_state_none)
   if state_specs is not None:
     flattened_state_specs, _ = jax.tree_util.tree_flatten(state_specs_none)
   else:
     flattened_state_specs = None
 
@@ -482,15 +469,15 @@
   # ... that are filtered out when calling jax.tree_util.tree_flatten() here.
   flattened_nested_names, _ = jax.tree_util.tree_flatten(nested_names)
   return flattened_train_state, flattened_nested_names, flattened_state_specs
 
 
 def _tensorstore_reconstruct(
     state_global_shapes: train_states.TrainState,
-    restored_train_state: Sequence[JTensorOrPartitionSpec],
+    restored_train_state: Sequence[JTensorOrPartitionSpec]
 ) -> train_states.TrainState:
   """Reconstructs a nested train state including MaskedNode.
 
   Args:
     state_global_shapes: The original nested train state with GDAs, which
       includes MaskedNode entries.
     restored_train_state: A flattened version of the restored train state, which
@@ -499,16 +486,15 @@
   Returns:
     A nested version of `restored_train_state` after adding back the MaskedNode
     instances, based on the original structure of `state_global_shapes`.
   """
   c = 0
   restored_flattened_train_state = []
   flattened_state_global_shapes, treedef = jax.tree_util.tree_flatten(
-      state_global_shapes
-  )
+      state_global_shapes)
   for l in flattened_state_global_shapes:
     if py_utils.is_optax_masked_node(l):
       restored_flattened_train_state.append(optax.MaskedNode())
     else:
       restored_flattened_train_state.append(restored_train_state[c])
       c += 1
   assert c == len(restored_train_state)
@@ -550,58 +536,50 @@
 
   def _set_param_names(self, param_names: PyTree):
     self._param_names = param_names
 
   def _get_param_names(self, item: PyTree) -> PyTree:
     return self._param_names
 
-  async def _write_aggregate_file(
-      self,
-      directory: epath.Path,
-      item: PyTree,
-      param_infos: PyTree,
-      save_args: PyTree,
-  ):
+  async def _write_aggregate_file(self, directory: epath.Path, item: PyTree,
+                                  param_infos: PyTree, save_args: PyTree):
     """Skip writing msgpack file for Pax since this file would be unused."""
     pass
 
   async def async_save(
       self,
       directory: epath.Path,
       item: PyTree,
       save_args: Optional[PyTree] = None,
       version: Optional[float] = None,
   ) -> Any:
     """Filters optax.MaskedNode before calling superclass async_save."""
     if version is None:
       raise ValueError('Expected version for saving.')
     flattened_train_state, flattened_nested_names, _ = _tensorstore_prepare(
-        item
-    )
+        item)
     # At that point, the flattened entries do not contain any reference to
     # MaskedNode's.
     self._set_param_names(flattened_nested_names)
     return await super().async_save(
-        directory, flattened_train_state, save_args=save_args
-    )
+        directory, flattened_train_state, save_args=save_args)
 
   def restore(
       self,
       directory: epath.Path,
       item: Optional[PyTree] = None,
       specs: Optional[PyTree] = None,
       mesh: Optional[jax.sharding.Mesh] = None,
       version: Optional[float] = None,
   ) -> PyTree:
     """Restores by filtering optax.MaskedNode and adding it back after calling superclass restore."""
     if version is None:
       raise ValueError('Expected version for restoration.')
     flattened_train_state, flattened_nested_names, flattened_state_specs = (
-        _tensorstore_prepare(item, specs)
-    )
+        _tensorstore_prepare(item, specs))
     # At that point, the flattened entries do not contain any reference to
     # MaskedNode's.
     self._set_param_names(flattened_nested_names)
 
     def create_restore_args(pspec, shape_struct):
       # Providing `None` indicates that the shape should be restored exactly as
       # saved.
@@ -612,36 +590,33 @@
           restore_type=jax.Array,
           mesh=mesh,
           mesh_axes=pspec,
           global_shape=restore_shape,
           dtype=shape_struct.dtype,
       )
 
-    restore_args = jax.tree_map(
-        create_restore_args, flattened_state_specs, flattened_train_state
-    )
+    restore_args = jax.tree_map(create_restore_args, flattened_state_specs,
+                                flattened_train_state)
 
     # Consequently, we restore the checkpoint that does not contain any
     # reference to MaskedNode's.
     restored_train_state = super().restore(
-        directory, item=flattened_train_state, restore_args=restore_args
-    )
+        directory, item=flattened_train_state, restore_args=restore_args)
     if self._enforce_restore_shape_check:
       _check_restored_shapes(restored_train_state, flattened_train_state)
 
     # We add back the MaskedNode entries into the pytree.
     restored_train_state = _tensorstore_reconstruct(item, restored_train_state)
 
     return restored_train_state
 
   def structure(self, directory: epath.Path) -> PyTree:
     return jax.tree_util.tree_map(
         orbax.checkpoint.utils.leaf_placeholder,
-        flax.serialization.to_state_dict(self._param_names),
-    )
+        flax.serialization.to_state_dict(self._param_names))
 
 
 class FlaxCheckpointHandler(orbax.checkpoint.PyTreeCheckpointHandler):
   """Override to process checkpoints in Flax format.
 
   Should only be used in conjunction with FlaxCheckpointer.
   """
@@ -762,15 +737,17 @@
       item: a BaseInput to be saved, which must have save() implemented.
     """
     checkpoint_path = (
         directory / f'process_{jax.process_index()}-of-{jax.process_count()}'
     )
     item.save(checkpoint_path)
 
-  def restore(self, directory: epath.Path, item: Any = None) -> None:
+  def restore(
+      self, directory: epath.Path, item: Any = None
+  ) -> None:
     """Restores the given item.
 
     Args:
       directory: restore location directory.
       item: a BaseInput to be restored, which must have restore() implemented.
         Not Optional (declared as optional to conform to
         orbax.checkpoint.CheckpointHandler superclass)
```

## paxml/eval_lib.py

```diff
@@ -467,28 +467,27 @@
 
   checkpoint_type = checkpoints.retrieve_checkpoint_type(
       maybe_use_persistence_checkpointing, jax_task.hparams
   )
   reshard_inputs = checkpoint_type != CheckpointType.PERSISTENCE
   partitioner = partitioning.create_partitioner(
       jax_task,
+      prng_key,
+      train_input_specs,
       init_is_eval=True,
       reshard_inputs=reshard_inputs,
       auto_sharding_mode=RunningMode.EVAL if enable_auto_sharding else None,
+      job_log_dir=job_log_dir,
   )
-  input_for_shape = None
   if not task_p.train.always_use_train_for_model_init:
     assert train_input_specs is None
     # TODO(pax-dev): Investigate if we can use model input specs
     # instead of instantiating this input pipeline.
     input_p = partitioner.preprocess_input_params(eval_input_p[0])
-    input_for_shape = instantiate(input_p)
-  partitioner.setup(
-      jax_task, prng_key, train_input_specs, input_for_shape, job_log_dir
-  )
+    partitioner.set_train_inputs_shape_dtype(instantiate(input_p))
 
   checkpointer = _create_checkpointer(
       jax_task,
       job_log_dir,
       checkpoint_type,
       EvaluationMode.EVAL,
       restore_checkpoint_dir=restore_checkpoint_dir,
@@ -655,37 +654,36 @@
 
   checkpoint_type = checkpoints.retrieve_checkpoint_type(
       maybe_use_persistence_checkpointing, jax_task.hparams
   )
   reshard_inputs = checkpoint_type != CheckpointType.PERSISTENCE
   partitioner = partitioning.create_partitioner(
       jax_task,
+      prng_key,
+      train_input_specs,
       init_is_eval=True,
       reshard_inputs=reshard_inputs,
       auto_sharding_mode=RunningMode.DECODE if enable_auto_sharding else None,
+      job_log_dir=job_log_dir,
   )
-  input_for_shape = None
   if not task_p.train.always_use_train_for_model_init:
     assert train_input_specs is None
     # We assume that either eval_input or decoder_input can be used to retrieve
     # all the model variable shapes, which is needed for restoring checkpoints.
     #
     # TODO(zhangqiaorjc): If we can no longer assume variable shapes will be the
     # same regardless of which eval_input or decoder_input we use to draw the
     # sample inputs, we need to revisit the design here.
 
     # TODO(pax-dev): Investigate if we can use model input specs
     # instead of instantiating this input pipeline.
     input_p = partitioner.preprocess_input_params(
         (decoder_inputs + eval_inputs)[0]
     )
-    input_for_shape = instantiate(input_p)
-  partitioner.setup(
-      jax_task, prng_key, train_input_specs, input_for_shape, job_log_dir
-  )
+    partitioner.set_train_inputs_shape_dtype(instantiate(input_p))
 
   checkpointer = _create_checkpointer(
       jax_task,
       job_log_dir,
       checkpoint_type,
       EvaluationMode.DECODE,
       restore_checkpoint_dir,
@@ -1870,26 +1868,26 @@
 
   maybe_use_persistence_checkpointing = False
   checkpoint_type = checkpoints.retrieve_checkpoint_type(
       maybe_use_persistence_checkpointing, task.hparams
   )
   reshard_inputs = checkpoint_type != CheckpointType.PERSISTENCE
   partitioner = partitioning.create_partitioner(
-      task, reshard_inputs=reshard_inputs
+      task,
+      prng_key,
+      train_input_specs,
+      reshard_inputs=reshard_inputs,
+      job_log_dir=job_log_dir,
   )
-  input_for_shape = None
   if not task_p.train.always_use_train_for_model_init:
     assert train_input_specs is None
     # TODO(pax-dev): Investigate if we can use model input specs
     # instead of instantiating this input pipeline.
     input_p = partitioner.preprocess_input_params(inputs_p[0])
-    input_for_shape = instantiate(input_p)
-  partitioner.setup(
-      task, prng_key, train_input_specs, input_for_shape, job_log_dir
-  )
+    partitioner.set_train_inputs_shape_dtype(instantiate(input_p))
 
   checkpointer = _create_checkpointer(
       task,
       job_log_dir,
       checkpoint_type,
       mode=None,
       restore_checkpoint_dir=task_p.infer_writer.restore_checkpoint_dir,
```

## paxml/partitioning.py

```diff
@@ -22,15 +22,14 @@
 from typing import Any, Callable, Dict, Optional, Protocol, Sequence, Tuple
 
 from absl import logging
 from clu import platform
 from etils import epath
 from flax.core import frozen_dict
 import jax
-from jax import core
 from jax import numpy as jnp
 from jax.experimental import pjit
 from paxml import tasks_lib
 from paxml import train_states
 from paxml import trainer_lib
 from praxis import asserts
 from praxis import base_input
@@ -100,15 +99,15 @@
     * The input shardings returned by the auto spmd partitioner.
   """
 
   def _create_aval(x):
     # canonicalize_dtype is necessary to avoid errors like
     # data types are different when compiling and when being called.
     dtype = jax.dtypes.canonicalize_dtype(x.dtype)
-    return core.ShapedArray(x.shape, dtype)
+    return jax.ShapedArray(x.shape, dtype)
 
   inputs_shape_dtype = jax.tree_map(_create_aval, inputs_shape_dtype)
   compiled = step_fn.lower(train_state, step_key, inputs_shape_dtype).compile()
   return compiled, compiled.input_shardings[0]
 
 
 def _remove_input_padding(
@@ -160,29 +159,23 @@
 class Partitioner(metaclass=abc.ABCMeta):
   """Interface for partitioning computations.
 
   Example usage:
 
   ```
   # Create the partitioner.
-  partitioner = create_partitioner()
+  partitioner = create_partitioner(
+      jax_task, init_key, train_inputs_shape_dtype, job_log_dir=job_log_dir)
 
-  # Sets up the partitioner.
-  train_input_pipeline = None
-
-  # [Optional] Use the train input pipeline to get the shape/dtype information
-  # for model.init. Needed only if train_inputs_shape_dtype is not available
-  # (==None) when we call setup below.
+  # [Optional] Set the training input shape/dtype information. Needed only if
+  # train_inputs_shape_dtype is not set when creating the partitioner above.
   train_input_p = ...  # The config for training input pipeline.
   train_input_p = partitioner.preprocess_input_params(train_input_p)
   train_input_pipeline = instantiate(train_input_p)
-
-  partitioner.setup(
-      jax_task, init_key, train_inputs_shape_dtype, train_input_pipeline,
-      job_log_dir)
+  partitioner.set_train_inputs_shape_dtype(train_input_pipeline)
 
   # Restore the train state.
   metadata = partitioner.get_train_state_metadata()
   train_state = restore(metadata, ...)
 
   # Create the PRNG key.
   root_prng_key = ...
@@ -205,81 +198,61 @@
   inputs = partitioner.preprocess_inputs(
       train_input_pipeline, inputs, input_pspec)
   partitioned_step_fn(
       train_state, train_key, inputs, unpadded_global_batch_size)
   ```
   """
 
-  def __init__(self, init_is_eval: bool):
-    """Constructor.
-
-    Args:
-      init_is_eval: Whether it should set is_eval=True when running
-        abstract_init_with_metadata.
-    """
-    # TODO(laigd): remove this option (it should always be False) once
-    # always_use_train_for_model_init is enabled by default.
-    self._init_is_eval = init_is_eval
-
-    # States to set in .setup().
-    self._jax_task = None
-    self._job_log_dir = None
-    self._init_key = None
-    self._train_inputs_shape_dtype = None
-
-    # The train state metadata, set in .get_train_state_metadata().
-    self._train_state_metadata = None
-
-  def setup(
+  def __init__(
       self,
       jax_task: tasks_lib.SingleTask,
       init_key: PRNGKey,
-      train_inputs_shape_dtype: Optional[NestedShapeDtypeLike],
-      # TODO(pax-dev): remove this arg and always use train_inputs_shape_dtype
-      # once all experiments provide input specs.
-      train_input_pipeline: Optional[base_input.BaseInput] = None,
+      train_inputs_shape_dtype: Optional[NestedShapeDtypeLike] = None,
+      init_is_eval: bool = False,
       job_log_dir: Optional[epath.Path] = None,
-  ) -> None:
-    """Sets training shape/dtype using sample inputs from the input pipeline.
+  ):
+    """Constructor.
 
     Args:
       jax_task: The task which is an instance of tasks.SingleTask.
       init_key: PRNGKey for initializing the model variables.
-      train_inputs_shape_dtype: Shape/dtype information of the training inputs
-        to model.init, for use in getting params of model variables. If None,
-        train_input_pipeline must be set.
-      train_input_pipeline: The training input pipeline, used to get the
-        shape/dtype information for model.init. If None,
-        train_inputs_shape_dtype must be set.
+      train_inputs_shape_dtype: Shape/dtype attributes of the training inputs to
+        model.init, for use in getting params of model variables. Can also be
+        set using self.set_train_inputs_shape_dtype() if not provided during
+        construction.
+      init_is_eval: Whether it should set is_eval=True when running
+        abstract_init_with_metadata.
       job_log_dir: Directory for the job logs.
     """
     self._jax_task = jax_task
     self._init_key = init_key
+    self._train_inputs_shape_dtype = train_inputs_shape_dtype
+    # TODO(laigd): remove this option (it should always be False) once
+    # always_use_train_for_model_init is enabled by default.
+    self._init_is_eval = init_is_eval
     self._job_log_dir = job_log_dir
-    if train_inputs_shape_dtype is not None:
-      assert train_input_pipeline is None
-      self._train_inputs_shape_dtype = train_inputs_shape_dtype
-    else:
-      assert train_input_pipeline
-      self._train_inputs_shape_dtype = self._get_train_inputs_shape_dtype(
-          train_input_pipeline
-      )
-
-  @abc.abstractmethod
-  def _get_train_inputs_shape_dtype(
-      self, train_input_pipeline: base_input.BaseInput
-  ) -> NestedShapeDtypeLike:
-    """Get the shape/dtype information for model.init."""
+    self._train_state_metadata = None
 
   @property
   def train_inputs_shape_dtype(self) -> Optional[NestedShapeDtypeLike]:
     """Shape/dtype attributes of the training inputs to model.init."""
-    assert self._train_inputs_shape_dtype
     return self._train_inputs_shape_dtype
 
+  # TODO(pax-dev): remove this method and switch to train_inputs_shape_dtype
+  # provided during construction once all experiments provide input specs.
+  @abc.abstractmethod
+  def set_train_inputs_shape_dtype(
+      self, train_input_pipeline: base_input.BaseInput
+  ) -> None:
+    """Sets training shape/dtype using sample inputs from the input pipeline.
+
+    Args:
+      train_input_pipeline: The training input pipeline.
+    """
+
   @property
   def global_mesh(self) -> Optional[jax.sharding.Mesh]:
     """The global mesh."""
     return None
 
   @abc.abstractmethod
   def preprocess_input_params(
@@ -376,15 +349,18 @@
     if self._jax_task.hparams.train.always_use_train_for_model_init:
       return False
     return self._init_is_eval
 
   def _get_train_state_metadata_default(self) -> TrainStateMetadata:
     """Helper method to get the TrainStateMetadata."""
     if not self._train_inputs_shape_dtype:
-      raise ValueError('Train input spec is not set. It can be set in setup().')
+      raise ValueError(
+          'Training input spec is not set. It can be set either when creating '
+          'the partitioner, or by calling set_train_inputs_shape_dtype().'
+      )
     return trainer_lib.create_train_state_metadata(
         self._jax_task,
         self._train_inputs_shape_dtype,
         discard_opt_states=False,
         do_eval=self._init_do_eval,
     )
 
@@ -483,32 +459,56 @@
       - input_partition_spec: The partition spec for the inputs of the step
         function.
     """
 
 
 class PmapPartitioner(Partitioner):
 
-  def __init__(self, init_is_eval: bool):
-    super().__init__(init_is_eval)
+  def __init__(
+      self,
+      jax_task: tasks_lib.SingleTask,
+      init_key: PRNGKey,
+      train_inputs_shape_dtype: Optional[NestedShapeDtypeLike] = None,
+      init_is_eval: bool = False,
+      job_log_dir: Optional[epath.Path] = None,
+  ):
+    """Constructor.
+
+    Args:
+      jax_task: The task which is an instance of tasks.SingleTask.
+      init_key: PRNGKey for initializing the model variables.
+      train_inputs_shape_dtype: Per-device shape/dtype attributes of the
+        training inputs to model.init, for use in getting params of model
+        variables. Can also be set using self.set_train_inputs_shape_dtype() if
+        not provided during construction.
+      init_is_eval: Whether it should set is_eval=True when running
+        abstract_init_with_metadata.
+      job_log_dir: Directory for the job logs.
+    """
     logging.info('Using pmap for data parallelism.')
+    super().__init__(
+        jax_task, init_key, train_inputs_shape_dtype, init_is_eval, job_log_dir
+    )
 
-  def _get_train_inputs_shape_dtype(
+  def set_train_inputs_shape_dtype(
       self, train_input_pipeline: base_input.BaseInput
-  ) -> NestedShapeDtypeLike:
+  ) -> None:
+    assert (
+        not self._train_inputs_shape_dtype
+    ), 'train_inputs_shape_dtype has been set before.'
     sample_inputs = train_input_pipeline.peek_padded()
     # Reshard inputs and only keep the inputs corresponding to a given device.
     sample_inputs = self.preprocess_inputs(
         train_input_pipeline, sample_inputs, partition_specs=None
     )
-    per_device_shape_dtype = jax.tree_map(
+    self._train_inputs_shape_dtype = jax.tree_map(
         lambda x: jax.ShapeDtypeStruct(shape=x.shape[1:], dtype=x.dtype),
         sample_inputs,
     )
-    _write_input_specs(per_device_shape_dtype, self._job_log_dir)
-    return per_device_shape_dtype
+    _write_input_specs(self._train_inputs_shape_dtype, self._job_log_dir)
 
   def preprocess_input_params(
       self, input_ps: base_input.BaseInput.HParams
   ) -> base_input.BaseInput.HParams:
     """Preprocess input hparam if necessary."""
     return input_ps
 
@@ -620,68 +620,78 @@
 
 
 class PjitPartitioner(Partitioner):
   """Used for partitioning a step function of a SPMD model."""
 
   def __init__(
       self,
-      init_is_eval: bool,
+      jax_task: tasks_lib.SingleTask,
+      init_key: PRNGKey,
       reshard_inputs: bool,
-      task_p: tasks_lib.SingleTask.HParams,
+      train_inputs_shape_dtype: Optional[NestedShapeDtypeLike] = None,
+      init_is_eval: bool = False,
+      job_log_dir: Optional[epath.Path] = None,
   ):
     """Constructor.
 
     Args:
+      jax_task: The task which is an instance of tasks.SingleTask.
+      init_key: PRNGKey for initializing the model variables.
       reshard_inputs: Whether to reshard model inputs before running the
         partitioned function. Only applicable for pjit.
+      train_inputs_shape_dtype: Global shape/dtype attributes of the inputs to
+        model.init, for use in getting params of model variables. This is needed
+        when always_use_train_for_model_init is True.
       init_is_eval: Whether it should set is_eval=True when running
         abstract_init_with_metadata.
-      task_p: The params for the task, needed to create global mesh.
+      job_log_dir: Directory for the job logs.
     """
-    super().__init__(init_is_eval)
-    self._reshard_inputs = reshard_inputs
     logging.info('Using SPMD sharding for model parallelism.')
-
-    # Creates global mesh.
-    model_p = task_p.model
+    super().__init__(
+        jax_task, init_key, train_inputs_shape_dtype, init_is_eval, job_log_dir
+    )
+    self._reshard_inputs = reshard_inputs
+    model_p = jax_task.hparams.model
     self._mesh_names = model_p.mesh_axis_names
+
+    # Create global mesh.
     device_mesh = py_utils.create_device_mesh(
         model_p.ici_mesh_shape,
         model_p.dcn_mesh_shape,
         contiguous_submeshes=model_p.contiguous_submeshes,
     )
     logging.info('device_mesh: %s', device_mesh)
     self._global_mesh = jax.sharding.Mesh(device_mesh, model_p.mesh_axis_names)
 
-    # Pjit'ed function to preprocess the prng key.
     self._broadcast_key_fn = None
 
-  def _get_train_inputs_shape_dtype(
+  def set_train_inputs_shape_dtype(
       self, train_input_pipeline: base_input.BaseInput
-  ) -> NestedShapeDtypeLike:
+  ) -> None:
+    assert (
+        not self._train_inputs_shape_dtype
+    ), 'train_inputs_shape_dtype has been set before.'
     sample_inputs = train_input_pipeline.peek_padded()
-    global_shape_dtype = jax.tree_map(
+    self._train_inputs_shape_dtype = jax.tree_map(
         py_utils.get_global_input_shape_dtype, sample_inputs
     )
     perhost_inputs_shape_dtype = jax.tree_map(
         lambda x: jax.ShapeDtypeStruct(shape=x.shape, dtype=x.dtype),
         sample_inputs,
     )
     _write_input_specs(perhost_inputs_shape_dtype, self._job_log_dir)
-    return global_shape_dtype
 
   @property
   def global_mesh(self) -> jax.sharding.Mesh:
     return self._global_mesh
 
   def preprocess_input_params(
       self, input_ps: base_input.BaseInput.HParams
   ) -> base_input.BaseInput.HParams:
     """Preprocess input hparam if necessary."""
-    assert self.global_mesh
     return trainer_lib.adjust_input_params_for_small_batch(
         input_ps, self.global_mesh
     )
 
   def initialize_prng_key_and_train_state(
       self,
       root_prng_key: PRNGKey,
@@ -1055,51 +1065,61 @@
     input_partition_spec: NestedPartitionSpec
 
     # Shape/dtype information for the inputs to partitioned_step_fn.
     inputs_shape_dtype: NestedShapeDtypeLike
 
   def __init__(
       self,
-      init_is_eval: bool,
+      jax_task: tasks_lib.SingleTask,
+      init_key: PRNGKey,
       reshard_inputs: bool,
-      task_p: tasks_lib.SingleTask.HParams,
       auto_sharding_info: AutoShardingInfo,
+      train_inputs_shape_dtype: Optional[NestedShapeDtypeLike] = None,
+      init_is_eval: bool = False,
+      job_log_dir: Optional[epath.Path] = None,
   ):
     """Constructor.
 
     Args:
-      init_is_eval: Whether it should set is_eval=True when running
-        abstract_init_with_metadata.
+      jax_task: The task which is an instance of tasks.SingleTask.
+      init_key: PRNGKey for initializing the model variables.
       reshard_inputs: Whether to reshard model inputs before running the
         partitioned function. Only applicable for pjit.
-      task_p: The params for the task, needed to create global mesh.
       auto_sharding_info: Information used for XLA auto-sharding. If None, it'll
         use the sharding information provided by the model config instead.
+      train_inputs_shape_dtype: Shape/dtype attributes of the inputs to
+        model.init, for use in getting params of model variables. This is needed
+        when always_use_train_for_model_init is True.
+      init_is_eval: Whether it should set is_eval=True when running
+        abstract_init_with_metadata.
+      job_log_dir: Directory for the job logs.
     """
-    super().__init__(init_is_eval, reshard_inputs, task_p)
+    super().__init__(
+        jax_task,
+        init_key,
+        reshard_inputs,
+        train_inputs_shape_dtype,
+        init_is_eval,
+        job_log_dir,
+    )
     self._auto_sharding_info = auto_sharding_info
     self._auto_sharding_result = None  # Used to cache auto-sharding results.
 
-  def _get_train_inputs_shape_dtype(
-      self, train_input_pipeline: base_input.BaseInput
-  ) -> NestedShapeDtypeLike:
-    global_shape_dtype = super()._get_train_inputs_shape_dtype(
-        train_input_pipeline
-    )
+  def set_train_inputs_shape_dtype(self, train_input_pipeline: Any):
+    super().set_train_inputs_shape_dtype(train_input_pipeline)
     # Extra checking in auto sharding case.
     train_input_p = train_input_pipeline.hparams
     if train_input_p.num_infeed_hosts < jax.process_count() or (
         train_input_p.cls.get_batch_size(train_input_p)
         < jax.local_device_count()
     ):
       raise NotImplementedError(
           'Per-device batch size < 1 not supported for auto sharding.'
       )
     logging.info('Auto sharding is enabled in PAX.')
-    return global_shape_dtype
 
   def _partition_auto_shard(
       self,
       step_fn: Partitioner.PartitionedStepFn,
       is_eval: bool,
       inputs_shape_dtype: NestedShapeDtypeLike,
       input_partition_spec: NestedPartitionSpec,
@@ -1262,43 +1282,68 @@
     step_fn = trainer_lib._decode_step_for_partitioner
 
   return step_fn, is_eval
 
 
 def create_partitioner(
     jax_task: tasks_lib.SingleTask,
+    init_key: PRNGKey,
+    train_inputs_shape_dtype: Optional[NestedShapeDtypeLike] = None,
     init_is_eval: bool = False,
     reshard_inputs: bool = False,
     auto_sharding_mode: Optional[RunningMode] = None,
+    job_log_dir: Optional[epath.Path] = None,
 ) -> Partitioner:
   """Return sharded train/eval/decode step function of the SPMD Model.
 
   Args:
     jax_task: The task which is an instance of tasks.SingleTask.
+    init_key: PRNGKey for initializing the model variables.
+    train_inputs_shape_dtype: Shape/dtype attributes of the inputs to
+      model.init, for use in getting params of model variables.
     init_is_eval: Whether it should set is_eval=True when running
       abstract_init_with_metadata.
     reshard_inputs: Whether to reshard model inputs before running the
       partitioned function. Only applicable for pjit.
     auto_sharding_mode: One of TRAIN, EVAL, and DECODE, that determines the step
       function to use for auto-sharding (when pjit is used). If None, it means
       to disable auto-sharding.
+    job_log_dir: Directory for the job logs.
 
   Returns:
     A Partitioner instance.
   """
   if jax_task.hparams.model.ici_mesh_shape is None:
-    partitioner = PmapPartitioner(init_is_eval)
+    partitioner = PmapPartitioner(
+        jax_task,
+        init_key,
+        train_inputs_shape_dtype,
+        init_is_eval,
+        job_log_dir,
+    )
   else:
     auto_sharding_info = None
-    task_p = jax_task.hparams
     if auto_sharding_mode:
       step_fn, step_fn_is_eval = get_step_fn(auto_sharding_mode)
       replicate_output = auto_sharding_mode == RunningMode.DECODE
       auto_sharding_info = AutoShardingPjitPartitioner.AutoShardingInfo(
           step_fn, step_fn_is_eval, replicate_output
       )
       partitioner = AutoShardingPjitPartitioner(
-          init_is_eval, reshard_inputs, task_p, auto_sharding_info
+          jax_task,
+          init_key,
+          reshard_inputs,
+          auto_sharding_info,
+          train_inputs_shape_dtype,
+          init_is_eval,
+          job_log_dir,
       )
     else:
-      partitioner = PjitPartitioner(init_is_eval, reshard_inputs, task_p)
+      partitioner = PjitPartitioner(
+          jax_task,
+          init_key,
+          reshard_inputs,
+          train_inputs_shape_dtype,
+          init_is_eval,
+          job_log_dir,
+      )
   return partitioner
```

## paxml/programs_test.py

```diff
@@ -124,17 +124,20 @@
 
   def test_train_program(self):
     inputs_shape_dtype = jax.tree_map(
         lambda x: jax.ShapeDtypeStruct(shape=x.shape, dtype=x.dtype),
         self.train_input.get_next(),
     )
     partitioner = partitioning.PjitPartitioner(
-        init_is_eval=False, reshard_inputs=True, task_p=self.task.hparams
+        self.task,
+        jax.random.PRNGKey(0),
+        reshard_inputs=True,
+        train_inputs_shape_dtype=inputs_shape_dtype,
+        init_is_eval=False,
     )
-    partitioner.setup(self.task, jax.random.PRNGKey(0), inputs_shape_dtype)
     train_pg = programs.SingleTaskTrainProgram(
         self.task, self.train_input, partitioner
     )
     self.assertEqual(2, train_pg.train_unpadded_global_batch_size)
 
 
 if __name__ == '__main__':
```

## paxml/seqio_input.py

```diff
@@ -689,25 +689,17 @@
     self.is_targets_init = True
 
   def save(self, checkpoint_path: epath.PathLike):
     self._ckpt = tf.train.Checkpoint(it=self._iter)
     self._ckpt.write(checkpoint_path)
 
   def restore(self, checkpoint_path: epath.PathLike):
-    self._peek = None
     self._ckpt = tf.train.Checkpoint(it=self._iter)
     self._ckpt.read(checkpoint_path).assert_consumed()
 
-  def get_state(self) -> bytes:
-    return self._iter._save().numpy()  # pylint: disable=protected-access
-
-  def set_state(self, state: bytes) -> None:
-    self._peek = None
-    self._iter._restore(state)  # pylint: disable=protected-access
-
   def get_next(self) -> NestedNpTensor:  # pytype: disable=signature-mismatch  # jax-ndarray
     return next(self._iter)
 
   def reset(self) -> None:
     self._iter = self._dataset.as_numpy_iterator()
 
   def _get_vocab(self, key) -> seqio.Vocabulary:
```

## paxml/seqio_input_test.py

```diff
@@ -308,24 +308,19 @@
         np.array([[0., 0., 0., 0., 0., 0.], [0., 0., 0., 1., 1., 1.]],
                  dtype=np.float32))
     # training data is repeated.
     for _ in range(5):
       inp.get_next()
 
   # TODO(b/272314337): enable after the next TF OSS release.
-  def test_file_based_checkpointing(self):
-    it = tf.data.Dataset.range(1).as_numpy_iterator()
-    if not isinstance(it, tf.__internal__.tracking.Trackable):
-      # TODO(b/272314337): enable after the next TF OSS release.
-      self.skipTest('file-based iterator checkpointing is not supported')
-
+  def disable_test_checkpointing(self):
     ckpt_dir = self.create_tempdir(name='checkpointing_test').full_path
     ckpt_path = ckpt_dir + '/checkpoint'
 
-    name = 'checkpointing_files'
+    name = 'checkpointing'
     x = [{
         'targets': [7, 8, 5, 6, 9],
     }, {
         'targets': [18, 14]
     }, {
         'targets': [21, 22, 23]
     }]
@@ -354,56 +349,14 @@
         np.array([[0, 21, 22, 23, 1, 0]], dtype=np.int32))
     inp.restore(ckpt_path)
     batch = inp.get_next()
     self.assertArraysEqual(
         batch.ids,
         np.array([[0, 21, 22, 23, 1, 0]], dtype=np.int32))
 
-  def test_byte_array_based_checkpointing(self):
-    it = tf.data.Dataset.range(1).as_numpy_iterator()
-    if not hasattr(it, '_save'):
-      # TODO(b/272314337): enable after the next TF OSS release.
-      self.skipTest('byte-based iterator checkpointing is not supported')
-    name = 'checkpointing_bytes'
-    x = [{
-        'targets': [7, 8, 5, 6, 9],
-    }, {
-        'targets': [18, 14]
-    }, {
-        'targets': [21, 22, 23]
-    }]
-    ds = seqio.test_utils.create_default_dataset(x, ['targets'])
-    _register_task(name, ds, output_feature_names=['targets'])
-
-    p = seqio_input.SeqIOInput.HParams()
-    p.mixture_name = name
-    p.split_name = 'train'
-    p.task_feature_lengths = {'targets': 6}
-    p.feature_converter = seqio_input.LanguageModelFeatures(pack=False)
-    p.batch_size = 1
-    inp = instantiate(p)
-    batch = inp.get_next()
-    self.assertArraysEqual(
-        batch.ids,
-        np.array([[0, 7, 8, 5, 6, 9]], dtype=np.int32))
-    batch = inp.get_next()
-    self.assertArraysEqual(
-        batch.ids,
-        np.array([[0, 18, 14, 1, 0, 0]], dtype=np.int32))
-    state = inp.get_state()
-    batch = inp.get_next()
-    self.assertArraysEqual(
-        batch.ids,
-        np.array([[0, 21, 22, 23, 1, 0]], dtype=np.int32))
-    inp.set_state(state)
-    batch = inp.get_next()
-    self.assertArraysEqual(
-        batch.ids,
-        np.array([[0, 21, 22, 23, 1, 0]], dtype=np.int32))
-
   def test_input_targets_only_pack(self):
     name = 'target_only_pack'
     x = [{
         'targets': [7, 6, 9],
     }, {
         'targets': [18, 14]
     }, {
@@ -756,14 +709,15 @@
       enum_id = py_utils.get_enumeration_id(ex)
       ex.update({'scores': scores[i]})
       eval_output.append((enum_id, ex))
     m = inp.compute_metrics_eval(eval_output)
     self.assertLen(m, 1)
     self.assertEqual(m[0]['total_score'], 3.5)
 
+
   def _setup_seqio_test_registry(self,
                                  num_examples=10,
                                  task_feature_lengths=None):
     if not task_feature_lengths:
       task_feature_lengths = {'inputs': 1024, 'targets': 256}
 
     output_features = {
```

## paxml/train.py

```diff
@@ -55,15 +55,15 @@
 Checkpointer = checkpoints.Checkpointer
 CheckpointType = checkpoints.CheckpointType
 instantiate = base_hyperparams.instantiate
 NestedShapeDtypeLike = pytypes.NestedShapeDtypeLike
 FlaxCheckpointer = checkpoints.FlaxCheckpointer
 FlaxCheckpointHandler = checkpoints.FlaxCheckpointHandler
 PaxCheckpointHandler = checkpoints.PaxCheckpointHandler
-# alias to internal checkpointer
+AsyncPersistenceCheckpointer = checkpoints.AsyncCheckpointer  # mapped to internal
 BaseInputCheckpointHandler = checkpoints.BaseInputCheckpointHandler
 PRNGKey = pytypes.PRNGKey
 RunningMode = trainer_lib.RunningMode
 SummaryWriter = tf.summary.SummaryWriter
 TrainState = train_states.TrainState
 
 PARAMS = base_layer.PARAMS
@@ -84,16 +84,15 @@
     checkpoint_dir.mkdir(parents=True, exist_ok=True)
   # Block all hosts until directory is ready.
   py_utils.sync_global_devices(f'checkpointer:makedirs:{checkpoint_dir}')
   return checkpoint_dir
 
 
 def _parse_duration(
-    duration_str: Optional[str],
-) -> Optional[datetime.timedelta]:
+    duration_str: Optional[str]) -> Optional[datetime.timedelta]:
   """Parses a duration string and returns the datetime.timedelta instance.
 
   Args:
     duration_str: A string representing a duration or None. Either (a) an
       integer, the implicit unit being the second, (b) an integer followed by
       's', e.g. '30s', the unit being the second, (c) an integer followed by
       'm', e.g. '15m', the unit being the minute, (d) an integer followed by
@@ -104,19 +103,16 @@
     The corresponding duration as a datetime.timedelta instance or None if the
     input was None.
   """
   if not duration_str:
     return None
   pattern = re.compile(r'(\d+)(\w)*')
   match = pattern.match(duration_str)
-  if (
-      not match
-      or len(match.groups()) != 2
-      or match.group(2) not in {None, 's', 'm', 'h', 'd'}
-  ):
+  if (not match or len(match.groups()) != 2 or
+      match.group(2) not in {None, 's', 'm', 'h', 'd'}):
     raise ValueError(f'Unable to parse string duration `{duration_str}`.')
   int_value = int(match.group(1))
   if match.group(2) is None or match.group(2) == 's':
     pass
   elif match.group(2) == 'm':
     int_value *= 60
   elif match.group(2) == 'h':
@@ -214,17 +210,16 @@
     with py_utils.timeit() as save_period:
       self.checkpoint_manager.save(
           step_i,
           partitioned_train_state,
           train_input_pipeline,
           force=force,
       )
-    monitoring.record_event_duration_secs(
-        _WRITE_CHECKPOINT_EVENT, save_period.elapsed
-    )
+    monitoring.record_event_duration_secs(_WRITE_CHECKPOINT_EVENT,
+                                          save_period.elapsed)
 
   def _restore_with_args(
       self,
       step_i,
       train_state_global_shapes,
       global_mesh,
       train_state_pspecs,
@@ -232,15 +227,15 @@
   ):
     restore_args = {}
     if self._checkpoint_type == CheckpointType.GDA:
       restore_args = {'specs': train_state_pspecs, 'mesh': global_mesh}
     elif self._checkpoint_type == CheckpointType.PERSISTENCE:
       restore_args = {
           'state_specs': train_state_pspecs,
-          'global_mesh': global_mesh,
+          'global_mesh': global_mesh
       }
     return self.checkpoint_manager.restore(
         step_i,
         train_state_global_shapes,
         train_input_pipeline,
         restore_kwargs=restore_args,
     )
@@ -297,17 +292,16 @@
         partitioned_train_state = self._restore_with_args(
             step,
             metadata.padded_global_shapes,
             partitioner.global_mesh,
             metadata.partition_specs,
             train_input_pipeline,
         )
-      monitoring.record_event_duration_secs(
-          _READ_CHECKPOINT_EVENT, restore_period.elapsed
-      )
+      monitoring.record_event_duration_secs(_READ_CHECKPOINT_EVENT,
+                                            restore_period.elapsed)
 
     root_prng_key, partitioned_train_state = (
         partitioner.initialize_prng_key_and_train_state(
             root_prng_key,
             partitioned_train_state,
             self.checkpoint_type,
         )
@@ -368,30 +362,17 @@
       fully_replicated_state_specs = jax.tree_map(
           _get_spec, train_state_global_shapes
       )
       restore_args = {
           'specs': fully_replicated_state_specs,
           'mesh': global_mesh,
       }
-    restored_state = self.checkpoint_manager.restore(
-        step_i,
-        train_state_global_shapes,
-        train_input_pipeline=train_input_pipeline,
-        restore_kwargs=restore_args,
+    return self.checkpoint_manager.restore(
+        step_i, train_state_global_shapes, restore_kwargs=restore_args
     )
-    if not py_utils.pmap_use_tensorstore():
-      return restored_state
-    if self._checkpoint_type == CheckpointType.PERSISTENCE:
-      return jax.tree_map(
-          py_utils.convert_fully_replicated_array_to_pmap_array,
-          restored_state,
-      )
-    # model_states is jax.Array; we convert back to DA or jax.Array with
-    # single device sharding for pmap.
-    return jax.tree_map(lambda x: x.addressable_data(0), restored_state)
 
   # TODO(laigd): merge this with _PmapEvalCheckpointer.get_model_states().
   def get_model_states(
       self,
       partitioner: partitioning.Partitioner,
       metadata: trainer_lib.TrainStateMetadata,
       root_prng_key: PRNGKey,
@@ -402,17 +383,16 @@
       step = self.checkpoint_manager.latest_step()
       if step is None:
         train_state = None
       else:
         train_state = self._restore_with_args(
             step, train_state_global_shapes, train_input_pipeline
         )
-    monitoring.record_event_duration_secs(
-        _READ_CHECKPOINT_EVENT, restore_period.elapsed
-    )
+    monitoring.record_event_duration_secs(_READ_CHECKPOINT_EVENT,
+                                          restore_period.elapsed)
 
     # TODO(laigd): move the logic below outside of get_model_states.
     root_prng_key, replicated_train_state = (
         partitioner.initialize_prng_key_and_train_state(
             root_prng_key, train_state, self.checkpoint_type
         )
     )
@@ -445,40 +425,37 @@
       is_final=False,
   ):
     if not self._enable_checkpoint_saving:
       return
 
     with py_utils.timeit() as save_period:
       if py_utils.pmap_use_tensorstore():
-        logging.info(
-            'Saving a ckpt at %sstep: %d', 'final ' if is_final else '', step_i
-        )
+        logging.info('Saving a ckpt at %sstep: %d',
+                     'final ' if is_final else '', step_i)
         fully_replicated_gda_train_state = jax.tree_map(
             py_utils.convert_host_local_array_to_global_array,
             partitioned_train_state,
         )
         self._save_with_args(
             step_i,
             train_state=fully_replicated_gda_train_state,
             train_input_pipeline=train_input_pipeline,
             force=is_final,
         )
       else:
-        unreplicated_train_state = jax.tree_map(
-            lambda x: x[0], partitioned_train_state
-        )
+        unreplicated_train_state = jax.tree_map(lambda x: x[0],
+                                                partitioned_train_state)
         self._save_with_args(
             step_i,
             train_state=unreplicated_train_state,
             train_input_pipeline=train_input_pipeline,
             force=is_final,
         )
-    monitoring.record_event_duration_secs(
-        _WRITE_CHECKPOINT_EVENT, save_period.elapsed
-    )
+    monitoring.record_event_duration_secs(_WRITE_CHECKPOINT_EVENT,
+                                          save_period.elapsed)
 
   def save_if_needed(
       self,
       step_i,
       partitioned_train_state,
       train_state_pspecs,
       train_input_pipeline=None,
@@ -537,15 +514,17 @@
       todelete_subdir=todelete_subdir,
   )
 
   if checkpoint_type == CheckpointType.FLAX:
     checkpointer = FlaxCheckpointer(FlaxCheckpointHandler())
   elif enable_async_checkpointing:
     if maybe_use_persistence_checkpointing:
-      raise NotImplementedError('Persistence checkpointer not supported.')
+      checkpointer = AsyncPersistenceCheckpointer(
+          timeout_secs=600,
+          enforce_restore_shape_check=enforce_restore_shape_check)
     else:
       checkpointer = checkpoints.AsyncCheckpointer(
           checkpoints.PaxCheckpointHandler(
               enforce_restore_shape_check=enforce_restore_shape_check
           ),
           timeout_secs=600,
       )
@@ -559,18 +538,17 @@
     elif checkpoint_type == CheckpointType.PERSISTENCE:
       raise ValueError('Checkpointer must already be initialized.')
     else:
       raise ValueError(f'Unsupported Orbax checkpoint type: {checkpoint_type}')
 
   train_input_checkpointer = None
   if train_p.enable_input_checkpointing:
-    if (
-        hasattr(train_input_p, 'deterministic_input')
-        and train_input_p.deterministic_input
-    ):
+    # TODO(gaoi): add more accurate check for deterministic SeqIO input
+    # by instantiating train_input_p (pending cl/515397058)
+    if hasattr(train_input_p, 'deterministic_input_start_index'):
       raise ValueError(
           'Checkpointing deterministic Seqio inputs is not supported via Orbax'
           ' (will be checkpointed independently). Please set'
           ' enable_input_checkpointing=False.'
       )
     train_input_checkpointer = checkpoints.BaseInputCheckpointHandler()
   checkpoint_manager = checkpoint_managers.OrbaxCheckpointManager(
@@ -581,42 +559,38 @@
       checkpoint_type=checkpoint_type,
   )
 
   if task_p.model.ici_mesh_shape is not None:
     checkpointer = _OrbaxPjitTrainingCheckpointer(
         checkpoint_manager,
         checkpoint_type,
-        enable_checkpoint_saving=enable_checkpoint_saving,
-    )
+        enable_checkpoint_saving=enable_checkpoint_saving)
   else:
     checkpointer = _OrbaxPmapTrainingCheckpointer(
         job_log_dir,
         checkpoint_manager,
         checkpoint_type,
         enable_checkpoint_saving=enable_checkpoint_saving,
     )
 
   return checkpointer
 
 
 def _train_log_interval_steps(
-    train_p: tasks_lib.SingleTask.TrainHParams,
-) -> int:
+    train_p: tasks_lib.SingleTask.TrainHParams) -> int:
   """Returns the interval to log train outputs."""
   if train_p.log_train_output_interval_steps is not None:
     return train_p.log_train_output_interval_steps
   else:
     return train_p.summary_interval_steps
 
 
-def write_hparams_file(
-    model_config: base_experiment.BaseExperiment,
-    job_log_dir: epath.Path,
-    filename_prefix: str = '',
-) -> None:
+def write_hparams_file(model_config: base_experiment.BaseExperiment,
+                       job_log_dir: epath.Path,
+                       filename_prefix: str = '') -> None:
   """Writes a params file into the root `job_log_dir`."""
   if jax.process_index() == 0:
     job_log_dir.mkdir(parents=True, exist_ok=True)
     params_fpath = job_log_dir / f'{filename_prefix}model_params.txt'
     with params_fpath.open('w') as hparams_file:
       for dataset in model_config.datasets():
         hparams_file.write(dataset.to_text())
@@ -651,16 +625,15 @@
     eval_on_test: Optional[bool],
     checkpoint_todelete_subdir: Optional[str] = None,
     early_stopping_fn: Optional[trainer_lib.EarlyStoppingFn] = None,
     run_decode: bool = False,
     enable_auto_sharding: bool = False,
     enable_async_checkpointing: bool = False,
     enable_checkpoint_saving: bool = True,
-    enforce_restore_shape_check: bool = False,
-) -> None:
+    enforce_restore_shape_check: bool = False,) -> None:
   """The shared path to run the training and evaluation loop.
 
   Args:
     experiment_config: an instance of BaseExperiment for the experiment to train
       and evaluate.
     job_log_dir: The directory for the job logs.
     maybe_use_persistence_checkpointing: If set, it will try to use
@@ -674,16 +647,17 @@
       and determining whether to early stop current training. The callable
       object has signature: (metrics_by_dataset, ckpt_step, is_final_ckpt) ->
       should_stop_early.
     run_decode: whether to periodically run decode as part of the training loop.
       If and only if this is True, every `task_p.train.decode_interval_steps` of
       training, model runs decode.
     enable_auto_sharding: Enables the XLA Auto SPMD partitioner.
-    enable_async_checkpointing: Allows training to continue when checkpointing
-      is going on as checkpointing happens in a different thread.
+    enable_async_checkpointing: Allows
+      training to continue when checkpointing is going on as checkpointing
+      happens in a different thread.
     enable_checkpoint_saving: Whether to perform checkpoint saving or not.
     enforce_restore_shape_check: Raises an error if restore shapes do not match
       checkpoint shapes.
   """
   jax.monitoring.record_event('/jax/pax/train_and_evaluate/beacon')
   task_p = experiment_config.task()
   task_p = typing.cast(tasks_lib.SingleTask.HParams, task_p)
@@ -695,58 +669,49 @@
   # Note that we modify input params below with runtime information, therefore
   # experiment_config.datasets() should not be called again as it won't have the
   # correct runtime information populated.
   for inp in input_p:
     if not isinstance(
         inp, (base_input.BaseInput.HParams, base_input.DistributedInputHParams)
     ):
-      raise ValueError(
-          f'Expecting BaseInput.HParams from datasets(), got: {inp.ToText()}'
-      )
+      raise ValueError('Expecting BaseInput.HParams from datasets(), got: '
+                       f'{inp.ToText()}')
     if inp.num_infeed_hosts == 0:
       inp.num_infeed_hosts = jax.process_count()
     inp.infeed_host_index = jax.process_index()
   train_input_p = [v for v in input_p if v.is_training]
   if len(train_input_p) != 1:
     raise ValueError(
-        f'Expecting exactly one training split. Got `{len(train_input_p)}`.'
-    )
+        f'Expecting exactly one training split. Got `{len(train_input_p)}`.')
   train_input_p = train_input_p[0]
 
   logging.info('train_input_p:')
   for line in train_input_p.to_text().splitlines():
     logging.info('  %s', line)
   logging.info('task_p:')
   for line in task_p.to_text().splitlines():
     logging.info('  %s', line)
 
   eval_input_p = []
-  if (
-      eval_on_test
-      and task_p.train.eval_interval_steps is not None
-      and task_p.train.eval_interval_steps > 0
-  ):
+  if (eval_on_test and task_p.train.eval_interval_steps is not None and
+      task_p.train.eval_interval_steps > 0):
     eval_input_p = [v for v in input_p if not v.is_training]
 
-  if (
-      run_decode
-      and task_p.train.decode_interval_steps is not None
-      and task_p.train.decode_interval_steps > 0
-  ):
+  if (run_decode and task_p.train.decode_interval_steps is not None and
+      task_p.train.decode_interval_steps > 0):
     decode_input_p = experiment_config.decoder_datasets()
   else:
     decode_input_p = []
   for inp in decode_input_p:
     if inp.num_infeed_hosts == 0:
       inp.num_infeed_hosts = jax.process_count()
     inp.infeed_host_index = jax.process_index()
 
   checkpoint_type = checkpoints.retrieve_checkpoint_type(
-      maybe_use_persistence_checkpointing, task_p
-  )
+      maybe_use_persistence_checkpointing, task_p)
 
   job_log_dir = epath.Path(job_log_dir)
   checkpointer = _create_checkpointer(
       task_p,
       job_log_dir,
       checkpoint_type,
       checkpoint_todelete_subdir,
@@ -754,16 +719,15 @@
       enable_async_checkpointing=enable_async_checkpointing,
       enable_checkpoint_saving=enable_checkpoint_saving,
       enforce_restore_shape_check=enforce_restore_shape_check,
       maybe_use_persistence_checkpointing=maybe_use_persistence_checkpointing,
   )
   if not enable_checkpoint_saving:
     logging.info(
-        'Checkpointing is disabled and no checkpoint will be saved to disk.'
-    )
+        'Checkpointing is disabled and no checkpoint will be saved to disk.')
 
   if task_p.model.ici_mesh_shape is not None:
     train_and_evaluate_spmd_model(
         task_p,
         train_input_p,
         job_log_dir,
         checkpointer,
@@ -792,17 +756,15 @@
     train_input_p: base_input.BaseInput.HParams,
     initial_global_step: int,
 ) -> base_input.BaseInput:
   """Updates `train_input_p` in place its latest model step."""
   if not hasattr(train_input_p, 'deterministic_input_start_index'):
     return train_input
   dp = train_input_p.deterministic_input_start_index
-  dp._latest_model_step = (
-      initial_global_step  # pylint: disable=protected-access
-  )
+  dp._latest_model_step = initial_global_step  # pylint: disable=protected-access
   logging.info('Reinstanting input because _latest_model_step is updated.')
   return instantiate(train_input_p)
 
 
 class _SummaryContextManager(contextlib.ExitStack):
   """Manage summary writers."""
 
@@ -843,38 +805,32 @@
           for name in decode_input_names
       ]
     else:
       self.summary_decode_dirs = []
     self.eval_skip_train = eval_skip_train
 
   def __enter__(
-      self,
+      self
   ) -> Tuple[SummaryWriter, SummaryWriter, SummaryWriter, SummaryWriter]:
     self.train_summary_writer = self.enter_context(
-        self.summary_writer(self.summary_train_dir)
-    )
+        self.summary_writer(self.summary_train_dir))
     self.eval_summary_writer = None
     if not self.eval_skip_train:
       self.eval_summary_writer = self.enter_context(
-          self.summary_writer(self.summary_eval_dir)
-      )
+          self.summary_writer(self.summary_eval_dir))
     self.eval_test_summary_writers = [
         self.enter_context(self.summary_writer(d))
         for d in self.summary_eval_test_dirs
     ]
     self.decode_summary_writers = [
         self.enter_context(self.summary_writer(d))
         for d in self.summary_decode_dirs
     ]
-    return (
-        self.train_summary_writer,
-        self.eval_summary_writer,
-        self.eval_test_summary_writers,
-        self.decode_summary_writers,
-    )
+    return (self.train_summary_writer, self.eval_summary_writer,
+            self.eval_test_summary_writers, self.decode_summary_writers)
 
 
 def train_and_evaluate_pmap(
     task_p: tasks_lib.SingleTask.HParams,
     train_input_p: base_input.BaseInput.HParams,
     job_log_dir: epath.Path,
     checkpointer: _TrainingCheckpointer,
@@ -1100,26 +1056,22 @@
     train_input_pipeline = experiment_train_program.train_input
   else:
     # The partitioner only needs shape/dtype information of the prng key.
     # TODO(laigd): let the partitioner take ShapeDtypeStruct of prng key
     # instead.
     partitioner = partitioning.create_partitioner(
         jax_task,
+        root_prng_key,
         reshard_inputs=reshard_inputs,
         auto_sharding_mode=RunningMode.TRAIN if enable_auto_sharding else None,
+        job_log_dir=job_log_dir,
     )
     train_input_p = partitioner.preprocess_input_params(train_input_p)
     train_input_pipeline = instantiate(train_input_p)
-    partitioner.setup(
-        jax_task,
-        root_prng_key,
-        train_inputs_shape_dtype=None,
-        train_input_pipeline=train_input_pipeline,
-        job_log_dir=job_log_dir,
-    )
+    partitioner.set_train_inputs_shape_dtype(train_input_pipeline)
   train_state_metadata = partitioner.get_train_state_metadata()
 
   # JaxContext needed for shared layer lookup from global scope.
   with base_layer.JaxContext.new_context():
     # Dump out model meta info for debugging.
     trainer_lib.write_post_init_model_hparams_file(
         jax_task.model, train_state_metadata.var_weight_hparams, job_log_dir
@@ -1137,18 +1089,17 @@
 
   initial_global_step = int(
       py_utils.maybe_unreplicate_for_fully_replicated(
           partitioned_train_state.step
       )
   )
   logging.info('Model initial global_step=%d', initial_global_step)
-  if not task_p.train.enable_input_checkpointing:
-    train_input_pipeline = _maybe_update_latest_model_step(
-        train_input_pipeline, train_input_p, initial_global_step
-    )
+  train_input_pipeline = _maybe_update_latest_model_step(
+      train_input_pipeline, train_input_p, initial_global_step
+  )
   if experiment_train_program:
     logging.info('Using customized train program.')
     train_program = experiment_train_program
   else:
     train_program = programs.SingleTaskTrainProgram(
         jax_task, train_input_pipeline, partitioner
     )
@@ -1210,15 +1161,17 @@
     train_prng_seed,
 ):
   """Training loop code common to both pmap and spmd."""
   task_p = task.hparams
   train_p = task_p.train
   train_state_metadata = partitioner.get_train_state_metadata()
   train_input = (
-      train_program.train_input if train_p.enable_input_checkpointing else None
+      train_program.train_input
+      if train_p.enable_input_checkpointing
+      else None
   )
 
   if decode_input_p:
     decode_once_fn, prng_key, decode_input_names = partition_decode_once_fns(
         prng_key, decode_input_p
     )
   else:
@@ -1253,28 +1206,24 @@
     # TODO(laigd): consider moving this into train program.
     train_summary_handler = summary_utils.SummaryHandler(
         train_summary_writer,
         train_p.summary_interval_steps,
         accumulate_interval_steps=train_p.summary_accumulate_interval_steps,
         log_interval_steps=_train_log_interval_steps(train_p),
         is_async=bool(train_p.device_sync_interval_steps),
-        name='training',
-    )
+        name='training')
     eval_summary_handler = summary_utils.SummaryHandler(
         eval_summary_writer,
         train_p.summary_interval_steps,
         accumulate_interval_steps=train_p.summary_accumulate_interval_steps,
-        name='eval',
-    )
+        name='eval')
 
     step_i = int(
         py_utils.maybe_unreplicate_for_fully_replicated(
-            partitioned_train_state.step
-        )
-    )
+            partitioned_train_state.step))
     train_program.setup(
         train_prng_seed,
         eval_prng_seed,
         step_i,
         train_summary_handler,
         eval_summary_handler,
     )
@@ -1293,39 +1242,32 @@
           partitioned_train_state,
           train_state_metadata.partition_specs,
           train_input,
       )
 
       if not train_program.should_run(partitioned_train_state, step_i):
         logging.info(
-            (
-                'Training loop completed (step (`%d`) greater than '
-                'num_train_step (`%d`).'
-            ),
-            step_i,
-            train_p.num_train_steps,
-        )
+            'Training loop completed (step (`%d`) greater than '
+            'num_train_step (`%d`).', step_i, train_p.num_train_steps)
         break
 
       program_output = train_program.run(partitioned_train_state, step_i)
       partitioned_train_state = program_output.state
       train_weighted_scalars = program_output.aux.weighted_scalars
       steps_per_sec = program_output.aux.steps_per_sec
       eval_train_metrics = program_output.aux.eval_train_metrics
 
       # While the eval ones below are post-model weight updates, hence the step
       # counter is incremented in between.
       step_i = program_output.aux.new_train_step
 
       eval_metrics: Optional[tuning_lib.EvalMetrics] = None
       # Run eval at regular step interval.
-      if (
-          train_p.eval_interval_steps
-          and step_i % train_p.eval_interval_steps == 0
-      ):
+      if (train_p.eval_interval_steps and
+          step_i % train_p.eval_interval_steps == 0):
         logging.debug('  Starting eval_step().')
         eval_partitioned_train_state = programs.get_eval_train_state(
             task, partitioned_train_state
         )
         # If we have eval test then also evaluate on test.
         if test_eval_programs:
           logging.debug('  Performing eval_step() runs on test splits.')
@@ -1348,38 +1290,33 @@
               input_names=[
                   eval_program.eval_input.name
                   for eval_program in test_eval_programs
               ],
           )
           logging.debug(
               '  Completed eval_step() runs on test splits in %f seconds.',
-              eval_period.elapsed,
-          )
+              eval_period.elapsed)
 
       decode_metrics: Optional[tuning_lib.DecodeMetrics] = None
-      if (
-          decode_input_p
-          and train_p.decode_interval_steps
-          and step_i % train_p.decode_interval_steps == 0
-      ):
+      if (decode_input_p and train_p.decode_interval_steps and
+          step_i % train_p.decode_interval_steps == 0):
         if train_p.decode_use_ema_states:
           if not tasks_lib.has_ema(task_p):
             raise ValueError(
                 'decode_use_ema_states is requested but the '
                 'learner does not seem to have ema enabled'
             )
           decode_partitioned_train_state = tasks_lib.extract_ema(
               partitioned_train_state
           )
           logging.debug('  Performing decode_once_fn() with ema states.')
         else:
           decode_partitioned_train_state = partitioned_train_state
-        decode_metrics = decode_once_fn(
-            decode_partitioned_train_state, decode_summary_writers
-        )
+        decode_metrics = decode_once_fn(decode_partitioned_train_state,
+                                        decode_summary_writers)
 
       logging.debug('step=`%d`: End', step_i - 1)
 
       if early_stopping_fn is not None:
         if tuning_lib.should_early_stop(
             early_stopping_fn,
             step_i,
@@ -1413,13 +1350,13 @@
           break
     gc.unfreeze()
     # Save checkpoint for the last step.
     checkpointer.save_final(
         step_i,
         partitioned_train_state=partitioned_train_state,
         train_state_pspecs=train_state_metadata.partition_specs,
-        train_input_pipeline=train_input,
+        train_input_pipeline=train_input
     )
 
     checkpointer.wait_until_finished()
     train_summary_handler.close()
     eval_summary_handler.close()
```

## paxml/contrib/gpu/scripts_gpu/configs.py

```diff
@@ -134,15 +134,14 @@
   R_COS_MIN_RATIO = 0.1
   LR_COS_MAX = 1.0
 
   
   def task(self) -> tasks_lib.SingleTask.HParams:
     task_p = super().task()
     task_p = configure_gpt3_task(self, task_p)
-    task_p.train.num_train_steps = self.MAX_STEPS
     
     model_p = task_p.model
     
     ### compute layernorm reductions in fp32. Needed for stable training on GPUs
     stacked_p = model_p.lm_tpl.stacked_transformer_tpl
     if stacked_p.cls == transformers.PipelinedTransformer:
       stacked_p = stacked_p.pipeline_stage
```

## Comparing `paxml-0.4.0.dist-info/LICENSE` & `paxml-1.0.0.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `paxml-0.4.0.dist-info/METADATA` & `paxml-1.0.0.dist-info/METADATA`

 * *Files 16% similar despite different names*

```diff
@@ -1,36 +1,38 @@
 Metadata-Version: 2.1
 Name: paxml
-Version: 0.4.0
+Version: 1.0.0
 Summary: Framework to configure and run machine learning experiments on top of Jax.
 Home-page: https://github.com/google/paxml
 Author: PAX team
 Author-email: pax-dev@google.com
 License: Apache-2.0
 Platform: UNKNOWN
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Programming Language :: Python :: 3.9
 Classifier: Programming Language :: Python :: 3.10
 Requires-Python: >=3.8
-Requires-Dist: absl-py
-Requires-Dist: clu
-Requires-Dist: etils
-Requires-Dist: flax
-Requires-Dist: jax
-Requires-Dist: lingvo
-Requires-Dist: numpy
-Requires-Dist: orbax
-Requires-Dist: praxis
+Requires-Dist: absl-py (==1.4.0)
+Requires-Dist: clu (==0.0.8)
+Requires-Dist: etils (==1.1.1)
+Requires-Dist: flax (==0.6.8)
+Requires-Dist: jax (==0.4.7)
+Requires-Dist: lingvo (==0.12.6)
+Requires-Dist: numpy (~=1.24.2)
+Requires-Dist: orbax (==0.1.6)
+Requires-Dist: praxis (==0.4.0)
 Requires-Dist: protobuf (==3.19.6)
-Requires-Dist: pyglove
-Requires-Dist: seqio
-Requires-Dist: t5
-Requires-Dist: tensorflow-text (~=2.9.0)
-Requires-Dist: tensorflow (~=2.9.2)
-Requires-Dist: tensorstore
+Requires-Dist: pyglove (==0.3.0)
+Requires-Dist: seqio (==0.0.15)
+Requires-Dist: t5 (==0.9.3)
+Requires-Dist: tensorflow-datasets (==4.8.3)
+Requires-Dist: tensorflow-text (==2.9.0)
+Requires-Dist: tensorflow (==2.9.3)
+Requires-Dist: tensorstore (==0.1.35)
+Requires-Dist: tfds-nightly (==4.8.3.dev202303280045)
 Provides-Extra: gpu
 Requires-Dist: jax-triton (==0.1.3) ; extra == 'gpu'
 Requires-Dist: jsonlines (==3.1.0) ; extra == 'gpu'
 Requires-Dist: pysimdjson (==5.0.2) ; extra == 'gpu'
 Requires-Dist: zstandard (==0.18.0) ; extra == 'gpu'
 
 UNKNOWN
```

## Comparing `paxml-0.4.0.dist-info/RECORD` & `paxml-1.0.0.dist-info/RECORD`

 * *Files 10% similar despite different names*

```diff
@@ -3,55 +3,55 @@
 paxml/automl_test.py,sha256=bZSarVNC05YdoqJcsI7IFrEa6V87UjFmng4h9aEj3EM,35471
 paxml/base_experiment.py,sha256=BnAgFv7dIvCG4YJrDPg3c2X3vN3MnGdDhlN5xWDMR-I,4810
 paxml/base_inference_runner.py,sha256=es6tAeJ3wT0qgWe0jmHtIpzGxJIfw4tIZr2QhDdOIh0,3105
 paxml/base_inference_runner_test.py,sha256=fIIiwOQj88xZEWySUHbyWdEdX_rGAhQC57AkzDoqpms,3026
 paxml/base_metrics.py,sha256=7FMCxHpLUIJ2SHTOxK8ondA0zEI4pp-pydDVwXqLzkk,15688
 paxml/base_metrics_test.py,sha256=ib0HwkIwj7qbLR0wHGUE0isG_olxlKq0T6bQcGpGbyA,5204
 paxml/base_task.py,sha256=LpsiwBqM-MoGPc2ZfTR4IcP6yrhmTGaD4G6NEx58QfA,1106
-paxml/checkpoint_managers.py,sha256=LvBAEfiKsfsJEDpY0ysB_bAXuqec6QUNPrQ5gc7zo1g,10867
-paxml/checkpoint_managers_test.py,sha256=x7QQ4N9Vl3oW4FOzpX3V4OI5Sirb3A2tbBUBQrVMSZI,21807
+paxml/checkpoint_managers.py,sha256=CkWbrMItKWC0W16TKiNtCusDq9WpE-2cQwQaNIIYAMQ,10825
+paxml/checkpoint_managers_test.py,sha256=_kcM-m5YQMaCtLrRbxBSu8lq_gxsDHMh67w9zK1kKMc,21585
 paxml/checkpoint_version.py,sha256=linfvPaDnbcreuTqRxc3PP3swhbxScoVsCJg9Xr5cvI,1310
-paxml/checkpoints.py,sha256=fjW0VGnjGfzxv3LR1Vo58vhUFH5BxPZ_hixXJGqq4jU,27845
+paxml/checkpoints.py,sha256=haZQe2eJppREfkmc3IYw6pnx0kfJ8v3uSoi-pY4btIs,27824
 paxml/checkpoints_test.py,sha256=c6u5fATgo4kHOwQEmvl5LG_00diZo4cKOJWZYLhIKT4,3643
-paxml/eval_lib.py,sha256=XnJSdUEmpIXs_8WjPEg0z5QFatu_BzL1TuRCub1js1c,72697
+paxml/eval_lib.py,sha256=sldSpHeApVk4WQapGXrPdjdfSumPbsC6fOlhk3uOeWE,72624
 paxml/experiment_imports_all_test.py,sha256=Xhd1LIbVZICjnH4jHM-9wQxy1csNKTaCueOE_P3nSTA,1659
 paxml/experiment_imports_test_helper.py,sha256=VQ9sVjDdmbDmV0RjvDOQsIEd0Aa2qf39FNjVhx-Al6I,5025
 paxml/experiment_registry.py,sha256=tM_W4fHYNqQMKyw_8Mv2NhpUjw1cvf2ODV6fIE-Xq0U,6707
 paxml/experiment_registry_test.py,sha256=Y9NDmN6PgRnkrt-WmKS_Oa-yDKeQQ0_rsR1Oks-QA5k,4770
 paxml/experiment_utils.py,sha256=FoJJAJYq3F2ShBXb3Szi50A7SajqKetWpl2KZAf0Cvw,4213
 paxml/io_utils.py,sha256=Jm0s7YPDoAtSnB0c1jLtPgo_uoAj7ODKd0C7JUL3qdw,13122
 paxml/io_utils_test.py,sha256=KSrBOg3ZTwM_mrJFOBZOhCjj-l6Wh_jIiu9yzwcCwNg,5537
 paxml/learners.py,sha256=IkD3Hr9TT6ux18tqO2Exg41dPlESibX3Ma05bpW9hao,23525
 paxml/learners_test.py,sha256=ePBH-y5Gse_YkaRcUtfGvvsy8RGH7dfTX_6qb3PoEYU,27456
 paxml/main.py,sha256=3rn4gaFSIRcaYt5QGWnmI5sqDEyHOeV07tyr2MRqh5s,18494
 paxml/metric_tracker_utils.py,sha256=L-mz0qmdbxUAHHw0FbcEaAIYuhwEI9pW3cV82X902zY,4842
 paxml/metric_tracker_utils_test.py,sha256=e2c1RfM5TA70TAZPxQbGxmDniSB2qaD9cN73Ig__FUo,1839
 paxml/metric_utils.py,sha256=kbWYkYm4gUZjNLLTpSPYy0clZxYI-Zfu5thnoSoHUJU,10151
 paxml/metric_utils_test.py,sha256=dPSBjoxdI6Vjzv0oW34t2qa8ihNs3YC13fEJivb9Zm8,11334
-paxml/partitioning.py,sha256=9B6A0PLoqS7zkuqF8s51-778ubez2j-btaJYq8Jmvl4,46957
+paxml/partitioning.py,sha256=M6usOFzc6O-qdIkRmWWvTmcyMFBrXe30fzHb6LAkPRo,48890
 paxml/partitioning_test.py,sha256=ZYP9PDJYyELqvWeeM5QkZVWjDGY-UDhcDQ-g1xpV6xE,1863
 paxml/preemption.py,sha256=yd75u7od6RTvcJRMSUJeWWzsHb9vOy-CXSl6NpgWoWE,923
 paxml/profiling.py,sha256=iPFsdt_0CbhOQmMukkXfiXpCLY45NdVpwjZb-tAFZS8,3038
 paxml/programs.py,sha256=AnY3ErMgYTODCKsOLSqXRsLq18ZH7wFOWi-MaknE1aM,27709
-paxml/programs_test.py,sha256=Hu655P3xGDbvFs4uz8FcEZTNRAHfXURW7910MZx5js8,4515
-paxml/seqio_input.py,sha256=gwLEgdMrtOIFAt5tIc95c5M18iI9HW_Z7nzZEq8KLvo,74969
-paxml/seqio_input_test.py,sha256=1rZB4ygJhEwIW7BVWHXwjsefy_TQgHmmeGyj7BtWAKk,41569
+paxml/programs_test.py,sha256=lAbXoHFihN7-gaj7TpxED_WlA3MR5i56o1idVhb6KOk,4525
+paxml/seqio_input.py,sha256=YS4jnUeddDU9tkXCiYyHg5Qshm9nMGXByIndrnKqKys,74705
+paxml/seqio_input_test.py,sha256=NHhiXYOP8PDXkkCP469AIlxZlJW95nA6bQCUEuLaW9A,39897
 paxml/setup_jax.py,sha256=UzJf4p72_6BtR7qtyOcmxqeYiz9b1k-j_bJlbZWF5Z0,3252
 paxml/sgf.py,sha256=DhDJTA9y82kc0kxJ_IySfnI1cji-EeJ8J6RjaCXg-P0,12213
 paxml/summary_utils.py,sha256=J71_aD64P16FSfxOQF-PIRZp2nufWJN_-UJgvaJmH6g,25668
 paxml/summary_utils_test.py,sha256=YWbfKqJLuP2BtRA2NyaCo24dj4eHaSzVjAsYws3cIVI,11514
 paxml/tasks_lib.py,sha256=f0F-2Z_9EIeE-ew_BmeGxx5Gy5eIYAUuK5viJE3BLck,61313
 paxml/tasks_lib_test.py,sha256=kqgMi2itsr1uNywYzUm-cGLYFEvI02k4aNdQNhzEfC8,27063
 paxml/test_helper.py,sha256=KBP7ihH-tgd60iKsaZdVJ7TOjGNsqXBlNAY570jDhw0,793
-paxml/train.py,sha256=hq9mwoJh6wLhxbG8hc7cPNfAV8549Hs2BA_jKDgAKek,48224
+paxml/train.py,sha256=VL2lxbijsaK4lbJBAp_oI8jQ4QOH5SQ5FVrQKY_1Quo,47710
 paxml/train_states.py,sha256=1Tyl4IbMVZqjXBxwRvNROb3kOe8_q6VVxTKVwXyq07s,2070
 paxml/trainer_lib.py,sha256=s1MNyshMLIPrqlvqomshrI2-IohTykMSNn7ANuXCbkE,46376
 paxml/tuning_lib.py,sha256=uYW2r-0K5NqVW440faXTgG6lJWQBDgsaBYDJXjuH84A,34972
 paxml/tuning_lib_test.py,sha256=A-OR90w-zLg_wVSh0-M1W4RmzFXUeC5NLVcuLARjZhU,31238
-paxml/contrib/gpu/scripts_gpu/configs.py,sha256=q9953ZmLzdyQ0Rbw53L_IK2RikwD6NyndlTHjpKIMNs,7590
+paxml/contrib/gpu/scripts_gpu/configs.py,sha256=AWH0mDN7JiF4WWbjiueeTGx5ss6DxyAXkGiNouPo-wc,7540
 paxml/contrib/gpu/scripts_gpu/download_lambada.py,sha256=0JhQcW3YM8BPOX-Iu4WRtr-MYzNWCj8RZQVTzzBhG9A,784
 paxml/contrib/gpu/scripts_gpu/download_the_pile.py,sha256=r7KDILgYl2P210QzZ57yx88uG6bmPa0lrFDyseCRZqo,777
 paxml/contrib/gpu/scripts_gpu/tasks.py,sha256=wrzT0e_8Kc0lAtc1i9EsH0dcCeWyzfjqqsrf8TC50jI,5881
 paxml/contrib/gpu/scripts_gpu/tfds_lambada.py,sha256=FgYHAYlcCV51Y7jUXAwCJ4qvhsjLX7LBahkQi8IkSR0,5431
 paxml/contrib/gpu/scripts_gpu/tfds_pile.py,sha256=w_0J5A6k_qs8qSpKXv6UfoXyvsnkNA3qqzmVr5Bvxc4,7376
 paxml/tasks/lm/__init__.py,sha256=Kvb2PoI3YIk0TIr1ntASQoVpYeVxpEwVj0tTxsU7uxg,597
 paxml/tasks/lm/input_generator.py,sha256=4WDdVqokmI0NM9sLZx3hbBHIUXPvIe8cpoQRQTqmZaY,17202
@@ -67,12 +67,12 @@
 paxml/tasks/vision/input_generator.py,sha256=uubzOb5dSO1HJtsUrtOeE6FrS4R63nJv2NncDHiLAQ8,5371
 paxml/tasks/vision/input_generator_test.py,sha256=4Tnn8YYYkI8w0zpVSxTdSUaUSLrEdzOdmhrckW1zuKo,1611
 paxml/tasks/vision/resnet_preprocessing.py,sha256=imHewQV5Xb6BAZxqi9ejPM_WtJO81okSLZdN7vUuuYs,7002
 paxml/tasks/vision/params/imagenet_resnets.py,sha256=gIwGFAZYwqT39gJeJMh3Y22RMvXPyBrhaN8uHgmgovk,8792
 paxml/tools/dump_hparams.py,sha256=DaC565Q8yArMjyh_2YTYT-QJi9kG0U5e2A0d7wAu_n8,7305
 paxml/tools/dump_input_specs.py,sha256=5afJViiiDxI6HSl7M83HmvZbIcA59U4DwrvBbYXywl4,1590
 paxml/tools/dump_input_specs_lib.py,sha256=QAJnS8gaVL5YBsb-lEgc3YNVAW0CbjwjD1HLDA_MztM,3834
-paxml-0.4.0.dist-info/LICENSE,sha256=WNHhf_5RCaeuKWyq_K39vmp9F28LxKsB4SpomwSZ2L0,11357
-paxml-0.4.0.dist-info/METADATA,sha256=38ODI2fZLX-MxzXRL4MOgiOt-qSxU8CcthjusVLO7l4,1069
-paxml-0.4.0.dist-info/WHEEL,sha256=g4nMs7d-Xl9-xC9XovUrsDHGXt-FT0E17Yqo92DEfvY,92
-paxml-0.4.0.dist-info/top_level.txt,sha256=hPiAZDM4XGMlFcftlHk-0rW4_hq3Nur4MaWwEiDB94c,6
-paxml-0.4.0.dist-info/RECORD,,
+paxml-1.0.0.dist-info/LICENSE,sha256=WNHhf_5RCaeuKWyq_K39vmp9F28LxKsB4SpomwSZ2L0,11357
+paxml-1.0.0.dist-info/METADATA,sha256=5MCEZ34dqhGkptSfTrAUYzrV7-gFvsZpkVwi9Q3tdd8,1302
+paxml-1.0.0.dist-info/WHEEL,sha256=g4nMs7d-Xl9-xC9XovUrsDHGXt-FT0E17Yqo92DEfvY,92
+paxml-1.0.0.dist-info/top_level.txt,sha256=hPiAZDM4XGMlFcftlHk-0rW4_hq3Nur4MaWwEiDB94c,6
+paxml-1.0.0.dist-info/RECORD,,
```

