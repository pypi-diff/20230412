# Comparing `tmp/thirdai-0.6.4-cp39-cp39-win_amd64.whl.zip` & `tmp/thirdai-0.6.5-cp39-cp39-win_amd64.whl.zip`

## zipinfo {}

```diff
@@ -1,63 +1,63 @@
-Zip file size: 3500793 bytes, number of entries: 61
--rw-rw-rw-  2.0 fat     1453 b- defN 23-Apr-06 01:10 thirdai/__init__.py
--rw-rw-rw-  2.0 fat     1624 b- defN 23-Apr-06 01:10 thirdai/_download.py
--rw-rw-rw-  2.0 fat  9250816 b- defN 23-Apr-06 01:43 thirdai/_thirdai.cp39-win_amd64.pyd
--rw-rw-rw-  2.0 fat      136 b- defN 23-Apr-06 01:10 thirdai/bolt_v2.py
--rw-rw-rw-  2.0 fat      145 b- defN 23-Apr-06 01:10 thirdai/deployment.py
--rw-rw-rw-  2.0 fat      139 b- defN 23-Apr-06 01:10 thirdai/distributed_bolt.py
--rw-rw-rw-  2.0 fat     1312 b- defN 23-Apr-06 01:10 thirdai/embeddings.py
--rw-rw-rw-  2.0 fat      136 b- defN 23-Apr-06 01:10 thirdai/hashing.py
--rw-rw-rw-  2.0 fat      195 b- defN 23-Apr-06 01:10 thirdai/licensing.py
--rw-rw-rw-  2.0 fat     1277 b- defN 23-Apr-06 01:10 thirdai/search.py
--rw-rw-rw-  2.0 fat        0 b- defN 23-Apr-06 01:10 thirdai/_deps/__init__.py
--rw-rw-rw-  2.0 fat        0 b- defN 23-Apr-06 01:10 thirdai/_deps/ColBERT/__init__.py
--rw-rw-rw-  2.0 fat       48 b- defN 23-Apr-06 01:10 thirdai/_deps/ColBERT/colbertconfig/__init__.py
--rw-rw-rw-  2.0 fat     2118 b- defN 23-Apr-06 01:10 thirdai/_deps/ColBERT/colbertconfig/base_config.py
--rw-rw-rw-  2.0 fat      314 b- defN 23-Apr-06 01:10 thirdai/_deps/ColBERT/colbertconfig/config.py
--rw-rw-rw-  2.0 fat     2321 b- defN 23-Apr-06 01:10 thirdai/_deps/ColBERT/colbertconfig/core_config.py
--rw-rw-rw-  2.0 fat     3887 b- defN 23-Apr-06 01:10 thirdai/_deps/ColBERT/colbertconfig/settings.py
--rw-rw-rw-  2.0 fat        0 b- defN 23-Apr-06 01:10 thirdai/_deps/ColBERT/colbertmodeling/__init__.py
--rw-rw-rw-  2.0 fat     1268 b- defN 23-Apr-06 01:10 thirdai/_deps/ColBERT/colbertmodeling/base_colbert.py
--rw-rw-rw-  2.0 fat     1418 b- defN 23-Apr-06 01:10 thirdai/_deps/ColBERT/colbertmodeling/checkpoint.py
--rw-rw-rw-  2.0 fat     2277 b- defN 23-Apr-06 01:10 thirdai/_deps/ColBERT/colbertmodeling/colbert.py
--rw-rw-rw-  2.0 fat     2175 b- defN 23-Apr-06 01:10 thirdai/_deps/ColBERT/colbertmodeling/hf_colbert.py
--rw-rw-rw-  2.0 fat      168 b- defN 23-Apr-06 01:10 thirdai/_deps/ColBERT/colbertmodeling/tokenization/__init__.py
--rw-rw-rw-  2.0 fat     2064 b- defN 23-Apr-06 01:10 thirdai/_deps/ColBERT/colbertmodeling/tokenization/doc_tokenization.py
--rw-rw-rw-  2.0 fat     3295 b- defN 23-Apr-06 01:10 thirdai/_deps/ColBERT/colbertmodeling/tokenization/query_tokenization.py
--rw-rw-rw-  2.0 fat        0 b- defN 23-Apr-06 01:10 thirdai/_deps/ColBERT/colbertutils/__init__.py
--rw-rw-rw-  2.0 fat      319 b- defN 23-Apr-06 01:10 thirdai/_deps/ColBERT/colbertutils/utils.py
--rw-rw-rw-  2.0 fat      380 b- defN 23-Apr-06 01:10 thirdai/_distributed_bolt/__init__.py
--rw-rw-rw-  2.0 fat     9277 b- defN 23-Apr-06 01:10 thirdai/_distributed_bolt/dataset_loaders.py
--rw-rw-rw-  2.0 fat    25855 b- defN 23-Apr-06 01:10 thirdai/_distributed_bolt/distributed.py
--rw-rw-rw-  2.0 fat     3070 b- defN 23-Apr-06 01:10 thirdai/_distributed_bolt/utils.py
--rw-rw-rw-  2.0 fat        0 b- defN 23-Apr-06 01:10 thirdai/_distributed_bolt/backend/__init__.py
--rw-rw-rw-  2.0 fat     3682 b- defN 23-Apr-06 01:10 thirdai/_distributed_bolt/backend/primary_worker.py
--rw-rw-rw-  2.0 fat     2117 b- defN 23-Apr-06 01:10 thirdai/_distributed_bolt/backend/replica_worker.py
--rw-rw-rw-  2.0 fat     8078 b- defN 23-Apr-06 01:10 thirdai/_distributed_bolt/backend/train_state_manager.py
--rw-rw-rw-  2.0 fat    10104 b- defN 23-Apr-06 01:10 thirdai/_distributed_bolt/backend/worker.py
--rw-rw-rw-  2.0 fat      162 b- defN 23-Apr-06 01:10 thirdai/_distributed_bolt/backend/communication/__init__.py
--rw-rw-rw-  2.0 fat     6770 b- defN 23-Apr-06 01:10 thirdai/_distributed_bolt/backend/communication/circular.py
--rw-rw-rw-  2.0 fat     1205 b- defN 23-Apr-06 01:10 thirdai/_distributed_bolt/backend/communication/gloo.py
--rw-rw-rw-  2.0 fat     1297 b- defN 23-Apr-06 01:10 thirdai/_distributed_bolt/backend/communication/linear.py
--rw-rw-rw-  2.0 fat      226 b- defN 23-Apr-06 01:10 thirdai/bolt/__init__.py
--rw-rw-rw-  2.0 fat     9515 b- defN 23-Apr-06 01:10 thirdai/bolt/udt_docs.py
--rw-rw-rw-  2.0 fat     4781 b- defN 23-Apr-06 01:10 thirdai/bolt/udt_modifications.py
--rw-rw-rw-  2.0 fat      525 b- defN 23-Apr-06 01:10 thirdai/data/__init__.py
--rw-rw-rw-  2.0 fat     1962 b- defN 23-Apr-06 01:10 thirdai/data/column_map_utils.py
--rw-rw-rw-  2.0 fat     2474 b- defN 23-Apr-06 01:10 thirdai/data/get_udt_columns.py
--rw-rw-rw-  2.0 fat     5748 b- defN 23-Apr-06 01:10 thirdai/data/type_inference.py
--rw-rw-rw-  2.0 fat      245 b- defN 23-Apr-06 01:10 thirdai/dataset/__init__.py
--rw-rw-rw-  2.0 fat     3784 b- defN 23-Apr-06 01:10 thirdai/dataset/csv_data_source.py
--rw-rw-rw-  2.0 fat     2061 b- defN 23-Apr-06 01:10 thirdai/dataset/parquet_data_source.py
--rw-rw-rw-  2.0 fat       34 b- defN 23-Apr-06 01:10 thirdai/demos/__init__.py
--rw-rw-rw-  2.0 fat     1619 b- defN 23-Apr-06 01:10 thirdai/demos/beir_download_utils.py
--rw-rw-rw-  2.0 fat    24074 b- defN 23-Apr-06 01:10 thirdai/demos/download_datasets.py
--rw-rw-rw-  2.0 fat       51 b- defN 23-Apr-06 01:10 thirdai/telemetry/__init__.py
--rw-rw-rw-  2.0 fat     5263 b- defN 23-Apr-06 01:10 thirdai/telemetry/telemetry_daemon.py
--rw-rw-rw-  2.0 fat     5939 b- defN 23-Apr-06 01:10 thirdai/telemetry/telemetry_start_and_stop.py
--rw-rw-rw-  2.0 fat    16919 b- defN 23-Apr-06 01:43 thirdai-0.6.4.dist-info/LICENSE.txt
--rw-rw-rw-  2.0 fat     1982 b- defN 23-Apr-06 01:43 thirdai-0.6.4.dist-info/METADATA
--rw-rw-rw-  2.0 fat      100 b- defN 23-Apr-06 01:43 thirdai-0.6.4.dist-info/WHEEL
--rw-rw-rw-  2.0 fat        8 b- defN 23-Apr-06 01:43 thirdai-0.6.4.dist-info/top_level.txt
-?rw-rw-r--  2.0 fat     5747 b- defN 23-Apr-06 01:43 thirdai-0.6.4.dist-info/RECORD
-61 files, 9443959 bytes uncompressed, 3491425 bytes compressed:  63.0%
+Zip file size: 3547441 bytes, number of entries: 61
+-rw-rw-rw-  2.0 fat     1453 b- defN 23-Apr-12 05:27 thirdai/__init__.py
+-rw-rw-rw-  2.0 fat     1624 b- defN 23-Apr-12 05:27 thirdai/_download.py
+-rw-rw-rw-  2.0 fat  9383424 b- defN 23-Apr-12 06:06 thirdai/_thirdai.cp39-win_amd64.pyd
+-rw-rw-rw-  2.0 fat      136 b- defN 23-Apr-12 05:27 thirdai/bolt_v2.py
+-rw-rw-rw-  2.0 fat      145 b- defN 23-Apr-12 05:27 thirdai/deployment.py
+-rw-rw-rw-  2.0 fat      139 b- defN 23-Apr-12 05:27 thirdai/distributed_bolt.py
+-rw-rw-rw-  2.0 fat     1312 b- defN 23-Apr-12 05:27 thirdai/embeddings.py
+-rw-rw-rw-  2.0 fat      136 b- defN 23-Apr-12 05:27 thirdai/hashing.py
+-rw-rw-rw-  2.0 fat      195 b- defN 23-Apr-12 05:27 thirdai/licensing.py
+-rw-rw-rw-  2.0 fat     1277 b- defN 23-Apr-12 05:27 thirdai/search.py
+-rw-rw-rw-  2.0 fat        0 b- defN 23-Apr-12 05:27 thirdai/_deps/__init__.py
+-rw-rw-rw-  2.0 fat        0 b- defN 23-Apr-12 05:27 thirdai/_deps/ColBERT/__init__.py
+-rw-rw-rw-  2.0 fat       48 b- defN 23-Apr-12 05:27 thirdai/_deps/ColBERT/colbertconfig/__init__.py
+-rw-rw-rw-  2.0 fat     2118 b- defN 23-Apr-12 05:27 thirdai/_deps/ColBERT/colbertconfig/base_config.py
+-rw-rw-rw-  2.0 fat      314 b- defN 23-Apr-12 05:27 thirdai/_deps/ColBERT/colbertconfig/config.py
+-rw-rw-rw-  2.0 fat     2321 b- defN 23-Apr-12 05:27 thirdai/_deps/ColBERT/colbertconfig/core_config.py
+-rw-rw-rw-  2.0 fat     3887 b- defN 23-Apr-12 05:27 thirdai/_deps/ColBERT/colbertconfig/settings.py
+-rw-rw-rw-  2.0 fat        0 b- defN 23-Apr-12 05:27 thirdai/_deps/ColBERT/colbertmodeling/__init__.py
+-rw-rw-rw-  2.0 fat     1268 b- defN 23-Apr-12 05:27 thirdai/_deps/ColBERT/colbertmodeling/base_colbert.py
+-rw-rw-rw-  2.0 fat     1418 b- defN 23-Apr-12 05:27 thirdai/_deps/ColBERT/colbertmodeling/checkpoint.py
+-rw-rw-rw-  2.0 fat     2277 b- defN 23-Apr-12 05:27 thirdai/_deps/ColBERT/colbertmodeling/colbert.py
+-rw-rw-rw-  2.0 fat     2175 b- defN 23-Apr-12 05:27 thirdai/_deps/ColBERT/colbertmodeling/hf_colbert.py
+-rw-rw-rw-  2.0 fat      168 b- defN 23-Apr-12 05:27 thirdai/_deps/ColBERT/colbertmodeling/tokenization/__init__.py
+-rw-rw-rw-  2.0 fat     2064 b- defN 23-Apr-12 05:27 thirdai/_deps/ColBERT/colbertmodeling/tokenization/doc_tokenization.py
+-rw-rw-rw-  2.0 fat     3295 b- defN 23-Apr-12 05:27 thirdai/_deps/ColBERT/colbertmodeling/tokenization/query_tokenization.py
+-rw-rw-rw-  2.0 fat        0 b- defN 23-Apr-12 05:27 thirdai/_deps/ColBERT/colbertutils/__init__.py
+-rw-rw-rw-  2.0 fat      319 b- defN 23-Apr-12 05:27 thirdai/_deps/ColBERT/colbertutils/utils.py
+-rw-rw-rw-  2.0 fat      380 b- defN 23-Apr-12 05:27 thirdai/_distributed_bolt/__init__.py
+-rw-rw-rw-  2.0 fat     9277 b- defN 23-Apr-12 05:27 thirdai/_distributed_bolt/dataset_loaders.py
+-rw-rw-rw-  2.0 fat    25565 b- defN 23-Apr-12 05:27 thirdai/_distributed_bolt/distributed.py
+-rw-rw-rw-  2.0 fat     3070 b- defN 23-Apr-12 05:27 thirdai/_distributed_bolt/utils.py
+-rw-rw-rw-  2.0 fat        0 b- defN 23-Apr-12 05:27 thirdai/_distributed_bolt/backend/__init__.py
+-rw-rw-rw-  2.0 fat     3682 b- defN 23-Apr-12 05:27 thirdai/_distributed_bolt/backend/primary_worker.py
+-rw-rw-rw-  2.0 fat     2117 b- defN 23-Apr-12 05:27 thirdai/_distributed_bolt/backend/replica_worker.py
+-rw-rw-rw-  2.0 fat     8078 b- defN 23-Apr-12 05:27 thirdai/_distributed_bolt/backend/train_state_manager.py
+-rw-rw-rw-  2.0 fat    10104 b- defN 23-Apr-12 05:27 thirdai/_distributed_bolt/backend/worker.py
+-rw-rw-rw-  2.0 fat      162 b- defN 23-Apr-12 05:27 thirdai/_distributed_bolt/backend/communication/__init__.py
+-rw-rw-rw-  2.0 fat     6770 b- defN 23-Apr-12 05:27 thirdai/_distributed_bolt/backend/communication/circular.py
+-rw-rw-rw-  2.0 fat     1205 b- defN 23-Apr-12 05:27 thirdai/_distributed_bolt/backend/communication/gloo.py
+-rw-rw-rw-  2.0 fat     1297 b- defN 23-Apr-12 05:27 thirdai/_distributed_bolt/backend/communication/linear.py
+-rw-rw-rw-  2.0 fat      226 b- defN 23-Apr-12 05:27 thirdai/bolt/__init__.py
+-rw-rw-rw-  2.0 fat     9515 b- defN 23-Apr-12 05:27 thirdai/bolt/udt_docs.py
+-rw-rw-rw-  2.0 fat     4781 b- defN 23-Apr-12 05:27 thirdai/bolt/udt_modifications.py
+-rw-rw-rw-  2.0 fat      525 b- defN 23-Apr-12 05:27 thirdai/data/__init__.py
+-rw-rw-rw-  2.0 fat     1962 b- defN 23-Apr-12 05:27 thirdai/data/column_map_utils.py
+-rw-rw-rw-  2.0 fat     2474 b- defN 23-Apr-12 05:27 thirdai/data/get_udt_columns.py
+-rw-rw-rw-  2.0 fat     5748 b- defN 23-Apr-12 05:27 thirdai/data/type_inference.py
+-rw-rw-rw-  2.0 fat      245 b- defN 23-Apr-12 05:27 thirdai/dataset/__init__.py
+-rw-rw-rw-  2.0 fat     3784 b- defN 23-Apr-12 05:27 thirdai/dataset/csv_data_source.py
+-rw-rw-rw-  2.0 fat     2061 b- defN 23-Apr-12 05:27 thirdai/dataset/parquet_data_source.py
+-rw-rw-rw-  2.0 fat       34 b- defN 23-Apr-12 05:27 thirdai/demos/__init__.py
+-rw-rw-rw-  2.0 fat     1619 b- defN 23-Apr-12 05:27 thirdai/demos/beir_download_utils.py
+-rw-rw-rw-  2.0 fat    24074 b- defN 23-Apr-12 05:27 thirdai/demos/download_datasets.py
+-rw-rw-rw-  2.0 fat       51 b- defN 23-Apr-12 05:27 thirdai/telemetry/__init__.py
+-rw-rw-rw-  2.0 fat     5263 b- defN 23-Apr-12 05:27 thirdai/telemetry/telemetry_daemon.py
+-rw-rw-rw-  2.0 fat     5939 b- defN 23-Apr-12 05:27 thirdai/telemetry/telemetry_start_and_stop.py
+-rw-rw-rw-  2.0 fat    16919 b- defN 23-Apr-12 06:06 thirdai-0.6.5.dist-info/LICENSE.txt
+-rw-rw-rw-  2.0 fat     1982 b- defN 23-Apr-12 06:06 thirdai-0.6.5.dist-info/METADATA
+-rw-rw-rw-  2.0 fat      100 b- defN 23-Apr-12 06:06 thirdai-0.6.5.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat        8 b- defN 23-Apr-12 06:06 thirdai-0.6.5.dist-info/top_level.txt
+?rw-rw-r--  2.0 fat     5747 b- defN 23-Apr-12 06:06 thirdai-0.6.5.dist-info/RECORD
+61 files, 9576277 bytes uncompressed, 3538073 bytes compressed:  63.1%
```

## zipnote {}

```diff
@@ -162,23 +162,23 @@
 
 Filename: thirdai/telemetry/telemetry_daemon.py
 Comment: 
 
 Filename: thirdai/telemetry/telemetry_start_and_stop.py
 Comment: 
 
-Filename: thirdai-0.6.4.dist-info/LICENSE.txt
+Filename: thirdai-0.6.5.dist-info/LICENSE.txt
 Comment: 
 
-Filename: thirdai-0.6.4.dist-info/METADATA
+Filename: thirdai-0.6.5.dist-info/METADATA
 Comment: 
 
-Filename: thirdai-0.6.4.dist-info/WHEEL
+Filename: thirdai-0.6.5.dist-info/WHEEL
 Comment: 
 
-Filename: thirdai-0.6.4.dist-info/top_level.txt
+Filename: thirdai-0.6.5.dist-info/top_level.txt
 Comment: 
 
-Filename: thirdai-0.6.4.dist-info/RECORD
+Filename: thirdai-0.6.5.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## thirdai/_distributed_bolt/distributed.py

```diff
@@ -46,33 +46,29 @@
         if not verbose:
             train_config.silence()
         if metrics:
             train_config.with_metrics(metrics)
 
         model = self._get_model()
 
-        dist_model = DistributedDataParallel(
+        distributed_trainer = DistributedDataParallel(
             cluster_config=cluster_config,
             model=model,
             train_config=train_config,
             train_sources=train_sources,
             validation_context=validation_context,
         )
 
-        # We are freezing hashtables by default for distributed training after one epoch,
-        # Ideally we should read freezehashtables from UDTOptions and then pass
-        # it to distributed Wrapper. However, for the time being we are just
-        # initializing freeze-hash-tables=True by default.
-        training_metrics = dist_model.train(freeze_hash_tables=True)
+        distributed_trainer.train(epochs)
 
-        model = dist_model.get_model(with_optimizer=True)
+        model = distributed_trainer.get_model(with_optimizer=True)
 
         self._set_model(trained_model=model)
 
-        return training_metrics
+        return distributed_trainer.get_metrics()
 
     def train_distributed(
         self,
         cluster_config: RayTrainingClusterConfig,
         filenames: List[str],
         batch_size: Optional[int] = None,
         learning_rate: float = 0.001,
@@ -471,125 +467,136 @@
             license_state = thirdai._thirdai.licensing._get_license_state()
             licensing_lambda = lambda: thirdai._thirdai.licensing._set_license_state(
                 license_state
             )
         else:
             licensing_lambda = lambda: None
 
-        self.logging.info("Initializing Primary Worker")
-        self.primary_worker = cluster_config.primary_worker_config.remote(
-            num_workers=cluster_config.num_workers,
-            model_lambda=lambda: ray.get(ray_model_ref),
-            licensing_lambda=licensing_lambda,
-            train_source=train_sources[0],
-            train_config=train_config,
-            communication_type=cluster_config.communication_type,
-            log_dir=cluster_config.log_dir,
-            validation_context=self.validation_context,
+        self.primary_worker = self._intialize_primary_worker(
+            cluster_config, ray_model_ref, licensing_lambda, train_sources
+        )
+        self.replica_workers = self._initialize_replica_workers(
+            cluster_config, ray_model_ref, licensing_lambda, train_sources
         )
-
-        self.logging.info("Primary Worker Intialized")
-        self.logging.info("Initializing Replica Workers")
-        self.replica_workers = []
-        for worker_id, replica_worker_config in enumerate(
-            cluster_config.replica_worker_configs, start=1
-        ):
-            self.replica_workers.append(
-                replica_worker_config.remote(
-                    num_workers=cluster_config.num_workers,
-                    model_lambda=lambda: ray.get(ray_model_ref),
-                    licensing_lambda=licensing_lambda,
-                    train_source=train_sources[worker_id],
-                    train_config=train_config,
-                    id=worker_id,
-                    primary_worker=self.primary_worker,
-                    communication_type=cluster_config.communication_type,
-                    log_dir=cluster_config.log_dir,
-                )
-            )
-        self.logging.info("Replica Workers Intialized")
-
         self.workers = [self.primary_worker] + self.replica_workers
 
         self.num_of_batches = min(
             ray.get([worker.num_of_batches.remote() for worker in self.workers])
         )
 
         self.logging.info(
             f"Data loaded on all nodes, minimmum num batches is {self.num_of_batches}."
         )
         self.total_batches_trained = 0
         self.validation_metrics = []
+        self.train_metrics = []
 
-    def post_batch_training_updates(self, train_state_manager):
-        self.total_batches_trained += 1
-        # whether we need to validate
-        if self.validation_context != None:
-            if (
-                train_state_manager.updates
-                % self.validation_context.validation_frequency
-                == 0
-            ):
-                self.validation_metrics.append(
-                    train_state_manager.validate_and_save_if_best()
-                )
-
-    def train_on_epoch(self, train_state_manager, epoch):
-        while train_state_manager.train_batch(epoch=epoch):
-            self.post_batch_training_updates(train_state_manager)
-
-        self.post_batch_training_updates(train_state_manager)
-        return train_state_manager.move_to_next_epoch()
-
-    def train(self, freeze_hash_tables=False) -> Dict[str, Union[int, str]]:
-        """
-        Runs distributed training on the passed in Bolt model on the passed in
-        Ray cluster. Note that this method does not call finish_training on the
-        underlying DistributedTrainingWrappers. This is not dangerous because
-        the only way to do inference on the wrapped models is to call
-        get_model(), which will do a pickle and depickle of the wrapped Bolt
-        model, which has the side effect of throwing away any batch state as
-        it is not saved as part of the model.
-
-        Returns:
-            Dict: A dictionary with some statistics about training, including
-            total batches trained and total real time.
-        """
-        train_start = time.time()
-        train_state_manager = TrainStateManager(
+        self.train_state_manager = TrainStateManager(
             self.workers,
             self.primary_worker,
             self.logging,
             self.communication_type,
         )
+        self.current_epoch = 0
 
-        starting_epoch = 0
-        train_metrics = {}
-        # We need this check since we have a test with num_epochs = 0
-        if freeze_hash_tables and self.train_config.num_epochs > 0:
-            train_metrics = self.train_on_epoch(
-                train_state_manager=train_state_manager,
-                epoch=starting_epoch,
-            )
+    def step(self):
+        has_next_batch = self.train_state_manager.train_batch(epoch=self.current_epoch)
+        self.total_batches_trained += 1
 
-            train_state_manager.freeze_hash_tables()
+        self._validate()
 
-            starting_epoch += 1
+        return has_next_batch
 
-        for epoch in range(starting_epoch, self.train_config.num_epochs):
-            train_metrics = self.train_on_epoch(
-                train_state_manager=train_state_manager, epoch=epoch
-            )
+    def restart_data(self):
+        self.train_metrics = self.train_state_manager.move_to_next_epoch()
+        self.current_epoch += 1
+
+    # Note(pratik): This function simplifies training for bolt, for training with bolt_v2,
+    # use step based training as freeze_hash_tables not implemented for it.
+    def train(self, epochs, freeze_hash_tables=True):
+        for epoch in range(epochs):
+            # We are freezing hashtables by default for distributed training after one epoch,
+            # Ideally we should read freezehashtables from UDTOptions and then pass
+            # it to distributed Wrapper. However, for the time being we are just
+            # initializing freeze-hash-tables=True by default.
+            if epoch == 1 and freeze_hash_tables:
+                self.train_state_manager.freeze_hash_tables()
 
-        # Here we are returning the whole train_metrics independently for each of
-        # the worker with the assumption that train_metrics for each of the worker
-        # would be aggregated by the user.
+            while self.step():
+                pass
+
+            self.restart_data()
+
+        return self.get_metrics()
+
+    def get_metrics(self):
         distributed_train_metrics = {
-            "time": time.time() - train_start,
             "total_batches_trained": self.total_batches_trained,
-            "train_metrics": train_metrics,
+            "train_metrics": self.train_metrics,
             "validation_metrics": self.validation_metrics,
         }
         return distributed_train_metrics
 
     def get_model(self, worker_id=0, with_optimizer=False):
         return ray.get(self.workers[worker_id].model.remote(with_optimizer))
+
+    def _validate(self):
+        # whether we need to validate
+        if self.validation_context != None:
+            if (
+                self.train_state_manager.updates
+                % self.validation_context.validation_frequency
+                == 0
+            ):
+                self.validation_metrics.append(
+                    self.train_state_manager.validate_and_save_if_best()
+                )
+
+    def _intialize_primary_worker(
+        self,
+        cluster_config: RayTrainingClusterConfig,
+        ray_model_ref,
+        licensing_lambda,
+        train_sources: Union[List[DistributedDatasetLoader], List[str]],
+    ):
+        self.logging.info("Initializing Primary Worker")
+        primary_worker = cluster_config.primary_worker_config.remote(
+            num_workers=cluster_config.num_workers,
+            model_lambda=lambda: ray.get(ray_model_ref),
+            licensing_lambda=licensing_lambda,
+            train_source=train_sources[0],
+            train_config=self.train_config,
+            communication_type=cluster_config.communication_type,
+            log_dir=cluster_config.log_dir,
+            validation_context=self.validation_context,
+        )
+
+        self.logging.info("Primary Worker Intialized")
+        return primary_worker
+
+    def _initialize_replica_workers(
+        self,
+        cluster_config: RayTrainingClusterConfig,
+        ray_model_ref,
+        licensing_lambda,
+        train_sources: Union[List[DistributedDatasetLoader], List[str]],
+    ):
+        self.logging.info("Initializing Replica Workers")
+        replica_workers = []
+        for worker_id, replica_worker_config in enumerate(
+            cluster_config.replica_worker_configs, start=1
+        ):
+            replica_workers.append(
+                replica_worker_config.remote(
+                    num_workers=cluster_config.num_workers,
+                    model_lambda=lambda: ray.get(ray_model_ref),
+                    licensing_lambda=licensing_lambda,
+                    train_source=train_sources[worker_id],
+                    train_config=self.train_config,
+                    id=worker_id,
+                    primary_worker=self.primary_worker,
+                    communication_type=cluster_config.communication_type,
+                    log_dir=cluster_config.log_dir,
+                )
+            )
+        self.logging.info("Replica Workers Intialized")
+        return replica_workers
```

## Comparing `thirdai-0.6.4.dist-info/LICENSE.txt` & `thirdai-0.6.5.dist-info/LICENSE.txt`

 * *Files identical despite different names*

## Comparing `thirdai-0.6.4.dist-info/METADATA` & `thirdai-0.6.5.dist-info/METADATA`

 * *Files 4% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: thirdai
-Version: 0.6.4
+Version: 0.6.5
 Summary: A faster cpu machine learning library
 Author: ThirdAI
 Author-email: contact@thirdai.com
 License: proprietary
 License-File: LICENSE.txt
 Requires-Dist: numpy
 Requires-Dist: typing-extensions
```

## Comparing `thirdai-0.6.4.dist-info/RECORD` & `thirdai-0.6.5.dist-info/RECORD`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 thirdai/__init__.py,sha256=-hZZnjcggHLDVabZfdA8QFrQw5ldurMTOXGfqF0cr8o,1453
 thirdai/_download.py,sha256=RaYCBN4qjutcYNtoV286-GYnPX3ACq1C7aEmP_x1N2g,1624
-thirdai/_thirdai.cp39-win_amd64.pyd,sha256=fernQtF52iGc4Ie5k3LlCnSQmyfQ-Bzt9RlsOoG6JaI,9250816
+thirdai/_thirdai.cp39-win_amd64.pyd,sha256=gGkWE3csjh5SiMWpaIuJ762N2BJe9HFRMc2tizPuiFU,9383424
 thirdai/bolt_v2.py,sha256=2jdGmVwFGSR0AC9E91zCvDQgZtlc-_K9gYDgg4gn6ws,136
 thirdai/deployment.py,sha256=e_06MzSrth4S8Gs2dpEzfnLPaZsDcGhcJav8qfxEczY,145
 thirdai/distributed_bolt.py,sha256=MwUmwd8Q2v-ZAMtuGPBAocrQxO7ZRZZruWhlAuZzJos,139
 thirdai/embeddings.py,sha256=Afq5qcejw2NUpC_jImB5D70YLWB4ZHWROZPL7GdT44E,1312
 thirdai/hashing.py,sha256=MttqG8D0RnrPW2U-9Tf9LekMJjwnVS8I8jQAaNlucu4,136
 thirdai/licensing.py,sha256=oLmHWRqfqq6jpTTdauTyQHrY6LO_ukdTTdhgWotOPUQ,195
 thirdai/search.py,sha256=8HTl393Vt3g-OweibrR5UTYTCDCoF6Rk6WvWYRv30rM,1277
@@ -23,15 +23,15 @@
 thirdai/_deps/ColBERT/colbertmodeling/tokenization/__init__.py,sha256=7Rwy_hl_63cv9GnOParV2deBNvY1HkC6lZQm76r--wE,168
 thirdai/_deps/ColBERT/colbertmodeling/tokenization/doc_tokenization.py,sha256=wTj2V-nAAludCX7V9dwaETvnwyBAKCtsYQ6pegxK--M,2064
 thirdai/_deps/ColBERT/colbertmodeling/tokenization/query_tokenization.py,sha256=pr4oYC__9BzE-eabPPoFOlz9X9PyVtDE8232Z3Bam3s,3295
 thirdai/_deps/ColBERT/colbertutils/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 thirdai/_deps/ColBERT/colbertutils/utils.py,sha256=TsQ71Ufd5Bu5QC1wWxQPvnSAEwjft8KLq8mUgcugf7Q,319
 thirdai/_distributed_bolt/__init__.py,sha256=oGQcLT4GLyml_0um5drl-mAYiS_MlhEEn6W-c-Dkkac,380
 thirdai/_distributed_bolt/dataset_loaders.py,sha256=b6oK2ZIfOoxQb0RzlbmPZmvZUxs2IsMv2wYlUTTv0r8,9277
-thirdai/_distributed_bolt/distributed.py,sha256=rh86QO4jOv2__fvuro4xsIsZ-9BXPOTjNCTLp4DUBCI,25855
+thirdai/_distributed_bolt/distributed.py,sha256=kRZSZQo1VbWBKauK7mcJ32K2HugriBODeFFh3aO0yUI,25565
 thirdai/_distributed_bolt/utils.py,sha256=1hCS1KXDulFxsmJkZUYE_VqM0-HOkCUfCe9i6gz1xME,3070
 thirdai/_distributed_bolt/backend/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 thirdai/_distributed_bolt/backend/primary_worker.py,sha256=pL_cYeWpXP1djCW0bo0G76F9_ptOtd23kjBgi9ZBumc,3682
 thirdai/_distributed_bolt/backend/replica_worker.py,sha256=ianxNsLKAsAkl3P4-6_GtWytVPPnxPOWINYul4Vse2o,2117
 thirdai/_distributed_bolt/backend/train_state_manager.py,sha256=hMXZiE61ygUZwwjfPD0gXHRw_cxWt4gcDRaig6-Ug34,8078
 thirdai/_distributed_bolt/backend/worker.py,sha256=r5JbgT4YjW2fyREYYs4cb51cq3_KU3djjm677LEywgs,10104
 thirdai/_distributed_bolt/backend/communication/__init__.py,sha256=HyoGy-fQvPpitxXjHPpJkUL6JmRgjGhMBALY6MUDUUk,162
@@ -50,12 +50,12 @@
 thirdai/dataset/parquet_data_source.py,sha256=hHVe7qgN7gWU1IU2u9P5Sb8F2ER_ZY-1ITPVpXWdAnI,2061
 thirdai/demos/__init__.py,sha256=T8tU5Haf1jgKEvdZc3eKFFQjnk8MrB-nAOtSgR4yISc,34
 thirdai/demos/beir_download_utils.py,sha256=nXMAeoc18d1GFG0F6tNmU3GzmieIz_uUC_V1hKHC520,1619
 thirdai/demos/download_datasets.py,sha256=Gz6Z3YiGOYi8Y8RqEdlDSYEsf956KhKtQQ5LlIYYubE,24074
 thirdai/telemetry/__init__.py,sha256=cxKYgX1QWTCuYwg64_1RgBNvKL2iqtssdcc25eF4-NI,51
 thirdai/telemetry/telemetry_daemon.py,sha256=Vx5yf-IN17TGNSe1Hy3Szqu_1kudiAl3ics-nBcdHHM,5263
 thirdai/telemetry/telemetry_start_and_stop.py,sha256=Dbw2KsFyOfjQcnrSXnwMNBLNlj62aRFcje6RfRzJJfo,5939
-thirdai-0.6.4.dist-info/LICENSE.txt,sha256=agSIzKgTDMipzr2SjcOEG_GTJJkwtt-4wrcVAY03gPo,16919
-thirdai-0.6.4.dist-info/METADATA,sha256=raXAIXoXD5LTk6xe1jM1erOR7372MgaYoj6vewHRDic,1982
-thirdai-0.6.4.dist-info/WHEEL,sha256=fVcVlLzi8CGi_Ul8vjMdn8gER25dn5GBg9E6k9z41-Y,100
-thirdai-0.6.4.dist-info/top_level.txt,sha256=yBixDeDldyBUN70Yfq9rnKJYCNICw3ae7uow_BdZysA,8
-thirdai-0.6.4.dist-info/RECORD,,
+thirdai-0.6.5.dist-info/LICENSE.txt,sha256=agSIzKgTDMipzr2SjcOEG_GTJJkwtt-4wrcVAY03gPo,16919
+thirdai-0.6.5.dist-info/METADATA,sha256=pbsCVvZKlRvfj1kOKkvFKHuH-W0numoX3HiM9x2znys,1982
+thirdai-0.6.5.dist-info/WHEEL,sha256=fVcVlLzi8CGi_Ul8vjMdn8gER25dn5GBg9E6k9z41-Y,100
+thirdai-0.6.5.dist-info/top_level.txt,sha256=yBixDeDldyBUN70Yfq9rnKJYCNICw3ae7uow_BdZysA,8
+thirdai-0.6.5.dist-info/RECORD,,
```

