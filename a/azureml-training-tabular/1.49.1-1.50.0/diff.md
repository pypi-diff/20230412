# Comparing `tmp/azureml_training_tabular-1.49.1-py3-none-any.whl.zip` & `tmp/azureml_training_tabular-1.50.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,152 +1,154 @@
-Zip file size: 1735586 bytes, number of entries: 150
--rw-rw-rw-  2.0 fat      267 b- defN 23-Mar-20 16:47 azureml/__init__.py
--rw-rw-rw-  2.0 fat      267 b- defN 23-Mar-20 16:47 azureml/training/__init__.py
--rw-rw-rw-  2.0 fat      574 b- defN 23-Mar-20 16:47 azureml/training/tabular/__init__.py
--rw-rw-rw-  2.0 fat     1896 b- defN 23-Mar-20 16:47 azureml/training/tabular/_types.py
--rw-rw-rw-  2.0 fat       36 b- defN 23-Mar-20 16:54 azureml/training/tabular/_version.py
--rw-rw-rw-  2.0 fat    29112 b- defN 23-Mar-20 16:47 azureml/training/tabular/_constants/__init__.py
--rw-rw-rw-  2.0 fat      183 b- defN 23-Mar-20 16:47 azureml/training/tabular/_diagnostics/__init__.py
--rw-rw-rw-  2.0 fat      721 b- defN 23-Mar-20 16:47 azureml/training/tabular/_diagnostics/azureml_error.py
--rw-rw-rw-  2.0 fat     7175 b- defN 23-Mar-20 16:47 azureml/training/tabular/_diagnostics/contract.py
--rw-rw-rw-  2.0 fat     1219 b- defN 23-Mar-20 16:47 azureml/training/tabular/_diagnostics/debug_logging.py
--rw-rw-rw-  2.0 fat    65271 b- defN 23-Mar-20 16:47 azureml/training/tabular/_diagnostics/error_definitions.py
--rw-rw-rw-  2.0 fat    67635 b- defN 23-Mar-20 16:47 azureml/training/tabular/_diagnostics/error_strings.py
--rw-rw-rw-  2.0 fat     2035 b- defN 23-Mar-20 16:47 azureml/training/tabular/_diagnostics/errors.py
--rw-rw-rw-  2.0 fat     2227 b- defN 23-Mar-20 16:47 azureml/training/tabular/_diagnostics/logging_utilities.py
--rw-rw-rw-  2.0 fat    56664 b- defN 23-Mar-20 16:47 azureml/training/tabular/_diagnostics/reference_codes.py
--rw-rw-rw-  2.0 fat     4390 b- defN 23-Mar-20 16:47 azureml/training/tabular/_diagnostics/validation.py
--rw-rw-rw-  2.0 fat      183 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/__init__.py
--rw-rw-rw-  2.0 fat     3074 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/_azureml_transformer.py
--rw-rw-rw-  2.0 fat    46894 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/_engineered_feature_names.py
--rw-rw-rw-  2.0 fat    29742 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/_featurization_config.py
--rw-rw-rw-  2.0 fat     2958 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/_featurization_info_provider.py
--rw-rw-rw-  2.0 fat     8987 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/_memory_utilities.py
--rw-rw-rw-  2.0 fat     1056 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/_operator_names.py
--rw-rw-rw-  2.0 fat    11658 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/_raw_feature_stats.py
--rw-rw-rw-  2.0 fat     6697 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/_supported_transformers.py
--rw-rw-rw-  2.0 fat     6951 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/_transformer_exceptions.py
--rw-rw-rw-  2.0 fat    14936 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/utilities.py
--rw-rw-rw-  2.0 fat      224 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/categorical/__init__.py
--rw-rw-rw-  2.0 fat     3799 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/categorical/cat_imputer.py
--rw-rw-rw-  2.0 fat     3479 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/categorical/hashonehotvectorizer_transformer.py
--rw-rw-rw-  2.0 fat     4024 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/categorical/labelencoder_transformer.py
--rw-rw-rw-  2.0 fat     3558 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/categorical/onehotencoder_transformer.py
--rw-rw-rw-  2.0 fat      183 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/data/__init__.py
--rw-rw-rw-  2.0 fat     4159 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/data/abstract_wordembeddings_provider.py
--rw-rw-rw-  2.0 fat     5958 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/data/pretrained_dnn_provider.py
--rw-rw-rw-  2.0 fat    25346 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/data/word_embeddings_info.py
--rw-rw-rw-  2.0 fat     5722 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/data/wordembeddings_provider.py
--rw-rw-rw-  2.0 fat      221 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/datetime/__init__.py
--rw-rw-rw-  2.0 fat     3377 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/datetime/datetime_transformer.py
--rw-rw-rw-  2.0 fat      228 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/generic/__init__.py
--rw-rw-rw-  2.0 fat     4140 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/generic/abstract_multiclass_target_encoder.py
--rw-rw-rw-  2.0 fat     3507 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/generic/countbased_target_encoder.py
--rw-rw-rw-  2.0 fat    10535 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/generic/crossvalidation_target_encoder.py
--rw-rw-rw-  2.0 fat     2011 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/generic/imputation_marker.py
--rw-rw-rw-  2.0 fat     3412 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/generic/modelbased_target_encoder.py
--rw-rw-rw-  2.0 fat     3815 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/generic/woe_target_encoder.py
--rw-rw-rw-  2.0 fat      228 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/numeric/__init__.py
--rw-rw-rw-  2.0 fat     2837 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/numeric/bin_transformer.py
--rw-rw-rw-  2.0 fat      225 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/text/__init__.py
--rw-rw-rw-  2.0 fat    75005 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/text/_modeling_bert_no_apex.py
--rw-rw-rw-  2.0 fat    11640 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/text/_pytorch_transformers.py
--rw-rw-rw-  2.0 fat     6233 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/text/bagofwords_transformer.py
--rw-rw-rw-  2.0 fat    42948 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/text/bilstm_attention_transformer.py
--rw-rw-rw-  2.0 fat     2640 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/text/naive_bayes.py
--rw-rw-rw-  2.0 fat    37508 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/text/pretrained_text_dnn_transformer.py
--rw-rw-rw-  2.0 fat     3828 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/text/stats_transformer.py
--rw-rw-rw-  2.0 fat     2651 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/text/string_concat_transformer.py
--rw-rw-rw-  2.0 fat     3281 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/text/stringcast_transformer.py
--rw-rw-rw-  2.0 fat     7130 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/text/wordembedding_transformer.py
--rw-rw-rw-  2.0 fat      231 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/timeseries/__init__.py
--rw-rw-rw-  2.0 fat      418 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/timeseries/_grain_based_stateful_transformer.py
--rw-rw-rw-  2.0 fat    15769 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/timeseries/_holidays.py
--rw-rw-rw-  2.0 fat     2120 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/timeseries/all_rows_dropper.py
--rw-rw-rw-  2.0 fat    10680 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/timeseries/category_binarizer.py
--rw-rw-rw-  2.0 fat     7201 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/timeseries/datetime_column_featurizer.py
--rw-rw-rw-  2.0 fat     5111 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/timeseries/drop_columns.py
--rw-rw-rw-  2.0 fat     2023 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/timeseries/forecasting_constants.py
--rw-rw-rw-  2.0 fat    32006 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/timeseries/forecasting_heuristic_utils.py
--rw-rw-rw-  2.0 fat     7617 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/timeseries/grain_dropper.py
--rw-rw-rw-  2.0 fat     9716 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/timeseries/grain_index_featurizer.py
--rw-rw-rw-  2.0 fat    59128 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/timeseries/lag_lead_operator.py
--rw-rw-rw-  2.0 fat     6346 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/timeseries/lagging_transformer.py
--rw-rw-rw-  2.0 fat     6175 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/timeseries/max_horizon_featurizer.py
--rw-rw-rw-  2.0 fat     3122 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/timeseries/missingdummies_transformer.py
--rw-rw-rw-  2.0 fat     5360 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/timeseries/numericalize_transformer.py
--rw-rw-rw-  2.0 fat     6203 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/timeseries/restore_dtypes_transformer.py
--rw-rw-rw-  2.0 fat    45052 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/timeseries/rolling_window.py
--rw-rw-rw-  2.0 fat     5415 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/timeseries/short_grain_dropper.py
--rw-rw-rw-  2.0 fat    10660 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/timeseries/stationary_featurizer.py
--rw-rw-rw-  2.0 fat    33731 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/timeseries/stl_featurizer.py
--rw-rw-rw-  2.0 fat    31506 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/timeseries/time_index_featurizer.py
--rw-rw-rw-  2.0 fat    56825 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/timeseries/time_series_imputer.py
--rw-rw-rw-  2.0 fat    83708 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/timeseries/timeseries_transformer.py
--rw-rw-rw-  2.0 fat    11689 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/timeseries/transform_utils.py
--rw-rw-rw-  2.0 fat     3763 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/timeseries/unique_target_grain_dropper.py
--rw-rw-rw-  2.0 fat     3767 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/timeseries/unique_target_grain_dropper_base.py
--rw-rw-rw-  2.0 fat      244 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/timeseries/_data/__init__.py
--rw-rw-rw-  2.0 fat     6580 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/timeseries/_data/holiday_effect_window.7z
--rw-rw-rw-  2.0 fat  1057912 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/timeseries/_data/holidays.7z
--rw-rw-rw-  2.0 fat   146216 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/timeseries/_data/holidays_origin.7z
--rw-rw-rw-  2.0 fat      243 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/timeseries/_distributed/__init__.py
--rw-rw-rw-  2.0 fat     2512 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/timeseries/_distributed/_distributed_timeseries_util.py
--rw-rw-rw-  2.0 fat     3748 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/timeseries/_distributed/aggregate_transformer.py
--rw-rw-rw-  2.0 fat     1718 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/timeseries/_distributed/aggregated_grain_dropper.py
--rw-rw-rw-  2.0 fat     1417 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/timeseries/_distributed/aggregated_transformer_factory.py
--rw-rw-rw-  2.0 fat     2369 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/timeseries/_distributed/aggregated_unique_target_grain_dropper.py
--rw-rw-rw-  2.0 fat     9359 b- defN 23-Mar-20 16:47 azureml/training/tabular/featurization/timeseries/_distributed/timeseries_data_profile.py
--rw-rw-rw-  2.0 fat      952 b- defN 23-Mar-20 16:47 azureml/training/tabular/models/__init__.py
--rw-rw-rw-  2.0 fat      632 b- defN 23-Mar-20 16:47 azureml/training/tabular/models/_abstract_model_wrapper.py
--rw-rw-rw-  2.0 fat     2712 b- defN 23-Mar-20 16:47 azureml/training/tabular/models/_forecast_scenario_data.py
--rw-rw-rw-  2.0 fat     9573 b- defN 23-Mar-20 16:47 azureml/training/tabular/models/calibrated_model.py
--rw-rw-rw-  2.0 fat    15685 b- defN 23-Mar-20 16:47 azureml/training/tabular/models/differencing_y_transformer.py
--rw-rw-rw-  2.0 fat    20434 b- defN 23-Mar-20 16:47 azureml/training/tabular/models/forecasting_models.py
--rw-rw-rw-  2.0 fat    47413 b- defN 23-Mar-20 16:47 azureml/training/tabular/models/forecasting_pipeline_wrapper.py
--rw-rw-rw-  2.0 fat   114293 b- defN 23-Mar-20 16:47 azureml/training/tabular/models/forecasting_pipeline_wrapper_base.py
--rw-rw-rw-  2.0 fat     9300 b- defN 23-Mar-20 16:47 azureml/training/tabular/models/pipeline_with_ytransformations.py
--rw-rw-rw-  2.0 fat     3162 b- defN 23-Mar-20 16:47 azureml/training/tabular/models/sparse_scale_zero_one.py
--rw-rw-rw-  2.0 fat    16802 b- defN 23-Mar-20 16:47 azureml/training/tabular/models/stack_ensemble.py
--rw-rw-rw-  2.0 fat     2687 b- defN 23-Mar-20 16:47 azureml/training/tabular/models/target_type_transformer.py
--rw-rw-rw-  2.0 fat    17575 b- defN 23-Mar-20 16:47 azureml/training/tabular/models/voting_ensemble.py
--rw-rw-rw-  2.0 fat     3559 b- defN 23-Mar-20 16:47 azureml/training/tabular/models/y_pipeline_transformer.py
--rw-rw-rw-  2.0 fat      183 b- defN 23-Mar-20 16:47 azureml/training/tabular/models/_timeseries/__init__.py
--rw-rw-rw-  2.0 fat    16166 b- defN 23-Mar-20 16:47 azureml/training/tabular/models/_timeseries/_arimax.py
--rw-rw-rw-  2.0 fat     8880 b- defN 23-Mar-20 16:47 azureml/training/tabular/models/_timeseries/_auto_arima.py
--rw-rw-rw-  2.0 fat    12145 b- defN 23-Mar-20 16:47 azureml/training/tabular/models/_timeseries/_exponential_smoothing.py
--rw-rw-rw-  2.0 fat    40663 b- defN 23-Mar-20 16:47 azureml/training/tabular/models/_timeseries/_multi_grain_forecast_base.py
--rw-rw-rw-  2.0 fat     9573 b- defN 23-Mar-20 16:47 azureml/training/tabular/models/_timeseries/_prophet_model.py
--rw-rw-rw-  2.0 fat      183 b- defN 23-Mar-20 16:47 azureml/training/tabular/preprocessing/__init__.py
--rw-rw-rw-  2.0 fat    10101 b- defN 23-Mar-20 16:47 azureml/training/tabular/preprocessing/_dataset_binning.py
--rw-rw-rw-  2.0 fat     3965 b- defN 23-Mar-20 16:47 azureml/training/tabular/preprocessing/data_cleaning.py
--rw-rw-rw-  2.0 fat      223 b- defN 23-Mar-20 16:47 azureml/training/tabular/score/__init__.py
--rw-rw-rw-  2.0 fat    46470 b- defN 23-Mar-20 16:47 azureml/training/tabular/score/_classification.py
--rw-rw-rw-  2.0 fat    38507 b- defN 23-Mar-20 16:47 azureml/training/tabular/score/_cv_splits.py
--rw-rw-rw-  2.0 fat    23809 b- defN 23-Mar-20 16:47 azureml/training/tabular/score/_forecasting.py
--rw-rw-rw-  2.0 fat     5122 b- defN 23-Mar-20 16:47 azureml/training/tabular/score/_metric_base.py
--rw-rw-rw-  2.0 fat    24431 b- defN 23-Mar-20 16:47 azureml/training/tabular/score/_regression.py
--rw-rw-rw-  2.0 fat    31164 b- defN 23-Mar-20 16:47 azureml/training/tabular/score/_scoring_utilities.py
--rw-rw-rw-  2.0 fat    18066 b- defN 23-Mar-20 16:47 azureml/training/tabular/score/_validation.py
--rw-rw-rw-  2.0 fat    15631 b- defN 23-Mar-20 16:47 azureml/training/tabular/score/constants.py
--rw-rw-rw-  2.0 fat    15054 b- defN 23-Mar-20 16:47 azureml/training/tabular/score/scoring.py
--rw-rw-rw-  2.0 fat     8287 b- defN 23-Mar-20 16:47 azureml/training/tabular/score/utilities.py
--rw-rw-rw-  2.0 fat      183 b- defN 23-Mar-20 16:47 azureml/training/tabular/timeseries/__init__.py
--rw-rw-rw-  2.0 fat     5867 b- defN 23-Mar-20 16:47 azureml/training/tabular/timeseries/_automl_forecast_freq.py
--rw-rw-rw-  2.0 fat     1832 b- defN 23-Mar-20 16:47 azureml/training/tabular/timeseries/_fixed_dataset.py
--rw-rw-rw-  2.0 fat    36767 b- defN 23-Mar-20 16:47 azureml/training/tabular/timeseries/_freq_aggregator.py
--rw-rw-rw-  2.0 fat    40127 b- defN 23-Mar-20 16:47 azureml/training/tabular/timeseries/_frequency_fixer.py
--rw-rw-rw-  2.0 fat    14687 b- defN 23-Mar-20 16:47 azureml/training/tabular/timeseries/_short_grain_padding.py
--rw-rw-rw-  2.0 fat    14956 b- defN 23-Mar-20 16:47 azureml/training/tabular/timeseries/_time_series_column_helper.py
--rw-rw-rw-  2.0 fat     5159 b- defN 23-Mar-20 16:47 azureml/training/tabular/timeseries/_time_series_data_config.py
--rw-rw-rw-  2.0 fat    60535 b- defN 23-Mar-20 16:47 azureml/training/tabular/timeseries/_time_series_data_set.py
--rw-rw-rw-  2.0 fat    14778 b- defN 23-Mar-20 16:47 azureml/training/tabular/timeseries/forecasting_ts_utils.py
--rw-rw-rw-  2.0 fat    15116 b- defN 23-Mar-20 16:47 azureml/training/tabular/timeseries/forecasting_utilities.py
--rw-rw-rw-  2.0 fat    10258 b- defN 23-Mar-20 16:47 azureml/training/tabular/timeseries/forecasting_verify.py
--rw-rw-rw-  2.0 fat     9999 b- defN 23-Mar-20 16:47 azureml/training/tabular/timeseries/rolling_origin_validator.py
--rw-rw-rw-  2.0 fat   126478 b- defN 23-Mar-20 16:47 azureml/training/tabular/timeseries/time_series_data_frame.py
--rw-rw-rw-  2.0 fat      859 b- defN 23-Mar-20 16:54 azureml_training_tabular-1.49.1.dist-info/LICENSE.txt
--rw-rw-rw-  2.0 fat     2250 b- defN 23-Mar-20 16:54 azureml_training_tabular-1.49.1.dist-info/METADATA
--rw-rw-rw-  2.0 fat       97 b- defN 23-Mar-20 16:54 azureml_training_tabular-1.49.1.dist-info/WHEEL
--rw-rw-rw-  2.0 fat        8 b- defN 23-Mar-20 16:54 azureml_training_tabular-1.49.1.dist-info/top_level.txt
-?rw-rw-r--  2.0 fat    17929 b- defN 23-Mar-20 16:54 azureml_training_tabular-1.49.1.dist-info/RECORD
-150 files, 3325607 bytes uncompressed, 1705356 bytes compressed:  48.7%
+Zip file size: 1740980 bytes, number of entries: 152
+-rw-rw-rw-  2.0 fat      267 b- defN 23-Apr-12 03:27 azureml/__init__.py
+-rw-rw-rw-  2.0 fat      267 b- defN 23-Apr-12 03:27 azureml/training/__init__.py
+-rw-rw-rw-  2.0 fat      574 b- defN 23-Apr-12 03:27 azureml/training/tabular/__init__.py
+-rw-rw-rw-  2.0 fat     1896 b- defN 23-Apr-12 03:27 azureml/training/tabular/_types.py
+-rw-rw-rw-  2.0 fat       36 b- defN 23-Apr-12 03:36 azureml/training/tabular/_version.py
+-rw-rw-rw-  2.0 fat    29157 b- defN 23-Apr-12 03:27 azureml/training/tabular/_constants/__init__.py
+-rw-rw-rw-  2.0 fat      183 b- defN 23-Apr-12 03:27 azureml/training/tabular/_diagnostics/__init__.py
+-rw-rw-rw-  2.0 fat      721 b- defN 23-Apr-12 03:27 azureml/training/tabular/_diagnostics/azureml_error.py
+-rw-rw-rw-  2.0 fat     7175 b- defN 23-Apr-12 03:27 azureml/training/tabular/_diagnostics/contract.py
+-rw-rw-rw-  2.0 fat     1219 b- defN 23-Apr-12 03:27 azureml/training/tabular/_diagnostics/debug_logging.py
+-rw-rw-rw-  2.0 fat    65271 b- defN 23-Apr-12 03:27 azureml/training/tabular/_diagnostics/error_definitions.py
+-rw-rw-rw-  2.0 fat    67635 b- defN 23-Apr-12 03:27 azureml/training/tabular/_diagnostics/error_strings.py
+-rw-rw-rw-  2.0 fat     2035 b- defN 23-Apr-12 03:27 azureml/training/tabular/_diagnostics/errors.py
+-rw-rw-rw-  2.0 fat     2227 b- defN 23-Apr-12 03:27 azureml/training/tabular/_diagnostics/logging_utilities.py
+-rw-rw-rw-  2.0 fat    56664 b- defN 23-Apr-12 03:27 azureml/training/tabular/_diagnostics/reference_codes.py
+-rw-rw-rw-  2.0 fat     4390 b- defN 23-Apr-12 03:27 azureml/training/tabular/_diagnostics/validation.py
+-rw-rw-rw-  2.0 fat      183 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/__init__.py
+-rw-rw-rw-  2.0 fat     3074 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/_azureml_transformer.py
+-rw-rw-rw-  2.0 fat    46894 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/_engineered_feature_names.py
+-rw-rw-rw-  2.0 fat    29742 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/_featurization_config.py
+-rw-rw-rw-  2.0 fat     2958 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/_featurization_info_provider.py
+-rw-rw-rw-  2.0 fat     8987 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/_memory_utilities.py
+-rw-rw-rw-  2.0 fat     1056 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/_operator_names.py
+-rw-rw-rw-  2.0 fat    11658 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/_raw_feature_stats.py
+-rw-rw-rw-  2.0 fat     6697 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/_supported_transformers.py
+-rw-rw-rw-  2.0 fat     6951 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/_transformer_exceptions.py
+-rw-rw-rw-  2.0 fat    14936 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/utilities.py
+-rw-rw-rw-  2.0 fat      224 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/categorical/__init__.py
+-rw-rw-rw-  2.0 fat     3799 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/categorical/cat_imputer.py
+-rw-rw-rw-  2.0 fat     3479 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/categorical/hashonehotvectorizer_transformer.py
+-rw-rw-rw-  2.0 fat     4024 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/categorical/labelencoder_transformer.py
+-rw-rw-rw-  2.0 fat     3558 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/categorical/onehotencoder_transformer.py
+-rw-rw-rw-  2.0 fat      183 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/data/__init__.py
+-rw-rw-rw-  2.0 fat     4159 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/data/abstract_wordembeddings_provider.py
+-rw-rw-rw-  2.0 fat     5958 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/data/pretrained_dnn_provider.py
+-rw-rw-rw-  2.0 fat    25346 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/data/word_embeddings_info.py
+-rw-rw-rw-  2.0 fat     5722 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/data/wordembeddings_provider.py
+-rw-rw-rw-  2.0 fat      221 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/datetime/__init__.py
+-rw-rw-rw-  2.0 fat     3377 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/datetime/datetime_transformer.py
+-rw-rw-rw-  2.0 fat      228 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/generic/__init__.py
+-rw-rw-rw-  2.0 fat     4140 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/generic/abstract_multiclass_target_encoder.py
+-rw-rw-rw-  2.0 fat     3507 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/generic/countbased_target_encoder.py
+-rw-rw-rw-  2.0 fat    10535 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/generic/crossvalidation_target_encoder.py
+-rw-rw-rw-  2.0 fat     2011 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/generic/imputation_marker.py
+-rw-rw-rw-  2.0 fat     3412 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/generic/modelbased_target_encoder.py
+-rw-rw-rw-  2.0 fat     3815 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/generic/woe_target_encoder.py
+-rw-rw-rw-  2.0 fat      228 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/numeric/__init__.py
+-rw-rw-rw-  2.0 fat     2837 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/numeric/bin_transformer.py
+-rw-rw-rw-  2.0 fat      225 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/text/__init__.py
+-rw-rw-rw-  2.0 fat    75005 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/text/_modeling_bert_no_apex.py
+-rw-rw-rw-  2.0 fat    11640 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/text/_pytorch_transformers.py
+-rw-rw-rw-  2.0 fat     6233 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/text/bagofwords_transformer.py
+-rw-rw-rw-  2.0 fat    42948 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/text/bilstm_attention_transformer.py
+-rw-rw-rw-  2.0 fat     2640 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/text/naive_bayes.py
+-rw-rw-rw-  2.0 fat    37508 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/text/pretrained_text_dnn_transformer.py
+-rw-rw-rw-  2.0 fat     3828 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/text/stats_transformer.py
+-rw-rw-rw-  2.0 fat     2651 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/text/string_concat_transformer.py
+-rw-rw-rw-  2.0 fat     3281 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/text/stringcast_transformer.py
+-rw-rw-rw-  2.0 fat     7130 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/text/wordembedding_transformer.py
+-rw-rw-rw-  2.0 fat      231 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/timeseries/__init__.py
+-rw-rw-rw-  2.0 fat      418 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/timeseries/_grain_based_stateful_transformer.py
+-rw-rw-rw-  2.0 fat    15769 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/timeseries/_holidays.py
+-rw-rw-rw-  2.0 fat     2120 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/timeseries/all_rows_dropper.py
+-rw-rw-rw-  2.0 fat    10680 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/timeseries/category_binarizer.py
+-rw-rw-rw-  2.0 fat     7201 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/timeseries/datetime_column_featurizer.py
+-rw-rw-rw-  2.0 fat     5111 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/timeseries/drop_columns.py
+-rw-rw-rw-  2.0 fat     2023 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/timeseries/forecasting_constants.py
+-rw-rw-rw-  2.0 fat    32006 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/timeseries/forecasting_heuristic_utils.py
+-rw-rw-rw-  2.0 fat     7617 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/timeseries/grain_dropper.py
+-rw-rw-rw-  2.0 fat     9716 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/timeseries/grain_index_featurizer.py
+-rw-rw-rw-  2.0 fat    59128 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/timeseries/lag_lead_operator.py
+-rw-rw-rw-  2.0 fat     6346 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/timeseries/lagging_transformer.py
+-rw-rw-rw-  2.0 fat     6175 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/timeseries/max_horizon_featurizer.py
+-rw-rw-rw-  2.0 fat     3122 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/timeseries/missingdummies_transformer.py
+-rw-rw-rw-  2.0 fat     5360 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/timeseries/numericalize_transformer.py
+-rw-rw-rw-  2.0 fat     6203 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/timeseries/restore_dtypes_transformer.py
+-rw-rw-rw-  2.0 fat    45052 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/timeseries/rolling_window.py
+-rw-rw-rw-  2.0 fat     5415 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/timeseries/short_grain_dropper.py
+-rw-rw-rw-  2.0 fat    10660 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/timeseries/stationary_featurizer.py
+-rw-rw-rw-  2.0 fat    33731 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/timeseries/stl_featurizer.py
+-rw-rw-rw-  2.0 fat    31506 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/timeseries/time_index_featurizer.py
+-rw-rw-rw-  2.0 fat    56825 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/timeseries/time_series_imputer.py
+-rw-rw-rw-  2.0 fat    83822 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/timeseries/timeseries_transformer.py
+-rw-rw-rw-  2.0 fat    11689 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/timeseries/transform_utils.py
+-rw-rw-rw-  2.0 fat     4988 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/timeseries/unique_target_grain_dropper.py
+-rw-rw-rw-  2.0 fat     4050 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/timeseries/unique_target_grain_dropper_base.py
+-rw-rw-rw-  2.0 fat      244 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/timeseries/_data/__init__.py
+-rw-rw-rw-  2.0 fat     6580 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/timeseries/_data/holiday_effect_window.7z
+-rw-rw-rw-  2.0 fat  1057912 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/timeseries/_data/holidays.7z
+-rw-rw-rw-  2.0 fat   146216 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/timeseries/_data/holidays_origin.7z
+-rw-rw-rw-  2.0 fat      243 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/timeseries/_distributed/__init__.py
+-rw-rw-rw-  2.0 fat     2512 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/timeseries/_distributed/_distributed_timeseries_util.py
+-rw-rw-rw-  2.0 fat     3748 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/timeseries/_distributed/aggregate_transformer.py
+-rw-rw-rw-  2.0 fat     1718 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/timeseries/_distributed/aggregated_grain_dropper.py
+-rw-rw-rw-  2.0 fat     1417 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/timeseries/_distributed/aggregated_transformer_factory.py
+-rw-rw-rw-  2.0 fat     3071 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/timeseries/_distributed/aggregated_unique_target_grain_dropper.py
+-rw-rw-rw-  2.0 fat     9359 b- defN 23-Apr-12 03:27 azureml/training/tabular/featurization/timeseries/_distributed/timeseries_data_profile.py
+-rw-rw-rw-  2.0 fat      952 b- defN 23-Apr-12 03:27 azureml/training/tabular/models/__init__.py
+-rw-rw-rw-  2.0 fat      632 b- defN 23-Apr-12 03:27 azureml/training/tabular/models/_abstract_model_wrapper.py
+-rw-rw-rw-  2.0 fat     2712 b- defN 23-Apr-12 03:27 azureml/training/tabular/models/_forecast_scenario_data.py
+-rw-rw-rw-  2.0 fat     9573 b- defN 23-Apr-12 03:27 azureml/training/tabular/models/calibrated_model.py
+-rw-rw-rw-  2.0 fat    15685 b- defN 23-Apr-12 03:27 azureml/training/tabular/models/differencing_y_transformer.py
+-rw-rw-rw-  2.0 fat    20434 b- defN 23-Apr-12 03:27 azureml/training/tabular/models/forecasting_models.py
+-rw-rw-rw-  2.0 fat    47754 b- defN 23-Apr-12 03:27 azureml/training/tabular/models/forecasting_pipeline_wrapper.py
+-rw-rw-rw-  2.0 fat   115267 b- defN 23-Apr-12 03:27 azureml/training/tabular/models/forecasting_pipeline_wrapper_base.py
+-rw-rw-rw-  2.0 fat     9300 b- defN 23-Apr-12 03:27 azureml/training/tabular/models/pipeline_with_ytransformations.py
+-rw-rw-rw-  2.0 fat     3162 b- defN 23-Apr-12 03:27 azureml/training/tabular/models/sparse_scale_zero_one.py
+-rw-rw-rw-  2.0 fat    16802 b- defN 23-Apr-12 03:27 azureml/training/tabular/models/stack_ensemble.py
+-rw-rw-rw-  2.0 fat     2687 b- defN 23-Apr-12 03:27 azureml/training/tabular/models/target_type_transformer.py
+-rw-rw-rw-  2.0 fat    17575 b- defN 23-Apr-12 03:27 azureml/training/tabular/models/voting_ensemble.py
+-rw-rw-rw-  2.0 fat     3559 b- defN 23-Apr-12 03:27 azureml/training/tabular/models/y_pipeline_transformer.py
+-rw-rw-rw-  2.0 fat      183 b- defN 23-Apr-12 03:27 azureml/training/tabular/models/_timeseries/__init__.py
+-rw-rw-rw-  2.0 fat    16166 b- defN 23-Apr-12 03:27 azureml/training/tabular/models/_timeseries/_arimax.py
+-rw-rw-rw-  2.0 fat     8880 b- defN 23-Apr-12 03:27 azureml/training/tabular/models/_timeseries/_auto_arima.py
+-rw-rw-rw-  2.0 fat    12145 b- defN 23-Apr-12 03:27 azureml/training/tabular/models/_timeseries/_exponential_smoothing.py
+-rw-rw-rw-  2.0 fat    40663 b- defN 23-Apr-12 03:27 azureml/training/tabular/models/_timeseries/_multi_grain_forecast_base.py
+-rw-rw-rw-  2.0 fat     9573 b- defN 23-Apr-12 03:27 azureml/training/tabular/models/_timeseries/_prophet_model.py
+-rw-rw-rw-  2.0 fat      267 b- defN 23-Apr-12 03:27 azureml/training/tabular/models/mlflow/__init__.py
+-rw-rw-rw-  2.0 fat    17673 b- defN 23-Apr-12 03:27 azureml/training/tabular/models/mlflow/timeseries/__init__.py
+-rw-rw-rw-  2.0 fat      183 b- defN 23-Apr-12 03:27 azureml/training/tabular/preprocessing/__init__.py
+-rw-rw-rw-  2.0 fat    10101 b- defN 23-Apr-12 03:27 azureml/training/tabular/preprocessing/_dataset_binning.py
+-rw-rw-rw-  2.0 fat     4451 b- defN 23-Apr-12 03:27 azureml/training/tabular/preprocessing/data_cleaning.py
+-rw-rw-rw-  2.0 fat      223 b- defN 23-Apr-12 03:27 azureml/training/tabular/score/__init__.py
+-rw-rw-rw-  2.0 fat    46470 b- defN 23-Apr-12 03:27 azureml/training/tabular/score/_classification.py
+-rw-rw-rw-  2.0 fat    38507 b- defN 23-Apr-12 03:27 azureml/training/tabular/score/_cv_splits.py
+-rw-rw-rw-  2.0 fat    23809 b- defN 23-Apr-12 03:27 azureml/training/tabular/score/_forecasting.py
+-rw-rw-rw-  2.0 fat     5122 b- defN 23-Apr-12 03:27 azureml/training/tabular/score/_metric_base.py
+-rw-rw-rw-  2.0 fat    24431 b- defN 23-Apr-12 03:27 azureml/training/tabular/score/_regression.py
+-rw-rw-rw-  2.0 fat    31164 b- defN 23-Apr-12 03:27 azureml/training/tabular/score/_scoring_utilities.py
+-rw-rw-rw-  2.0 fat    18066 b- defN 23-Apr-12 03:27 azureml/training/tabular/score/_validation.py
+-rw-rw-rw-  2.0 fat    15631 b- defN 23-Apr-12 03:27 azureml/training/tabular/score/constants.py
+-rw-rw-rw-  2.0 fat    15054 b- defN 23-Apr-12 03:27 azureml/training/tabular/score/scoring.py
+-rw-rw-rw-  2.0 fat     8287 b- defN 23-Apr-12 03:27 azureml/training/tabular/score/utilities.py
+-rw-rw-rw-  2.0 fat      183 b- defN 23-Apr-12 03:27 azureml/training/tabular/timeseries/__init__.py
+-rw-rw-rw-  2.0 fat     5867 b- defN 23-Apr-12 03:27 azureml/training/tabular/timeseries/_automl_forecast_freq.py
+-rw-rw-rw-  2.0 fat     1832 b- defN 23-Apr-12 03:27 azureml/training/tabular/timeseries/_fixed_dataset.py
+-rw-rw-rw-  2.0 fat    36767 b- defN 23-Apr-12 03:27 azureml/training/tabular/timeseries/_freq_aggregator.py
+-rw-rw-rw-  2.0 fat    40127 b- defN 23-Apr-12 03:27 azureml/training/tabular/timeseries/_frequency_fixer.py
+-rw-rw-rw-  2.0 fat    14687 b- defN 23-Apr-12 03:27 azureml/training/tabular/timeseries/_short_grain_padding.py
+-rw-rw-rw-  2.0 fat    14956 b- defN 23-Apr-12 03:27 azureml/training/tabular/timeseries/_time_series_column_helper.py
+-rw-rw-rw-  2.0 fat     5159 b- defN 23-Apr-12 03:27 azureml/training/tabular/timeseries/_time_series_data_config.py
+-rw-rw-rw-  2.0 fat    60535 b- defN 23-Apr-12 03:27 azureml/training/tabular/timeseries/_time_series_data_set.py
+-rw-rw-rw-  2.0 fat    14778 b- defN 23-Apr-12 03:27 azureml/training/tabular/timeseries/forecasting_ts_utils.py
+-rw-rw-rw-  2.0 fat    15116 b- defN 23-Apr-12 03:27 azureml/training/tabular/timeseries/forecasting_utilities.py
+-rw-rw-rw-  2.0 fat    10258 b- defN 23-Apr-12 03:27 azureml/training/tabular/timeseries/forecasting_verify.py
+-rw-rw-rw-  2.0 fat     9999 b- defN 23-Apr-12 03:27 azureml/training/tabular/timeseries/rolling_origin_validator.py
+-rw-rw-rw-  2.0 fat   126478 b- defN 23-Apr-12 03:27 azureml/training/tabular/timeseries/time_series_data_frame.py
+-rw-rw-rw-  2.0 fat      859 b- defN 23-Apr-12 03:36 azureml_training_tabular-1.50.0.dist-info/LICENSE.txt
+-rw-rw-rw-  2.0 fat     2250 b- defN 23-Apr-12 03:36 azureml_training_tabular-1.50.0.dist-info/METADATA
+-rw-rw-rw-  2.0 fat       97 b- defN 23-Apr-12 03:36 azureml_training_tabular-1.50.0.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat        8 b- defN 23-Apr-12 03:36 azureml_training_tabular-1.50.0.dist-info/top_level.txt
+?rw-rw-r--  2.0 fat    18154 b- defN 23-Apr-12 03:36 azureml_training_tabular-1.50.0.dist-info/RECORD
+152 files, 3347942 bytes uncompressed, 1710376 bytes compressed:  48.9%
```

## zipnote {}

```diff
@@ -345,14 +345,20 @@
 
 Filename: azureml/training/tabular/models/_timeseries/_multi_grain_forecast_base.py
 Comment: 
 
 Filename: azureml/training/tabular/models/_timeseries/_prophet_model.py
 Comment: 
 
+Filename: azureml/training/tabular/models/mlflow/__init__.py
+Comment: 
+
+Filename: azureml/training/tabular/models/mlflow/timeseries/__init__.py
+Comment: 
+
 Filename: azureml/training/tabular/preprocessing/__init__.py
 Comment: 
 
 Filename: azureml/training/tabular/preprocessing/_dataset_binning.py
 Comment: 
 
 Filename: azureml/training/tabular/preprocessing/data_cleaning.py
@@ -429,23 +435,23 @@
 
 Filename: azureml/training/tabular/timeseries/rolling_origin_validator.py
 Comment: 
 
 Filename: azureml/training/tabular/timeseries/time_series_data_frame.py
 Comment: 
 
-Filename: azureml_training_tabular-1.49.1.dist-info/LICENSE.txt
+Filename: azureml_training_tabular-1.50.0.dist-info/LICENSE.txt
 Comment: 
 
-Filename: azureml_training_tabular-1.49.1.dist-info/METADATA
+Filename: azureml_training_tabular-1.50.0.dist-info/METADATA
 Comment: 
 
-Filename: azureml_training_tabular-1.49.1.dist-info/WHEEL
+Filename: azureml_training_tabular-1.50.0.dist-info/WHEEL
 Comment: 
 
-Filename: azureml_training_tabular-1.49.1.dist-info/top_level.txt
+Filename: azureml_training_tabular-1.50.0.dist-info/top_level.txt
 Comment: 
 
-Filename: azureml_training_tabular-1.49.1.dist-info/RECORD
+Filename: azureml_training_tabular-1.50.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## azureml/training/tabular/_version.py

```diff
@@ -1,2 +1,2 @@
-ver = "1.49.1"
-selfver = "1.49.1"
+ver = "1.50.0"
+selfver = "1.50.0"
```

## azureml/training/tabular/_constants/__init__.py

```diff
@@ -113,14 +113,15 @@
     SERIES_LEN_PERC_50 = "series_len_perc_50"
     SERIES_LEN_PERC_75 = "series_len_perc_75"
     SHORT_SERIES_HANDLING = "short_series_handling"
     SHORT_SERIES_HANDLING_CONFIG = "short_series_handling_configuration"
     STL_OPTION_SEASON = "season"
     STL_OPTION_SEASON_TREND = "season_trend"
     TARGET_COLUMN_NAME = 'target_column_name'
+    LABEL_COLUMN_NAME = "label_column_name"
     TARGET_LAGS = "target_lags"
     TARGET_ROLLING_WINDOW_SIZE = "target_rolling_window_size"
     TIME_COLUMN_NAME = "time_column_name"
     TIME_SERIES_ID_COLUMN_NAMES = "time_series_id_column_names"
     USE_STL = "use_stl"
     TARGET_AGG_FUN = "target_aggregation_function"
     ALL_FORECASTING_PARAMETERS = {
```

## azureml/training/tabular/featurization/timeseries/timeseries_transformer.py

```diff
@@ -1471,15 +1471,18 @@
     def parameters(self) -> Dict[str, Any]:
         """Return the parameters needed to reconstruct the time series transformer"""
         return self._parameters
 
     @property
     def user_target_column_name(self) -> Optional[str]:
         """Get the target, or label, column name supplied by the user in AutoML configuration."""
-        return cast(Optional[str], self._parameters.get(TimeSeries.TARGET_COLUMN_NAME))
+        res = self._parameters.get(TimeSeries.TARGET_COLUMN_NAME)
+        if res is None:
+            res = self._parameters.get(TimeSeries.LABEL_COLUMN_NAME)
+        return cast(Optional[str], res)
 
     @property
     def lookback_features_removed(self) -> bool:
         """Returned true if lookback features were removed due to memory limitations."""
         return self._lookback_features_removed
 
     @staticmethod
```

## azureml/training/tabular/featurization/timeseries/unique_target_grain_dropper.py

```diff
@@ -39,38 +39,64 @@
         """
         UniqueTargetGrainDropperBase.__init__(self)
         GrainDropper.__init__(
             self, target_rolling_window_size, target_lags, n_cross_validations, cv_step_size, max_horizon,
             drop_single_grain=False, drop_unknown=False)
         self._last_X = None  # type: Optional[pd.DataFrame]
         self._last_y = None  # type: Optional[np.ndarray]
+        self._last_valid_X = None  # type: Optional[pd.DataFrame]
+        self._last_valid_y = None  # type: Optional[np.ndarray]
 
-    @function_debug_log_wrapped(logging.INFO)
-    def _fit(self, X: TimeSeriesDataSet, y: Any = None) -> 'UniqueTargetGrainDropper':
+    def _set_last_X_y(self, X: TimeSeriesDataSet, validation: bool = False) -> None:
+        """
+        Set last X and y for both training and validation data based on the validation parameter.
+
+        :param X: TimeSeriesDataSet.
+        :param validation: True if the data is validation data.
+        """
         target_col = X.target_column_name
 
         dfs = []
         for grain, df in X.groupby_time_series_id():
-            # short grain and all missing value won't be handled by unique target grain dropper.
-            n_unique = _get_num_unique(df[target_col], ignore_na=True)
-            if n_unique != 1 or not self.is_df_long(df, X):
-                self._grains_to_keep.add(grain)
+            if not validation:  # only do keep grains / drop grains in training data
+                # short grain and all missing value won't be handled by unique target grain dropper.
+                n_unique = _get_num_unique(df[target_col], ignore_na=True)
+                if n_unique != 1 or not self.is_df_long(df, X):
+                    self._grains_to_keep.add(grain)
+                else:
+                    self._grains_to_drop.append(grain)
+                    dfs.append(df.tail(1))
             else:
-                self._grains_to_drop.append(grain)
                 dfs.append(df.tail(1))
 
         if dfs:
-            self._last_X = pd.concat(dfs, sort=False)
-            self._last_y = self._last_X.pop(target_col).values
+            if validation:
+                self._last_valid_X = pd.concat(dfs, sort=False)
+                self._last_valid_y = self._last_valid_X.pop(target_col).values
+            else:
+                self._last_X = pd.concat(dfs, sort=False)
+                self._last_y = self._last_X.pop(target_col).values
 
+    @function_debug_log_wrapped(logging.INFO)
+    def _fit(self, X: TimeSeriesDataSet, y: Any = None) -> 'UniqueTargetGrainDropper':
+        self._set_last_X_y(X)
         return self
 
     def _validate_transformed_data(self, df: TimeSeriesDataSet, dropped_grains: List[GrainType]) -> None:
         pass
 
+    def set_last_validation_data(self, validation_X: TimeSeriesDataSet) -> None:
+        """Set last validation data."""
+        self._set_last_X_y(validation_X, True)
+
+    @property
+    def last_validation_X_y(self) -> Tuple[Optional[pd.DataFrame], Optional[np.ndarray]]:
+        """The last validation X"""
+        return self._last_valid_X, self._last_valid_y
+
     @property
     def last_X_y(self) -> Tuple[Optional[pd.DataFrame], Optional[np.ndarray]]:
         """The last X and y observed during fit."""
         return self._last_X, self._last_y
 
     @property
     def unique_target_grains(self) -> Set[str]:
```

## azureml/training/tabular/featurization/timeseries/unique_target_grain_dropper_base.py

```diff
@@ -30,19 +30,27 @@
     def grains_to_keep(self) -> Set[str]:
         raise NotImplementedError
 
     @abstractmethod
     def fit(self, X: TimeSeriesDataSet, y: Any = None) -> 'UniqueTargetGrainDropperBase':
         raise NotImplementedError
 
+    def set_last_validation_data(self, validation_X: TimeSeriesDataSet) -> None:
+        raise NotImplementedError
+
     @property
     @abstractmethod
     def last_X_y(self) -> Tuple[Optional[pd.DataFrame], Optional[np.ndarray]]:
         raise NotImplementedError
 
+    @property
+    @abstractmethod
+    def last_validation_X_y(self) -> Tuple[Optional[pd.DataFrame], Optional[np.ndarray]]:
+        raise NotImplementedError
+
     def unique_grain_data_generator(
             self,
             df: pd.DataFrame,
             grain_column_names: List[str]
     ) -> Generator[Tuple[Any, pd.DataFrame], None, None]:
         """Generate the unique target grains which will drop after featurization."""
         return filter(lambda x: x[0] in self.unique_target_grains, df.groupby(grain_column_names))
```

## azureml/training/tabular/featurization/timeseries/_distributed/aggregated_unique_target_grain_dropper.py

```diff
@@ -31,23 +31,39 @@
         return next(self._unique_target_grains_dropper_generator(), None) is not None
 
     @property
     def unique_target_grains(self) -> Set[str]:
         return set(itertools.chain.from_iterable(
             map(lambda x: x.unique_target_grains, self._unique_target_grains_dropper_generator())))
 
-    @property
-    def last_X_y(self) -> Tuple[Optional[pd.DataFrame], Optional[np.ndarray]]:
-        """Last X and y in the fit data."""
+    def _get_last_X_y(self, validation: bool = False) -> Tuple[Optional[pd.DataFrame], Optional[np.ndarray]]:
+        """
+        Returns last X and y in the fit data for training and validation based on the validation flag.
+
+        :param validation: True if required last X and y in the validation data, False otherwise.
+        """
         dfs = []
+        last_X = None
+        last_y = None
         for dropper in self._unique_target_grains_dropper_generator():
-            last_X, last_y = dropper.last_X_y
+            if validation:
+                last_X, last_y = dropper.last_validation_X_y
+            else:
+                last_X, last_y = dropper.last_X_y
             if last_X is not None:
                 last_X[constants.TimeSeriesInternal.DUMMY_TARGET_COLUMN] = last_y
                 dfs.append(last_X)
 
         if dfs:
             last_X = pd.concat(dfs, sort=False)
             last_y = last_X.pop(constants.TimeSeriesInternal.DUMMY_TARGET_COLUMN).values
-            return last_X, last_y
-        else:
-            return None, None
+        return last_X, last_y
+
+    @property
+    def last_X_y(self) -> Tuple[Optional[pd.DataFrame], Optional[np.ndarray]]:
+        """Last X and y in the fit data."""
+        return self._get_last_X_y()
+
+    @property
+    def last_validation_X_y(self) -> Tuple[Optional[pd.DataFrame], Optional[np.ndarray]]:
+        """Last X and y in the validation data."""
+        return self._get_last_X_y(validation=True)
```

## azureml/training/tabular/models/forecasting_pipeline_wrapper.py

```diff
@@ -210,15 +210,15 @@
         y_transformer = None
         if hasattr(self.pipeline, 'y_transformer'):
             y_transformer = self.pipeline.y_transformer
         ForecastingPipelineWrapperBase.__init__(self, ts_transformer, y_transformer)
 
         # Calling fit naive here as we don't explicitly calling the fit method.
         if self._get_not_none_ts_transformer().has_unique_target_grains_dropper:
-            self._fit_naive()
+            self._fit_naive(True)
 
     def __setstate__(self, state: Dict[str, Any]):
         if "_y_transformer" not in state:
             state["_y_transformer"] = None
         self.__dict__.update(state)
 
     def _get_preprocessors_and_forecaster(self) -> Tuple[List[Any], Any]:
@@ -399,16 +399,16 @@
 
         # Order the time series data frame as it was encountered as in initial input.
         if X_pred is not None:
             test_feats = self.align_output_to_input(Xy_pred_in, test_feats)
         else:
             test_feats.sort_index(inplace=True)
         # Gap adjustment
-        if (not max_horizon_exceeded and hasattr(self, 'adj_dict') and self.adj_dict
-                and TimeSeriesInternal.ADJUSTMENT in self.adj_dict and self.adj_dict[TimeSeriesInternal.ADJUSTMENT]):
+        if (not max_horizon_exceeded and hasattr(self, 'adj_dict') and self.adj_dict and
+                TimeSeriesInternal.ADJUSTMENT in self.adj_dict and self.adj_dict[TimeSeriesInternal.ADJUSTMENT]):
             test_feats = ForecastingPipelineWrapperBase._adjust_forecast(test_feats,
                                                                          self.adj_dict,
                                                                          self.target_column_name,
                                                                          self.time_column_name,
                                                                          self.grain_column_names)
         y_pred = test_feats[self.target_column_name].to_numpy()
 
@@ -575,25 +575,30 @@
                 mod_time = [1] * len(horizons)
         else:
             # If no horizon is present we are doing a forecast with no lookback features.
             # The last known timestamp can be used to calculate the horizon. We can then apply
             # an increase in uncertainty as horizon increases.
             def add_horizon(grp):
                 grains = grp.name
-                last_known_single_grain = dict_known[grains]
-                forecast_times = grp.index.get_level_values(self.time_column_name)
-                date_grid = pd.date_range(
-                    last_known_single_grain, forecast_times.max(), freq=freq
-                )
-
-                grp[MOD_TIME_COLUMN_CONSTANT] = [
-                    (date_grid.get_loc(forecast_times[i])
-                     if forecast_times[i] >= last_known_single_grain else 1)
-                    for i in range(len(grp))
-                ]
+                if grains in dict_known:
+                    last_known_single_grain = dict_known[grains]
+                    forecast_times = grp.index.get_level_values(self.time_column_name)
+                    date_grid = pd.date_range(
+                        last_known_single_grain, forecast_times.max(), freq=freq
+                    )
+
+                    grp[MOD_TIME_COLUMN_CONSTANT] = [
+                        (date_grid.get_loc(forecast_times[i])
+                         if forecast_times[i] >= last_known_single_grain else 1)
+                        for i in range(len(grp))
+                    ]
+                else:
+                    # If we have encountered grain not present in the training set, we will set mod_time to 1
+                    # as finally we will get NaN as a prediction.
+                    grp[MOD_TIME_COLUMN_CONSTANT] = 1
                 return grp
 
             # We can groupby grain and then apply the horizon based on the time index within the grain
             # and the last known timestamps. We still need to know the horizons, but in this case the model
             # is not horizon aware, so there should only be one stddev and any forecast will use that value
             # with horizon (mod_time) used to increase uncertainty.
             mod_time = transformed_data.groupby(self.grain_column_names) \
@@ -606,15 +611,15 @@
                 horizon_stddevs[idx] = self._stddev[horizon] * is_not_known[idx] * math.sqrt(mod_time[idx])
             except IndexError:
                 # In case of short training set cv may have nor estimated
                 # stdev for highest horizon(s). Fix it by returning np.NaN
                 horizon_stddevs[idx] = np.NaN
 
         # Get the prediction quantiles
-        pred_quantiles = self._get_ci(pred, horizon_stddevs, self._quantiles)
+        pred_quantiles = self._get_ci(pred, horizon_stddevs, self.quantiles)
 
         # Get time and grain columns from transformed data
         transformed_data = transformed_data.reset_index()
         time_column = transformed_data[self.time_column_name]
         grain_df = None
         if (self.grain_column_names is not None) and \
                 (self.grain_column_names[0] != TimeSeriesInternal.DUMMY_GRAIN_COLUMN):
```

## azureml/training/tabular/models/forecasting_pipeline_wrapper_base.py

```diff
@@ -111,15 +111,18 @@
         self._origin_col_name = ts_transformer.origin_column_name
         self._time_col_name = ts_transformer.time_column_name
         self.grain_column_names = ts_transformer.grain_column_names
         self.target_column_name = ts_transformer.target_column_name
         self.data_frequency = cast(pd.DateOffset, ts_transformer.freq_offset)
         self.forecast_origin = ts_transformer.dict_latest_date
         if ts_transformer.has_unique_target_grains_dropper:
-            self._update_forecast_origin(ts_transformer.unique_target_grain_dropper.last_X_y[0])
+            if ts_transformer.unique_target_grain_dropper.last_validation_X_y[0] is not None:
+                self._update_forecast_origin(ts_transformer.unique_target_grain_dropper.last_validation_X_y[0])
+            else:
+                self._update_forecast_origin(ts_transformer.unique_target_grain_dropper.last_X_y[0])
 
     @property
     def time_column_name(self) -> str:
         """Return the name of the time column."""
         return cast(str, self._time_col_name)
 
     @property
@@ -621,54 +624,59 @@
             forecast_df.sort_values(cols_in_result_df, inplace=True, ignore_index=True)
         return forecast_df
 
     def forecast_quantiles(
             self,
             X_pred: Optional[pd.DataFrame] = None,
             y_pred: Optional[Union[pd.DataFrame, np.ndarray]] = None,
+            quantiles: Optional[Union[float, List[float]]] = None,
             forecast_destination: Optional[pd.Timestamp] = None,
             ignore_data_errors: bool = False) -> pd.DataFrame:
         """
         Get the prediction and quantiles from the fitted pipeline.
 
         :param X_pred: the prediction dataframe combining X_past and X_future in a time-contiguous manner.
                        Empty values in X_pred will be imputed.
         :param y_pred: the target value combining definite values for y_past and missing values for Y_future.
                        If None the predictions will be made for every X_pred.
+        :param quantiles: The list of quantiles at which we want to forecast.
+        :type quantiles: float or list of floats
         :param forecast_destination: Forecast_destination: a time-stamp value.
                                      Forecasts will be made all the way to the forecast_destination time,
                                      for all grains. Dictionary input { grain -> timestamp } will not be accepted.
                                      If forecast_destination is not given, it will be imputed as the last time
                                      occurring in X_pred for every grain.
         :type forecast_destination: pandas.Timestamp
         :param ignore_data_errors: Ignore errors in user data.
         :type ignore_data_errors: bool
-        :return: A dataframe containing time, grain, and corresponding quantiles for requested prediction.
+        :return: A dataframe containing the columns and predictions made at requested quantiles.
         """
+        default_quantiles = self.quantiles
+        if quantiles:
+            self.quantiles = quantiles
         # First get the point forecast
         pred, transformed_data = self.forecast(X_pred, y_pred, forecast_destination, ignore_data_errors)
-
         _, forecast_df = self._scenario_forecast(
             ForecastingPipelineWrapperBase._FORECAST_SCENARIO_FORECAST_QUANTILES,
             X_pred, y_pred,
             forecast_destination=forecast_destination, ignore_data_errors=ignore_data_errors,
             pred=pred, transformed_data=transformed_data,
         )
-
+        self.quantiles = default_quantiles
         return forecast_df
 
     def fit(self, X: pd.DataFrame, y: np.ndarray) -> 'ForecastingPipelineWrapperBase':
         """
         Fit the model with input X and y.
 
         :param X: Input X data.
         :param y: Input y data.
         """
         if self._get_not_none_ts_transformer().has_unique_target_grains_dropper:
-            self._fit_naive()
+            self._fit_naive(True)
         return self._pipeline_fit_internal(X, y)
 
     def _update_forecast_origin(self, df: pd.DataFrame) -> None:
         for grain, df_one in df.groupby(self.grain_column_list):
             self.forecast_origin[grain] = pd.Timestamp(df_one.reset_index()[self.time_column_name].values[-1])
 
     def _extend_internal(self, preprocessors: List[Any], forecaster: Any, X_known: pd.DataFrame,
@@ -1927,20 +1935,27 @@
         if isinstance(model_obj, (PreFittedSoftVotingRegressor, StackEnsembleRegressor)):
             return any(isinstance(forecaster, _MultiGrainForecastBase)
                        for forecaster in self._get_estimators_in_ensemble(model_obj))
         else:
             return isinstance(model_obj, _MultiGrainForecastBase)
 
     # region Naive Forecaster related methods.
-    def _fit_naive(self) -> 'ForecastingPipelineWrapperBase':
-        """Fit the result on the naive part."""
+    def _fit_naive(self, on_validation_data: bool = False) -> 'ForecastingPipelineWrapperBase':
+        """
+        Fit the result on the naive part.
+
+        :param on_validation_data: The test predictions will come from the latest observations in the validation set.
+        """
         ts_transformer = self._get_not_none_ts_transformer()
         if self._naive_model is None:
             self._naive_model = Naive(ts_transformer.parameters, ts_transformer.freq, allow_extend_missing_X=True)
-        last_X, last_y = ts_transformer.unique_target_grain_dropper.last_X_y
+        if on_validation_data and ts_transformer.unique_target_grain_dropper.last_validation_X_y[0] is not None:
+            last_X, last_y = ts_transformer.unique_target_grain_dropper.last_validation_X_y
+        else:
+            last_X, last_y = ts_transformer.unique_target_grain_dropper.last_X_y
         Contract.assert_non_empty(last_X, "last_X")
         Contract.assert_non_empty(last_y, "last_y")
         last_X = cast(pd.DataFrame, last_X)
         last_y = cast(np.ndarray, last_y)
         self._update_forecast_origin(last_X)
         self._naive_model.fit(last_X, last_y)
         return self
@@ -1949,15 +1964,15 @@
             self,
             Xy_pred_in: pd.DataFrame,
             ignore_data_errors: bool,
             dict_rename_back: Optional[Dict[str, Any]] = None
     ) -> Optional[pd.DataFrame]:
         """Get the forecast result using naive forecaster."""
         if self._naive_model is None:
-            self._fit_naive()
+            self._fit_naive(True)
         self._naive_model = cast(Naive, self._naive_model)
 
         # No unique target grains passed in.
         if Xy_pred_in.empty:
             return None
         Xy_pred, Xy_known, _ = self._prepare_prediction_data_for_forecast(
             Xy_pred_in, ignore_data_errors=ignore_data_errors)
```

## azureml/training/tabular/preprocessing/data_cleaning.py

```diff
@@ -3,16 +3,18 @@
 # ---------------------------------------------------------
 import logging
 from typing import Optional, Tuple, Union
 
 import numpy as np
 import pandas as pd
 import scipy
+from azureml._common._error_definition import AzureMLError
+from azureml.automl.core.shared._diagnostics.automl_error_definitions import AllTargetsNan
 
-from azureml._base_sdk_common._docstring_wrapper import experimental
+from azureml.automl.core.shared.exceptions import DataException
 
 from .._types import CoreDataInputType, CoreDataSingleColumnInputType
 
 from azureml.automl.core.constants import TransformerParams, SupportedTransformers
 from azureml.automl.core.featurization import FeaturizationConfig
 
 logger = logging.getLogger(__name__)
@@ -47,14 +49,19 @@
     if X is not None and y is not None and _remove_y_nan_needed(is_timeseries, target_column, featurization_config):
         if isinstance(y, pd.DataFrame):
             y = y.values.ravel()
         nan_y_index = _get_indices_missing_labels_output_column(y)
 
         logger.info("Inspecting target column for missing values.")
 
+        if len(nan_y_index) == X.shape[0]:
+            logger.error("All values in the target column evaluated to one of '[None, \"\", \"nan\"]') during "
+                         "data cleaning, resulting in an empty training data set.")
+            raise DataException(azureml_error=AzureMLError.create(AllTargetsNan, target="y"))
+
         if len(nan_y_index) > 0:
             logger.info("Dropping rows with invalid or empty values [np.nan, 'nan', '', None] in the target column.")
             y_new = np.delete(y, nan_y_index)
             if scipy.sparse.issparse(X):
                 X_new = X_new.toarray()
             if isinstance(X_new, pd.DataFrame):
                 X_new = X_new.iloc[list(set(range(X_new.shape[0])) - set(nan_y_index))]
```

## Comparing `azureml_training_tabular-1.49.1.dist-info/LICENSE.txt` & `azureml_training_tabular-1.50.0.dist-info/LICENSE.txt`

 * *Files identical despite different names*

## Comparing `azureml_training_tabular-1.49.1.dist-info/METADATA` & `azureml_training_tabular-1.50.0.dist-info/METADATA`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: azureml-training-tabular
-Version: 1.49.1
+Version: 1.50.0
 Summary: Contains ML models, featurizers and scoring code which can either be used with AutoML or standalone.
 Home-page: https://docs.microsoft.com/python/api/overview/azure/ml/?view=azure-ml-py
 Author: Microsoft Corp
 License: https://aka.ms/azureml-sdk-license
 Platform: UNKNOWN
 Classifier: Development Status :: 5 - Production/Stable
 Classifier: Intended Audience :: Developers
@@ -16,15 +16,15 @@
 Classifier: Programming Language :: Python :: 3.8
 Classifier: Topic :: Scientific/Engineering :: Artificial Intelligence
 Classifier: Operating System :: Microsoft :: Windows
 Classifier: Operating System :: MacOS
 Classifier: Operating System :: POSIX :: Linux
 Requires-Python: >=3.7,<3.9
 Description-Content-Type: text/x-rst
-Requires-Dist: azureml-automl-core (~=1.49.1)
+Requires-Dist: azureml-automl-core (~=1.50.0)
 Requires-Dist: dill (<0.4.0,>=0.2.8)
 Requires-Dist: gensim (<3.9.0)
 Requires-Dist: smart-open (<=1.9.0)
 Requires-Dist: lightgbm (<=3.2.1,>=2.0.11)
 Requires-Dist: pandas (==1.1.5)
 Requires-Dist: psutil (<6.0.0,>=5.2.2)
 Requires-Dist: scipy (<=1.5.3,>=1.0.0)
```

## Comparing `azureml_training_tabular-1.49.1.dist-info/RECORD` & `azureml_training_tabular-1.50.0.dist-info/RECORD`

 * *Files 2% similar despite different names*

```diff
@@ -1,13 +1,13 @@
 azureml/__init__.py,sha256=_a9uPeIDwvRCe07_84QytQ_Qv9bbO1lGzZnfArCb66o,267
 azureml/training/__init__.py,sha256=_a9uPeIDwvRCe07_84QytQ_Qv9bbO1lGzZnfArCb66o,267
 azureml/training/tabular/__init__.py,sha256=-DmfTHycKcvvWx-YpsEOaL5Kt_NSCjrjYjRWGkUF9BY,574
 azureml/training/tabular/_types.py,sha256=UeW0d5d1LmlxC05Vt0aHIx0RKF-49ltOkOCLPeWywyI,1896
-azureml/training/tabular/_version.py,sha256=wRfg0YCwjcI2BFfGz_ZyG2c4M_EIcRC_pnn95r8HbGU,36
-azureml/training/tabular/_constants/__init__.py,sha256=jD4T-ppF2ZvPtga3waMxIvFWUGMDcbY7F0E1XvH5w54,29112
+azureml/training/tabular/_version.py,sha256=xqpEx6QygS_dX6G8s7BZ2_7aMS5GjnkxYk1ou2bHUjU,36
+azureml/training/tabular/_constants/__init__.py,sha256=TG4nXbcp_PwW-e_pZ2sAAtvC_qv7sT9DTwnSdAEdX9k,29157
 azureml/training/tabular/_diagnostics/__init__.py,sha256=JlCCObuOLZyNhIZlsoL51KtFxiY4xKIIzIRDBcdeu6Y,183
 azureml/training/tabular/_diagnostics/azureml_error.py,sha256=tkgzFjoMt5Z9Bg5Hi62xnzzFn0Ej6iOLlBklH47eGEM,721
 azureml/training/tabular/_diagnostics/contract.py,sha256=NE-FctLGjF73t5hkPJozFAOWptHw4CohLZ84eBQ5BmM,7175
 azureml/training/tabular/_diagnostics/debug_logging.py,sha256=7An0ZU2j3CLHHB_eyqLOMPsLL_4n_3D2R3juzoPogfo,1219
 azureml/training/tabular/_diagnostics/error_definitions.py,sha256=wskI93Gftr0NWCZhuEudm1zmW0gRDr-ukfnsOi445u4,65271
 azureml/training/tabular/_diagnostics/error_strings.py,sha256=XEAS2hsznaXwpyTkOA_Qe-XaCliO04mF--0TAcWLjFg,67635
 azureml/training/tabular/_diagnostics/errors.py,sha256=wzHYJmMztycI7hVT0ZPKFsKbvuDnBL6J9Ym3iXG7icg,2035
@@ -76,52 +76,54 @@
 azureml/training/tabular/featurization/timeseries/restore_dtypes_transformer.py,sha256=zKApv6SM-gmtE_8t_8jnRWcURuhptqz2Twdp6jGzLS0,6203
 azureml/training/tabular/featurization/timeseries/rolling_window.py,sha256=r3qAgzEWTtMwPXDd5lPxLYI-Ax13psM3DBTusVf9Y90,45052
 azureml/training/tabular/featurization/timeseries/short_grain_dropper.py,sha256=7rYj0ydCUR1i3HJxXoQTC-5TeVvSYPHUPLEhCjRXD3c,5415
 azureml/training/tabular/featurization/timeseries/stationary_featurizer.py,sha256=GCxhwYquGGmvgXI63_TBQYjbZV-J28mgIWlE6IcHNyo,10660
 azureml/training/tabular/featurization/timeseries/stl_featurizer.py,sha256=yP2DQ6x1cmhIZVa0uPiYTLi1si2hFtFQphDb7OTaOIw,33731
 azureml/training/tabular/featurization/timeseries/time_index_featurizer.py,sha256=9VvK-KZWdBzNC2wTjuA27_fq5XmpEFwQXPBWs0PQaEs,31506
 azureml/training/tabular/featurization/timeseries/time_series_imputer.py,sha256=lSq2jUCRYXCSpk4roKf1Xze1pzD4GCLpJWoGYeevZUA,56825
-azureml/training/tabular/featurization/timeseries/timeseries_transformer.py,sha256=eL3ByKjuYBAUyuWF4NxQMrUxzoy9NYxWUeuKM8XU3sM,83708
+azureml/training/tabular/featurization/timeseries/timeseries_transformer.py,sha256=YQHK2PDMU6d9wfy7uMS29rTLVceL2iBFDXrXbHOiOE4,83822
 azureml/training/tabular/featurization/timeseries/transform_utils.py,sha256=TXd9ona-FMfQp4Po_huIe_Ur9DB40O30hMJNTl-jprw,11689
-azureml/training/tabular/featurization/timeseries/unique_target_grain_dropper.py,sha256=Ww3g8t3wpfeVB-k5eFmkNSUaKeKnXeE2JJaCwdxiwD4,3763
-azureml/training/tabular/featurization/timeseries/unique_target_grain_dropper_base.py,sha256=_HmFoskhpvMKMd95mjlC_gsBaCftcgpCmPkp1skbEkU,3767
+azureml/training/tabular/featurization/timeseries/unique_target_grain_dropper.py,sha256=ba5AfV7mudVpvnYAKfl793vOG6AZu0Zk0hMWjZcDSs0,4988
+azureml/training/tabular/featurization/timeseries/unique_target_grain_dropper_base.py,sha256=T-yklBEEIk1gJZbpMKoqIZAv3Ujd-iZlrei9qhSMNeU,4050
 azureml/training/tabular/featurization/timeseries/_data/__init__.py,sha256=O16u6qXGAgfu5PX10WfN64BK7z1LqQChNKdQ7-NJvI4,244
 azureml/training/tabular/featurization/timeseries/_data/holiday_effect_window.7z,sha256=gUKBexf1BjVWDDjue00PXl0CTwKRUrvwK5c6VmJFohM,6580
 azureml/training/tabular/featurization/timeseries/_data/holidays.7z,sha256=9Pn8V5UQNNCVX_wcU8fSKsEBdHo6y_pzmEIuMD1EXU0,1057912
 azureml/training/tabular/featurization/timeseries/_data/holidays_origin.7z,sha256=a-Y3QvgkRoW7HcAxDTzsv_sEcIoC28QJ9QMOICWJKSs,146216
 azureml/training/tabular/featurization/timeseries/_distributed/__init__.py,sha256=5p-vUiu6MCBIpaGKSDzBge52s551ZPk_Y0WtwCruiS0,243
 azureml/training/tabular/featurization/timeseries/_distributed/_distributed_timeseries_util.py,sha256=OvgBbaF04ejJcfddofUF1ktBPyxLqgf_869zaAjymJE,2512
 azureml/training/tabular/featurization/timeseries/_distributed/aggregate_transformer.py,sha256=UocmgXOjdgopwSU08QC0iHzUtQLHb2c_1Ww8c7FELRU,3748
 azureml/training/tabular/featurization/timeseries/_distributed/aggregated_grain_dropper.py,sha256=GXEVN3A1auIFtnhg2p-lDpK4JVDVfRhvGwC9hUd-od8,1718
 azureml/training/tabular/featurization/timeseries/_distributed/aggregated_transformer_factory.py,sha256=NnXezMI_WX_2Tr3AhWZcNoOK9Ap1NehA4VDNReIkAxs,1417
-azureml/training/tabular/featurization/timeseries/_distributed/aggregated_unique_target_grain_dropper.py,sha256=FDmJT7PJ3tlhs6HEuwdJbubMJ4k3LS9bE58JS48l6Ro,2369
+azureml/training/tabular/featurization/timeseries/_distributed/aggregated_unique_target_grain_dropper.py,sha256=VIOzUgO6IWOn26d7iK_zIZ390Jj7hbBheQj_kwQXtUE,3071
 azureml/training/tabular/featurization/timeseries/_distributed/timeseries_data_profile.py,sha256=bIb149jBLQxhl9l7ttrkeZt1eLUH0hAiPaJPa3Wp7LY,9359
 azureml/training/tabular/models/__init__.py,sha256=B2RaEMXjlPJtUA_bXc-ujVPwL6DFRtHLihbVymqpQjI,952
 azureml/training/tabular/models/_abstract_model_wrapper.py,sha256=-k9Q8NtR9VSzahFZFW7dpgZW-nfGV9zWL91pABeLLgI,632
 azureml/training/tabular/models/_forecast_scenario_data.py,sha256=2Tlhrj6pZSdLgV6i5ydxFapqRzV_TxW8-PUcg5CTn3Q,2712
 azureml/training/tabular/models/calibrated_model.py,sha256=scZyl5RsQPKeP5ZVCTvYs6XwDjwZvX7Neh6zagbFqrg,9573
 azureml/training/tabular/models/differencing_y_transformer.py,sha256=-lwBXWAMnXpkyvBq6UCJTti9WS0v0y5-d-EB7lSVESo,15685
 azureml/training/tabular/models/forecasting_models.py,sha256=127WHVPBMIE-b53GnHMmAzzW90Or1pjqH7JMm4Hhcyg,20434
-azureml/training/tabular/models/forecasting_pipeline_wrapper.py,sha256=sJmWUCwN5t0fRhQS4BbBTpubry1fhqiB_3-VqUN8apk,47413
-azureml/training/tabular/models/forecasting_pipeline_wrapper_base.py,sha256=vr_ox0CQJAemrwnQHLwQTujuqNTj7jvWD1fOfP0vVX8,114293
+azureml/training/tabular/models/forecasting_pipeline_wrapper.py,sha256=YT52f6YI1Ja5xie9vduUrEmPhh4kdtaLXdfZKMcTQWM,47754
+azureml/training/tabular/models/forecasting_pipeline_wrapper_base.py,sha256=pFv4I-t5TtQtS2cYVLwrszj6TScLvm_Uno1OO8AXgbU,115267
 azureml/training/tabular/models/pipeline_with_ytransformations.py,sha256=qKbUybxdm0xL2pAqcTqwBTO6IPjdz5YLMTa3NgTr1ug,9300
 azureml/training/tabular/models/sparse_scale_zero_one.py,sha256=g-WBDovVHdLs4SGBcqErvHkzenM-_cOcSQXDRRZEyoc,3162
 azureml/training/tabular/models/stack_ensemble.py,sha256=kDKl4-3hMKKMP-MmlzZpanGiqUgs8nxqWdrAsLEfCkk,16802
 azureml/training/tabular/models/target_type_transformer.py,sha256=M15HhdSEdAR1i9ILz09U88hVE-iZ0Kjy6InQn5UfGh4,2687
 azureml/training/tabular/models/voting_ensemble.py,sha256=7pV3v0zCSXikeiOMTQdOMMuoN7BDylhOhO2u8UYmnkY,17575
 azureml/training/tabular/models/y_pipeline_transformer.py,sha256=gNhWr_Ko-ExXIodCkFin1xnOTWkf9opM9Bn4vOxNiM8,3559
 azureml/training/tabular/models/_timeseries/__init__.py,sha256=JlCCObuOLZyNhIZlsoL51KtFxiY4xKIIzIRDBcdeu6Y,183
 azureml/training/tabular/models/_timeseries/_arimax.py,sha256=_GlrgxU6nJ3D66Yo68cF5fZ4Crfsyl8JVJ17ioVUlkE,16166
 azureml/training/tabular/models/_timeseries/_auto_arima.py,sha256=GausIFXjUk6EWiqTpLGF7xvdyaG3QgW7Rl2wP2frBto,8880
 azureml/training/tabular/models/_timeseries/_exponential_smoothing.py,sha256=Kcq9GEqP5YALIM3N4as6ufc-Q0GiK9ei7Mj2PCsZtFw,12145
 azureml/training/tabular/models/_timeseries/_multi_grain_forecast_base.py,sha256=gYQQAr11kLW0ZSwYekmmzpvyibccm6Ai1xlHAN7VFXc,40663
 azureml/training/tabular/models/_timeseries/_prophet_model.py,sha256=zazNWTRy-1-BY7etju419cy-V5zfZNv7FLDnX8hQFjw,9573
+azureml/training/tabular/models/mlflow/__init__.py,sha256=_a9uPeIDwvRCe07_84QytQ_Qv9bbO1lGzZnfArCb66o,267
+azureml/training/tabular/models/mlflow/timeseries/__init__.py,sha256=8PWFeJuDK0HY4eqVLhr-0zXVaiIbNdn50-Xs7zPIAOo,17673
 azureml/training/tabular/preprocessing/__init__.py,sha256=JlCCObuOLZyNhIZlsoL51KtFxiY4xKIIzIRDBcdeu6Y,183
 azureml/training/tabular/preprocessing/_dataset_binning.py,sha256=953HJoBbfflgIymR9iBjlQuiRMAgAjOSuVcW6-B-39w,10101
-azureml/training/tabular/preprocessing/data_cleaning.py,sha256=OZBn5PIdmc6uvmcDXHu6nh_iTYN0NWTfXmGvAppCetM,3965
+azureml/training/tabular/preprocessing/data_cleaning.py,sha256=_PXavKOTE0PQ0O-Vsk2z_oRQH6Rxm14rCeh6wOdTJlQ,4451
 azureml/training/tabular/score/__init__.py,sha256=-vcJch0GaeNUqYk6FqAaQWeKEE1mdH2jD0NXdMB0_iA,223
 azureml/training/tabular/score/_classification.py,sha256=2yNfLq_XG5bB_wOxN3e03B2Q_4kXrk7Jg_nljjv7v2A,46470
 azureml/training/tabular/score/_cv_splits.py,sha256=8Fdychyy51wTQR0s7bPZH7_oyKrhEbJTu2o8VMftsrE,38507
 azureml/training/tabular/score/_forecasting.py,sha256=Mv6LDmNvQK2PRaICqxrOb_WfxgJ8pw0OisrToInwPz4,23809
 azureml/training/tabular/score/_metric_base.py,sha256=ukYtIXZbkZKIbtLJ7Z_VppQKaJ2CoN7a_0Vr8BO8mI0,5122
 azureml/training/tabular/score/_regression.py,sha256=hhQT7LozM4DLMzgfa7Rc5aqa2b0Y7FVAIpphOk6yqvg,24431
 azureml/training/tabular/score/_scoring_utilities.py,sha256=4nywpsZiojOba3QdpJ5anBFfKy5SGjpqUedSjlxGlHQ,31164
@@ -139,12 +141,12 @@
 azureml/training/tabular/timeseries/_time_series_data_config.py,sha256=_RYQmU5mIvnWlyK38PxdI5DrNX70k4ywiiHlWsblfzg,5159
 azureml/training/tabular/timeseries/_time_series_data_set.py,sha256=l2wkyDKqRFhcldfTvHuphycmGFFKBpoC_RcqtEqxg3Q,60535
 azureml/training/tabular/timeseries/forecasting_ts_utils.py,sha256=jHI4S7Q20uaEB5-8wYrWVsA8Km2_bozks0D5dXeeikM,14778
 azureml/training/tabular/timeseries/forecasting_utilities.py,sha256=gAKNNmQtb8Cp2Wif_1sSiSH51_wr3Y1quImIbUwFY8I,15116
 azureml/training/tabular/timeseries/forecasting_verify.py,sha256=_5cufa4YpT3SNbxsZRfd8U-FFaH7gguWZaUBdtVfwLI,10258
 azureml/training/tabular/timeseries/rolling_origin_validator.py,sha256=27oKNcsNwHdosC9OGzp34N30WBngtG2CMn847ynmTPc,9999
 azureml/training/tabular/timeseries/time_series_data_frame.py,sha256=ylxjEmjKWNt5ki5gzffQVz9YYnRBTt6CmaSnUpkkrao,126478
-azureml_training_tabular-1.49.1.dist-info/LICENSE.txt,sha256=GBoIyZ-6vJ4xjRc8U3wTw4EfkuaEdVTm_gbr1Nm8uDI,859
-azureml_training_tabular-1.49.1.dist-info/METADATA,sha256=Zfijv1rn4CIOVfeiHzkSKIPk0bo512CMMEC3jyppl_E,2250
-azureml_training_tabular-1.49.1.dist-info/WHEEL,sha256=YUYzQ6UQdoqxXjimOitTqynltBCkwY6qlTfTh2IzqQU,97
-azureml_training_tabular-1.49.1.dist-info/top_level.txt,sha256=ZOeEa0TAXo6i5wOjwBoqfIGEuxOcKuscGgNSpizqREY,8
-azureml_training_tabular-1.49.1.dist-info/RECORD,,
+azureml_training_tabular-1.50.0.dist-info/LICENSE.txt,sha256=GBoIyZ-6vJ4xjRc8U3wTw4EfkuaEdVTm_gbr1Nm8uDI,859
+azureml_training_tabular-1.50.0.dist-info/METADATA,sha256=Gm3Az70nJhdyd0efJVpoeEdVO9TIDoDEjqnWR9AGbtk,2250
+azureml_training_tabular-1.50.0.dist-info/WHEEL,sha256=YUYzQ6UQdoqxXjimOitTqynltBCkwY6qlTfTh2IzqQU,97
+azureml_training_tabular-1.50.0.dist-info/top_level.txt,sha256=ZOeEa0TAXo6i5wOjwBoqfIGEuxOcKuscGgNSpizqREY,8
+azureml_training_tabular-1.50.0.dist-info/RECORD,,
```

