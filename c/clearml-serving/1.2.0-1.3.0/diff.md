# Comparing `tmp/clearml_serving-1.2.0-py3-none-any.whl.zip` & `tmp/clearml_serving-1.3.0-py3-none-any.whl.zip`

## zipinfo {}

```diff
@@ -1,24 +1,24 @@
-Zip file size: 51597 bytes, number of entries: 22
--rw-r--r--  2.0 unx        0 b- defN 22-Oct-08 11:39 clearml_serving/__init__.py
--rw-r--r--  2.0 unx    29932 b- defN 22-Oct-08 11:39 clearml_serving/__main__.py
--rw-r--r--  2.0 unx       22 b- defN 22-Oct-08 11:39 clearml_serving/version.py
--rw-r--r--  2.0 unx        0 b- defN 22-Oct-08 11:39 clearml_serving/engines/__init__.py
--rw-r--r--  2.0 unx        0 b- defN 22-Oct-08 11:39 clearml_serving/engines/triton/__init__.py
--rw-r--r--  2.0 unx    22705 b- defN 22-Oct-08 11:39 clearml_serving/engines/triton/triton_helper.py
--rw-r--r--  2.0 unx        0 b- defN 22-Oct-08 11:39 clearml_serving/serving/__init__.py
--rw-r--r--  2.0 unx     6260 b- defN 22-Oct-08 11:39 clearml_serving/serving/endpoints.py
--rw-r--r--  2.0 unx     1330 b- defN 22-Oct-08 11:39 clearml_serving/serving/init.py
--rw-r--r--  2.0 unx     3416 b- defN 22-Oct-08 11:39 clearml_serving/serving/main.py
--rw-r--r--  2.0 unx    55993 b- defN 22-Oct-08 11:39 clearml_serving/serving/model_request_processor.py
--rw-r--r--  2.0 unx    23305 b- defN 22-Oct-08 11:39 clearml_serving/serving/preprocess_service.py
--rw-r--r--  2.0 unx      158 b- defN 22-Oct-08 11:39 clearml_serving/serving/uvicorn_mp_entrypoint.py
--rw-r--r--  2.0 unx        0 b- defN 22-Oct-08 11:39 clearml_serving/statistics/__init__.py
--rw-r--r--  2.0 unx     1493 b- defN 22-Oct-08 11:39 clearml_serving/statistics/main.py
--rw-r--r--  2.0 unx    14140 b- defN 22-Oct-08 11:39 clearml_serving/statistics/metrics.py
--rw-r--r--  2.0 unx    11357 b- defN 22-Oct-08 11:40 clearml_serving-1.2.0.dist-info/LICENSE
--rw-r--r--  2.0 unx    20824 b- defN 22-Oct-08 11:40 clearml_serving-1.2.0.dist-info/METADATA
--rw-r--r--  2.0 unx       92 b- defN 22-Oct-08 11:40 clearml_serving-1.2.0.dist-info/WHEEL
--rw-r--r--  2.0 unx       67 b- defN 22-Oct-08 11:40 clearml_serving-1.2.0.dist-info/entry_points.txt
--rw-r--r--  2.0 unx       16 b- defN 22-Oct-08 11:40 clearml_serving-1.2.0.dist-info/top_level.txt
-?rw-rw-r--  2.0 unx     2019 b- defN 22-Oct-08 11:40 clearml_serving-1.2.0.dist-info/RECORD
-22 files, 193129 bytes uncompressed, 48231 bytes compressed:  75.0%
+Zip file size: 52096 bytes, number of entries: 22
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-12 21:37 clearml_serving/__init__.py
+-rw-r--r--  2.0 unx    29932 b- defN 23-Apr-12 21:37 clearml_serving/__main__.py
+-rw-r--r--  2.0 unx       22 b- defN 23-Apr-12 21:37 clearml_serving/version.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-12 21:37 clearml_serving/engines/__init__.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-12 21:37 clearml_serving/engines/triton/__init__.py
+-rw-r--r--  2.0 unx    22705 b- defN 23-Apr-12 21:37 clearml_serving/engines/triton/triton_helper.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-12 21:37 clearml_serving/serving/__init__.py
+-rw-r--r--  2.0 unx     6260 b- defN 23-Apr-12 21:37 clearml_serving/serving/endpoints.py
+-rw-r--r--  2.0 unx     1330 b- defN 23-Apr-12 21:37 clearml_serving/serving/init.py
+-rw-r--r--  2.0 unx     3416 b- defN 23-Apr-12 21:37 clearml_serving/serving/main.py
+-rw-r--r--  2.0 unx    57531 b- defN 23-Apr-12 21:37 clearml_serving/serving/model_request_processor.py
+-rw-r--r--  2.0 unx    23891 b- defN 23-Apr-12 21:37 clearml_serving/serving/preprocess_service.py
+-rw-r--r--  2.0 unx      158 b- defN 23-Apr-12 21:37 clearml_serving/serving/uvicorn_mp_entrypoint.py
+-rw-r--r--  2.0 unx        0 b- defN 23-Apr-12 21:37 clearml_serving/statistics/__init__.py
+-rw-r--r--  2.0 unx     1493 b- defN 23-Apr-12 21:37 clearml_serving/statistics/main.py
+-rw-r--r--  2.0 unx    14140 b- defN 23-Apr-12 21:37 clearml_serving/statistics/metrics.py
+-rw-r--r--  2.0 unx    11357 b- defN 23-Apr-12 21:37 clearml_serving-1.3.0.dist-info/LICENSE
+-rw-r--r--  2.0 unx    20875 b- defN 23-Apr-12 21:37 clearml_serving-1.3.0.dist-info/METADATA
+-rw-r--r--  2.0 unx       92 b- defN 23-Apr-12 21:37 clearml_serving-1.3.0.dist-info/WHEEL
+-rw-r--r--  2.0 unx       67 b- defN 23-Apr-12 21:37 clearml_serving-1.3.0.dist-info/entry_points.txt
+-rw-r--r--  2.0 unx       16 b- defN 23-Apr-12 21:37 clearml_serving-1.3.0.dist-info/top_level.txt
+?rw-rw-r--  2.0 unx     2019 b- defN 23-Apr-12 21:37 clearml_serving-1.3.0.dist-info/RECORD
+22 files, 195304 bytes uncompressed, 48730 bytes compressed:  75.0%
```

## zipnote {}

```diff
@@ -42,26 +42,26 @@
 
 Filename: clearml_serving/statistics/main.py
 Comment: 
 
 Filename: clearml_serving/statistics/metrics.py
 Comment: 
 
-Filename: clearml_serving-1.2.0.dist-info/LICENSE
+Filename: clearml_serving-1.3.0.dist-info/LICENSE
 Comment: 
 
-Filename: clearml_serving-1.2.0.dist-info/METADATA
+Filename: clearml_serving-1.3.0.dist-info/METADATA
 Comment: 
 
-Filename: clearml_serving-1.2.0.dist-info/WHEEL
+Filename: clearml_serving-1.3.0.dist-info/WHEEL
 Comment: 
 
-Filename: clearml_serving-1.2.0.dist-info/entry_points.txt
+Filename: clearml_serving-1.3.0.dist-info/entry_points.txt
 Comment: 
 
-Filename: clearml_serving-1.2.0.dist-info/top_level.txt
+Filename: clearml_serving-1.3.0.dist-info/top_level.txt
 Comment: 
 
-Filename: clearml_serving-1.2.0.dist-info/RECORD
+Filename: clearml_serving-1.3.0.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## clearml_serving/__main__.py

```diff
@@ -416,15 +416,15 @@
         '--name', type=str, required=True,
         help='Specifying the model name to be registered in')
     parser_model_upload.add_argument(
         '--tags', type=str, nargs='+',
         help='Optional: Add tags to the newly created model')
     parser_model_upload.add_argument(
         '--project', type=str, required=True,
-        help='Specifying the project for the model tp be registered in')
+        help='Specifying the project for the model to be registered in')
     parser_model_upload.add_argument(
         '--framework', type=str,
         choices=[p for p in Framework.__dict__.keys()
                  if not p.startswith("_") and not callable(getattr(Framework, p))]+["custom"],
         help='[Optional] Specify the model framework: "scikit-learn", "xgboost", "lightgbm", "tensorflow", "pytorch"')
     parser_model_upload.add_argument(
         '--publish', action='store_true',
```

## clearml_serving/version.py

```diff
@@ -1 +1 @@
-__version__ = '1.2.0'
+__version__ = '1.3.0'
```

## clearml_serving/serving/model_request_processor.py

```diff
@@ -5,15 +5,14 @@
 from random import random
 from time import sleep, time
 from typing import Optional, Union, Dict, List
 import itertools
 import threading
 from multiprocessing import Lock
 import asyncio
-from numpy import isin
 from numpy.random import choice
 
 from clearml import Task, Model
 from clearml.utilities.dicts import merge_dicts, cast_str_to_bool
 from clearml.storage.util import hash_dict
 from .preprocess_service import BasePreprocessRequest
 from .endpoints import ModelEndpoint, ModelMonitoring, CanaryEP, EndpointMetricLogging
@@ -284,14 +283,17 @@
             if not Path(preprocess_code).exists():
                 raise ValueError("Preprocessing code \'{}\' could not be found".format(preprocess_code))
             preprocess_artifact_name = "py_code_{}".format(url.replace("/", "_"))
             self._task.upload_artifact(
                 name=preprocess_artifact_name, artifact_object=Path(preprocess_code), wait_on_upload=True)
             endpoint.preprocess_artifact = preprocess_artifact_name
 
+        # register the model
+        self._add_registered_input_model(endpoint_url=endpoint.serving_url, model_id=endpoint.model_id)
+
         self._endpoints[url] = endpoint
         return url
 
     def add_model_monitoring(
             self,
             monitoring: Union[ModelMonitoring, dict],
             preprocess_code: Optional[str] = None,
@@ -344,14 +346,15 @@
         """
         Remove specific model endpoint, use base_model_url as unique identifier
         """
         endpoint_url = self._normalize_endpoint_url(endpoint_url, version)
         if endpoint_url not in self._endpoints:
             return False
         self._endpoints.pop(endpoint_url, None)
+        self._remove_registered_input_model(endpoint_url)
         return True
 
     def add_canary_endpoint(
             self,
             canary: Union[CanaryEP, dict],
     ) -> str:
         """
@@ -684,40 +687,41 @@
                 url = "{}/{}".format(serving_base_url, version)
                 if url in self._model_monitoring_endpoints:
                     continue
                 model = self._model_monitoring.get(serving_base_url)
                 if not model:
                     # this should never happen
                     continue
-                ep = ModelEndpoint(
-                    engine_type=model.engine_type,
-                    serving_url=serving_base_url,
-                    model_id=model_id,
-                    version=str(version),
-                    preprocess_artifact=model.preprocess_artifact,
-                    input_size=model.input_size,
-                    input_type=model.input_type,
-                    output_size=model.output_size,
-                    output_type=model.output_type
-                )
+                model_endpoint_config = {
+                    i: j for i, j in model.as_dict(remove_null_entries=True).items()
+                    if hasattr(ModelEndpoint.__attrs_attrs__, i)
+                }
+                model_endpoint_config["serving_url"] = serving_base_url
+                model_endpoint_config["model_id"] = model_id
+                model_endpoint_config["version"] = str(version)
+                ep = ModelEndpoint(**model_endpoint_config)
                 self._model_monitoring_endpoints[url] = ep
                 dirty = True
 
         # filter out old model monitoring endpoints
         for ep_url in list(self._model_monitoring_endpoints.keys()):
             if not any(True for url in self._model_monitoring_versions if ep_url.startswith(url+"/")):
                 self._model_monitoring_endpoints.pop(ep_url, None)
+                self._remove_registered_input_model(ep_url)
                 dirty = True
 
         # reset flag
         self._model_monitoring_update_request = False
 
         if dirty:
             config_dict = {k: v.as_dict(remove_null_entries=True) for k, v in self._model_monitoring_endpoints.items()}
             self._task.set_configuration_object(name='model_monitoring_eps', config_dict=config_dict)
+            for m in self._model_monitoring_endpoints.values():
+                # log us on the main task
+                self._add_registered_input_model(endpoint_url=m.serving_url, model_id=m.model_id)
 
         return dirty
 
     def _update_monitored_models(self):
         for model in self._model_monitoring.values():
             current_served_models = self._model_monitoring_versions.get(model.base_serving_url, {})
             # To Do: sort by updated time ?
@@ -1295,7 +1299,41 @@
                     'input_type', 'input_size', 'input_name',
                     'output_type', 'output_size', 'output_name',
                 ] if not d.get(k)
             ]
             if not endpoint.auxiliary_cfg and missing:
                 raise ValueError("Triton engine requires input description - missing values in {}".format(missing))
         return True
+
+    def _add_registered_input_model(self, endpoint_url: str, model_id: str) -> bool:
+        """
+        Add registered endpoint url, return True if successful
+        """
+        if not self._task or not model_id or not endpoint_url:
+            return False
+
+        # noinspection PyBroadException
+        try:
+            self._task.set_input_model(model_id=model_id, name=endpoint_url.strip("/"))
+        except Exception:
+            return False
+
+        return True
+
+    def _remove_registered_input_model(self, endpoint_url: str) -> bool:
+        """
+        Remove registered endpoint url, return True if successful
+        """
+        if not self._task or not endpoint_url:
+            return False
+
+        # noinspection PyBroadException
+        try:
+            # we assume we have the API version ot support it
+            from clearml.backend_api.services import tasks
+            self._task.send(tasks.DeleteModelsRequest(
+                task=self._task.id, models=[dict(name=endpoint_url.strip("/"), type=tasks.ModelTypeEnum.input)]
+            ))
+        except Exception:
+            return False
+
+        return True
```

## clearml_serving/serving/preprocess_service.py

```diff
@@ -12,14 +12,15 @@
 
 from .endpoints import ModelEndpoint
 
 
 class BasePreprocessRequest(object):
     __preprocessing_lookup = {}
     __preprocessing_modules = set()
+    _grpc_env_conf_prefix = "CLEARML_GRPC_"
     _default_serving_base_url = "http://127.0.0.1:8080/serve/"
     _server_config = {}  # externally configured by the serving inference service
     _timeout = None  # timeout in seconds for the entire request, set in __init__
     is_preprocess_async = False
     is_process_async = False
     is_postprocess_async = False
 
@@ -242,22 +243,22 @@
             return None
         return return_value.json()
 
 
 @BasePreprocessRequest.register_engine("triton", modules=["grpc", "tritonclient"])
 class TritonPreprocessRequest(BasePreprocessRequest):
     _content_lookup = {
+        getattr(np, 'int', int): 'int_contents',
         np.uint8: 'uint_contents',
         np.int8: 'int_contents',
         np.int64: 'int64_contents',
         np.uint64: 'uint64_contents',
-        np.int: 'int_contents',
         np.int32: 'int_contents',
         np.uint: 'uint_contents',
-        np.bool: 'bool_contents',
+        getattr(np, 'bool', bool): 'bool_contents',
         np.float32: 'fp32_contents',
         np.float64: 'fp64_contents',
     }
     _default_grpc_address = "127.0.0.1:8001"
     _default_grpc_compression = False
     _ext_grpc = None
     _ext_np_to_triton_dtype = None
@@ -322,16 +323,28 @@
         if not triton_server_address:
             raise ValueError("External Triton gRPC server is not configured!")
 
         tid = threading.get_ident()
         if self._grpc_stub.get(tid):
             grpc_stub = self._grpc_stub.get(tid)
         else:
+            channel_opt = []
+            for k, v in os.environ.items():
+                if str(k).startswith(self._grpc_env_conf_prefix):
+                    try:
+                        v = int(v)
+                    except:  # noqa
+                        try:
+                            v = float(v)
+                        except:  # noqa
+                            pass
+                    channel_opt.append(('grpc.{}'.format(k[len(self._grpc_env_conf_prefix):]), v))
+
             try:
-                channel = self._ext_grpc.aio.insecure_channel(triton_server_address)
+                channel = self._ext_grpc.aio.insecure_channel(triton_server_address, options=channel_opt or None)
                 grpc_stub = self._ext_service_pb2_grpc.GRPCInferenceServiceStub(channel)
                 self._grpc_stub[tid] = grpc_stub
             except Exception as ex:
                 raise ValueError("External Triton gRPC server misconfigured [{}]: {}".format(triton_server_address, ex))
 
         use_compression = self._server_config.get("triton_grpc_compression", self._default_grpc_compression)
```

## Comparing `clearml_serving-1.2.0.dist-info/LICENSE` & `clearml_serving-1.3.0.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `clearml_serving-1.2.0.dist-info/METADATA` & `clearml_serving-1.3.0.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: clearml-serving
-Version: 1.2.0
+Version: 1.3.0
 Summary: clearml-serving - Model-Serving Orchestration and Repository Solution
 Home-page: https://github.com/allegroai/clearml-serving.git
 Author: ClearML
 Author-email: support@clear.ml
 License: Apache License 2.0
 Keywords: clearml mlops devops trains development machine deep learning version control machine-learning machinelearning deeplearning deep-learning model-serving
 Platform: UNKNOWN
@@ -31,15 +31,15 @@
 
 <div align="center">
 
 <a href="https://app.clear.ml"><img src="https://github.com/allegroai/clearml/blob/master/docs/clearml-logo.svg?raw=true" width="250px"></a>
 
 **ClearML Serving - Model deployment made easy**
 
-## **`clearml-serving v1.2` </br> :sparkles: Model Serving (ML/DL) Made Easy :tada:**
+## **`clearml-serving v1.3` </br> :sparkles: Model Serving (ML/DL) Made Easy :tada:** <br> :fire: NEW version 1.3 :rocket: 20% faster ! 
 
 
 [![GitHub license](https://img.shields.io/github/license/allegroai/clearml-serving.svg)](https://img.shields.io/github/license/allegroai/clearml-serving.svg)
 [![PyPI pyversions](https://img.shields.io/pypi/pyversions/clearml-serving.svg)](https://img.shields.io/pypi/pyversions/clearml-serving.svg)
 [![PyPI version shields.io](https://img.shields.io/pypi/v/clearml-serving.svg)](https://img.shields.io/pypi/v/clearml-serving.svg)
 [![Artifact Hub](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/allegroai)](https://artifacthub.io/packages/helm/allegroai/clearml-serving)
 [![Slack Channel](https://img.shields.io/badge/slack-%23clearml--community-blueviolet?logo=slack)](https://join.slack.com/t/allegroai-trains/shared_invite/zt-c0t13pty-aVUZZW1TSSSg2vyIGVPBhg)
```

### html2text {}

```diff
@@ -1,8 +1,8 @@
-Metadata-Version: 2.1 Name: clearml-serving Version: 1.2.0 Summary: clearml-
+Metadata-Version: 2.1 Name: clearml-serving Version: 1.3.0 Summary: clearml-
 serving - Model-Serving Orchestration and Repository Solution Home-page: https:
 //github.com/allegroai/clearml-serving.git Author: ClearML Author-email:
 support@clear.ml License: Apache License 2.0 Keywords: clearml mlops devops
 trains development machine deep learning version control machine-learning
 machinelearning deeplearning deep-learning model-serving Platform: UNKNOWN
 Classifier: Development Status :: 5 - Production/Stable Classifier: Intended
 Audience :: Developers Classifier: Intended Audience :: Science/Research
@@ -15,25 +15,26 @@
 Programming Language :: Python :: 3.7 Classifier: Programming Language ::
 Python :: 3.8 Classifier: Programming Language :: Python :: 3.9 Classifier:
 Programming Language :: Python :: 3.10 Classifier: License :: OSI Approved ::
 Apache Software License Description-Content-Type: text/markdown Requires-Dist:
 clearml (>=1.3.1)
         [https://github.com/allegroai/clearml/blob/master/docs/clearml-
     logo.svg?raw=true] **ClearML Serving - Model deployment made easy** ##
-**`clearml-serving v1.2`  :sparkles: Model Serving (ML/DL) Made Easy :tada:**
-  [![GitHub license](https://img.shields.io/github/license/allegroai/clearml-
-    serving.svg)](https://img.shields.io/github/license/allegroai/clearml-
-   serving.svg) [![PyPI pyversions](https://img.shields.io/pypi/pyversions/
-     clearml-serving.svg)](https://img.shields.io/pypi/pyversions/clearml-
-serving.svg) [![PyPI version shields.io](https://img.shields.io/pypi/v/clearml-
- serving.svg)](https://img.shields.io/pypi/v/clearml-serving.svg) [![Artifact
-    Hub](https://img.shields.io/endpoint?url=https://artifacthub.io/badge/
-repository/allegroai)](https://artifacthub.io/packages/helm/allegroai/clearml-
-  serving) [![Slack Channel](https://img.shields.io/badge/slack-%23clearml--
- community-blueviolet?logo=slack)](https://join.slack.com/t/allegroai-trains/
+**`clearml-serving v1.3`  :sparkles: Model Serving (ML/DL) Made Easy :tada:**
+   :fire: NEW version 1.3 :rocket: 20% faster ! [![GitHub license](https://
+    img.shields.io/github/license/allegroai/clearml-serving.svg)](https://
+     img.shields.io/github/license/allegroai/clearml-serving.svg) [![PyPI
+pyversions](https://img.shields.io/pypi/pyversions/clearml-serving.svg)](https:
+     //img.shields.io/pypi/pyversions/clearml-serving.svg) [![PyPI version
+   shields.io](https://img.shields.io/pypi/v/clearml-serving.svg)](https://
+     img.shields.io/pypi/v/clearml-serving.svg) [![Artifact Hub](https://
+img.shields.io/endpoint?url=https://artifacthub.io/badge/repository/allegroai)]
+   (https://artifacthub.io/packages/helm/allegroai/clearml-serving) [![Slack
+      Channel](https://img.shields.io/badge/slack-%23clearml--community-
+      blueviolet?logo=slack)](https://join.slack.com/t/allegroai-trains/
                shared_invite/zt-c0t13pty-aVUZZW1TSSSg2vyIGVPBhg)
 **`clearml-serving`** is a command line utility for model deployment and
 orchestration. It enables model deployment including serving and preprocessing
 code to a Kubernetes cluster or custom container based solution. ### :fire: NEW
 :confetti_ball: Take it for a spin with a simple `docker-compose` [command]
 (#nail_care-initial-setup) :magic_wand: :sparkles: [https://github.com/
 allegroai/clearml-serving/blob/main/docs/design_diagram.png?raw=true] Features:
```

## Comparing `clearml_serving-1.2.0.dist-info/RECORD` & `clearml_serving-1.3.0.dist-info/RECORD`

 * *Files 14% similar despite different names*

```diff
@@ -1,22 +1,22 @@
 clearml_serving/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-clearml_serving/__main__.py,sha256=NtFaK17u4aNftDusKVTC7JeXiENtFO6VGi0pf_gkiAc,29932
-clearml_serving/version.py,sha256=U3f_Jgr3zpgiYG2kLcvcT05TQsVzN9Kktg_f3Q9OZFA,22
+clearml_serving/__main__.py,sha256=5fNkU1YeBY74mVd5VWZWpkaq14BXsSphsEFSoGooTx4,29932
+clearml_serving/version.py,sha256=zi_LaUT_OsChAtsPXbOeRpQkCohSsOyeXfavQPM0GoE,22
 clearml_serving/engines/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 clearml_serving/engines/triton/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 clearml_serving/engines/triton/triton_helper.py,sha256=CyA5WB7QKB-uqh-3ElCkPwJP8VZ1yFmXs76RevXgABk,22705
 clearml_serving/serving/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 clearml_serving/serving/endpoints.py,sha256=NKVjFv_cxDd7x8I2KJ6S4Ikf1vYfb8pWMMD-uH4e8ss,6260
 clearml_serving/serving/init.py,sha256=zyW6yawFp5fdYzDD4a_gr83zgAvcoCkoocCR71TTv9A,1330
 clearml_serving/serving/main.py,sha256=WqLUumBDYXmwfHwLi3TGjkuLsoEwLUXLPlGUosSAVCk,3416
-clearml_serving/serving/model_request_processor.py,sha256=wlzcblRTCPQC-gphJgjCMvCcMSQiezPHEj_e0rT45t4,55993
-clearml_serving/serving/preprocess_service.py,sha256=IkEawGtLmQLuH75dAcaC7WZPkkprBgtQnvq3NIWBC9E,23305
+clearml_serving/serving/model_request_processor.py,sha256=PZq46uHuMEXERhRoMwgWwzua-W5H4wMdwbb6_0noBkY,57531
+clearml_serving/serving/preprocess_service.py,sha256=DdwkVJYWQ6YdAqcciEVptUB8CKzPHLTPOdoO1gXwQjQ,23891
 clearml_serving/serving/uvicorn_mp_entrypoint.py,sha256=vnH9lCtIVcGf4PqkkPgtmCU00OFHc6ltYzsQM3xP4nY,158
 clearml_serving/statistics/__init__.py,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 clearml_serving/statistics/main.py,sha256=rUhnu3lvlk6DTEYcXivaooIu65HcNtrNeKO0TGx-zrQ,1493
 clearml_serving/statistics/metrics.py,sha256=YjN5PVouQQo6jFT5eB_sOUI_IOxhLJ5PUDpyq-XowSo,14140
-clearml_serving-1.2.0.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
-clearml_serving-1.2.0.dist-info/METADATA,sha256=xjnoDlwdaEc_34lDfAhQW-5nZn4N9hanpq6sHM8JG8Y,20824
-clearml_serving-1.2.0.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
-clearml_serving-1.2.0.dist-info/entry_points.txt,sha256=R3zaaa8w-7hfkUZYj7R3GQ8fQHtk3JGzzqtxvC67eg4,67
-clearml_serving-1.2.0.dist-info/top_level.txt,sha256=U5osC4E2fjHEuVHegkJJxShiB6NnX2z8e54w9m0xkTg,16
-clearml_serving-1.2.0.dist-info/RECORD,,
+clearml_serving-1.3.0.dist-info/LICENSE,sha256=xx0jnfkXJvxRnG63LTGOxlggYnIysveWIZ6H3PNdCrQ,11357
+clearml_serving-1.3.0.dist-info/METADATA,sha256=774dijqj4sPOKmOgLtfDOl_fIpnb70eTzLK80fPQ7O0,20875
+clearml_serving-1.3.0.dist-info/WHEEL,sha256=G16H4A3IeoQmnOrYV4ueZGKSjhipXx8zc8nu9FGlvMA,92
+clearml_serving-1.3.0.dist-info/entry_points.txt,sha256=R3zaaa8w-7hfkUZYj7R3GQ8fQHtk3JGzzqtxvC67eg4,67
+clearml_serving-1.3.0.dist-info/top_level.txt,sha256=U5osC4E2fjHEuVHegkJJxShiB6NnX2z8e54w9m0xkTg,16
+clearml_serving-1.3.0.dist-info/RECORD,,
```

