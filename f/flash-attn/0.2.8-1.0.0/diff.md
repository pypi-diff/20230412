# Comparing `tmp/flash_attn-0.2.8.tar.gz` & `tmp/flash_attn-1.0.0.tar.gz`

## filetype from file(1)

```diff
@@ -1 +1 @@
-gzip compressed data, was "flash_attn-0.2.8.tar", last modified: Thu Jan 19 21:25:37 2023, max compression
+gzip compressed data, was "flash_attn-1.0.0.tar", last modified: Wed Apr 12 06:37:27 2023, max compression
```

## Comparing `flash_attn-0.2.8.tar` & `flash_attn-1.0.0.tar`

### file list

```diff
@@ -1,1547 +1,1694 @@
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:25:37.509227 flash_attn-0.2.8/
--rw-r--r--   0 root         (0) root         (0)       56 2022-11-17 23:40:55.000000 flash_attn-0.2.8/AUTHORS
--rw-r--r--   0 root         (0) root         (0)     1558 2022-09-09 19:08:03.000000 flash_attn-0.2.8/LICENSE
--rw-r--r--   0 root         (0) root         (0)      251 2022-12-18 05:19:38.000000 flash_attn-0.2.8/MANIFEST.in
--rw-rw-r--   0 root         (0) root         (0)     8124 2023-01-19 21:25:37.500156 flash_attn-0.2.8/PKG-INFO
--rw-r--r--   0 root         (0) root         (0)     7614 2022-12-18 05:19:38.000000 flash_attn-0.2.8/README.md
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:46.866060 flash_attn-0.2.8/csrc/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:47.346222 flash_attn-0.2.8/csrc/flash_attn/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:46.474043 flash_attn-0.2.8/csrc/flash_attn/cutlass/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:47.461089 flash_attn-0.2.8/csrc/flash_attn/cutlass/cmake/
--rw-rw-r--   0 root         (0) root         (0)     2023 2022-06-02 16:47:40.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/cmake/nop.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:46.116505 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:47.563896 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/00_basic_gemm/
--rw-rw-r--   0 root         (0) root         (0)    14698 2022-06-02 16:47:40.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/00_basic_gemm/basic_gemm.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:47.783060 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/01_cutlass_utilities/
--rw-rw-r--   0 root         (0) root         (0)    13255 2022-06-02 16:47:40.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/01_cutlass_utilities/cutlass_utilities.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:47.960381 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/02_dump_reg_shmem/
--rw-rw-r--   0 root         (0) root         (0)     7157 2022-06-02 16:47:40.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/02_dump_reg_shmem/dump_reg_shmem.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:48.377712 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/03_visualize_layout/
--rw-rw-r--   0 root         (0) root         (0)     4478 2022-06-02 16:47:40.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/03_visualize_layout/options.h
--rw-r--r--   0 root         (0) root         (0)     7081 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/03_visualize_layout/register_layout.cu
--rw-rw-r--   0 root         (0) root         (0)     2691 2022-06-02 16:47:40.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/03_visualize_layout/register_layout.h
--rw-r--r--   0 root         (0) root         (0)     5819 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/03_visualize_layout/visualize_layout.cpp
--rw-rw-r--   0 root         (0) root         (0)    11415 2022-06-02 16:47:40.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/03_visualize_layout/visualize_layout.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:48.481706 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/04_tile_iterator/
--rw-r--r--   0 root         (0) root         (0)     8226 2022-08-07 23:35:00.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/04_tile_iterator/tile_iterator.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:48.670325 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/05_batched_gemm/
--rw-r--r--   0 root         (0) root         (0)    15161 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/05_batched_gemm/batched_gemm.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:48.840374 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/06_splitK_gemm/
--rw-r--r--   0 root         (0) root         (0)    17570 2022-08-07 23:35:00.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/06_splitK_gemm/splitk_gemm.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:48.950672 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/07_volta_tensorop_gemm/
--rw-rw-r--   0 root         (0) root         (0)    18280 2022-06-02 16:47:40.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/07_volta_tensorop_gemm/volta_tensorop_gemm.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:49.028405 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/08_turing_tensorop_gemm/
--rw-rw-r--   0 root         (0) root         (0)    18226 2022-06-02 16:47:40.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/08_turing_tensorop_gemm/turing_tensorop_gemm.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:49.168350 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/09_turing_tensorop_conv2dfprop/
--rw-r--r--   0 root         (0) root         (0)    28124 2022-08-07 23:35:00.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/09_turing_tensorop_conv2dfprop/turing_tensorop_conv2dfprop.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:49.295910 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/10_planar_complex/
--rw-r--r--   0 root         (0) root         (0)    21947 2022-08-07 23:35:00.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/10_planar_complex/planar_complex.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:49.493266 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/11_planar_complex_array/
--rw-r--r--   0 root         (0) root         (0)    23244 2022-08-07 23:35:00.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/11_planar_complex_array/planar_complex_array.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:49.670761 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/12_gemm_bias_relu/
--rw-r--r--   0 root         (0) root         (0)    13151 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/12_gemm_bias_relu/gemm_bias_relu.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:54.969832 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/
--rw-r--r--   0 root         (0) root         (0)    26102 2022-08-05 17:48:52.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/b2b_conv2d_run.h
--rw-r--r--   0 root         (0) root         (0)    22877 2022-08-05 17:48:52.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/b2b_gemm_run.h
--rw-r--r--   0 root         (0) root         (0)    28268 2022-08-05 17:48:52.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/b2b_interleaved_conv2d_run.h
--rw-r--r--   0 root         (0) root         (0)    24493 2022-08-05 17:48:52.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/b2b_interleaved_gemm_run.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:55.435627 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/device/
--rw-r--r--   0 root         (0) root         (0)    15552 2022-08-05 17:48:52.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/device/b2b_gemm.h
--rw-rw-r--   0 root         (0) root         (0)    11520 2022-06-02 16:47:40.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/device/b2b_implicit_gemm_convolution.h
--rw-r--r--   0 root         (0) root         (0)     8756 2022-08-05 17:48:52.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm75_rf.cu
--rw-r--r--   0 root         (0) root         (0)     8759 2022-08-05 17:48:52.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm75_shmem.cu
--rw-r--r--   0 root         (0) root         (0)     8712 2022-08-05 17:48:52.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm80_rf.cu
--rw-r--r--   0 root         (0) root         (0)     8762 2022-08-05 17:48:52.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm80_shmem.cu
--rw-r--r--   0 root         (0) root         (0)     8787 2022-08-05 17:48:52.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm75_rf.cu
--rw-r--r--   0 root         (0) root         (0)     8793 2022-08-05 17:48:52.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm75_shmem.cu
--rw-r--r--   0 root         (0) root         (0)     8711 2022-08-05 17:48:52.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm80_rf.cu
--rw-r--r--   0 root         (0) root         (0)     8775 2022-08-05 17:48:52.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm80_shmem.cu
--rw-r--r--   0 root         (0) root         (0)     7269 2022-08-05 17:48:52.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm75_rf.cu
--rw-r--r--   0 root         (0) root         (0)     7338 2022-08-05 17:48:52.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm75_shmem.cu
--rw-r--r--   0 root         (0) root         (0)     7294 2022-08-05 17:48:52.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm80_rf.cu
--rw-r--r--   0 root         (0) root         (0)     7359 2022-08-05 17:48:52.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm80_shmem.cu
--rw-r--r--   0 root         (0) root         (0)     7362 2022-08-05 17:48:52.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm75_rf.cu
--rw-r--r--   0 root         (0) root         (0)     7430 2022-08-05 17:48:52.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm75_shmem.cu
--rw-r--r--   0 root         (0) root         (0)     7627 2022-08-05 17:48:52.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm80_rf.cu
--rw-r--r--   0 root         (0) root         (0)     7634 2022-08-05 17:48:52.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm80_shmem.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:57.148826 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/kernel/
--rw-r--r--   0 root         (0) root         (0)    16152 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/kernel/b2b_gemm.h
--rw-rw-r--   0 root         (0) root         (0)    18151 2022-06-02 16:47:40.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/kernel/b2b_implicit_gemm_convolution.h
--rw-rw-r--   0 root         (0) root         (0)     3973 2022-06-02 16:47:40.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop.h
--rw-rw-r--   0 root         (0) root         (0)    26762 2022-06-02 16:47:40.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_sm75.h
--rw-rw-r--   0 root         (0) root         (0)    26775 2022-06-02 16:47:40.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_sm80.h
--rw-rw-r--   0 root         (0) root         (0)    28422 2022-06-02 16:47:40.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_smem_accumulator_sm75.h
--rw-r--r--   0 root         (0) root         (0)    28073 2022-08-05 17:48:52.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_smem_accumulator_sm80.h
--rw-rw-r--   0 root         (0) root         (0)    17111 2022-06-02 16:47:40.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_gemm.h
--rw-rw-r--   0 root         (0) root         (0)    15658 2022-06-02 16:47:40.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_gemm_smem_accumulator.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:45.879556 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/reference/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:57.264712 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/reference/device/
--rw-r--r--   0 root         (0) root         (0)    10368 2022-08-05 17:48:52.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/reference/device/tensor_scale_bias.h
--rw-rw-r--   0 root         (0) root         (0)     3577 2022-06-02 16:47:40.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/test_run.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:59.044341 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/
--rw-r--r--   0 root         (0) root         (0)    31616 2022-08-05 17:48:52.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_multistage.h
--rw-rw-r--   0 root         (0) root         (0)    31443 2022-06-02 16:47:40.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_multistage_smem_accumulator.h
--rw-rw-r--   0 root         (0) root         (0)    21010 2022-06-02 16:47:40.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_pipelined.h
--rw-rw-r--   0 root         (0) root         (0)    20493 2022-06-02 16:47:40.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_pipelined_smem_accumulator.h
--rw-rw-r--   0 root         (0) root         (0)     7983 2022-06-02 16:47:40.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_base.h
--rw-rw-r--   0 root         (0) root         (0)     6047 2022-06-02 16:47:40.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_base_smem_accumulator.h
--rw-r--r--   0 root         (0) root         (0)    33824 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_multistage.h
--rw-r--r--   0 root         (0) root         (0)    33518 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_multistage_smem_accumulator.h
--rw-r--r--   0 root         (0) root         (0)    21451 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_pipelined.h
--rw-r--r--   0 root         (0) root         (0)    21065 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_pipelined_smem_accumulator.h
--rw-r--r--   0 root         (0) root         (0)    27144 2022-08-05 17:48:52.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/default_b2b_mma.h
--rw-r--r--   0 root         (0) root         (0)    27400 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/default_b2b_mma_smem_accumulator.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:59.147678 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/14_ampere_tf32_tensorop_gemm/
--rw-rw-r--   0 root         (0) root         (0)    18020 2022-06-02 16:47:40.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/14_ampere_tf32_tensorop_gemm/ampere_tf32_tensorop_gemm.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:59.260441 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/15_ampere_sparse_tensorop_gemm/
--rw-rw-r--   0 root         (0) root         (0)    15042 2022-06-02 16:47:40.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/15_ampere_sparse_tensorop_gemm/ampere_sparse_tensorop_gemm.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:59.413078 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/16_ampere_tensorop_conv2dfprop/
--rw-r--r--   0 root         (0) root         (0)    27755 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/16_ampere_tensorop_conv2dfprop/ampere_tensorop_conv2dfprop.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:59.528050 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/17_fprop_per_channel_bias/
--rw-r--r--   0 root         (0) root         (0)    12580 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/17_fprop_per_channel_bias/fprop_per_channel_bias.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:59.652581 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/18_ampere_fp64_tensorop_affine2_gemm/
--rw-r--r--   0 root         (0) root         (0)    14007 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/18_ampere_fp64_tensorop_affine2_gemm/ampere_fp64_tensorop_affine2_gemm.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:59.762064 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/19_tensorop_canonical/
--rw-rw-r--   0 root         (0) root         (0)    13401 2022-06-02 16:47:40.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/19_tensorop_canonical/tensorop_canonical.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:59.850272 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/20_simt_canonical/
--rw-rw-r--   0 root         (0) root         (0)    12556 2022-06-02 16:47:40.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/20_simt_canonical/simt_canonical.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:59.967100 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/21_quaternion_gemm/
--rw-rw-r--   0 root         (0) root         (0)    17319 2022-06-02 16:47:40.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/21_quaternion_gemm/quaternion_gemm.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:00.070780 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/22_quaternion_conv/
--rw-r--r--   0 root         (0) root         (0)    21495 2022-08-07 23:35:00.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/22_quaternion_conv/quaternion_conv.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:00.177024 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/23_ampere_gemm_operand_reduction_fusion/
--rw-r--r--   0 root         (0) root         (0)    27530 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/23_ampere_gemm_operand_reduction_fusion/ampere_gemm_operand_reduction_fusion.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:00.600914 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/24_gemm_grouped/
--rw-r--r--   0 root         (0) root         (0)    50996 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/24_gemm_grouped/gemm_grouped.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:01.183040 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/25_ampere_fprop_mainloop_fusion/
--rw-r--r--   0 root         (0) root         (0)    26547 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/25_ampere_fprop_mainloop_fusion/ampere_3d_fprop_mainloop_fusion.cu
--rw-r--r--   0 root         (0) root         (0)    25628 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/25_ampere_fprop_mainloop_fusion/ampere_fprop_mainloop_fusion.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:01.313391 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/26_ampere_wgrad_mainloop_fusion/
--rw-r--r--   0 root         (0) root         (0)    25538 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/26_ampere_wgrad_mainloop_fusion/ampere_wgrad_mainloop_fusion.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:01.411455 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/27_ampere_3xtf32_fast_accurate_tensorop_gemm/
--rw-rw-r--   0 root         (0) root         (0)    30446 2022-06-02 16:47:40.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/27_ampere_3xtf32_fast_accurate_tensorop_gemm/27_ampere_3xtf32_fast_accurate_tensorop_gemm.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:01.579431 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/28_ampere_3xtf32_fast_accurate_tensorop_fprop/
--rw-r--r--   0 root         (0) root         (0)    28159 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/28_ampere_3xtf32_fast_accurate_tensorop_fprop/ampere_3xtf32_fast_accurate_tensorop_fprop.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:02.068863 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/29_ampere_3xtf32_fast_accurate_tensorop_complex_gemm/
--rw-rw-r--   0 root         (0) root         (0)    28403 2022-06-02 16:47:40.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/29_ampere_3xtf32_fast_accurate_tensorop_complex_gemm/29_ampere_3xtf32_fast_accurate_tensorop_complex_gemm.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:02.829316 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/30_wgrad_split_k/
--rw-r--r--   0 root         (0) root         (0)    27329 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/30_wgrad_split_k/30_wgrad_split_k.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:03.169980 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/31_basic_syrk/
--rw-r--r--   0 root         (0) root         (0)    15206 2022-08-05 17:49:15.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/31_basic_syrk/basic_syrk.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:03.249802 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/32_basic_trmm/
--rw-r--r--   0 root         (0) root         (0)    15907 2022-08-05 17:49:15.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/32_basic_trmm/basic_trmm.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:03.414894 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/33_ampere_3xtf32_tensorop_symm/
--rw-rw-r--   0 root         (0) root         (0)    31803 2022-06-02 16:47:40.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/33_ampere_3xtf32_tensorop_symm/ampere_3xtf32_tensorop_symm.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:03.542214 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/34_transposed_conv2d/
--rw-r--r--   0 root         (0) root         (0)    22378 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/34_transposed_conv2d/34_transposed_conv2d.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:04.185787 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/35_gemm_softmax/
--rw-r--r--   0 root         (0) root         (0)    23114 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/35_gemm_softmax/gemm_softmax.cu
--rw-r--r--   0 root         (0) root         (0)    16723 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/35_gemm_softmax/gemm_with_epilogue_visitor.h
--rw-r--r--   0 root         (0) root         (0)    18713 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/35_gemm_softmax/gemm_with_softmax.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:04.274062 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/36_gather_scatter_fusion/
--rw-r--r--   0 root         (0) root         (0)    20795 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/36_gather_scatter_fusion/gather_scatter_fusion.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:05.758278 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/37_gemm_layernorm_gemm_fusion/
--rw-r--r--   0 root         (0) root         (0)    31111 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/37_gemm_layernorm_gemm_fusion/gemm_layernorm.cu
--rw-r--r--   0 root         (0) root         (0)    13982 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/37_gemm_layernorm_gemm_fusion/gemm_with_epilogue_visitor.h
--rw-r--r--   0 root         (0) root         (0)    33916 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/37_gemm_layernorm_gemm_fusion/gemm_with_layernorm.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:05.843614 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/38_syr2k_grouped/
--rw-r--r--   0 root         (0) root         (0)    47455 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/38_syr2k_grouped/syr2k_grouped.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:05.999340 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/39_gemm_permute/
--rw-r--r--   0 root         (0) root         (0)    37896 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/39_gemm_permute/gemm_permute.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:08.516702 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/
--rw-r--r--   0 root         (0) root         (0)    18389 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/attention_scaling_coefs_updater.h
--rw-r--r--   0 root         (0) root         (0)     8286 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/debug_utils.h
--rw-r--r--   0 root         (0) root         (0)     9888 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/default_fmha_grouped.h
--rw-r--r--   0 root         (0) root         (0)    22349 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/epilogue_pipelined.h
--rw-r--r--   0 root         (0) root         (0)     9162 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/epilogue_rescale_output.h
--rw-r--r--   0 root         (0) root         (0)     6111 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/epilogue_thread_apply_logsumexp.h
--rw-r--r--   0 root         (0) root         (0)     6768 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/find_default_mma.h
--rw-r--r--   0 root         (0) root         (0)    29972 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/fmha_grouped.h
--rw-r--r--   0 root         (0) root         (0)     6666 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/fmha_grouped_problem_visitor.h
--rw-rw-r--   0 root         (0) root         (0)    37104 2022-12-14 23:22:53.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/fused_multihead_attention_fixed_seqlen.cu
--rw-rw-r--   0 root         (0) root         (0)    39975 2022-12-14 23:22:53.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/fused_multihead_attention_variable_seqlen.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:09.113694 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/gemm/
--rw-r--r--   0 root         (0) root         (0)     3994 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma.h
--rw-r--r--   0 root         (0) root         (0)     6241 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma_base.h
--rw-r--r--   0 root         (0) root         (0)    27196 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma_multistage.h
--rw-r--r--   0 root         (0) root         (0)    14090 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma_pipelined.h
--rw-r--r--   0 root         (0) root         (0)    12089 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/gemm_kernel_utils.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:09.629588 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/iterators/
--rw-r--r--   0 root         (0) root         (0)    23805 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/iterators/epilogue_predicated_tile_iterator.h
--rw-r--r--   0 root         (0) root         (0)     3142 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/iterators/make_residual_last.h
--rw-r--r--   0 root         (0) root         (0)    64480 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/iterators/predicated_tile_access_iterator_residual_last.h
--rw-r--r--   0 root         (0) root         (0)    64500 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/iterators/predicated_tile_iterator_residual_last.h
--rw-rw-r--   0 root         (0) root         (0)    37905 2022-12-14 23:22:53.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/kernel_forward.h
--rw-r--r--   0 root         (0) root         (0)    61211 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/mma_from_smem.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:10.129190 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_multi_head_attention/
--rw-r--r--   0 root         (0) root         (0)    37396 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_multi_head_attention/fused_multihead_attention.cu
--rw-r--r--   0 root         (0) root         (0)    17839 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_multi_head_attention/gemm_attention.h
--rw-r--r--   0 root         (0) root         (0)    16152 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_multi_head_attention/gemm_grouped_with_softmax_visitor.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:10.216009 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/42_ampere_tensorop_group_conv/
--rw-r--r--   0 root         (0) root         (0)    23901 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/42_ampere_tensorop_group_conv/ampere_tensorop_group_conv.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:10.337739 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/43_ell_block_sparse_gemm/
--rw-r--r--   0 root         (0) root         (0)    23867 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/43_ell_block_sparse_gemm/ell_block_sparse_gemm.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:10.578546 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:46.077507 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:46.066481 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:11.158567 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/
--rw-r--r--   0 root         (0) root         (0)     6370 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/default_bias_act_epilogue_tensor_op.h
--rw-r--r--   0 root         (0) root         (0)     4099 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/default_thread_map_tensor_op_for_fused_bias.h
--rw-r--r--   0 root         (0) root         (0)     8285 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/fused_bias_act_epilogue.h
--rw-r--r--   0 root         (0) root         (0)    10439 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/output_tile_thread_map_for_fused_bias.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:11.240237 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/warp/
--rw-r--r--   0 root         (0) root         (0)     6848 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/warp/fused_bias_act_fragment_iterator_tensor_op.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:46.083252 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/gemm/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:11.452145 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/gemm/warp/
--rw-r--r--   0 root         (0) root         (0)    14747 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/gemm/warp/mma_tensor_op_fragment_iterator_without_output_op.h
--rw-r--r--   0 root         (0) root         (0)    10231 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/leaky_bias.h
--rw-r--r--   0 root         (0) root         (0)     3745 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/utils.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:12.117049 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/45_dual_gemm/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:12.279483 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/45_dual_gemm/device/
--rw-r--r--   0 root         (0) root         (0)    15362 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/45_dual_gemm/device/dual_gemm.h
--rw-r--r--   0 root         (0) root         (0)     8109 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/45_dual_gemm/dual_gemm.cu
--rw-r--r--   0 root         (0) root         (0)    26478 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/45_dual_gemm/dual_gemm_run.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:12.380352 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/45_dual_gemm/kernel/
--rw-r--r--   0 root         (0) root         (0)    16424 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/45_dual_gemm/kernel/dual_gemm.h
--rw-r--r--   0 root         (0) root         (0)     3577 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/45_dual_gemm/test_run.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:12.635914 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/45_dual_gemm/thread/
--rw-r--r--   0 root         (0) root         (0)     5818 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/45_dual_gemm/thread/left_silu_and_mul.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:13.183229 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/45_dual_gemm/threadblock/
--rw-r--r--   0 root         (0) root         (0)    15613 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/45_dual_gemm/threadblock/dual_epilogue.h
--rw-r--r--   0 root         (0) root         (0)     7264 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/45_dual_gemm/threadblock/dual_mma_base.h
--rw-r--r--   0 root         (0) root         (0)    28982 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/45_dual_gemm/threadblock/dual_mma_multistage.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:13.375448 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/46_depthwise_simt_conv2dfprop/
--rw-r--r--   0 root         (0) root         (0)    24464 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/46_depthwise_simt_conv2dfprop/depthwise_simt_conv2dfprop.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:13.489522 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/common/
--rw-rw-r--   0 root         (0) root         (0)     1434 2022-06-02 16:47:40.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/common/helper.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:46.133098 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:21.179807 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/
--rw-rw-r--   0 root         (0) root         (0)     3793 2022-06-02 16:47:40.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/aligned_buffer.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:26.065537 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/
--rw-rw-r--   0 root         (0) root         (0)     3538 2022-12-14 23:22:53.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/arch.h
--rw-rw-r--   0 root         (0) root         (0)     2691 2022-06-02 16:47:40.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/cache_operation.h
--rw-r--r--   0 root         (0) root         (0)    14313 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/memory.h
--rw-r--r--   0 root         (0) root         (0)    10490 2022-09-05 01:02:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/memory_sm75.h
--rw-rw-r--   0 root         (0) root         (0)    15154 2022-12-14 23:22:53.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/memory_sm80.h
--rw-r--r--   0 root         (0) root         (0)     8037 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/mma.h
--rw-r--r--   0 root         (0) root         (0)    11096 2022-08-07 23:35:00.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/mma_sm50.h
--rw-r--r--   0 root         (0) root         (0)     7040 2022-08-07 23:35:00.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/mma_sm60.h
--rw-r--r--   0 root         (0) root         (0)     4193 2022-08-07 23:35:00.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/mma_sm61.h
--rw-rw-r--   0 root         (0) root         (0)    16554 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/mma_sm70.h
--rw-r--r--   0 root         (0) root         (0)    31652 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/mma_sm75.h
--rw-r--r--   0 root         (0) root         (0)    55581 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/mma_sm80.h
--rw-r--r--   0 root         (0) root         (0)     4430 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/mma_sm90.h
--rw-r--r--   0 root         (0) root         (0)    43978 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/mma_sparse_sm80.h
--rw-rw-r--   0 root         (0) root         (0)     3998 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/simd.h
--rw-rw-r--   0 root         (0) root         (0)     3656 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/simd_sm60.h
--rw-rw-r--   0 root         (0) root         (0)     5102 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/simd_sm61.h
--rw-rw-r--   0 root         (0) root         (0)     8473 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/wmma.h
--rw-rw-r--   0 root         (0) root         (0)     5286 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/wmma_sm70.h
--rw-rw-r--   0 root         (0) root         (0)     7746 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/wmma_sm72.h
--rw-rw-r--   0 root         (0) root         (0)     7616 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/wmma_sm75.h
--rw-r--r--   0 root         (0) root         (0)    62373 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/array.h
--rw-rw-r--   0 root         (0) root         (0)     3662 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/array_planar_complex.h
--rw-rw-r--   0 root         (0) root         (0)    13154 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/array_subbyte.h
--rw-r--r--   0 root         (0) root         (0)     6521 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/barrier.h
--rw-r--r--   0 root         (0) root         (0)    13371 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/bfloat16.h
--rw-r--r--   0 root         (0) root         (0)     6338 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/blas3.h
--rw-rw-r--   0 root         (0) root         (0)     9372 2022-12-14 23:22:53.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/block_striped.h
--rw-r--r--   0 root         (0) root         (0)    19422 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/complex.h
--rw-rw-r--   0 root         (0) root         (0)    47943 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/constants.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:26.325798 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/
--rw-rw-r--   0 root         (0) root         (0)    22725 2022-12-14 23:22:53.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/conv2d_problem_size.h
--rw-rw-r--   0 root         (0) root         (0)    16292 2022-12-14 23:22:53.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/conv3d_problem_size.h
--rw-r--r--   0 root         (0) root         (0)     6664 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/convolution.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:26.803927 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/device/
--rw-r--r--   0 root         (0) root         (0)     9744 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/device/direct_convolution.h
--rw-r--r--   0 root         (0) root         (0)    12619 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/device/implicit_gemm_convolution.h
--rw-rw-r--   0 root         (0) root         (0)    10044 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/device/implicit_gemm_convolution_fusion.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:30.969698 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/
--rw-rw-r--   0 root         (0) root         (0)     7671 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv2d.h
--rw-rw-r--   0 root         (0) root         (0)    53546 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv2d_dgrad.h
--rw-rw-r--   0 root         (0) root         (0)    56838 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop.h
--rw-r--r--   0 root         (0) root         (0)    11953 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_fusion.h
--rw-rw-r--   0 root         (0) root         (0)     4658 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_with_broadcast.h
--rw-rw-r--   0 root         (0) root         (0)     4660 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_with_reduction.h
--rw-r--r--   0 root         (0) root         (0)    15891 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv2d_group_fprop.h
--rw-rw-r--   0 root         (0) root         (0)    28745 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv2d_wgrad.h
--rw-rw-r--   0 root         (0) root         (0)    10459 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv2d_wgrad_fusion.h
--rw-rw-r--   0 root         (0) root         (0)     9324 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv3d_dgrad.h
--rw-rw-r--   0 root         (0) root         (0)    14864 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv3d_fprop.h
--rw-r--r--   0 root         (0) root         (0)    11980 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv3d_fprop_fusion.h
--rw-rw-r--   0 root         (0) root         (0)    14883 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv3d_wgrad.h
--rw-r--r--   0 root         (0) root         (0)    19294 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_depthwise_fprop.h
--rw-r--r--   0 root         (0) root         (0)    18048 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/direct_convolution.h
--rw-r--r--   0 root         (0) root         (0)    15454 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution.h
--rw-r--r--   0 root         (0) root         (0)    15709 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution_fusion.h
--rw-r--r--   0 root         (0) root         (0)    17222 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution_strided_dgrad.h
--rw-r--r--   0 root         (0) root         (0)    16749 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution_with_fused_epilogue.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:31.139244 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/thread/
--rw-r--r--   0 root         (0) root         (0)     9689 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/thread/depthwise_mma.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:39.619946 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/
--rw-rw-r--   0 root         (0) root         (0)    15306 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_filter_tile_access_iterator_analytic.h
--rw-r--r--   0 root         (0) root         (0)    19735 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_filter_tile_access_iterator_optimized.h
--rw-r--r--   0 root         (0) root         (0)    18940 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_output_gradient_tile_access_iterator_analytic.h
--rw-r--r--   0 root         (0) root         (0)    26137 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_output_gradient_tile_access_iterator_optimized.h
--rw-r--r--   0 root         (0) root         (0)    10953 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_analytic.h
--rw-rw-r--   0 root         (0) root         (0)    11529 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_few_channels.h
--rw-rw-r--   0 root         (0) root         (0)    11333 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_fixed_channels.h
--rw-rw-r--   0 root         (0) root         (0)    13664 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_optimized.h
--rw-r--r--   0 root         (0) root         (0)    10627 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_analytic.h
--rw-rw-r--   0 root         (0) root         (0)     9314 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_few_channels.h
--rw-rw-r--   0 root         (0) root         (0)     9018 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_fixed_channels.h
--rw-r--r--   0 root         (0) root         (0)    10387 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_optimized.h
--rw-r--r--   0 root         (0) root         (0)    30197 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_params.h
--rw-r--r--   0 root         (0) root         (0)    11202 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_tile_iterator.h
--rw-rw-r--   0 root         (0) root         (0)    10350 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_activation_tile_access_iterator_analytic.h
--rw-rw-r--   0 root         (0) root         (0)    11520 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_activation_tile_access_iterator_optimized.h
--rw-rw-r--   0 root         (0) root         (0)     9043 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_output_gradient_tile_access_iterator_analytic.h
--rw-rw-r--   0 root         (0) root         (0)    10832 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_output_gradient_tile_access_iterator_optimized.h
--rw-rw-r--   0 root         (0) root         (0)     8450 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_filter_tile_access_iterator_analytic.h
--rw-rw-r--   0 root         (0) root         (0)     9569 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_filter_tile_access_iterator_optimized.h
--rw-rw-r--   0 root         (0) root         (0)    11020 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_output_gradient_tile_access_iterator_analytic.h
--rw-rw-r--   0 root         (0) root         (0)    15014 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_output_gradient_tile_access_iterator_optimized.h
--rw-rw-r--   0 root         (0) root         (0)     9634 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_activation_tile_access_iterator_analytic.h
--rw-rw-r--   0 root         (0) root         (0)    15132 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_activation_tile_access_iterator_optimized.h
--rw-rw-r--   0 root         (0) root         (0)     7945 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_filter_tile_access_iterator_analytic.h
--rw-rw-r--   0 root         (0) root         (0)     8891 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_filter_tile_access_iterator_optimized.h
--rw-r--r--   0 root         (0) root         (0)    18249 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_params.h
--rw-rw-r--   0 root         (0) root         (0)     9971 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_activation_tile_access_iterator_analytic.h
--rw-rw-r--   0 root         (0) root         (0)    12024 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_activation_tile_access_iterator_optimized.h
--rw-rw-r--   0 root         (0) root         (0)     8821 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_output_gradient_tile_access_iterator_analytic.h
--rw-rw-r--   0 root         (0) root         (0)    10744 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_output_gradient_tile_access_iterator_optimized.h
--rw-r--r--   0 root         (0) root         (0)     8871 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/depthwise_direct_conv_params.h
--rw-r--r--   0 root         (0) root         (0)    10747 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_activation_tile_access_iterator_direct_conv_fixed_stride_dilation.h
--rw-r--r--   0 root         (0) root         (0)     9899 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_activation_tile_access_iterator_direct_conv_optimized.h
--rw-r--r--   0 root         (0) root         (0)    20899 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_direct_conv_multistage.h
--rw-r--r--   0 root         (0) root         (0)     8921 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_filter_tile_access_iterator_direct_conv_optimized.h
--rw-r--r--   0 root         (0) root         (0)    12744 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_pipelined.h
--rw-r--r--   0 root         (0) root         (0)     8097 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/depthwise_mma_base.h
--rw-r--r--   0 root         (0) root         (0)    36697 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/depthwise_mma_core_with_lane_access_size.h
--rw-r--r--   0 root         (0) root         (0)    30106 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/implicit_gemm_fprop_fusion_multistage.h
--rw-r--r--   0 root         (0) root         (0)    20086 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/implicit_gemm_multistage.h
--rw-r--r--   0 root         (0) root         (0)    12174 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/implicit_gemm_pipelined.h
--rw-r--r--   0 root         (0) root         (0)    26320 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/implicit_gemm_wgrad_fusion_multistage.h
--rw-r--r--   0 root         (0) root         (0)    16915 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/predicated_scale_bias_vector_access_iterator.h
--rw-rw-r--   0 root         (0) root         (0)    12476 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/predicated_scale_bias_vector_iterator.h
--rw-r--r--   0 root         (0) root         (0)     8050 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/threadblock_swizzle.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:41.197045 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/warp/
--rw-r--r--   0 root         (0) root         (0)    12419 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/warp/mma_depthwise_simt.h
--rw-r--r--   0 root         (0) root         (0)    30655 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/warp/mma_depthwise_simt_tile_iterator.h
--rw-r--r--   0 root         (0) root         (0)     8772 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/warp/scale_bias_relu_transform.h
--rw-r--r--   0 root         (0) root         (0)    11827 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/coord.h
--rw-r--r--   0 root         (0) root         (0)    11077 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/core_io.h
--rw-r--r--   0 root         (0) root         (0)     7549 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/cutlass.h
--rw-r--r--   0 root         (0) root         (0)     3108 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/device_kernel.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:46.196584 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:47.030251 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/
--rw-r--r--   0 root         (0) root         (0)    18909 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/activation.h
--rw-r--r--   0 root         (0) root         (0)     4691 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/conversion_op.h
--rw-r--r--   0 root         (0) root         (0)     9349 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination.h
--rw-r--r--   0 root         (0) root         (0)     8344 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_bias_elementwise.h
--rw-r--r--   0 root         (0) root         (0)    13490 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_bias_relu.h
--rw-rw-r--   0 root         (0) root         (0)    23649 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_clamp.h
--rw-rw-r--   0 root         (0) root         (0)     9067 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_dgelu.h
--rw-rw-r--   0 root         (0) root         (0)    15195 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_drelu.h
--rw-rw-r--   0 root         (0) root         (0)     3669 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_gelu.h
--rw-r--r--   0 root         (0) root         (0)     8065 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_generic.h
--rw-rw-r--   0 root         (0) root         (0)     3693 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_hardswish.h
--rw-r--r--   0 root         (0) root         (0)     8344 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_leaky_relu.h
--rw-r--r--   0 root         (0) root         (0)     3058 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_params.h
--rw-rw-r--   0 root         (0) root         (0)     9351 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_planar_complex.h
--rw-r--r--   0 root         (0) root         (0)    20486 2022-08-05 17:48:52.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_relu.h
--rw-rw-r--   0 root         (0) root         (0)    19348 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_relu0.h
--rw-r--r--   0 root         (0) root         (0)    11855 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_residual_block.h
--rw-rw-r--   0 root         (0) root         (0)     3688 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_sigmoid.h
--rw-rw-r--   0 root         (0) root         (0)     3669 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_silu.h
--rw-rw-r--   0 root         (0) root         (0)     8662 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_with_elementwise.h
--rw-rw-r--   0 root         (0) root         (0)     3416 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/reduction_op.h
--rw-rw-r--   0 root         (0) root         (0)     2656 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/scale_type.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:53.397228 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/
--rw-rw-r--   0 root         (0) root         (0)     9142 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_complex_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)     9441 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_complex_tensor_op_blas3.h
--rw-rw-r--   0 root         (0) root         (0)     3234 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_direct_store.h
--rw-rw-r--   0 root         (0) root         (0)     7209 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_planar_complex.h
--rw-r--r--   0 root         (0) root         (0)    13319 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_simt.h
--rw-r--r--   0 root         (0) root         (0)    27150 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)     7129 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_tensor_op_blas3.h
--rw-r--r--   0 root         (0) root         (0)    10846 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_volta_tensor_op.h
--rw-r--r--   0 root         (0) root         (0)     5817 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_with_broadcast.h
--rw-r--r--   0 root         (0) root         (0)     5763 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_with_reduction.h
--rw-r--r--   0 root         (0) root         (0)     5947 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_wmma_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)     4409 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_simt.h
--rw-rw-r--   0 root         (0) root         (0)     7398 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)     7303 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_volta_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)     4098 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_wmma_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)     4678 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/direct_store_epilogue_iterator.h
--rw-rw-r--   0 root         (0) root         (0)    15628 2022-12-14 23:22:53.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue.h
--rw-rw-r--   0 root         (0) root         (0)     8279 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_base.h
--rw-rw-r--   0 root         (0) root         (0)     7455 2022-12-14 23:22:53.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_base_streamk.h
--rw-r--r--   0 root         (0) root         (0)    13424 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_depthwise.h
--rw-r--r--   0 root         (0) root         (0)    13933 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_direct_store.h
--rw-r--r--   0 root         (0) root         (0)     7401 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_gemm_k_reduction.h
--rw-rw-r--   0 root         (0) root         (0)    14610 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_planar_complex.h
--rw-rw-r--   0 root         (0) root         (0)     9073 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_smem_accumulator.h
--rw-r--r--   0 root         (0) root         (0)    16804 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_visitor_with_softmax.h
--rw-r--r--   0 root         (0) root         (0)    52430 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_broadcast.h
--rw-r--r--   0 root         (0) root         (0)    29199 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_reduction.h
--rw-r--r--   0 root         (0) root         (0)    13454 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_visitor.h
--rw-rw-r--   0 root         (0) root         (0)     7308 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_workspace.h
--rw-rw-r--   0 root         (0) root         (0)    13546 2022-12-14 23:22:53.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/interleaved_epilogue.h
--rw-rw-r--   0 root         (0) root         (0)     2912 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/output_iterator_parameter.h
--rw-r--r--   0 root         (0) root         (0)    19750 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/output_tile_thread_map.h
--rw-r--r--   0 root         (0) root         (0)    40870 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator.h
--rw-rw-r--   0 root         (0) root         (0)    18821 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_affine.h
--rw-r--r--   0 root         (0) root         (0)     5636 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_affine_layout_params.h
--rw-rw-r--   0 root         (0) root         (0)    21249 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_blas3.h
--rw-r--r--   0 root         (0) root         (0)    13872 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_direct_conv.h
--rw-r--r--   0 root         (0) root         (0)    14496 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_params.h
--rw-rw-r--   0 root         (0) root         (0)     9146 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_predicates.h
--rw-rw-r--   0 root         (0) root         (0)    15536 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_strided_dgrad.h
--rw-r--r--   0 root         (0) root         (0)     7487 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/shared_load_iterator.h
--rw-r--r--   0 root         (0) root         (0)    17683 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/shared_load_iterator_mixed.h
--rw-r--r--   0 root         (0) root         (0)     7394 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/shared_load_iterator_pitch_liner.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:58.074417 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/
--rw-rw-r--   0 root         (0) root         (0)     7055 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/fragment_iterator_complex_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)     7736 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/fragment_iterator_gaussian_complex_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)     5880 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/fragment_iterator_simt.h
--rw-rw-r--   0 root         (0) root         (0)     9883 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/fragment_iterator_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)     8924 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/fragment_iterator_volta_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)     6045 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/fragment_iterator_wmma_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)     4864 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/simt_policy.h
--rw-rw-r--   0 root         (0) root         (0)     5979 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/tensor_op_policy.h
--rw-r--r--   0 root         (0) root         (0)    25658 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/tile_iterator_simt.h
--rw-r--r--   0 root         (0) root         (0)    20290 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/tile_iterator_tensor_op.h
--rw-r--r--   0 root         (0) root         (0)    22857 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/tile_iterator_tensor_op_mixed.h
--rw-r--r--   0 root         (0) root         (0)    14258 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/tile_iterator_volta_tensor_op.h
--rw-r--r--   0 root         (0) root         (0)     7704 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/tile_iterator_wmma_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)     7485 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/volta_tensor_op_policy.h
--rw-rw-r--   0 root         (0) root         (0)     3916 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/wmma_tensor_op_policy.h
--rw-r--r--   0 root         (0) root         (0)    26026 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/fast_math.h
--rw-r--r--   0 root         (0) root         (0)    35181 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/float8.h
--rw-r--r--   0 root         (0) root         (0)     2645 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/floating_point_nvrtc.h
--rw-r--r--   0 root         (0) root         (0)    11132 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/functional.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:22:59.176095 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:23:01.893715 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/
--rw-r--r--   0 root         (0) root         (0)    17023 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/base_grouped.h
--rw-r--r--   0 root         (0) root         (0)    24413 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/default_gemm_configuration.h
--rw-r--r--   0 root         (0) root         (0)    27616 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/ell_gemm.h
--rw-r--r--   0 root         (0) root         (0)    25194 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm.h
--rw-rw-r--   0 root         (0) root         (0)    22367 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_array.h
--rw-r--r--   0 root         (0) root         (0)    22375 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_batched.h
--rw-rw-r--   0 root         (0) root         (0)    22725 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_complex.h
--rw-r--r--   0 root         (0) root         (0)     2591 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_grouped.h
--rw-r--r--   0 root         (0) root         (0)    13736 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_layernorm_mainloop_fusion.h
--rw-rw-r--   0 root         (0) root         (0)    17329 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_sparse.h
--rw-rw-r--   0 root         (0) root         (0)    20450 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_splitk_parallel.h
--rw-r--r--   0 root         (0) root         (0)    14902 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_universal.h
--rw-r--r--   0 root         (0) root         (0)     7444 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_universal_adapter.h
--rw-r--r--   0 root         (0) root         (0)    13089 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_universal_base.h
--rw-r--r--   0 root         (0) root         (0)    13968 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_universal_with_broadcast.h
--rw-r--r--   0 root         (0) root         (0)    14853 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_with_k_reduction.h
--rw-rw-r--   0 root         (0) root         (0)     5690 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemv.h
--rw-r--r--   0 root         (0) root         (0)    18127 2022-08-05 17:48:52.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/rank_2k.h
--rw-r--r--   0 root         (0) root         (0)     2747 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/rank_2k_grouped.h
--rw-rw-r--   0 root         (0) root         (0)    16719 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/rank_k.h
--rwxr-xr-x   0 root         (0) root         (0)    21050 2022-08-05 17:48:52.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/symm.h
--rw-r--r--   0 root         (0) root         (0)    26464 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/trmm.h
--rw-rw-r--   0 root         (0) root         (0)    11570 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/gemm.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:23:11.051598 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/
--rw-r--r--   0 root         (0) root         (0)    29360 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_ell_gemm.h
--rw-r--r--   0 root         (0) root         (0)    37752 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm.h
--rw-r--r--   0 root         (0) root         (0)    16130 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_complex.h
--rw-r--r--   0 root         (0) root         (0)    12385 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_grouped.h
--rw-r--r--   0 root         (0) root         (0)     6592 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_grouped_softmax_mainloop_fusion.h
--rw-r--r--   0 root         (0) root         (0)     5848 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_layernorm_mainloop_fusion.h
--rw-rw-r--   0 root         (0) root         (0)    11104 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_planar_complex_universal.h
--rw-rw-r--   0 root         (0) root         (0)     7983 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_sparse.h
--rw-rw-r--   0 root         (0) root         (0)     4932 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_splitk_parallel.h
--rw-r--r--   0 root         (0) root         (0)    11951 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_universal.h
--rw-rw-r--   0 root         (0) root         (0)     8063 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_with_broadcast.h
--rw-r--r--   0 root         (0) root         (0)     6457 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_with_k_reduction.h
--rw-rw-r--   0 root         (0) root         (0)     8086 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_with_reduction.h
--rwxrwxr-x   0 root         (0) root         (0)     5349 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemv.h
--rw-r--r--   0 root         (0) root         (0)    11560 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_rank_2k.h
--rw-r--r--   0 root         (0) root         (0)    20509 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_rank_2k_complex.h
--rw-r--r--   0 root         (0) root         (0)    12470 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_rank_2k_grouped.h
--rw-rw-r--   0 root         (0) root         (0)    10620 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_rank_2k_universal.h
--rw-r--r--   0 root         (0) root         (0)     9872 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_rank_k.h
--rw-r--r--   0 root         (0) root         (0)    16990 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_rank_k_complex.h
--rw-rw-r--   0 root         (0) root         (0)     9444 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_rank_k_universal.h
--rwxr-xr-x   0 root         (0) root         (0)    13375 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_symm.h
--rwxr-xr-x   0 root         (0) root         (0)    21830 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_symm_complex.h
--rwxrwxr-x   0 root         (0) root         (0)    10315 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_symm_universal.h
--rw-r--r--   0 root         (0) root         (0)    10873 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_trmm.h
--rw-r--r--   0 root         (0) root         (0)    10730 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_trmm_complex.h
--rw-rw-r--   0 root         (0) root         (0)    10850 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_trmm_universal.h
--rw-r--r--   0 root         (0) root         (0)    28916 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/ell_gemm.h
--rw-rw-r--   0 root         (0) root         (0)    13381 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm.h
--rw-rw-r--   0 root         (0) root         (0)     8717 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_array.h
--rw-rw-r--   0 root         (0) root         (0)     8785 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_batched.h
--rw-r--r--   0 root         (0) root         (0)    14711 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_grouped.h
--rw-r--r--   0 root         (0) root         (0)     4691 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_grouped_problem_visitor.h
--rw-r--r--   0 root         (0) root         (0)    15623 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_grouped_softmax_mainloop_fusion.h
--rw-r--r--   0 root         (0) root         (0)    27281 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_layernorm_mainloop_fusion.h
--rwxrwxr-x   0 root         (0) root         (0)     6144 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_params.h
--rw-rw-r--   0 root         (0) root         (0)     5165 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_pipelined.h
--rw-r--r--   0 root         (0) root         (0)    22973 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_planar_complex.h
--rw-r--r--   0 root         (0) root         (0)    18961 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_planar_complex_array.h
--rw-rw-r--   0 root         (0) root         (0)     8142 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_splitk_parallel.h
--rw-rw-r--   0 root         (0) root         (0)     4291 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_transpose_operands.h
--rw-r--r--   0 root         (0) root         (0)    22881 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_universal.h
--rw-rw-r--   0 root         (0) root         (0)    38687 2022-12-14 23:22:53.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_universal_streamk.h
--rw-r--r--   0 root         (0) root         (0)    47222 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_with_fused_epilogue.h
--rw-r--r--   0 root         (0) root         (0)    23629 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_with_k_reduction.h
--rw-r--r--   0 root         (0) root         (0)     8090 2022-08-05 17:48:52.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemv.h
--rwxrwxr-x   0 root         (0) root         (0)     8979 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemv_batched_strided.h
--rw-r--r--   0 root         (0) root         (0)    16849 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/grouped_problem_visitor.h
--rw-r--r--   0 root         (0) root         (0)     7148 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/params_universal_base.h
--rw-r--r--   0 root         (0) root         (0)    22962 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/rank_2k_grouped.h
--rw-r--r--   0 root         (0) root         (0)    16100 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/rank_2k_grouped_problem_visitor.h
--rw-r--r--   0 root         (0) root         (0)     4334 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/rank_2k_transpose_operands.h
--rw-rw-r--   0 root         (0) root         (0)    24162 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/rank_2k_universal.h
--rw-rw-r--   0 root         (0) root         (0)    17567 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/rank_k_universal.h
--rw-rw-r--   0 root         (0) root         (0)    13610 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/sparse_gemm.h
--rwxrwxr-x   0 root         (0) root         (0)    23900 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/symm_universal.h
--rw-rw-r--   0 root         (0) root         (0)    19537 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/trmm_universal.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:23:11.826318 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/thread/
--rw-rw-r--   0 root         (0) root         (0)     3567 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/thread/mma.h
--rw-r--r--   0 root         (0) root         (0)    15373 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/thread/mma_sm50.h
--rw-rw-r--   0 root         (0) root         (0)    29987 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/thread/mma_sm60.h
--rw-rw-r--   0 root         (0) root         (0)     8142 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/thread/mma_sm61.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:23:18.800064 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/
--rw-r--r--   0 root         (0) root         (0)    31930 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_ell_mma.h
--rwxrwxr-x   0 root         (0) root         (0)     6979 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_gemv_core.h
--rw-r--r--   0 root         (0) root         (0)    34241 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma.h
--rw-r--r--   0 root         (0) root         (0)     5123 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_core.h
--rw-rw-r--   0 root         (0) root         (0)    57426 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_core_simt.h
--rw-rw-r--   0 root         (0) root         (0)    19257 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sm70.h
--rw-r--r--   0 root         (0) root         (0)    42310 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sm75.h
--rw-r--r--   0 root         (0) root         (0)   103000 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sm80.h
--rw-rw-r--   0 root         (0) root         (0)    32106 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sparse_sm80.h
--rw-r--r--   0 root         (0) root         (0)    12645 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_core_with_access_size.h
--rw-r--r--   0 root         (0) root         (0)     7387 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_core_with_reduction.h
--rw-rw-r--   0 root         (0) root         (0)    20975 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_core_wmma.h
--rw-r--r--   0 root         (0) root         (0)     7998 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_layernorm_mainloop_fusion.h
--rw-rw-r--   0 root         (0) root         (0)     5110 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_planar_complex_multistage.h
--rw-rw-r--   0 root         (0) root         (0)     4627 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_planar_complex_pipelined.h
--rw-r--r--   0 root         (0) root         (0)     7113 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_softmax_mainloop_fusion.h
--rw-rw-r--   0 root         (0) root         (0)     6323 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_with_reduction.h
--rw-rw-r--   0 root         (0) root         (0)     7121 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_multistage_mma_complex.h
--rw-rw-r--   0 root         (0) root         (0)     4959 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_multistage_mma_complex_core.h
--rw-r--r--   0 root         (0) root         (0)    65201 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_multistage_mma_complex_core_sm80.h
--rw-rw-r--   0 root         (0) root         (0)    25495 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_multistage_trmm_complex.h
--rw-rw-r--   0 root         (0) root         (0)     8509 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_sparse_mma.h
--rw-rw-r--   0 root         (0) root         (0)    19515 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_trmm.h
--rw-r--r--   0 root         (0) root         (0)    24047 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/ell_mma_multistage.h
--rw-r--r--   0 root         (0) root         (0)    13836 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/ell_mma_pipelined.h
--rwxrwxr-x   0 root         (0) root         (0)     4726 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/gemv.h
--rw-r--r--   0 root         (0) root         (0)     3652 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/index_remat.h
--rw-r--r--   0 root         (0) root         (0)     7823 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_base.h
--rw-r--r--   0 root         (0) root         (0)    27413 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_blas3_multistage.h
--rw-r--r--   0 root         (0) root         (0)    32892 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_layernorm_mainloop_fusion_multistage.h
--rw-r--r--   0 root         (0) root         (0)    28013 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_multistage.h
--rw-r--r--   0 root         (0) root         (0)    15995 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_pipelined.h
--rw-rw-r--   0 root         (0) root         (0)     6901 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_planar_complex_base.h
--rw-rw-r--   0 root         (0) root         (0)    22805 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_planar_complex_multistage.h
--rw-rw-r--   0 root         (0) root         (0)    14746 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_planar_complex_pipelined.h
--rw-rw-r--   0 root         (0) root         (0)     9864 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_singlestage.h
--rw-r--r--   0 root         (0) root         (0)    27059 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_softmax_mainloop_fusion_multistage.h
--rw-r--r--   0 root         (0) root         (0)     9210 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_sparse_base.h
--rw-r--r--   0 root         (0) root         (0)    25364 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_sparse_multistage.h
--rw-r--r--   0 root         (0) root         (0)    20471 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_with_reduction_multistage.h
--rw-r--r--   0 root         (0) root         (0)    15007 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/threadblock_swizzle.h
--rw-r--r--   0 root         (0) root         (0)    25617 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/threadblock_swizzle_streamk.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:23:23.603274 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/
--rw-r--r--   0 root         (0) root         (0)    20553 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/default_mma_complex_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)     6684 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/default_mma_sparse_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)     5160 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/default_mma_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)     9026 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/default_mma_tensor_op_sm80.h
--rw-r--r--   0 root         (0) root         (0)     4053 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/default_mma_with_reduction_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)     4685 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/default_mma_wmma_tensor_op.h
--rw-r--r--   0 root         (0) root         (0)     5725 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/layernorm_scale_bias_transform.h
--rw-rw-r--   0 root         (0) root         (0)     2619 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma.h
--rw-r--r--   0 root         (0) root         (0)    37705 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_complex_tensor_op.h
--rw-r--r--   0 root         (0) root         (0)    23132 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_complex_tensor_op_fast_f32.h
--rw-rw-r--   0 root         (0) root         (0)    78615 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_complex_tensor_op_tile_iterator_sm80.h
--rw-r--r--   0 root         (0) root         (0)    21205 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_gaussian_complex_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)    14589 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_gaussian_complex_tensor_op_tile_iterator_sm80.h
--rw-rw-r--   0 root         (0) root         (0)     6144 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_planar_complex.h
--rw-rw-r--   0 root         (0) root         (0)     8446 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_simt.h
--rw-rw-r--   0 root         (0) root         (0)     3079 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_simt_policy.h
--rw-r--r--   0 root         (0) root         (0)    59793 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_simt_tile_iterator.h
--rw-rw-r--   0 root         (0) root         (0)    11758 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_sparse_tensor_op.h
--rw-r--r--   0 root         (0) root         (0)    14407 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)    15721 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_fast_f32.h
--rw-rw-r--   0 root         (0) root         (0)    18643 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_fragment_iterator.h
--rw-rw-r--   0 root         (0) root         (0)     2939 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_policy.h
--rw-rw-r--   0 root         (0) root         (0)     8966 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_sm70.h
--rw-r--r--   0 root         (0) root         (0)    11017 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_access_iterator.h
--rw-r--r--   0 root         (0) root         (0)   140855 2022-12-17 23:33:29.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator.h
--rw-rw-r--   0 root         (0) root         (0)    99649 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_sm70.h
--rw-rw-r--   0 root         (0) root         (0)    75179 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_sm80.h
--rw-rw-r--   0 root         (0) root         (0)    13151 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_sparse.h
--rw-r--r--   0 root         (0) root         (0)    27101 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_wmma.h
--rw-rw-r--   0 root         (0) root         (0)     7241 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_wmma.h
--rw-r--r--   0 root         (0) root         (0)    17271 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_with_reduction_tensor_op.h
--rw-r--r--   0 root         (0) root         (0)    19125 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/scale_bias_tile_iterator.h
--rw-r--r--   0 root         (0) root         (0)     4610 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/softmax_scale_bias_transform.h
--rw-rw-r--   0 root         (0) root         (0)     8728 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/tile_iterator_planar_complex.h
--rw-r--r--   0 root         (0) root         (0)    23615 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/half.h
--rw-r--r--   0 root         (0) root         (0)     6893 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/integer_subbyte.h
--rw-rw-r--   0 root         (0) root         (0)     2801 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/kernel_launch.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:23:26.452581 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/layout/
--rw-rw-r--   0 root         (0) root         (0)     3020 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/layout/layout.h
--rw-rw-r--   0 root         (0) root         (0)    34712 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/layout/matrix.h
--rw-r--r--   0 root         (0) root         (0)     9133 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/layout/permute.h
--rw-rw-r--   0 root         (0) root         (0)     4696 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/layout/pitch_linear.h
--rw-rw-r--   0 root         (0) root         (0)    18295 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/layout/tensor.h
--rw-rw-r--   0 root         (0) root         (0)    29599 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/layout/tensor_op_multiplicand_sm70.h
--rw-r--r--   0 root         (0) root         (0)    33137 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/layout/tensor_op_multiplicand_sm75.h
--rw-r--r--   0 root         (0) root         (0)    29336 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/layout/tensor_op_multiplicand_sm80.h
--rw-rw-r--   0 root         (0) root         (0)     3328 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/layout/vector.h
--rw-rw-r--   0 root         (0) root         (0)   364115 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/matrix.h
--rw-rw-r--   0 root         (0) root         (0)     4991 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/matrix_coord.h
--rw-rw-r--   0 root         (0) root         (0)     2726 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/matrix_shape.h
--rw-r--r--   0 root         (0) root         (0)    71278 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/numeric_conversion.h
--rw-r--r--   0 root         (0) root         (0)     3505 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/numeric_types.h
--rw-rw-r--   0 root         (0) root         (0)     5492 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/pitch_linear_coord.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:23:26.527108 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/platform/
--rw-r--r--   0 root         (0) root         (0)    26097 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/platform/platform.h
--rw-rw-r--   0 root         (0) root         (0)    15565 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/predicate_vector.h
--rw-r--r--   0 root         (0) root         (0)    20901 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/quaternion.h
--rw-rw-r--   0 root         (0) root         (0)     2369 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/real.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:23:26.619118 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/reduction/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:23:27.192460 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/reduction/device/
--rw-rw-r--   0 root         (0) root         (0)     6823 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/reduction/device/reduce_split_k.h
--rw-rw-r--   0 root         (0) root         (0)     8152 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/reduction/device/tensor_reduce.h
--rw-rw-r--   0 root         (0) root         (0)    11579 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/reduction/device/tensor_reduce_affine_contiguous.h
--rw-rw-r--   0 root         (0) root         (0)    11448 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/reduction/device/tensor_reduce_affine_strided.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:23:27.528998 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/reduction/kernel/
--rw-r--r--   0 root         (0) root         (0)     8762 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/reduction/kernel/reduce_softmax_final.h
--rw-rw-r--   0 root         (0) root         (0)     7897 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/reduction/kernel/reduce_split_k.h
--rw-rw-r--   0 root         (0) root         (0)    20685 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/reduction/kernel/tensor_reduce_affine_contiguous.h
--rw-rw-r--   0 root         (0) root         (0)    21662 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/reduction/kernel/tensor_reduce_affine_strided.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:23:27.807928 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/reduction/thread/
--rw-rw-r--   0 root         (0) root         (0)     7208 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/reduction/thread/reduce.h
--rw-rw-r--   0 root         (0) root         (0)     6790 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/reduction/thread/reduction_operators.h
--rw-rw-r--   0 root         (0) root         (0)     2936 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/reduction/threadblock_swizzle.h
--rw-rw-r--   0 root         (0) root         (0)     5929 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/relatively_equal.h
--rw-r--r--   0 root         (0) root         (0)     4186 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/semaphore.h
--rw-rw-r--   0 root         (0) root         (0)    16587 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/subbyte_reference.h
--rw-rw-r--   0 root         (0) root         (0)     8964 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/tensor_coord.h
--rw-rw-r--   0 root         (0) root         (0)    12207 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/tensor_ref.h
--rw-rw-r--   0 root         (0) root         (0)    11201 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/tensor_ref_planar_complex.h
--rw-rw-r--   0 root         (0) root         (0)     9509 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/tensor_view.h
--rw-rw-r--   0 root         (0) root         (0)    10250 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/tensor_view_planar_complex.h
--rw-r--r--   0 root         (0) root         (0)    13017 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/tfloat32.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:23:28.267609 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/thread/
--rw-rw-r--   0 root         (0) root         (0)     5931 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/thread/matrix.h
--rw-rw-r--   0 root         (0) root         (0)     2581 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/trace.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:23:28.335166 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/
--rw-r--r--   0 root         (0) root         (0)    33392 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/pitch_linear_thread_map.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:23:28.852173 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/thread/
--rw-rw-r--   0 root         (0) root         (0)     3835 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/thread/transpose.h
--rw-r--r--   0 root         (0) root         (0)     4309 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/thread/unaryOp.h
--rw-r--r--   0 root         (0) root         (0)     4309 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/thread/unary_op.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:23:33.223679 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/
--rw-r--r--   0 root         (0) root         (0)     6181 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/ell_iterator.h
--rw-r--r--   0 root         (0) root         (0)    44443 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/ell_predicated_tile_access_iterator.h
--rw-r--r--   0 root         (0) root         (0)    44309 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/ell_predicated_tile_iterator.h
--rw-r--r--   0 root         (0) root         (0)    12890 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_scale_bias_vector_access_iterator.h
--rw-r--r--   0 root         (0) root         (0)    11097 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_scale_bias_vector_iterator.h
--rw-r--r--   0 root         (0) root         (0)    70684 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator.h
--rw-rw-r--   0 root         (0) root         (0)    28232 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator_2dthreadtile.h
--rwxrwxr-x   0 root         (0) root         (0)    10243 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator_params.h
--rw-rw-r--   0 root         (0) root         (0)    31412 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator_triangular_matrix.h
--rw-r--r--   0 root         (0) root         (0)    62672 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_tile_iterator.h
--rw-rw-r--   0 root         (0) root         (0)    27175 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_tile_iterator_2dthreadtile.h
--rw-rw-r--   0 root         (0) root         (0)    28064 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_tile_iterator_triangular_matrix.h
--rw-r--r--   0 root         (0) root         (0)    13088 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_vector_access_iterator.h
--rw-r--r--   0 root         (0) root         (0)     8232 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_scale_bias_vector_access_iterator.h
--rw-rw-r--   0 root         (0) root         (0)     2638 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator.h
--rw-rw-r--   0 root         (0) root         (0)    13283 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_pitch_linear.h
--rw-r--r--   0 root         (0) root         (0)    18623 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_pitch_linear_direct_conv.h
--rw-r--r--   0 root         (0) root         (0)    30576 2022-12-15 06:04:58.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)    47789 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_tensor_op_sm80.h
--rw-rw-r--   0 root         (0) root         (0)     2616 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator.h
--rw-rw-r--   0 root         (0) root         (0)    16510 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_pitch_linear.h
--rw-rw-r--   0 root         (0) root         (0)    15486 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_pitch_linear_2dthreadtile.h
--rw-r--r--   0 root         (0) root         (0)    36552 2022-11-27 00:34:43.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_tensor_op.h
--rw-rw-r--   0 root         (0) root         (0)    43663 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_tensor_op_sm70.h
--rw-rw-r--   0 root         (0) root         (0)     5226 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/vector_iterator.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:23:33.327655 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/warp/
--rw-rw-r--   0 root         (0) root         (0)     8828 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/warp/vector_fragment_iterator.h
--rw-r--r--   0 root         (0) root         (0)     8139 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/uint128.h
--rw-r--r--   0 root         (0) root         (0)     3359 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/wmma_array.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:46.297221 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:23:33.625418 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:23:33.794515 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/common/
--rw-rw-r--   0 root         (0) root         (0)     4273 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/common/cutlass_unit_test.h
--rw-r--r--   0 root         (0) root         (0)     4341 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/common/filter_architecture.cpp
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:46.315454 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:23:46.009961 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/
--rw-rw-r--   0 root         (0) root         (0)    21797 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/cache_testbed_output.h
--rw-rw-r--   0 root         (0) root         (0)     5344 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)     5443 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm80.cu
--rw-r--r--   0 root         (0) root         (0)    11470 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f16_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5239 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     9110 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)     8485 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5243 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5378 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu
--rw-r--r--   0 root         (0) root         (0)    12054 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_few_channels_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     9603 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_fixed_channels_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5267 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)     5357 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5089 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu
--rw-rw-r--   0 root         (0) root         (0)    13690 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f16_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5390 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5191 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)    11136 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)     5291 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     3551 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)     5157 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.cu
--rwxrwxr-x   0 root         (0) root         (0)     8278 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_qf32nhwc_qf32nhwc_qf32nhwc_simt_f32_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    20555 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4ncxhwx_s4cxrskx_s4ncxhwx_tensor_op_s32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    20647 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4ncxhwx_s4cxrskx_s4ncxhwx_tensor_op_s32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5155 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4nhwc_s4nhwc_s32nhwc_tensor_op_s32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)     5239 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4nhwc_s4nhwc_s32nhwc_tensor_op_s32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    26114 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8ncxhwx_s8cxrskx_s8ncxhwx_tensor_op_s32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    26210 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8ncxhwx_s8cxrskx_s8ncxhwx_tensor_op_s32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5111 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8nhwc_s8nhwc_s32nhwc_tensor_op_s32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)     5194 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8nhwc_s8nhwc_s32nhwc_tensor_op_s32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5738 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5439 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_with_broadcast_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     7363 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_with_broadcast_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)     3984 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_with_reduction_sm75.cu
--rw-r--r--   0 root         (0) root         (0)    39452 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_problems.h
--rw-r--r--   0 root         (0) root         (0)    14471 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_strided_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu
--rw-r--r--   0 root         (0) root         (0)     4662 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_strided_dgrad_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu
--rw-r--r--   0 root         (0) root         (0)    26224 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_testbed.h
--rw-r--r--   0 root         (0) root         (0)    21174 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_testbed_interleaved.h
--rw-rw-r--   0 root         (0) root         (0)     5179 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)     5358 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5264 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f16_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     3615 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     7591 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    10514 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5157 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5772 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu
--rw-r--r--   0 root         (0) root         (0)    23460 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_with_broadcast_testbed.h
--rw-r--r--   0 root         (0) root         (0)    21512 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_with_reduction_testbed.h
--rw-rw-r--   0 root         (0) root         (0)     5135 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_dgrad_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5347 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_dgrad_implicit_gemm_tf32ndhwc_tf32ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     3736 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_fprop_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)     6560 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_fprop_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5257 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_fprop_implicit_gemm_tf32ndhwc_tf32ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    12276 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_problems.h
--rw-r--r--   0 root         (0) root         (0)    21643 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_testbed.h
--rw-rw-r--   0 root         (0) root         (0)     3622 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)     6560 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5256 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_tf32ndhwc_tf32ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
--rw-r--r--   0 root         (0) root         (0)    17700 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/depthwise_conv2d_direct_conv_testbed.h
--rw-r--r--   0 root         (0) root         (0)    18437 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_direct_conv_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu
--rw-r--r--   0 root         (0) root         (0)    22194 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_direct_conv_fixed_stride_dilation_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu
--rw-r--r--   0 root         (0) root         (0)     9383 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu
--rw-r--r--   0 root         (0) root         (0)     9387 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/depthwise_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu
--rw-r--r--   0 root         (0) root         (0)    16100 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/group_conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:23:48.133014 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/core/
--rw-rw-r--   0 root         (0) root         (0)     7365 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/core/array.cu
--rw-rw-r--   0 root         (0) root         (0)     7353 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/core/bfloat16.cu
--rw-rw-r--   0 root         (0) root         (0)     6981 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/core/complex.cu
--rw-r--r--   0 root         (0) root         (0)     4009 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/core/float8.cu
--rw-rw-r--   0 root         (0) root         (0)    13001 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/core/functional.cu
--rw-rw-r--   0 root         (0) root         (0)     3553 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/core/half.cu
--rw-rw-r--   0 root         (0) root         (0)     5295 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/core/matrix.cu
--rw-rw-r--   0 root         (0) root         (0)     8592 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/core/matrix_coord.cu
--rw-r--r--   0 root         (0) root         (0)    11508 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/core/numeric_conversion.cu
--rw-rw-r--   0 root         (0) root         (0)     8148 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/core/predicate_vector.cu
--rw-rw-r--   0 root         (0) root         (0)     5777 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/core/quaternion.cu
--rw-rw-r--   0 root         (0) root         (0)     6746 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/core/tensor_ref.cu
--rw-rw-r--   0 root         (0) root         (0)     8885 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/core/tensor_view.cu
--rw-rw-r--   0 root         (0) root         (0)     2050 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/core/test_unit_core.cpp
--rw-rw-r--   0 root         (0) root         (0)     7088 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/core/tfloat32.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:46.341725 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:23:48.542452 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/thread/
--rw-r--r--   0 root         (0) root         (0)    15818 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/thread/activation.cu
--rw-rw-r--   0 root         (0) root         (0)     6534 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/thread/linear_combination.cu
--rw-rw-r--   0 root         (0) root         (0)     9964 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/thread/linear_combination_planar_complex.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:23:52.276936 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/
--rw-r--r--   0 root         (0) root         (0)    13824 2022-08-07 23:35:00.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/epilogue_planar_complex.cu
--rw-r--r--   0 root         (0) root         (0)    27176 2022-08-07 23:35:00.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/epilogue_simt.cu
--rw-r--r--   0 root         (0) root         (0)    12061 2022-08-07 23:35:00.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/epilogue_simt_sm60.cu
--rw-r--r--   0 root         (0) root         (0)    25275 2022-08-07 23:35:00.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/epilogue_simt_sm61.cu
--rw-r--r--   0 root         (0) root         (0)    84612 2022-08-07 23:35:00.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/epilogue_tensor_op.cu
--rw-r--r--   0 root         (0) root         (0)    70486 2022-08-07 23:35:00.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/epilogue_volta_tensor_op.cu
--rw-r--r--   0 root         (0) root         (0)    25293 2022-08-07 23:35:00.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/epilogue_with_reduction_tensor_op.cu
--rw-rw-r--   0 root         (0) root         (0)    13012 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/epilogue_with_reduction_testbed.h
--rw-r--r--   0 root         (0) root         (0)     7743 2022-08-07 23:35:00.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/epilogue_wmma_tensor_op_sm70.cu
--rw-r--r--   0 root         (0) root         (0)    19178 2022-08-07 23:35:00.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/output_tile_threadmap.cu
--rw-rw-r--   0 root         (0) root         (0)    28433 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/predicated_tile_iterator.cu
--rw-rw-r--   0 root         (0) root         (0)    11038 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/testbed.h
--rw-rw-r--   0 root         (0) root         (0)    11734 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/testbed_planar_complex.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:23:52.950072 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/warp/
--rw-rw-r--   0 root         (0) root         (0)     6783 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/warp/fragment_iterator_tensor_op.cu
--rw-rw-r--   0 root         (0) root         (0)     7275 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/warp/fragment_iterator_volta_tensor_op.cu
--rw-rw-r--   0 root         (0) root         (0)     6616 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/warp/fragment_iterator_wmma_tensor_op.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:46.374230 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:24:43.101545 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/
--rw-r--r--   0 root         (0) root         (0)    10189 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32n_tensor_op_s32_sm75.cu
--rw-r--r--   0 root         (0) root         (0)    17899 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32n_tensor_op_s32_sm80.cu
--rw-r--r--   0 root         (0) root         (0)     8933 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32n_wmma_tensor_op_s32_sm75.cu
--rw-r--r--   0 root         (0) root         (0)    10164 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32t_tensor_op_s32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    17984 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32t_tensor_op_s32_sm80.cu
--rw-r--r--   0 root         (0) root         (0)     8915 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32t_wmma_tensor_op_s32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    16447 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_bf16n_bf16n_f32t_tensor_op_f32_sm80.cu
--rw-r--r--   0 root         (0) root         (0)    16575 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_bf16t_bf16t_bf16t_tensor_op_f32_sm80.cu
--rw-r--r--   0 root         (0) root         (0)     8318 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_cf32n_cf32t_cf32t_tensor_op_tf32_f32_sm80.cu
--rw-r--r--   0 root         (0) root         (0)     8317 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_cf32t_cf32n_cf32t_tensor_op_tf32_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     6714 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_gaussian_sm80.cu
--rw-r--r--   0 root         (0) root         (0)     6735 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_gaussian_sm90.cu
--rw-rw-r--   0 root         (0) root         (0)     7895 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_sm80.cu
--rw-r--r--   0 root         (0) root         (0)     7918 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_sm90.cu
--rw-rw-r--   0 root         (0) root         (0)     6516 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_gaussian_sm80.cu
--rw-r--r--   0 root         (0) root         (0)     6537 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_gaussian_sm90.cu
--rw-rw-r--   0 root         (0) root         (0)     9016 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_sm80.cu
--rw-r--r--   0 root         (0) root         (0)     9041 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_sm90.cu
--rw-rw-r--   0 root         (0) root         (0)     4628 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16n_direct_store_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     6165 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16n_wmma_tensor_op_f16_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     6124 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16n_wmma_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     9634 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_tensor_op_f32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    16357 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    13189 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_tensor_op_f32_sparse_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8845 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_volta_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)    13583 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_wmma_tensor_op_f16_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)    13464 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_wmma_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     9571 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32n_tensor_op_f32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    16239 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32n_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     6140 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32n_wmma_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     9544 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_tensor_op_f32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    16417 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    13075 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_tensor_op_f32_sparse_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8775 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_volta_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)    11470 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_wmma_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     6156 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16n_wmma_tensor_op_f16_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     6116 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16n_wmma_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     3528 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_slicedk_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)     3539 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_slicedk_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     7965 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    16470 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    13273 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_sparse_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     3648 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8608 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_volta_tensor_op_f16_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)    13518 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_wmma_tensor_op_f16_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     3645 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_wmma_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     6096 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32n_wmma_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     7845 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_tensor_op_f32_sm75.cu
--rw-r--r--   0 root         (0) root         (0)    18135 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    13008 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_tensor_op_f32_sparse_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8505 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_volta_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)    11497 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_wmma_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)    11090 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16n_singlestage_wmma_tensor_op_f16_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     6156 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16n_wmma_tensor_op_f16_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     6116 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16n_wmma_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)    11066 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_singlestage_wmma_tensor_op_f16_sm70.cu
--rw-r--r--   0 root         (0) root         (0)    17114 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_broadcast_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     3528 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_slicedk_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)     3540 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_slicedk_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     7964 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    16457 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    13266 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_sparse_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8933 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_volta_tensor_op_f16_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)    13551 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_wmma_tensor_op_f16_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)    13540 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_wmma_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     6130 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32n_wmma_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     8160 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_singlestage_wmma_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     7847 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_tensor_op_f32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    16131 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    13014 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_tensor_op_f32_sparse_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8754 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_volta_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)    11497 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_wmma_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     6147 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16n_wmma_tensor_op_f16_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     6107 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16n_wmma_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)    13518 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16t_wmma_tensor_op_f16_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)    13398 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16t_wmma_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     7845 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32n_tensor_op_f32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    16149 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32n_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     6119 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32n_wmma_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     7827 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_tensor_op_f32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    16101 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     9526 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_tensor_op_f32_sparse_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     7898 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_volta_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)    11470 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_wmma_tensor_op_f32_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     3584 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f32n_f32n_f32t_tensor_op_bf16_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     3473 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f32n_f32n_f32t_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    12967 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f32n_f32n_f32t_tensor_op_f32_sparse_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    12931 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f32n_f32t_f32t_tensor_op_f32_sparse_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    12930 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f32t_f32n_f32t_tensor_op_f32_sparse_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    12895 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f32t_f32t_f32t_tensor_op_f32_sparse_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8349 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f64n_f64t_f64t_tensor_op_f64_sm80.cu
--rw-r--r--   0 root         (0) root         (0)     7288 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f64n_f64t_f64t_tensor_op_f64_sm90.cu
--rw-rw-r--   0 root         (0) root         (0)     8348 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f64t_f64n_f64t_tensor_op_f64_sm80.cu
--rw-r--r--   0 root         (0) root         (0)     7279 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f64t_f64n_f64t_tensor_op_f64_sm90.cu
--rw-r--r--   0 root         (0) root         (0)    10240 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_grouped_scheduler_sm80.cu
--rw-r--r--   0 root         (0) root         (0)    26146 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_grouped_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    11339 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_planar_complex_f16_f16_f32_tensor_op_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     7346 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_planar_complex_f16_f16_f32_tensor_op_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    12397 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_planar_complex_f16_f16_f32_tensor_op_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     6859 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4n_s4t_s4n_tensor_op_s32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)     7239 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4n_s4t_s4n_tensor_op_s32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8121 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32n_tensor_op_s32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    16882 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32n_tensor_op_s32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8407 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32n_wmma_tensor_op_s32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)     8103 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_tensor_op_s32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    17111 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_tensor_op_s32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    12637 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_tensor_op_s32_sparse_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8388 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_wmma_tensor_op_s32_sm75.cu
--rw-r--r--   0 root         (0) root         (0)    10044 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4n_tensor_op_s32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    17544 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4n_tensor_op_s32_sm80.cu
--rw-r--r--   0 root         (0) root         (0)    10020 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4t_tensor_op_s32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    17544 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4t_tensor_op_s32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     9588 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8n_s8t_s8n_tensor_op_s32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    11288 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8n_s8t_s8n_tensor_op_s32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     7977 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32n_tensor_op_s32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    16531 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32n_tensor_op_s32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5693 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32n_wmma_tensor_op_s32_sm72.cu
--rw-rw-r--   0 root         (0) root         (0)     7959 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_tensor_op_s32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    16691 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_tensor_op_s32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    12408 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_tensor_op_s32_sparse_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     6864 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_wmma_tensor_op_s32_sm72.cu
--rw-rw-r--   0 root         (0) root         (0)     7744 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8n_tensor_op_s32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    16531 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8n_tensor_op_s32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     6675 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8n_wmma_tensor_op_s32_sm72.cu
--rw-rw-r--   0 root         (0) root         (0)     7752 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8t_tensor_op_s32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    16484 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8t_tensor_op_s32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     6663 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8t_wmma_tensor_op_s32_sm72.cu
--rw-rw-r--   0 root         (0) root         (0)     4663 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_splitk_serial_tensor_op_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)     4945 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_splitk_simt_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)     6616 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_splitk_tensor_op_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)    10581 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_splitk_tensor_op_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    16950 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_tf32n_tf32n_f32t_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    16902 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_tf32n_tf32t_f32t_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    15131 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_tf32t_tf32n_f32t_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    16855 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_tf32t_tf32t_f32t_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     6854 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_u8t_u8n_s32t_wmma_tensor_op_s32_sm72.cu
--rw-rw-r--   0 root         (0) root         (0)     6686 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_universal_cf32n_cf32n_cf32n_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     6755 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_universal_cf64n_cf64t_cf64t_tensor_op_f64_gaussian_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     6687 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_universal_cf64n_cf64t_cf64t_tensor_op_f64_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     4726 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_universal_f16n_f16t_f32n_tensor_op_f32_sm75.cu
--rw-r--r--   0 root         (0) root         (0)     4718 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_universal_f16n_f16t_f32t_tensor_op_f32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    16715 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_with_broadcast_f16n_f16n_f16n_tensorop_f32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    12841 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_with_reduction_f16n_f16n_f16n_tensorop_f32_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)     4544 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_with_reduction_f16t_f16n_f16n_tensorop_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    13157 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemv.cu
--rw-rw-r--   0 root         (0) root         (0)     6028 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_f32_ls_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     6031 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_f32_rs_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     6064 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_fast_f32_ls_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     6067 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_fast_f32_rs_sm80.cu
--rw-r--r--   0 root         (0) root         (0)     4897 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/hemm_cf64_cf64_cf64_tensor_op_f64_sm90.cu
--rw-rw-r--   0 root         (0) root         (0)     6088 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/hemm_cf64h_cf64n_cf64n_tensor_op_ls_f64_gaussian_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     6037 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/hemm_cf64h_cf64n_cf64n_tensor_op_ls_f64_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     6040 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/hemm_cf64h_cf64n_cf64n_tensor_op_rs_f64_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5382 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/her2k_cf32h_cf32n_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5406 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/her2k_cf32h_cf32n_tensor_op_fast_f32_sm80.cu
--rw-r--r--   0 root         (0) root         (0)     5390 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/her2k_cf64_cf64_tensor_op_f64_sm90.cu
--rw-r--r--   0 root         (0) root         (0)    13055 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/her2k_cf64h_cf64n_tensor_op_f64_grouped_sm80.cu
--rw-r--r--   0 root         (0) root         (0)    13027 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/her2k_cf64n_cf64n_tensor_op_f64_grouped_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5388 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/her2k_cf64n_cf64n_tensor_op_f64_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     6939 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/her2k_cf64n_cf64t_tensor_op_f64_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     7677 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/herk_cf32h_cf32n_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     7725 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/herk_cf32h_cf32n_tensor_op_fast_f32_sm80.cu
--rw-r--r--   0 root         (0) root         (0)     3842 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/herk_cf64_cf64_tensor_op_f64_sm90.cu
--rw-rw-r--   0 root         (0) root         (0)     6396 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/herk_cf64h_cf64n_tensor_op_f64_sm80.cu
--rw-r--r--   0 root         (0) root         (0)    10023 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/multistage_testbed.h
--rw-rw-r--   0 root         (0) root         (0)     9189 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/multistage_testbed_interleaved.h
--rw-r--r--   0 root         (0) root         (0)    11186 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/rank_2k_grouped_scheduler_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    46795 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_cgemm_nn_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    54085 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_cgemm_nt_sm50.cu
--rw-r--r--   0 root         (0) root         (0)     8318 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_cgemm_nt_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    46687 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_cgemm_tn_sm50.cu
--rw-r--r--   0 root         (0) root         (0)     8411 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_cgemm_tn_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    46578 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_cgemm_tt_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    40533 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_dgemm_nn_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    47656 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_dgemm_nt_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    40441 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_dgemm_tn_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    40354 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_dgemm_tt_sm50.cu
--rw-r--r--   0 root         (0) root         (0)     3513 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_f8gemm_tn_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    89517 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_hgemm_nn_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    89304 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_hgemm_nt_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    89304 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_hgemm_tn_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    89091 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_hgemm_tt_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    69175 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_igemm_nn_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    71438 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_igemm_nt_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    67796 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_igemm_tn_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    70056 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_igemm_tt_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)     7156 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_int8_igemm_sm61.cu
--rw-rw-r--   0 root         (0) root         (0)     6067 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_int8_igemm_sm61_perf.cu
--rw-rw-r--   0 root         (0) root         (0)     9063 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_int8_igemm_sm61_sliced_k.cu
--rw-r--r--   0 root         (0) root         (0)    35894 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_qgemm_nn_sm50.cu
--rw-r--r--   0 root         (0) root         (0)    35813 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_qgemm_nt_sm50.cu
--rw-r--r--   0 root         (0) root         (0)    35813 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_qgemm_tn_sm50.cu
--rw-r--r--   0 root         (0) root         (0)    35732 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_qgemm_tt_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    70872 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_sgemm_nn_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    73136 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_sgemm_nt_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)     8870 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_sgemm_nt_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    69488 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_sgemm_tn_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)     8865 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_sgemm_tn_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    71755 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_sgemm_tt_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    33231 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_zgemm_nn_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    33156 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_zgemm_nt_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    33156 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_zgemm_tn_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    33081 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_zgemm_tt_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)     5923 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_f32_ls_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5926 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_f32_rs_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5959 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_fast_f32_ls_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5962 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_fast_f32_rs_sm80.cu
--rw-r--r--   0 root         (0) root         (0)     4827 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_cf64_cf64_cf64_tensor_op_f64_sm90.cu
--rw-rw-r--   0 root         (0) root         (0)     5983 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_cf64n_cf64n_cf64n_tensor_op_ls_f64_gaussian_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5932 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_cf64n_cf64n_cf64n_tensor_op_ls_f64_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5935 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_cf64n_cf64n_cf64n_tensor_op_rs_f64_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    15203 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f32n_f32n_tensor_op_fast_f32_ls_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8623 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f32n_f32n_tensor_op_fast_f32_rs_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    15104 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f32t_f32t_tensor_op_fast_f32_ls_sm80.cu
--rw-r--r--   0 root         (0) root         (0)     4765 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f64_f64_tensor_op_f64_sm90.cu
--rw-rw-r--   0 root         (0) root         (0)     8103 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f64n_f64n_tensor_op_f64_ls_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8108 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f64n_f64n_tensor_op_f64_rs_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8088 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f64n_f64t_tensor_op_f64_ls_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8093 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f64n_f64t_tensor_op_f64_rs_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8073 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f64t_f64n_tensor_op_f64_ls_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8078 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f64t_f64n_tensor_op_f64_rs_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8058 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f64t_f64t_tensor_op_f64_ls_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8063 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f64t_f64t_tensor_op_f64_rs_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    15071 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_tf32n_f32n_tensor_op_f32_ls_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8551 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_tf32n_f32n_tensor_op_f32_rs_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    14972 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_tf32t_f32t_tensor_op_f32_ls_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5362 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32n_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5386 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32n_tensor_op_fast_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5356 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32t_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5380 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32t_tensor_op_fast_f32_sm80.cu
--rw-r--r--   0 root         (0) root         (0)     5367 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf64_cf64_tensor_op_f64_sm90.cu
--rw-r--r--   0 root         (0) root         (0)    12952 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64n_tensor_op_f64_grouped_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5368 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64n_tensor_op_f64_sm80.cu
--rw-r--r--   0 root         (0) root         (0)     7208 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64t_tensor_op_f64_grouped_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5362 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64t_tensor_op_f64_sm80.cu
--rw-r--r--   0 root         (0) root         (0)     7199 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf64t_cf64n_tensor_op_f64_grouped_sm80.cu
--rw-r--r--   0 root         (0) root         (0)     7190 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf64t_cf64t_tensor_op_f64_grouped_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     4794 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_f32n_f32n_tensor_op_fast_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     4783 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_f32t_f32n_tensor_op_fast_f32_sm80.cu
--rw-r--r--   0 root         (0) root         (0)     4728 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_f64_f64_tensor_op_f64_sm90.cu
--rw-r--r--   0 root         (0) root         (0)    19145 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_f64n_f64n_tensor_op_f64_grouped_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     7991 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_f64n_f64n_tensor_op_f64_sm80.cu
--rw-r--r--   0 root         (0) root         (0)    11015 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_f64n_f64t_tensor_op_f64_grouped_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     7976 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_f64n_f64t_tensor_op_f64_sm80.cu
--rw-r--r--   0 root         (0) root         (0)    12342 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_f64t_f64n_tensor_op_f64_grouped_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     7961 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_f64t_f64n_tensor_op_f64_sm80.cu
--rw-r--r--   0 root         (0) root         (0)    12321 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_f64t_f64t_tensor_op_f64_grouped_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     4786 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_tf32n_f32n_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     4775 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_tf32t_f32n_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     4993 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_cf32n_cf32n_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5017 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_cf32n_cf32n_tensor_op_fast_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     4987 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_cf32n_cf32t_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     5011 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_cf32n_cf32t_tensor_op_fast_f32_sm80.cu
--rw-r--r--   0 root         (0) root         (0)     5012 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_cf64_cf64_tensor_op_f64_sm90.cu
--rw-rw-r--   0 root         (0) root         (0)     4996 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_cf64n_cf64n_tensor_op_f64_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     3793 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_cf64n_cf64t_tensor_op_f64_gaussian_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     4990 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_cf64n_cf64t_tensor_op_f64_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    16083 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_f32n_f32t_tensor_op_fast_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    16041 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_f32t_f32t_tensor_op_fast_f32_sm80.cu
--rw-r--r--   0 root         (0) root         (0)     4518 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_f64_f64_tensor_op_f64_sm90.cu
--rw-rw-r--   0 root         (0) root         (0)     7451 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_f64n_f64t_tensor_op_f64_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     9401 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_f64t_f64n_tensor_op_f64_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    16027 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_tf32n_f32t_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    15985 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_tf32t_f32t_tensor_op_f32_sm80.cu
--rw-r--r--   0 root         (0) root         (0)    20333 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed.h
--rw-r--r--   0 root         (0) root         (0)     8136 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_complex.h
--rw-r--r--   0 root         (0) root         (0)    20590 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_gemm_with_broadcast.h
--rw-r--r--   0 root         (0) root         (0)    19346 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_gemm_with_reduction.h
--rw-r--r--   0 root         (0) root         (0)    16502 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_grouped.h
--rw-r--r--   0 root         (0) root         (0)    16562 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_grouped_rank_2k.h
--rw-r--r--   0 root         (0) root         (0)    17002 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_grouped_rank_2k_scheduler.h
--rw-r--r--   0 root         (0) root         (0)    14698 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_grouped_scheduler.h
--rw-r--r--   0 root         (0) root         (0)    10130 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_interleaved.h
--rw-r--r--   0 root         (0) root         (0)     9481 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_planar_complex.h
--rw-r--r--   0 root         (0) root         (0)    20761 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_rank2k_universal.h
--rw-r--r--   0 root         (0) root         (0)    15562 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_rank_k_universal.h
--rw-r--r--   0 root         (0) root         (0)     8639 2022-08-07 23:35:00.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_sanity.h
--rw-r--r--   0 root         (0) root         (0)    15769 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_sparse.h
--rw-r--r--   0 root         (0) root         (0)     6124 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_splitk.h
--rw-r--r--   0 root         (0) root         (0)    19861 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_symm_universal.h
--rw-r--r--   0 root         (0) root         (0)    20200 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_trmm_universal.h
--rw-r--r--   0 root         (0) root         (0)    17348 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_universal.h
--rw-rw-r--   0 root         (0) root         (0)     2626 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_utils.h
--rw-rw-r--   0 root         (0) root         (0)     9916 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_cf32n_cf32n_cf32t_tensor_op_f32_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     9988 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_cf32n_cf32n_cf32t_tensor_op_fast_f32_sm80.cu
--rw-r--r--   0 root         (0) root         (0)     4977 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_cf64_cf64_cf64_tensor_op_f64_sm90.cu
--rw-rw-r--   0 root         (0) root         (0)     4992 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_cf64n_cf64n_cf64t_tensor_op_f64_gaussian_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     9762 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_cf64n_cf64n_cf64t_tensor_op_f64_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    15614 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_f32n_f32t_f32t_tensor_op_fast_f32_ls_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8733 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_f32n_f32t_f32t_tensor_op_fast_f32_rs_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    14089 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_f32t_f32n_f32n_tensor_op_fast_f32_ls_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    14444 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_f32t_f32n_f32t_tensor_op_fast_f32_ls_sm80.cu
--rw-r--r--   0 root         (0) root         (0)     4596 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_f64_f64_f64_tensor_op_f64_sm90.cu
--rw-rw-r--   0 root         (0) root         (0)    12798 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_f64n_f64n_f64t_tensor_op_f64_ls_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    12809 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_f64n_f64n_f64t_tensor_op_f64_rs_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    12764 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_f64n_f64t_f64t_tensor_op_f64_rs_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    12768 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_f64t_f64t_f64n_tensor_op_f64_ls_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    12779 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_f64t_f64t_f64n_tensor_op_f64_rs_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    15504 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_tf32n_tf32t_f32t_tensor_op_f32_ls_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)     8673 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_tf32n_tf32t_f32t_tensor_op_f32_rs_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    13989 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_tf32t_tf32n_f32n_tensor_op_f32_ls_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    14344 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_tf32t_tf32n_f32t_tensor_op_f32_ls_sm80.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:24:43.528186 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/kernel/
--rwxrwxr-x   0 root         (0) root         (0)    46470 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/kernel/batched_gemv.cu
--rwxrwxr-x   0 root         (0) root         (0)    14350 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/kernel/testbed_gemv.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:24:43.852436 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/thread/
--rw-rw-r--   0 root         (0) root         (0)     4847 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/thread/gemm_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)    12503 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/thread/gemm_sm60.cu
--rw-rw-r--   0 root         (0) root         (0)     3109 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/thread/gemm_sm61.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:24:44.049797 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/thread/host/
--rw-rw-r--   0 root         (0) root         (0)     5198 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/thread/host/gemm_sm60_host.cu
--rw-rw-r--   0 root         (0) root         (0)     7161 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/thread/host/testbed_host.h
--rw-rw-r--   0 root         (0) root         (0)     7124 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/thread/testbed.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:24:48.442477 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/
--rw-rw-r--   0 root         (0) root         (0)    24658 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/batched_gemv.cu
--rw-rw-r--   0 root         (0) root         (0)     4345 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/epilogue_workspace.cu
--rw-rw-r--   0 root         (0) root         (0)   135045 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_multistage.cu
--rw-rw-r--   0 root         (0) root         (0)     4644 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_multistage_slicedk.cu
--rw-rw-r--   0 root         (0) root         (0)    94442 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_multistage_sparse.cu
--rw-r--r--   0 root         (0) root         (0)    17109 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_multistage_sparse_testbed.h
--rw-rw-r--   0 root         (0) root         (0)    13131 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_multistage_testbed.h
--rw-r--r--   0 root         (0) root         (0)    14539 2022-08-07 23:35:00.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_multistage_testbed_slicedk.h
--rw-rw-r--   0 root         (0) root         (0)    49052 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_pipelined_simt.cu
--rw-rw-r--   0 root         (0) root         (0)     8407 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_pipelined_slicedk.cu
--rw-rw-r--   0 root         (0) root         (0)    18705 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_pipelined_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)    78122 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_pipelined_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    21051 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_pipelined_sm80.cu
--rw-r--r--   0 root         (0) root         (0)    13413 2022-08-07 23:35:00.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_pipelined_testbed.h
--rw-r--r--   0 root         (0) root         (0)    14239 2022-08-07 23:35:00.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_pipelined_testbed_slicedk.h
--rw-rw-r--   0 root         (0) root         (0)    29772 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_pipelined_wmma_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)    12395 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_pipelined_wmma_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)     3502 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_planar_complex_sm80.cu
--rw-r--r--   0 root         (0) root         (0)    12138 2022-08-07 23:35:00.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_planar_complex_testbed.h
--rw-rw-r--   0 root         (0) root         (0)    16308 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_singlestage_wmma_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)    12502 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_singlestage_wmma_sm75.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:24:51.059512 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/warp/
--rw-r--r--   0 root         (0) root         (0)    22128 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_complex_sm80.cu
--rw-r--r--   0 root         (0) root         (0)    10904 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_complex_sm90.cu
--rw-rw-r--   0 root         (0) root         (0)     9873 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_gaussian_complex_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    18220 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_sm50.cu
--rw-rw-r--   0 root         (0) root         (0)     4920 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_sm60.cu
--rw-rw-r--   0 root         (0) root         (0)     6291 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_sm61.cu
--rw-rw-r--   0 root         (0) root         (0)     9297 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)    37942 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_sm75.cu
--rw-rw-r--   0 root         (0) root         (0)    81659 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_sm80.cu
--rw-r--r--   0 root         (0) root         (0)     9077 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_sm90.cu
--rw-rw-r--   0 root         (0) root         (0)    48928 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_sparse_sm80.cu
--rw-rw-r--   0 root         (0) root         (0)    45327 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/warp/testbed.h
--rw-rw-r--   0 root         (0) root         (0)    25780 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/warp/wmma_sm70.cu
--rw-rw-r--   0 root         (0) root         (0)     7544 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/warp/wmma_sm72.cu
--rw-rw-r--   0 root         (0) root         (0)     6487 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/warp/wmma_sm75.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:24:51.432670 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/layout/
--rw-rw-r--   0 root         (0) root         (0)     5788 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/layout/matrix.cu
--rw-rw-r--   0 root         (0) root         (0)     5984 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/layout/tensor.cu
--rw-rw-r--   0 root         (0) root         (0)     7081 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/layout/tensor_nhwc.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:46.422571 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/nvrtc/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:46.403631 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/nvrtc/cutlass/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:24:51.498026 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/nvrtc/cutlass/nvrtc/
--rw-rw-r--   0 root         (0) root         (0)     2096 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/nvrtc/cutlass/nvrtc/environment.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:46.417539 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/nvrtc/kernel/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:24:51.608373 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/nvrtc/kernel/thread/
--rw-rw-r--   0 root         (0) root         (0)     2915 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/nvrtc/kernel/thread/testbed_kernel.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:24:51.745614 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/nvrtc/stdlib/
--rw-rw-r--   0 root         (0) root         (0)        0 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/nvrtc/stdlib/assert.h
--rw-rw-r--   0 root         (0) root         (0)     4250 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/nvrtc/stdlib/stdint.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:24:52.079797 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/nvrtc/thread/
--rw-rw-r--   0 root         (0) root         (0)     5727 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/nvrtc/thread/gemm_nvrtc.cu
--rw-rw-r--   0 root         (0) root         (0)    10328 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/nvrtc/thread/testbed.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:46.448572 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/reduction/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:24:52.766562 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/reduction/device/
--rw-rw-r--   0 root         (0) root         (0)    14684 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/reduction/device/tensor_reduce_contiguous.cu
--rw-rw-r--   0 root         (0) root         (0)    15609 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/reduction/device/tensor_reduce_strided.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:24:53.006678 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/reduction/kernel/
--rw-rw-r--   0 root         (0) root         (0)    11350 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/reduction/kernel/reduce_splitk.cu
--rw-rw-r--   0 root         (0) root         (0)     2228 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/reduction/kernel/reduce_splitk_testbed.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:24:53.171006 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/reduction/thread/
--rw-rw-r--   0 root         (0) root         (0)     3110 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/reduction/thread/reduction_thread.cu
--rw-rw-r--   0 root         (0) root         (0)     6657 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/reduction/thread/testbed.h
--rw-rw-r--   0 root         (0) root         (0)     2047 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/test_unit.cpp
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:46.460695 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/transform/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:24:53.432322 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/transform/threadblock/
--rw-rw-r--   0 root         (0) root         (0)    25527 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/transform/threadblock/predicated_tile_iterator.cu
--rw-rw-r--   0 root         (0) root         (0)     9501 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/transform/threadblock/regular_tile_iterator_tensor_op.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:24:53.858289 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/util/
--rw-rw-r--   0 root         (0) root         (0)     2663 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/util/cutlass_test_levels.cu
--rw-rw-r--   0 root         (0) root         (0)     7474 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/util/tensor_reduce.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:46.759549 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:46.727244 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:46.641417 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/include/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:46.646867 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/include/cutlass/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:24:54.513031 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/include/cutlass/library/
--rw-r--r--   0 root         (0) root         (0)     4118 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/include/cutlass/library/arch_mappings.h
--rw-rw-r--   0 root         (0) root         (0)    16013 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/include/cutlass/library/handle.h
--rw-r--r--   0 root         (0) root         (0)    38340 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/include/cutlass/library/library.h
--rw-rw-r--   0 root         (0) root         (0)     4070 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/include/cutlass/library/manifest.h
--rw-rw-r--   0 root         (0) root         (0)    17934 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/include/cutlass/library/operation_table.h
--rw-rw-r--   0 root         (0) root         (0)     2724 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/include/cutlass/library/singleton.h
--rw-rw-r--   0 root         (0) root         (0)     7904 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/include/cutlass/library/util.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:46.660172 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:46.665764 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:46.671193 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:24:54.901577 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/
--rw-r--r--   0 root         (0) root         (0)     2788 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/compiler.h
--rw-r--r--   0 root         (0) root         (0)     6223 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/cutlass.cpp
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:24:55.392568 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/
--rw-r--r--   0 root         (0) root         (0)     2851 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/arch.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:24:56.064494 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/conv/
--rw-r--r--   0 root         (0) root         (0)     5897 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/conv/conv_problem_size.h
--rw-r--r--   0 root         (0) root         (0)     4763 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/conv/convolution.h
--rw-r--r--   0 root         (0) root         (0)     2650 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/conv/host.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:24:56.221863 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/
--rw-r--r--   0 root         (0) root         (0)     7072 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_generic.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:25:00.025731 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/
--rw-r--r--   0 root         (0) root         (0)     3003 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/binary_ops.h
--rw-r--r--   0 root         (0) root         (0)     6103 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/unary_ops.h
--rw-r--r--   0 root         (0) root         (0)     4698 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_accumulator.h
--rw-r--r--   0 root         (0) root         (0)     8442 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_binary.h
--rw-r--r--   0 root         (0) root         (0)     8830 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_column_broadcast.h
--rw-r--r--   0 root         (0) root         (0)    13040 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_column_reduction.h
--rw-r--r--   0 root         (0) root         (0)     9476 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_linear_combination.h
--rw-r--r--   0 root         (0) root         (0)     9085 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_row_broadcast.h
--rw-r--r--   0 root         (0) root         (0)    12017 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_row_reduction.h
--rw-r--r--   0 root         (0) root         (0)     6177 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_tensor_input.h
--rw-r--r--   0 root         (0) root         (0)     8017 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_tensor_output.h
--rw-r--r--   0 root         (0) root         (0)     7223 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_unary.h
--rw-r--r--   0 root         (0) root         (0)    16985 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_with_layernorm.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:25:00.622206 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/gemm/
--rw-r--r--   0 root         (0) root         (0)     3673 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/gemm/gemm.h
--rw-r--r--   0 root         (0) root         (0)    22378 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/gemm/gemm_universal_with_visitor.h
--rw-r--r--   0 root         (0) root         (0)     2328 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/gemm/host.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:25:01.274780 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/layout/
--rw-r--r--   0 root         (0) root         (0)     2115 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/layout/layout.h
--rw-r--r--   0 root         (0) root         (0)     4337 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/layout/matrix.h
--rw-r--r--   0 root         (0) root         (0)     3694 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/layout/tensor.h
--rw-r--r--   0 root         (0) root         (0)     8624 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/swizzling.h
--rw-r--r--   0 root         (0) root         (0)     3902 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/tensor_coord.h
--rw-r--r--   0 root         (0) root         (0)     5563 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/tensor_ref_view.h
--rw-r--r--   0 root         (0) root         (0)     4855 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/types.h
--rw-r--r--   0 root         (0) root         (0)      811 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/library.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:46.717380 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/test/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:25:01.643451 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/test/conv/
--rw-r--r--   0 root         (0) root         (0)     2651 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/test/conv/conv_problems.h
--rw-r--r--   0 root         (0) root         (0)     2253 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/test/conv/convolution.h
--rw-r--r--   0 root         (0) root         (0)     8826 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/test/conv/host.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:25:01.908520 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/test/gemm/
--rw-r--r--   0 root         (0) root         (0)     2139 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/test/gemm/gemm.h
--rw-r--r--   0 root         (0) root         (0)    18930 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/test/gemm/host.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:25:03.640790 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/
--rw-r--r--   0 root         (0) root         (0)    22377 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/conv2d_operation.h
--rw-r--r--   0 root         (0) root         (0)    13851 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/conv3d_operation.h
--rw-r--r--   0 root         (0) root         (0)    42129 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/gemm_operation.h
--rw-rw-r--   0 root         (0) root         (0)    35709 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/handle.cu
--rw-rw-r--   0 root         (0) root         (0)    12616 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/library_internal.h
--rw-rw-r--   0 root         (0) root         (0)     3782 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/manifest.cpp
--rw-rw-r--   0 root         (0) root         (0)     5468 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/operation_table.cu
--rw-rw-r--   0 root         (0) root         (0)    12873 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/rank_2k_operation.h
--rw-rw-r--   0 root         (0) root         (0)    11367 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/rank_k_operation.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:25:04.935435 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/reduction/
--rw-rw-r--   0 root         (0) root         (0)     3190 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/reduction/init_reduction_operations.cu
--rw-rw-r--   0 root         (0) root         (0)     6367 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/reduction/reduction_device.cu
--rw-rw-r--   0 root         (0) root         (0)    10270 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/reduction/reduction_operation.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:25:05.961121 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/reference/
--rw-rw-r--   0 root         (0) root         (0)     6746 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/reference/conv2d.cu
--rw-rw-r--   0 root         (0) root         (0)     6286 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/reference/conv3d.cu
--rw-rw-r--   0 root         (0) root         (0)    17191 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/reference/conv_reference_operation.h
--rw-rw-r--   0 root         (0) root         (0)     7199 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/reference/gemm.cu
--rw-rw-r--   0 root         (0) root         (0)    14732 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/reference/gemm_reference_operation.h
--rw-rw-r--   0 root         (0) root         (0)     2857 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/reference/initialize_reference_operations.cu
--rw-r--r--   0 root         (0) root         (0)     2669 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/singleton.cu
--rw-rw-r--   0 root         (0) root         (0)    13134 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/symm_operation.h
--rw-rw-r--   0 root         (0) root         (0)    11698 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/trmm_operation.h
--rw-r--r--   0 root         (0) root         (0)    43704 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/util.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:46.750147 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:25:12.773096 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/
--rw-r--r--   0 root         (0) root         (0)    54128 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/conv2d_operation_profiler.cu
--rw-r--r--   0 root         (0) root         (0)    18170 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/conv2d_operation_profiler.h
--rw-rw-r--   0 root         (0) root         (0)    48659 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/conv3d_operation_profiler.cu
--rw-rw-r--   0 root         (0) root         (0)    16043 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/conv3d_operation_profiler.h
--rw-rw-r--   0 root         (0) root         (0)    36462 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/cublas_helpers.cu
--rw-rw-r--   0 root         (0) root         (0)    10627 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/cublas_helpers.h
--rw-r--r--   0 root         (0) root         (0)    17049 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/cudnn_helpers.cpp
--rw-r--r--   0 root         (0) root         (0)    20433 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/cudnn_helpers.h
--rw-rw-r--   0 root         (0) root         (0)     7233 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/cutlass_profiler.cu
--rw-rw-r--   0 root         (0) root         (0)     3233 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/cutlass_profiler.h
--rw-rw-r--   0 root         (0) root         (0)     2453 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/debug.h
--rw-rw-r--   0 root         (0) root         (0)    53643 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/device_allocation.cu
--rw-rw-r--   0 root         (0) root         (0)     7217 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/device_allocation.h
--rw-rw-r--   0 root         (0) root         (0)     6841 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/device_context.cu
--rw-rw-r--   0 root         (0) root         (0)     4300 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/device_context.h
--rw-rw-r--   0 root         (0) root         (0)     8296 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/enumerated_types.cpp
--rw-rw-r--   0 root         (0) root         (0)     6421 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/enumerated_types.h
--rw-rw-r--   0 root         (0) root         (0)    41919 2022-11-26 00:33:28.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/gemm_operation_profiler.cu
--rw-rw-r--   0 root         (0) root         (0)     8544 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/gemm_operation_profiler.h
--rw-rw-r--   0 root         (0) root         (0)     3874 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/gpu_timer.cpp
--rw-rw-r--   0 root         (0) root         (0)     2724 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/gpu_timer.h
--rw-rw-r--   0 root         (0) root         (0)     2340 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/main.cpp
--rw-rw-r--   0 root         (0) root         (0)    20944 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/operation_profiler.cu
--rw-rw-r--   0 root         (0) root         (0)     7876 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/operation_profiler.h
--rw-rw-r--   0 root         (0) root         (0)    27172 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/options.cu
--rw-rw-r--   0 root         (0) root         (0)     8773 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/options.h
--rw-rw-r--   0 root         (0) root         (0)    14192 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/performance_report.cpp
--rw-rw-r--   0 root         (0) root         (0)     4337 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/performance_report.h
--rw-rw-r--   0 root         (0) root         (0)     2494 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/performance_result.cu
--rw-rw-r--   0 root         (0) root         (0)     3941 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/performance_result.h
--rw-rw-r--   0 root         (0) root         (0)    37487 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/problem_space.cpp
--rw-rw-r--   0 root         (0) root         (0)    27747 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/problem_space.h
--rw-rw-r--   0 root         (0) root         (0)    25014 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/rank_2k_operation_profiler.cu
--rw-rw-r--   0 root         (0) root         (0)     6891 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/rank_2k_operation_profiler.h
--rw-rw-r--   0 root         (0) root         (0)    24253 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/rank_k_operation_profiler.cu
--rw-rw-r--   0 root         (0) root         (0)     6830 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/rank_k_operation_profiler.h
--rw-rw-r--   0 root         (0) root         (0)     5452 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/reduction_operation_profiler.h
--rw-rw-r--   0 root         (0) root         (0)    20688 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/sparse_gemm_operation_profiler.cu
--rw-rw-r--   0 root         (0) root         (0)     6471 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/sparse_gemm_operation_profiler.h
--rw-rw-r--   0 root         (0) root         (0)    26610 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/symm_operation_profiler.cu
--rw-rw-r--   0 root         (0) root         (0)     6933 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/symm_operation_profiler.h
--rw-rw-r--   0 root         (0) root         (0)    24431 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/trmm_operation_profiler.cu
--rw-rw-r--   0 root         (0) root         (0)     6599 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/trmm_operation_profiler.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:46.768542 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:46.780613 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:46.786633 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:25:18.159740 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/
--rw-rw-r--   0 root         (0) root         (0)     9774 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/command_line.h
--rw-rw-r--   0 root         (0) root         (0)     5104 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/debug.h
--rw-rw-r--   0 root         (0) root         (0)     5953 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/device_dump.h
--rw-r--r--   0 root         (0) root         (0)    17695 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/device_groupnorm.h
--rw-r--r--   0 root         (0) root         (0)    20880 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/device_layernorm.h
--rw-rw-r--   0 root         (0) root         (0)    10561 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/device_memory.h
--rw-rw-r--   0 root         (0) root         (0)     5219 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/device_nchw_to_nhwc.h
--rw-rw-r--   0 root         (0) root         (0)    11067 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/device_nhwc_padding.h
--rw-r--r--   0 root         (0) root         (0)    18653 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/device_nhwc_pooling.h
--rw-rw-r--   0 root         (0) root         (0)     5214 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/device_nhwc_to_nchw.h
--rw-r--r--   0 root         (0) root         (0)     4007 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/device_utils.h
--rw-r--r--   0 root         (0) root         (0)     4597 2022-08-07 23:35:00.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/distribution.h
--rw-rw-r--   0 root         (0) root         (0)     2674 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/exceptions.h
--rw-rw-r--   0 root         (0) root         (0)     4821 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/host_reorder.h
--rw-rw-r--   0 root         (0) root         (0)    16745 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/host_tensor.h
--rw-rw-r--   0 root         (0) root         (0)    20354 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/host_tensor_planar_complex.h
--rw-r--r--   0 root         (0) root         (0)     5890 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/host_uncompress.h
--rw-rw-r--   0 root         (0) root         (0)     1962 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/index_sequence.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:21:46.821723 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:25:18.405530 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/detail/
--rw-rw-r--   0 root         (0) root         (0)     4606 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/detail/inner_product.h
--rw-rw-r--   0 root         (0) root         (0)     3527 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/detail/linear_to_coordinate.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:25:20.199020 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/
--rw-r--r--   0 root         (0) root         (0)    48350 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/convolution.h
--rw-rw-r--   0 root         (0) root         (0)    14296 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/gemm.h
--rw-rw-r--   0 root         (0) root         (0)    10524 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/gemm_complex.h
--rw-r--r--   0 root         (0) root         (0)     9652 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/gemm_planar_complex.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:25:20.529676 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/kernel/
--rw-rw-r--   0 root         (0) root         (0)     5381 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/kernel/gemm.h
--rw-rw-r--   0 root         (0) root         (0)     6198 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/kernel/tensor_elementwise.h
--rw-rw-r--   0 root         (0) root         (0)     5126 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/kernel/tensor_foreach.h
--rw-rw-r--   0 root         (0) root         (0)    11615 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/rank_2k_complex.h
--rw-rw-r--   0 root         (0) root         (0)     7278 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/tensor_compare.h
--rw-rw-r--   0 root         (0) root         (0)    46444 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/tensor_fill.h
--rw-rw-r--   0 root         (0) root         (0)     5293 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/tensor_foreach.h
--rw-rw-r--   0 root         (0) root         (0)    15964 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/tensor_reduce.h
--rw-rw-r--   0 root         (0) root         (0)     4589 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/tensor_relu.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:25:20.635532 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/thread/
--rw-rw-r--   0 root         (0) root         (0)     5872 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/thread/gemm.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:25:22.677690 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/
--rw-r--r--   0 root         (0) root         (0)    28439 2022-09-05 01:02:49.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/convolution.h
--rw-rw-r--   0 root         (0) root         (0)     2766 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/error_metrics.h
--rw-rw-r--   0 root         (0) root         (0)    17163 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/gemm.h
--rw-rw-r--   0 root         (0) root         (0)     7096 2022-12-14 23:22:53.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/gemm_complex.h
--rw-r--r--   0 root         (0) root         (0)     7708 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/gemm_planar_complex.h
--rw-rw-r--   0 root         (0) root         (0)     9441 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/rank_2k.h
--rw-rw-r--   0 root         (0) root         (0)    11444 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/rank_2k_complex.h
--rw-rw-r--   0 root         (0) root         (0)     8148 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/rank_k_complex.h
--rw-rw-r--   0 root         (0) root         (0)    10509 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/symm.h
--rw-rw-r--   0 root         (0) root         (0)    12296 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/symm_complex.h
--rw-rw-r--   0 root         (0) root         (0)     8440 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/tensor_compare.h
--rw-rw-r--   0 root         (0) root         (0)     8317 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/tensor_copy.h
--rw-r--r--   0 root         (0) root         (0)     9027 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/tensor_elementwise.h
--rw-r--r--   0 root         (0) root         (0)    43961 2022-11-23 23:56:02.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/tensor_fill.h
--rw-rw-r--   0 root         (0) root         (0)     4756 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/tensor_foreach.h
--rw-rw-r--   0 root         (0) root         (0)     2133 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/tensor_norm.h
--rw-rw-r--   0 root         (0) root         (0)     6111 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/tensor_reduce.h
--rw-rw-r--   0 root         (0) root         (0)     7670 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/trmm.h
--rw-rw-r--   0 root         (0) root         (0)     9874 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/trmm_complex.h
--rw-rw-r--   0 root         (0) root         (0)     8285 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/tensor_view_io.h
--rw-rw-r--   0 root         (0) root         (0)     8809 2022-06-02 16:47:41.000000 flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/type_traits.h
--rw-r--r--   0 root         (0) root         (0)    32213 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/flash_attn/fmha_api.cpp
--rw-r--r--   0 root         (0) root         (0)     9833 2022-07-08 17:33:25.000000 flash_attn-0.2.8/csrc/flash_attn/rotary.cuh
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:25:26.067940 flash_attn-0.2.8/csrc/flash_attn/src/
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:25:27.600957 flash_attn-0.2.8/csrc/flash_attn/src/fmha/
--rw-r--r--   0 root         (0) root         (0)     7150 2022-12-17 01:12:27.000000 flash_attn-0.2.8/csrc/flash_attn/src/fmha/epilogue.h
--rw-r--r--   0 root         (0) root         (0)    14984 2022-12-17 01:12:27.000000 flash_attn-0.2.8/csrc/flash_attn/src/fmha/epilogue_predicated_tile_iterator.h
--rw-r--r--   0 root         (0) root         (0)    17999 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/flash_attn/src/fmha/gemm.h
--rw-r--r--   0 root         (0) root         (0)    22872 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/flash_attn/src/fmha/gmem_tile.h
--rw-r--r--   0 root         (0) root         (0)     5997 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/flash_attn/src/fmha/kernel_traits.h
--rw-r--r--   0 root         (0) root         (0)     4362 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/flash_attn/src/fmha/mask.h
--rw-r--r--   0 root         (0) root         (0)    13491 2022-12-18 05:18:49.000000 flash_attn-0.2.8/csrc/flash_attn/src/fmha/mma_core_sm75.h
--rw-r--r--   0 root         (0) root         (0)    15174 2022-11-26 23:47:50.000000 flash_attn-0.2.8/csrc/flash_attn/src/fmha/regular_tile_access_iterator_tensor_op.h
--rw-r--r--   0 root         (0) root         (0)    74010 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/flash_attn/src/fmha/smem_tile.h
--rw-r--r--   0 root         (0) root         (0)    25514 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/flash_attn/src/fmha/softmax.h
--rw-r--r--   0 root         (0) root         (0)     1999 2022-12-17 01:12:27.000000 flash_attn-0.2.8/csrc/flash_attn/src/fmha/summary_stats.h
--rw-r--r--   0 root         (0) root         (0)    41059 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/flash_attn/src/fmha/utils.h
--rw-r--r--   0 root         (0) root         (0)     7152 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/flash_attn/src/fmha.h
--rw-r--r--   0 root         (0) root         (0)     4118 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/flash_attn/src/fmha_block_dgrad_fp16_kernel_loop.sm80.cu
--rw-r--r--   0 root         (0) root         (0)    33506 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/flash_attn/src/fmha_block_dgrad_kernel_1xN_loop.h
--rw-r--r--   0 root         (0) root         (0)     5292 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/flash_attn/src/fmha_block_fprop_fp16_kernel.sm80.cu
--rw-r--r--   0 root         (0) root         (0)    23207 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/flash_attn/src/fmha_block_fprop_kernel_1xN.h
--rw-r--r--   0 root         (0) root         (0)     2502 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/flash_attn/src/fmha_blockmask.h
--rw-r--r--   0 root         (0) root         (0)      465 2023-01-06 22:35:38.000000 flash_attn-0.2.8/csrc/flash_attn/src/fmha_bwd_hdim128.cu
--rw-r--r--   0 root         (0) root         (0)      727 2023-01-06 22:35:38.000000 flash_attn-0.2.8/csrc/flash_attn/src/fmha_bwd_hdim32.cu
--rw-r--r--   0 root         (0) root         (0)     1656 2023-01-06 22:35:38.000000 flash_attn-0.2.8/csrc/flash_attn/src/fmha_bwd_hdim64.cu
--rw-r--r--   0 root         (0) root         (0)     6453 2023-01-06 22:38:22.000000 flash_attn-0.2.8/csrc/flash_attn/src/fmha_bwd_launch_template.h
--rw-r--r--   0 root         (0) root         (0)     8020 2022-12-14 22:56:12.000000 flash_attn-0.2.8/csrc/flash_attn/src/fmha_dgrad_fp16_kernel_loop.sm80.cu
--rw-r--r--   0 root         (0) root         (0)    37194 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/flash_attn/src/fmha_dgrad_kernel_1xN_loop.h
--rw-r--r--   0 root         (0) root         (0)     9144 2022-11-25 23:51:06.000000 flash_attn-0.2.8/csrc/flash_attn/src/fmha_dgrad_launch_template.h
--rw-r--r--   0 root         (0) root         (0)    11546 2022-12-14 22:56:12.000000 flash_attn-0.2.8/csrc/flash_attn/src/fmha_fprop_fp16_kernel.sm80.cu
--rw-r--r--   0 root         (0) root         (0)      441 2022-11-25 23:36:17.000000 flash_attn-0.2.8/csrc/flash_attn/src/fmha_fprop_hdim128.cu
--rw-r--r--   0 root         (0) root         (0)      716 2022-11-25 23:35:59.000000 flash_attn-0.2.8/csrc/flash_attn/src/fmha_fprop_hdim32.cu
--rw-r--r--   0 root         (0) root         (0)      717 2022-11-25 23:36:05.000000 flash_attn-0.2.8/csrc/flash_attn/src/fmha_fprop_hdim64.cu
--rw-r--r--   0 root         (0) root         (0)    30832 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/flash_attn/src/fmha_fprop_kernel_1xN.h
--rw-r--r--   0 root         (0) root         (0)     7808 2022-12-18 05:18:49.000000 flash_attn-0.2.8/csrc/flash_attn/src/fmha_fprop_kernel_dispatch.cu
--rw-r--r--   0 root         (0) root         (0)     4422 2022-11-25 23:41:55.000000 flash_attn-0.2.8/csrc/flash_attn/src/fmha_fprop_launch_template.h
--rw-r--r--   0 root         (0) root         (0)      445 2023-01-06 22:35:38.000000 flash_attn-0.2.8/csrc/flash_attn/src/fmha_fwd_hdim128.cu
--rw-r--r--   0 root         (0) root         (0)      724 2023-01-06 22:35:38.000000 flash_attn-0.2.8/csrc/flash_attn/src/fmha_fwd_hdim32.cu
--rw-r--r--   0 root         (0) root         (0)      725 2023-01-06 22:35:38.000000 flash_attn-0.2.8/csrc/flash_attn/src/fmha_fwd_hdim64.cu
--rw-r--r--   0 root         (0) root         (0)     4393 2023-01-06 22:38:37.000000 flash_attn-0.2.8/csrc/flash_attn/src/fmha_fwd_launch_template.h
--rw-r--r--   0 root         (0) root         (0)     3104 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/flash_attn/src/fmha_kernel.h
--rw-r--r--   0 root         (0) root         (0)     4892 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/flash_attn/src/fmha_utils.h
--rw-r--r--   0 root         (0) root         (0)     1196 2022-12-14 22:56:12.000000 flash_attn-0.2.8/csrc/flash_attn/src/fp16_switch.h
--rw-r--r--   0 root         (0) root         (0)     4356 2022-11-25 02:52:23.000000 flash_attn-0.2.8/csrc/flash_attn/src/fprop_heuristic.cuh
--rw-r--r--   0 root         (0) root         (0)     5462 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/flash_attn/src/philox.cuh
--rw-r--r--   0 root         (0) root         (0)     1686 2023-01-06 22:36:29.000000 flash_attn-0.2.8/csrc/flash_attn/src/static_switch.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:25:28.027753 flash_attn-0.2.8/csrc/flash_gen/
--rw-r--r--   0 root         (0) root         (0)    13430 2022-11-17 23:56:13.000000 flash_attn-0.2.8/csrc/flash_gen/bfloat16_fallback_kenrels.cuh
--rw-r--r--   0 root         (0) root         (0)      698 2022-11-17 23:56:13.000000 flash_attn-0.2.8/csrc/flash_gen/cuda_bf16_wrapper.h
--rw-r--r--   0 root         (0) root         (0)     7018 2022-11-21 06:35:03.000000 flash_attn-0.2.8/csrc/flash_gen/decoder_masked_multihead_attention.cu
--rw-r--r--   0 root         (0) root         (0)     6811 2022-11-19 00:41:50.000000 flash_attn-0.2.8/csrc/flash_gen/decoder_masked_multihead_attention.h
--rw-r--r--   0 root         (0) root         (0)    49817 2022-11-19 00:41:30.000000 flash_attn-0.2.8/csrc/flash_gen/decoder_masked_multihead_attention_utils.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:25:28.566630 flash_attn-0.2.8/csrc/ft_attention/
--rw-r--r--   0 root         (0) root         (0)     8253 2023-01-04 00:17:17.000000 flash_attn-0.2.8/csrc/ft_attention/bfloat16_fallback.cuh
--rw-r--r--   0 root         (0) root         (0)    13402 2022-11-19 22:12:54.000000 flash_attn-0.2.8/csrc/ft_attention/bfloat16_fallback_kenrels.cuh
--rw-r--r--   0 root         (0) root         (0)     8253 2023-01-04 00:17:17.000000 flash_attn-0.2.8/csrc/ft_attention/cuda_bf16_fallbacks.cuh
--rw-r--r--   0 root         (0) root         (0)      867 2023-01-04 00:14:11.000000 flash_attn-0.2.8/csrc/ft_attention/cuda_bf16_wrapper.h
--rw-r--r--   0 root         (0) root         (0)     7243 2023-01-04 00:35:29.000000 flash_attn-0.2.8/csrc/ft_attention/decoder_masked_multihead_attention.cu
--rw-r--r--   0 root         (0) root         (0)     7463 2023-01-04 00:18:17.000000 flash_attn-0.2.8/csrc/ft_attention/decoder_masked_multihead_attention.h
--rw-r--r--   0 root         (0) root         (0)    52490 2023-01-04 00:16:00.000000 flash_attn-0.2.8/csrc/ft_attention/decoder_masked_multihead_attention_utils.h
--rw-r--r--   0 root         (0) root         (0)     7423 2023-01-15 23:06:19.000000 flash_attn-0.2.8/csrc/ft_attention/ft_attention.cpp
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:25:28.606576 flash_attn-0.2.8/csrc/fused_dense_lib/
--rw-r--r--   0 root         (0) root         (0)     8215 2023-01-18 00:41:27.000000 flash_attn-0.2.8/csrc/fused_dense_lib/fused_dense.cpp
--rw-r--r--   0 root         (0) root         (0)    24645 2023-01-18 00:03:05.000000 flash_attn-0.2.8/csrc/fused_dense_lib/fused_dense_cuda.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:25:30.554918 flash_attn-0.2.8/csrc/fused_softmax/
--rw-r--r--   0 root         (0) root         (0)     5037 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/fused_softmax/fused_softmax.cpp
--rw-rw-r--   0 root         (0) root         (0)     3102 2022-10-24 04:42:29.000000 flash_attn-0.2.8/csrc/fused_softmax/scaled_masked_softmax.cpp
--rw-r--r--   0 root         (0) root         (0)    23616 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/fused_softmax/scaled_masked_softmax.h
--rw-r--r--   0 root         (0) root         (0)     4209 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/fused_softmax/scaled_masked_softmax_cuda.cu
--rw-rw-r--   0 root         (0) root         (0)     2553 2022-10-24 04:42:51.000000 flash_attn-0.2.8/csrc/fused_softmax/scaled_upper_triang_masked_softmax.cpp
--rw-r--r--   0 root         (0) root         (0)    24659 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/fused_softmax/scaled_upper_triang_masked_softmax.h
--rw-r--r--   0 root         (0) root         (0)     3154 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/fused_softmax/scaled_upper_triang_masked_softmax_cuda.cu
--rw-r--r--   0 root         (0) root         (0)     1216 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/fused_softmax/type_shim.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:25:32.803730 flash_attn-0.2.8/csrc/layer_norm/
--rw-r--r--   0 root         (0) root         (0)     6013 2023-01-19 07:33:07.000000 flash_attn-0.2.8/csrc/layer_norm/ln.h
--rw-r--r--   0 root         (0) root         (0)    20683 2023-01-19 07:34:14.000000 flash_attn-0.2.8/csrc/layer_norm/ln_api.cpp
--rw-r--r--   0 root         (0) root         (0)      987 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/layer_norm/ln_bwd_1024.cu
--rw-r--r--   0 root         (0) root         (0)      987 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/layer_norm/ln_bwd_1280.cu
--rw-r--r--   0 root         (0) root         (0)      977 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/layer_norm/ln_bwd_1536.cu
--rw-r--r--   0 root         (0) root         (0)      976 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/layer_norm/ln_bwd_2048.cu
--rw-r--r--   0 root         (0) root         (0)      977 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/layer_norm/ln_bwd_256.cu
--rw-r--r--   0 root         (0) root         (0)      977 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/layer_norm/ln_bwd_2560.cu
--rw-r--r--   0 root         (0) root         (0)      976 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/layer_norm/ln_bwd_3072.cu
--rw-r--r--   0 root         (0) root         (0)      976 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/layer_norm/ln_bwd_4096.cu
--rw-r--r--   0 root         (0) root         (0)      977 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/layer_norm/ln_bwd_512.cu
--rw-r--r--   0 root         (0) root         (0)      976 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/layer_norm/ln_bwd_5120.cu
--rw-r--r--   0 root         (0) root         (0)      976 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/layer_norm/ln_bwd_6144.cu
--rw-r--r--   0 root         (0) root         (0)      977 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/layer_norm/ln_bwd_768.cu
--rw-r--r--   0 root         (0) root         (0)    25647 2023-01-19 07:34:25.000000 flash_attn-0.2.8/csrc/layer_norm/ln_bwd_kernels.cuh
--rw-r--r--   0 root         (0) root         (0)    19938 2022-12-06 21:18:58.000000 flash_attn-0.2.8/csrc/layer_norm/ln_bwd_semi_cuda_kernel.cu
--rw-r--r--   0 root         (0) root         (0)    19944 2023-01-19 07:34:02.000000 flash_attn-0.2.8/csrc/layer_norm/ln_bwd_semi_cuda_kernel_old.cu
--rw-r--r--   0 root         (0) root         (0)      925 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/layer_norm/ln_fwd_1024.cu
--rw-r--r--   0 root         (0) root         (0)      925 2022-12-05 08:45:58.000000 flash_attn-0.2.8/csrc/layer_norm/ln_fwd_128.cu
--rw-r--r--   0 root         (0) root         (0)      925 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/layer_norm/ln_fwd_1280.cu
--rw-r--r--   0 root         (0) root         (0)      925 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/layer_norm/ln_fwd_1536.cu
--rw-r--r--   0 root         (0) root         (0)      925 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/layer_norm/ln_fwd_2048.cu
--rw-r--r--   0 root         (0) root         (0)      925 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/layer_norm/ln_fwd_256.cu
--rw-r--r--   0 root         (0) root         (0)      925 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/layer_norm/ln_fwd_2560.cu
--rw-r--r--   0 root         (0) root         (0)      925 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/layer_norm/ln_fwd_3072.cu
--rw-r--r--   0 root         (0) root         (0)      925 2022-12-05 08:50:57.000000 flash_attn-0.2.8/csrc/layer_norm/ln_fwd_384.cu
--rw-r--r--   0 root         (0) root         (0)      925 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/layer_norm/ln_fwd_4096.cu
--rw-r--r--   0 root         (0) root         (0)      925 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/layer_norm/ln_fwd_512.cu
--rw-r--r--   0 root         (0) root         (0)      925 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/layer_norm/ln_fwd_5120.cu
--rw-r--r--   0 root         (0) root         (0)      925 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/layer_norm/ln_fwd_6144.cu
--rw-r--r--   0 root         (0) root         (0)      925 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/layer_norm/ln_fwd_768.cu
--rw-r--r--   0 root         (0) root         (0)    18000 2022-12-06 21:18:58.000000 flash_attn-0.2.8/csrc/layer_norm/ln_fwd_cuda_kernel.cu
--rw-r--r--   0 root         (0) root         (0)    18000 2022-12-06 21:18:58.000000 flash_attn-0.2.8/csrc/layer_norm/ln_fwd_cuda_kernel_old.cu
--rw-r--r--   0 root         (0) root         (0)    12721 2023-01-19 07:33:35.000000 flash_attn-0.2.8/csrc/layer_norm/ln_fwd_kernels.cuh
--rw-r--r--   0 root         (0) root         (0)     6655 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/layer_norm/ln_kernel_traits.h
--rw-r--r--   0 root         (0) root         (0)    25812 2023-01-07 01:18:06.000000 flash_attn-0.2.8/csrc/layer_norm/ln_utils.cuh
--rw-r--r--   0 root         (0) root         (0)     1278 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/layer_norm/static_switch.h
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:25:32.932220 flash_attn-0.2.8/csrc/rotary/
--rw-r--r--   0 root         (0) root         (0)     1612 2022-12-25 00:27:47.000000 flash_attn-0.2.8/csrc/rotary/rotary.cpp
--rw-r--r--   0 root         (0) root         (0)     1790 2022-12-18 05:19:38.000000 flash_attn-0.2.8/csrc/rotary/rotary_cuda.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:25:33.137756 flash_attn-0.2.8/csrc/xentropy/
--rw-r--r--   0 root         (0) root         (0)     2290 2022-12-23 21:56:53.000000 flash_attn-0.2.8/csrc/xentropy/interface.cpp
--rw-r--r--   0 root         (0) root         (0)    25783 2022-12-23 20:09:55.000000 flash_attn-0.2.8/csrc/xentropy/xentropy_kernel.cu
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:25:35.844735 flash_attn-0.2.8/flash_attn/
--rw-r--r--   0 root         (0) root         (0)        0 2022-07-04 00:53:37.000000 flash_attn-0.2.8/flash_attn/__init__.py
--rw-rw-r--   0 root         (0) root         (0)    20845 2022-10-31 02:25:05.000000 flash_attn-0.2.8/flash_attn/attention_kernl.py
--rw-r--r--   0 root         (0) root         (0)     5898 2022-12-18 05:19:38.000000 flash_attn-0.2.8/flash_attn/bert_padding.py
--rw-r--r--   0 root         (0) root         (0)     4775 2023-01-16 09:20:34.000000 flash_attn-0.2.8/flash_attn/flash_attention.py
--rw-r--r--   0 root         (0) root         (0)    20427 2022-12-18 05:19:38.000000 flash_attn-0.2.8/flash_attn/flash_attn_interface.py
--rw-r--r--   0 root         (0) root         (0)    37754 2022-12-18 05:19:38.000000 flash_attn-0.2.8/flash_attn/flash_attn_triton.py
--rw-r--r--   0 root         (0) root         (0)    10593 2022-12-18 05:19:38.000000 flash_attn-0.2.8/flash_attn/flash_attn_triton_og.py
--rw-r--r--   0 root         (0) root         (0)     8255 2022-11-18 03:30:00.000000 flash_attn-0.2.8/flash_attn/flash_attn_triton_single_query.py
--rw-rw-r--   0 root         (0) root         (0)    22846 2022-10-31 04:09:26.000000 flash_attn-0.2.8/flash_attn/flash_attn_triton_tmp.py
--rw-rw-r--   0 root         (0) root         (0)    22919 2022-10-31 00:28:55.000000 flash_attn-0.2.8/flash_attn/flash_attn_triton_varlen.py
--rw-r--r--   0 root         (0) root         (0)     6819 2022-06-26 00:59:43.000000 flash_attn-0.2.8/flash_attn/flash_blocksparse_attention.py
--rw-r--r--   0 root         (0) root         (0)     7036 2022-06-26 00:59:43.000000 flash_attn-0.2.8/flash_attn/flash_blocksparse_attn_interface.py
--rw-r--r--   0 root         (0) root         (0)     7902 2022-12-18 05:19:38.000000 flash_attn-0.2.8/flash_attn/fused_softmax.py
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:25:36.138120 flash_attn-0.2.8/flash_attn/layers/
--rw-r--r--   0 root         (0) root         (0)        0 2022-12-18 05:19:38.000000 flash_attn-0.2.8/flash_attn/layers/__init__.py
--rw-r--r--   0 root         (0) root         (0)     2039 2022-12-22 18:07:11.000000 flash_attn-0.2.8/flash_attn/layers/patch_embed.py
--rw-r--r--   0 root         (0) root         (0)     8880 2022-12-30 04:24:40.000000 flash_attn-0.2.8/flash_attn/layers/rotary.py
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:25:36.858561 flash_attn-0.2.8/flash_attn/losses/
--rw-r--r--   0 root         (0) root         (0)        0 2022-12-18 05:19:38.000000 flash_attn-0.2.8/flash_attn/losses/__init__.py
--rw-r--r--   0 root         (0) root         (0)     6697 2022-12-27 00:24:02.000000 flash_attn-0.2.8/flash_attn/losses/cross_entropy.py
--rw-r--r--   0 root         (0) root         (0)     2122 2022-12-18 05:19:38.000000 flash_attn-0.2.8/flash_attn/losses/cross_entropy_apex.py
--rw-r--r--   0 root         (0) root         (0)     6649 2022-12-23 22:38:19.000000 flash_attn-0.2.8/flash_attn/losses/cross_entropy_parallel.py
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:25:37.004660 flash_attn-0.2.8/flash_attn/models/
--rw-r--r--   0 root         (0) root         (0)        0 2022-12-18 05:19:38.000000 flash_attn-0.2.8/flash_attn/models/__init__.py
--rw-r--r--   0 root         (0) root         (0)    26630 2023-01-18 01:10:49.000000 flash_attn-0.2.8/flash_attn/models/bert.py
--rw-r--r--   0 root         (0) root         (0)    25428 2023-01-19 07:41:23.000000 flash_attn-0.2.8/flash_attn/models/gpt.py
--rw-r--r--   0 root         (0) root         (0)     4990 2023-01-16 05:42:51.000000 flash_attn-0.2.8/flash_attn/models/opt.py
--rw-r--r--   0 root         (0) root         (0)    13621 2023-01-18 01:11:37.000000 flash_attn-0.2.8/flash_attn/models/vit.py
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:25:37.096894 flash_attn-0.2.8/flash_attn/modules/
--rw-r--r--   0 root         (0) root         (0)        0 2022-12-18 05:19:38.000000 flash_attn-0.2.8/flash_attn/modules/__init__.py
--rw-r--r--   0 root         (0) root         (0)     9882 2023-01-18 01:24:20.000000 flash_attn-0.2.8/flash_attn/modules/block.py
--rw-r--r--   0 root         (0) root         (0)     8620 2023-01-16 05:38:37.000000 flash_attn-0.2.8/flash_attn/modules/embedding.py
--rw-r--r--   0 root         (0) root         (0)    31783 2023-01-16 09:20:34.000000 flash_attn-0.2.8/flash_attn/modules/mha.py
--rw-r--r--   0 root         (0) root         (0)     1023 2023-01-18 01:06:45.000000 flash_attn-0.2.8/flash_attn/modules/mlp.py
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:25:37.185001 flash_attn-0.2.8/flash_attn/ops/
--rw-r--r--   0 root         (0) root         (0)        0 2022-12-18 05:19:38.000000 flash_attn-0.2.8/flash_attn/ops/__init__.py
--rw-r--r--   0 root         (0) root         (0)    25279 2023-01-18 01:27:10.000000 flash_attn-0.2.8/flash_attn/ops/fused_dense.py
--rw-r--r--   0 root         (0) root         (0)     2685 2022-12-18 05:19:38.000000 flash_attn-0.2.8/flash_attn/ops/gelu_activation.py
--rw-r--r--   0 root         (0) root         (0)    12959 2023-01-19 07:31:05.000000 flash_attn-0.2.8/flash_attn/ops/layer_norm.py
--rw-r--r--   0 root         (0) root         (0)     2572 2023-01-19 07:39:12.000000 flash_attn-0.2.8/flash_attn/ops/rms_norm.py
--rw-r--r--   0 root         (0) root         (0)     5855 2022-12-17 01:12:27.000000 flash_attn-0.2.8/flash_attn/rotary.py
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:25:37.222398 flash_attn-0.2.8/flash_attn/triton/
--rw-rw-r--   0 root         (0) root         (0)        0 2022-11-18 00:51:48.000000 flash_attn-0.2.8/flash_attn/triton/__init__.py
--rw-rw-r--   0 root         (0) root         (0)    14332 2022-10-23 23:52:09.000000 flash_attn-0.2.8/flash_attn/triton/fused_attention.py
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:25:37.480035 flash_attn-0.2.8/flash_attn/utils/
--rw-r--r--   0 root         (0) root         (0)        0 2022-12-18 05:19:38.000000 flash_attn-0.2.8/flash_attn/utils/__init__.py
--rw-r--r--   0 root         (0) root         (0)     5909 2023-01-01 06:51:31.000000 flash_attn-0.2.8/flash_attn/utils/benchmark.py
--rw-r--r--   0 root         (0) root         (0)     5545 2023-01-18 01:04:37.000000 flash_attn-0.2.8/flash_attn/utils/distributed.py
--rw-r--r--   0 root         (0) root         (0)    11976 2023-01-18 03:26:22.000000 flash_attn-0.2.8/flash_attn/utils/generation.py
--rw-r--r--   0 root         (0) root         (0)     1540 2023-01-18 03:20:36.000000 flash_attn-0.2.8/flash_attn/utils/pretrained.py
-drwxrwxr-x   0 root         (0) root         (0)        0 2023-01-19 21:25:36.082717 flash_attn-0.2.8/flash_attn.egg-info/
--rw-rw-r--   0 root         (0) root         (0)     8124 2023-01-19 21:21:33.000000 flash_attn-0.2.8/flash_attn.egg-info/PKG-INFO
--rw-rw-r--   0 root         (0) root         (0)   105192 2023-01-19 21:21:45.000000 flash_attn-0.2.8/flash_attn.egg-info/SOURCES.txt
--rw-rw-r--   0 root         (0) root         (0)        1 2023-01-19 21:21:33.000000 flash_attn-0.2.8/flash_attn.egg-info/dependency_links.txt
--rw-rw-r--   0 root         (0) root         (0)       13 2023-01-19 21:21:33.000000 flash_attn-0.2.8/flash_attn.egg-info/requires.txt
--rw-rw-r--   0 root         (0) root         (0)       27 2023-01-19 21:21:33.000000 flash_attn-0.2.8/flash_attn.egg-info/top_level.txt
--rw-rw-r--   0 root         (0) root         (0)       38 2023-01-19 21:25:37.509156 flash_attn-0.2.8/setup.cfg
--rw-r--r--   0 root         (0) root         (0)     7326 2023-01-19 21:16:26.000000 flash_attn-0.2.8/setup.py
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:27.167849 flash_attn-1.0.0/
+-rw-r--r--   0 root         (0) root         (0)       56 2022-11-17 23:40:55.000000 flash_attn-1.0.0/AUTHORS
+-rw-r--r--   0 root         (0) root         (0)     1558 2022-09-09 19:08:03.000000 flash_attn-1.0.0/LICENSE
+-rw-r--r--   0 root         (0) root         (0)      251 2023-04-12 06:28:28.000000 flash_attn-1.0.0/MANIFEST.in
+-rw-rw-r--   0 root         (0) root         (0)    10037 2023-04-12 06:37:27.163859 flash_attn-1.0.0/PKG-INFO
+-rw-r--r--   0 root         (0) root         (0)     9529 2023-04-12 06:31:27.000000 flash_attn-1.0.0/README.md
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:49.522416 flash_attn-1.0.0/csrc/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:49.831107 flash_attn-1.0.0/csrc/flash_attn/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:49.292243 flash_attn-1.0.0/csrc/flash_attn/cutlass/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:49.957247 flash_attn-1.0.0/csrc/flash_attn/cutlass/cmake/
+-rw-r--r--   0 root         (0) root         (0)     2023 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/cmake/nop.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:48.893621 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:50.281335 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/00_basic_gemm/
+-rw-r--r--   0 root         (0) root         (0)    14698 2023-03-13 04:24:25.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/00_basic_gemm/basic_gemm.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:50.304969 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/01_cutlass_utilities/
+-rw-r--r--   0 root         (0) root         (0)    13255 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/01_cutlass_utilities/cutlass_utilities.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:50.490603 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/02_dump_reg_shmem/
+-rw-r--r--   0 root         (0) root         (0)     7157 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/02_dump_reg_shmem/dump_reg_shmem.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:50.910665 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/03_visualize_layout/
+-rw-r--r--   0 root         (0) root         (0)     4478 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/03_visualize_layout/options.h
+-rw-r--r--   0 root         (0) root         (0)     7081 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/03_visualize_layout/register_layout.cu
+-rw-r--r--   0 root         (0) root         (0)     2691 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/03_visualize_layout/register_layout.h
+-rw-r--r--   0 root         (0) root         (0)     5819 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/03_visualize_layout/visualize_layout.cpp
+-rw-r--r--   0 root         (0) root         (0)    11415 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/03_visualize_layout/visualize_layout.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:51.009821 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/04_tile_iterator/
+-rw-r--r--   0 root         (0) root         (0)     8226 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/04_tile_iterator/tile_iterator.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:51.094185 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/05_batched_gemm/
+-rw-r--r--   0 root         (0) root         (0)    15161 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/05_batched_gemm/batched_gemm.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:51.320405 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/06_splitK_gemm/
+-rw-r--r--   0 root         (0) root         (0)    17570 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/06_splitK_gemm/splitk_gemm.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:51.419017 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/07_volta_tensorop_gemm/
+-rw-r--r--   0 root         (0) root         (0)    18283 2023-03-13 04:24:25.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/07_volta_tensorop_gemm/volta_tensorop_gemm.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:51.540496 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/08_turing_tensorop_gemm/
+-rw-r--r--   0 root         (0) root         (0)    18229 2023-03-13 04:24:25.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/08_turing_tensorop_gemm/turing_tensorop_gemm.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:51.563738 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/09_turing_tensorop_conv2dfprop/
+-rw-r--r--   0 root         (0) root         (0)    28127 2023-03-13 04:24:25.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/09_turing_tensorop_conv2dfprop/turing_tensorop_conv2dfprop.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:51.590131 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/10_planar_complex/
+-rw-r--r--   0 root         (0) root         (0)    21947 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/10_planar_complex/planar_complex.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:51.725821 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/11_planar_complex_array/
+-rw-r--r--   0 root         (0) root         (0)    23244 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/11_planar_complex_array/planar_complex_array.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:51.903862 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/12_gemm_bias_relu/
+-rw-r--r--   0 root         (0) root         (0)    13151 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/12_gemm_bias_relu/gemm_bias_relu.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:55.202337 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/
+-rw-r--r--   0 root         (0) root         (0)    26102 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/b2b_conv2d_run.h
+-rw-r--r--   0 root         (0) root         (0)    22877 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/b2b_gemm_run.h
+-rw-r--r--   0 root         (0) root         (0)    28268 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/b2b_interleaved_conv2d_run.h
+-rw-r--r--   0 root         (0) root         (0)    24493 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/b2b_interleaved_gemm_run.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:55.496592 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/device/
+-rw-r--r--   0 root         (0) root         (0)    15552 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/device/b2b_gemm.h
+-rw-r--r--   0 root         (0) root         (0)    11520 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/device/b2b_implicit_gemm_convolution.h
+-rw-r--r--   0 root         (0) root         (0)     8756 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm75_rf.cu
+-rw-r--r--   0 root         (0) root         (0)     8759 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm75_shmem.cu
+-rw-r--r--   0 root         (0) root         (0)     8712 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm80_rf.cu
+-rw-r--r--   0 root         (0) root         (0)     8762 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm80_shmem.cu
+-rw-r--r--   0 root         (0) root         (0)     8787 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm75_rf.cu
+-rw-r--r--   0 root         (0) root         (0)     8793 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm75_shmem.cu
+-rw-r--r--   0 root         (0) root         (0)     8711 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm80_rf.cu
+-rw-r--r--   0 root         (0) root         (0)     8775 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm80_shmem.cu
+-rw-r--r--   0 root         (0) root         (0)     7269 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm75_rf.cu
+-rw-r--r--   0 root         (0) root         (0)     7338 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm75_shmem.cu
+-rw-r--r--   0 root         (0) root         (0)     7294 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm80_rf.cu
+-rw-r--r--   0 root         (0) root         (0)     7359 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm80_shmem.cu
+-rw-r--r--   0 root         (0) root         (0)     7362 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm75_rf.cu
+-rw-r--r--   0 root         (0) root         (0)     7430 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm75_shmem.cu
+-rw-r--r--   0 root         (0) root         (0)     7627 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm80_rf.cu
+-rw-r--r--   0 root         (0) root         (0)     7634 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm80_shmem.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:56.652826 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/kernel/
+-rw-r--r--   0 root         (0) root         (0)    16152 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/kernel/b2b_gemm.h
+-rw-r--r--   0 root         (0) root         (0)    18151 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/kernel/b2b_implicit_gemm_convolution.h
+-rw-r--r--   0 root         (0) root         (0)     3973 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop.h
+-rw-r--r--   0 root         (0) root         (0)    26762 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_sm75.h
+-rw-r--r--   0 root         (0) root         (0)    26775 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_sm80.h
+-rw-r--r--   0 root         (0) root         (0)    28422 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_smem_accumulator_sm75.h
+-rw-r--r--   0 root         (0) root         (0)    28073 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_smem_accumulator_sm80.h
+-rw-r--r--   0 root         (0) root         (0)    17111 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_gemm.h
+-rw-r--r--   0 root         (0) root         (0)    15658 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_gemm_smem_accumulator.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:48.622407 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/reference/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:56.783089 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/reference/device/
+-rw-r--r--   0 root         (0) root         (0)    10368 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/reference/device/tensor_scale_bias.h
+-rw-r--r--   0 root         (0) root         (0)     3577 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/test_run.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:58.154860 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/
+-rw-r--r--   0 root         (0) root         (0)    31616 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_multistage.h
+-rw-r--r--   0 root         (0) root         (0)    31443 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_multistage_smem_accumulator.h
+-rw-r--r--   0 root         (0) root         (0)    21012 2023-03-13 04:24:25.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_pipelined.h
+-rw-r--r--   0 root         (0) root         (0)    20494 2023-03-13 04:24:25.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_pipelined_smem_accumulator.h
+-rw-r--r--   0 root         (0) root         (0)     7983 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_base.h
+-rw-r--r--   0 root         (0) root         (0)     6047 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_base_smem_accumulator.h
+-rw-r--r--   0 root         (0) root         (0)    33788 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_multistage.h
+-rw-r--r--   0 root         (0) root         (0)    33506 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_multistage_smem_accumulator.h
+-rw-r--r--   0 root         (0) root         (0)    21452 2023-03-13 04:24:25.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_pipelined.h
+-rw-r--r--   0 root         (0) root         (0)    21066 2023-03-13 04:24:25.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_pipelined_smem_accumulator.h
+-rw-r--r--   0 root         (0) root         (0)    27144 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/default_b2b_mma.h
+-rw-r--r--   0 root         (0) root         (0)    27400 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/default_b2b_mma_smem_accumulator.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:58.455355 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/14_ampere_tf32_tensorop_gemm/
+-rw-r--r--   0 root         (0) root         (0)    18020 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/14_ampere_tf32_tensorop_gemm/ampere_tf32_tensorop_gemm.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:58.625810 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/15_ampere_sparse_tensorop_gemm/
+-rw-r--r--   0 root         (0) root         (0)    15042 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/15_ampere_sparse_tensorop_gemm/ampere_sparse_tensorop_gemm.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:58.717549 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/16_ampere_tensorop_conv2dfprop/
+-rw-r--r--   0 root         (0) root         (0)    27758 2023-03-13 04:24:25.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/16_ampere_tensorop_conv2dfprop/ampere_tensorop_conv2dfprop.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:58.741223 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/17_fprop_per_channel_bias/
+-rw-r--r--   0 root         (0) root         (0)    12580 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/17_fprop_per_channel_bias/fprop_per_channel_bias.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:58.816917 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/18_ampere_fp64_tensorop_affine2_gemm/
+-rw-r--r--   0 root         (0) root         (0)    14007 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/18_ampere_fp64_tensorop_affine2_gemm/ampere_fp64_tensorop_affine2_gemm.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:58.942489 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/19_tensorop_canonical/
+-rw-r--r--   0 root         (0) root         (0)    13401 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/19_tensorop_canonical/tensorop_canonical.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:59.030177 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/20_simt_canonical/
+-rw-r--r--   0 root         (0) root         (0)    12556 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/20_simt_canonical/simt_canonical.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:59.135500 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/21_quaternion_gemm/
+-rw-r--r--   0 root         (0) root         (0)    17319 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/21_quaternion_gemm/quaternion_gemm.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:59.213302 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/22_quaternion_conv/
+-rw-r--r--   0 root         (0) root         (0)    21495 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/22_quaternion_conv/quaternion_conv.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:59.326541 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/23_ampere_gemm_operand_reduction_fusion/
+-rw-r--r--   0 root         (0) root         (0)    27530 2023-03-13 04:24:25.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/23_ampere_gemm_operand_reduction_fusion/ampere_gemm_operand_reduction_fusion.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:59.426010 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/24_gemm_grouped/
+-rw-r--r--   0 root         (0) root         (0)    50967 2023-03-13 04:24:25.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/24_gemm_grouped/gemm_grouped.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:59.614905 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/25_ampere_fprop_mainloop_fusion/
+-rw-r--r--   0 root         (0) root         (0)    26547 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/25_ampere_fprop_mainloop_fusion/ampere_3d_fprop_mainloop_fusion.cu
+-rw-r--r--   0 root         (0) root         (0)    25628 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/25_ampere_fprop_mainloop_fusion/ampere_fprop_mainloop_fusion.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:59.738448 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/26_ampere_wgrad_mainloop_fusion/
+-rw-r--r--   0 root         (0) root         (0)    25538 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/26_ampere_wgrad_mainloop_fusion/ampere_wgrad_mainloop_fusion.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:59.881439 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/27_ampere_3xtf32_fast_accurate_tensorop_gemm/
+-rw-r--r--   0 root         (0) root         (0)    30446 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/27_ampere_3xtf32_fast_accurate_tensorop_gemm/27_ampere_3xtf32_fast_accurate_tensorop_gemm.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:00.138057 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/28_ampere_3xtf32_fast_accurate_tensorop_fprop/
+-rw-r--r--   0 root         (0) root         (0)    28159 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/28_ampere_3xtf32_fast_accurate_tensorop_fprop/ampere_3xtf32_fast_accurate_tensorop_fprop.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:00.229351 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/29_ampere_3xtf32_fast_accurate_tensorop_complex_gemm/
+-rw-r--r--   0 root         (0) root         (0)    28403 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/29_ampere_3xtf32_fast_accurate_tensorop_complex_gemm/29_ampere_3xtf32_fast_accurate_tensorop_complex_gemm.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:00.343401 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/30_wgrad_split_k/
+-rw-r--r--   0 root         (0) root         (0)    27329 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/30_wgrad_split_k/30_wgrad_split_k.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:00.420167 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/31_basic_syrk/
+-rw-r--r--   0 root         (0) root         (0)    15206 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/31_basic_syrk/basic_syrk.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:00.528884 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/32_basic_trmm/
+-rw-r--r--   0 root         (0) root         (0)    15907 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/32_basic_trmm/basic_trmm.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:00.624443 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/33_ampere_3xtf32_tensorop_symm/
+-rw-r--r--   0 root         (0) root         (0)    31803 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/33_ampere_3xtf32_tensorop_symm/ampere_3xtf32_tensorop_symm.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:00.710975 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/34_transposed_conv2d/
+-rw-r--r--   0 root         (0) root         (0)    22378 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/34_transposed_conv2d/34_transposed_conv2d.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:01.133089 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/35_gemm_softmax/
+-rw-r--r--   0 root         (0) root         (0)    23114 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/35_gemm_softmax/gemm_softmax.cu
+-rw-r--r--   0 root         (0) root         (0)    16723 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/35_gemm_softmax/gemm_with_epilogue_visitor.h
+-rw-r--r--   0 root         (0) root         (0)    18713 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/35_gemm_softmax/gemm_with_softmax.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:01.263435 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/36_gather_scatter_fusion/
+-rw-r--r--   0 root         (0) root         (0)    20795 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/36_gather_scatter_fusion/gather_scatter_fusion.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:01.715901 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/37_gemm_layernorm_gemm_fusion/
+-rw-r--r--   0 root         (0) root         (0)    31111 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/37_gemm_layernorm_gemm_fusion/gemm_layernorm.cu
+-rw-r--r--   0 root         (0) root         (0)    13982 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/37_gemm_layernorm_gemm_fusion/gemm_with_epilogue_visitor.h
+-rw-r--r--   0 root         (0) root         (0)    33905 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/37_gemm_layernorm_gemm_fusion/gemm_with_layernorm.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:01.804892 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/38_syr2k_grouped/
+-rw-r--r--   0 root         (0) root         (0)    47455 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/38_syr2k_grouped/syr2k_grouped.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:02.046147 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/39_gemm_permute/
+-rw-r--r--   0 root         (0) root         (0)    37896 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/39_gemm_permute/gemm_permute.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:03.044770 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/
+-rw-r--r--   0 root         (0) root         (0)    18389 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/attention_scaling_coefs_updater.h
+-rw-r--r--   0 root         (0) root         (0)    11865 2023-03-13 04:24:25.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/debug_utils.h
+-rw-r--r--   0 root         (0) root         (0)     9885 2023-03-13 04:24:25.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/default_fmha_grouped.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:03.152433 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/epilogue/
+-rw-r--r--   0 root         (0) root         (0)    22349 2023-03-13 04:24:25.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/epilogue/epilogue_pipelined.h
+-rw-r--r--   0 root         (0) root         (0)     9162 2023-03-13 04:24:25.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/epilogue/epilogue_rescale_output.h
+-rw-r--r--   0 root         (0) root         (0)     6111 2023-03-13 04:24:25.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/epilogue/epilogue_thread_apply_logsumexp.h
+-rw-r--r--   0 root         (0) root         (0)    22349 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/epilogue_pipelined.h
+-rw-r--r--   0 root         (0) root         (0)     9162 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/epilogue_rescale_output.h
+-rw-r--r--   0 root         (0) root         (0)     6111 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/epilogue_thread_apply_logsumexp.h
+-rw-r--r--   0 root         (0) root         (0)     6768 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/find_default_mma.h
+-rw-r--r--   0 root         (0) root         (0)    34379 2023-03-13 04:24:25.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/fmha_grouped.h
+-rw-r--r--   0 root         (0) root         (0)     6666 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/fmha_grouped_problem_visitor.h
+-rw-r--r--   0 root         (0) root         (0)    38173 2023-03-13 04:24:25.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/fused_multihead_attention_fixed_seqlen.cu
+-rw-r--r--   0 root         (0) root         (0)    39997 2023-03-13 04:24:25.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/fused_multihead_attention_variable_seqlen.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:03.762939 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/gemm/
+-rw-r--r--   0 root         (0) root         (0)     3994 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma.h
+-rw-r--r--   0 root         (0) root         (0)     6241 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma_base.h
+-rw-r--r--   0 root         (0) root         (0)    27198 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma_multistage.h
+-rw-r--r--   0 root         (0) root         (0)    14091 2023-03-13 04:24:25.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma_pipelined.h
+-rw-r--r--   0 root         (0) root         (0)     6782 2023-03-13 04:24:25.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/gemm/find_default_mma.h
+-rw-r--r--   0 root         (0) root         (0)    13959 2023-03-13 04:24:25.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/gemm/mma_accum_lambda_iterator.h
+-rw-r--r--   0 root         (0) root         (0)    72984 2023-03-13 04:24:25.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/gemm/mma_from_smem.h
+-rw-r--r--   0 root         (0) root         (0)    10878 2023-03-13 04:24:25.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/gemm_kernel_utils.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:04.117644 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/iterators/
+-rw-r--r--   0 root         (0) root         (0)    23855 2023-03-13 04:24:25.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/iterators/epilogue_predicated_tile_iterator.h
+-rw-r--r--   0 root         (0) root         (0)     3142 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/iterators/make_residual_last.h
+-rw-r--r--   0 root         (0) root         (0)    64480 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/iterators/predicated_tile_access_iterator_residual_last.h
+-rw-r--r--   0 root         (0) root         (0)    64500 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/iterators/predicated_tile_iterator_residual_last.h
+-rw-r--r--   0 root         (0) root         (0)     2435 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/iterators/transpose_warp_iterator.h
+-rw-r--r--   0 root         (0) root         (0)     9497 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/iterators/warp_iterator_from_smem.h
+-rw-r--r--   0 root         (0) root         (0)    48655 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/kernel_forward.h
+-rw-r--r--   0 root         (0) root         (0)    61195 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/mma_from_smem.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:04.217250 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/transform/
+-rw-r--r--   0 root         (0) root         (0)     3747 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/transform/tile_smem_loader.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:04.240664 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/42_ampere_tensorop_group_conv/
+-rw-r--r--   0 root         (0) root         (0)    23901 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/42_ampere_tensorop_group_conv/ampere_tensorop_group_conv.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:04.474242 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/43_ell_block_sparse_gemm/
+-rw-r--r--   0 root         (0) root         (0)    23867 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/43_ell_block_sparse_gemm/ell_block_sparse_gemm.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:04.823947 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:48.826868 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:48.816288 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:05.323713 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/
+-rw-r--r--   0 root         (0) root         (0)     6370 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/default_bias_act_epilogue_tensor_op.h
+-rw-r--r--   0 root         (0) root         (0)     4099 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/default_thread_map_tensor_op_for_fused_bias.h
+-rw-r--r--   0 root         (0) root         (0)     8285 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/fused_bias_act_epilogue.h
+-rw-r--r--   0 root         (0) root         (0)    10439 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/output_tile_thread_map_for_fused_bias.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:05.505470 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/warp/
+-rw-r--r--   0 root         (0) root         (0)     6848 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/warp/fused_bias_act_fragment_iterator_tensor_op.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:48.832399 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/gemm/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:05.781618 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/gemm/warp/
+-rw-r--r--   0 root         (0) root         (0)    14747 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/gemm/warp/mma_tensor_op_fragment_iterator_without_output_op.h
+-rw-r--r--   0 root         (0) root         (0)    10231 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/leaky_bias.h
+-rw-r--r--   0 root         (0) root         (0)     3745 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/utils.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:05.894838 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/45_dual_gemm/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:05.985887 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/45_dual_gemm/device/
+-rw-r--r--   0 root         (0) root         (0)    16955 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/45_dual_gemm/device/dual_gemm.h
+-rw-r--r--   0 root         (0) root         (0)    12669 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/45_dual_gemm/dual_gemm.cu
+-rw-r--r--   0 root         (0) root         (0)     2366 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/45_dual_gemm/dual_gemm_common.h
+-rw-r--r--   0 root         (0) root         (0)    31360 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/45_dual_gemm/dual_gemm_run.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:06.009254 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/45_dual_gemm/kernel/
+-rw-r--r--   0 root         (0) root         (0)    18422 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/45_dual_gemm/kernel/dual_gemm.h
+-rw-r--r--   0 root         (0) root         (0)     3577 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/45_dual_gemm/test_run.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:06.034997 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/45_dual_gemm/thread/
+-rw-r--r--   0 root         (0) root         (0)     5818 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/45_dual_gemm/thread/left_silu_and_mul.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:06.305702 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/45_dual_gemm/threadblock/
+-rw-r--r--   0 root         (0) root         (0)    15613 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/45_dual_gemm/threadblock/dual_epilogue.h
+-rw-r--r--   0 root         (0) root         (0)     7920 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/45_dual_gemm/threadblock/dual_mma_base.h
+-rw-r--r--   0 root         (0) root         (0)    29976 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/45_dual_gemm/threadblock/dual_mma_multistage.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:06.513527 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/46_depthwise_simt_conv2dfprop/
+-rw-r--r--   0 root         (0) root         (0)    24464 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/46_depthwise_simt_conv2dfprop/depthwise_simt_conv2dfprop.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:06.769717 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/47_ampere_gemm_universal_streamk/
+-rw-r--r--   0 root         (0) root         (0)    22676 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/47_ampere_gemm_universal_streamk/ampere_gemm_universal_streamk.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:06.848554 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/48_hopper_warp_specialized_gemm/
+-rw-r--r--   0 root         (0) root         (0)    16736 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/48_hopper_warp_specialized_gemm/48_hopper_warp_specialized_gemm.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:06.925596 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/49_hopper_gemm_schedules_with_collective_builder/
+-rw-r--r--   0 root         (0) root         (0)    22625 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/49_hopper_gemm_schedules_with_collective_builder/49_hopper_gemm_schedules_with_collective_builder.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:06.950596 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/50_hopper_gemm_with_epilogue_swizzle/
+-rw-r--r--   0 root         (0) root         (0)    18635 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/50_hopper_gemm_with_epilogue_swizzle/50_hopper_gemm_with_epilogue_swizzle.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:07.015085 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/60_cutlass_import/
+-rw-r--r--   0 root         (0) root         (0)     2849 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/60_cutlass_import/main.cpp
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:07.225459 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/common/
+-rw-r--r--   0 root         (0) root         (0)     4449 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/common/helper.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:48.904938 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/cute/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:07.252541 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/cute/tutorial/
+-rw-r--r--   0 root         (0) root         (0)    14342 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/cute/tutorial/sgemm_nt_1.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:48.916386 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:10.432132 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/
+-rw-r--r--   0 root         (0) root         (0)     3793 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/aligned_buffer.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:12.081505 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/
+-rw-r--r--   0 root         (0) root         (0)     3538 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/arch.h
+-rw-r--r--   0 root         (0) root         (0)    12127 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/barrier.h
+-rw-r--r--   0 root         (0) root         (0)     2691 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/cache_operation.h
+-rw-r--r--   0 root         (0) root         (0)    14313 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/memory.h
+-rw-r--r--   0 root         (0) root         (0)     8511 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/memory_sm75.h
+-rw-r--r--   0 root         (0) root         (0)    15166 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/memory_sm80.h
+-rw-r--r--   0 root         (0) root         (0)     8074 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/mma.h
+-rw-r--r--   0 root         (0) root         (0)    11096 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/mma_sm50.h
+-rw-r--r--   0 root         (0) root         (0)     7040 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/mma_sm60.h
+-rw-r--r--   0 root         (0) root         (0)     4193 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/mma_sm61.h
+-rw-r--r--   0 root         (0) root         (0)    16554 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/mma_sm70.h
+-rw-r--r--   0 root         (0) root         (0)    31682 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/mma_sm75.h
+-rw-r--r--   0 root         (0) root         (0)    55577 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/mma_sm80.h
+-rw-r--r--   0 root         (0) root         (0)     8254 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/mma_sm90.h
+-rw-r--r--   0 root         (0) root         (0)    43978 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/mma_sparse_sm80.h
+-rw-r--r--   0 root         (0) root         (0)     2622 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/reg_reconfig.h
+-rw-r--r--   0 root         (0) root         (0)     3998 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/simd.h
+-rw-r--r--   0 root         (0) root         (0)     3656 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/simd_sm60.h
+-rw-r--r--   0 root         (0) root         (0)     5102 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/simd_sm61.h
+-rw-r--r--   0 root         (0) root         (0)     8473 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/wmma.h
+-rw-r--r--   0 root         (0) root         (0)     5286 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/wmma_sm70.h
+-rw-r--r--   0 root         (0) root         (0)     7746 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/wmma_sm72.h
+-rw-r--r--   0 root         (0) root         (0)     7616 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/wmma_sm75.h
+-rw-r--r--   0 root         (0) root         (0)    62709 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/array.h
+-rw-r--r--   0 root         (0) root         (0)     3662 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/array_planar_complex.h
+-rw-r--r--   0 root         (0) root         (0)    13128 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/array_subbyte.h
+-rw-r--r--   0 root         (0) root         (0)     6371 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/barrier.h
+-rw-r--r--   0 root         (0) root         (0)    13371 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/bfloat16.h
+-rw-r--r--   0 root         (0) root         (0)     6338 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/blas3.h
+-rw-r--r--   0 root         (0) root         (0)     9372 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/block_striped.h
+-rw-r--r--   0 root         (0) root         (0)    19422 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/complex.h
+-rw-r--r--   0 root         (0) root         (0)    47943 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/constants.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:12.395292 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/
+-rw-r--r--   0 root         (0) root         (0)    22725 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/conv2d_problem_size.h
+-rw-r--r--   0 root         (0) root         (0)    16292 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/conv3d_problem_size.h
+-rw-r--r--   0 root         (0) root         (0)     6664 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/convolution.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:12.703080 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/device/
+-rw-r--r--   0 root         (0) root         (0)     9744 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/device/direct_convolution.h
+-rw-r--r--   0 root         (0) root         (0)    12078 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/device/implicit_gemm_convolution.h
+-rw-r--r--   0 root         (0) root         (0)    10044 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/device/implicit_gemm_convolution_fusion.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:15.592357 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/
+-rw-r--r--   0 root         (0) root         (0)     7671 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv2d.h
+-rw-r--r--   0 root         (0) root         (0)    53546 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv2d_dgrad.h
+-rw-r--r--   0 root         (0) root         (0)    56838 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop.h
+-rw-r--r--   0 root         (0) root         (0)    11953 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_fusion.h
+-rw-r--r--   0 root         (0) root         (0)     4690 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_with_broadcast.h
+-rw-r--r--   0 root         (0) root         (0)     4660 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_with_reduction.h
+-rw-r--r--   0 root         (0) root         (0)    15891 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv2d_group_fprop.h
+-rw-r--r--   0 root         (0) root         (0)    28745 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv2d_wgrad.h
+-rw-r--r--   0 root         (0) root         (0)    10459 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv2d_wgrad_fusion.h
+-rw-r--r--   0 root         (0) root         (0)     9324 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv3d_dgrad.h
+-rw-r--r--   0 root         (0) root         (0)    14864 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv3d_fprop.h
+-rw-r--r--   0 root         (0) root         (0)    11980 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv3d_fprop_fusion.h
+-rw-r--r--   0 root         (0) root         (0)    14883 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv3d_wgrad.h
+-rw-r--r--   0 root         (0) root         (0)    19294 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_depthwise_fprop.h
+-rw-r--r--   0 root         (0) root         (0)    18048 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/direct_convolution.h
+-rw-r--r--   0 root         (0) root         (0)    15430 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution.h
+-rw-r--r--   0 root         (0) root         (0)    15685 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution_fusion.h
+-rw-r--r--   0 root         (0) root         (0)    17107 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution_strided_dgrad.h
+-rw-r--r--   0 root         (0) root         (0)    16725 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution_with_fused_epilogue.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:15.824424 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/thread/
+-rw-r--r--   0 root         (0) root         (0)     9689 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/thread/depthwise_mma.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:22.186616 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/
+-rw-r--r--   0 root         (0) root         (0)    15306 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_filter_tile_access_iterator_analytic.h
+-rw-r--r--   0 root         (0) root         (0)    19735 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_filter_tile_access_iterator_optimized.h
+-rw-r--r--   0 root         (0) root         (0)    18940 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_output_gradient_tile_access_iterator_analytic.h
+-rw-r--r--   0 root         (0) root         (0)    26136 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_output_gradient_tile_access_iterator_optimized.h
+-rw-r--r--   0 root         (0) root         (0)    10953 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_analytic.h
+-rw-r--r--   0 root         (0) root         (0)    11529 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_few_channels.h
+-rw-r--r--   0 root         (0) root         (0)    11333 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_fixed_channels.h
+-rw-r--r--   0 root         (0) root         (0)    13664 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_optimized.h
+-rw-r--r--   0 root         (0) root         (0)    10627 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_analytic.h
+-rw-r--r--   0 root         (0) root         (0)     9314 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_few_channels.h
+-rw-r--r--   0 root         (0) root         (0)     9018 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_fixed_channels.h
+-rw-r--r--   0 root         (0) root         (0)    10387 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_optimized.h
+-rw-r--r--   0 root         (0) root         (0)    30197 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_params.h
+-rw-r--r--   0 root         (0) root         (0)    11202 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_tile_iterator.h
+-rw-r--r--   0 root         (0) root         (0)    10349 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_activation_tile_access_iterator_analytic.h
+-rw-r--r--   0 root         (0) root         (0)    11519 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_activation_tile_access_iterator_optimized.h
+-rw-r--r--   0 root         (0) root         (0)     9043 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_output_gradient_tile_access_iterator_analytic.h
+-rw-r--r--   0 root         (0) root         (0)    10832 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_output_gradient_tile_access_iterator_optimized.h
+-rw-r--r--   0 root         (0) root         (0)     8450 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_filter_tile_access_iterator_analytic.h
+-rw-r--r--   0 root         (0) root         (0)     9569 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_filter_tile_access_iterator_optimized.h
+-rw-r--r--   0 root         (0) root         (0)    11020 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_output_gradient_tile_access_iterator_analytic.h
+-rw-r--r--   0 root         (0) root         (0)    15014 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_output_gradient_tile_access_iterator_optimized.h
+-rw-r--r--   0 root         (0) root         (0)     9634 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_activation_tile_access_iterator_analytic.h
+-rw-r--r--   0 root         (0) root         (0)    15132 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_activation_tile_access_iterator_optimized.h
+-rw-r--r--   0 root         (0) root         (0)     7945 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_filter_tile_access_iterator_analytic.h
+-rw-r--r--   0 root         (0) root         (0)     8891 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_filter_tile_access_iterator_optimized.h
+-rw-r--r--   0 root         (0) root         (0)    18249 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_params.h
+-rw-r--r--   0 root         (0) root         (0)     9971 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_activation_tile_access_iterator_analytic.h
+-rw-r--r--   0 root         (0) root         (0)    12024 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_activation_tile_access_iterator_optimized.h
+-rw-r--r--   0 root         (0) root         (0)     8821 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_output_gradient_tile_access_iterator_analytic.h
+-rw-r--r--   0 root         (0) root         (0)    10744 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_output_gradient_tile_access_iterator_optimized.h
+-rw-r--r--   0 root         (0) root         (0)     8871 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/depthwise_direct_conv_params.h
+-rw-r--r--   0 root         (0) root         (0)    10747 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_activation_tile_access_iterator_direct_conv_fixed_stride_dilation.h
+-rw-r--r--   0 root         (0) root         (0)     9899 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_activation_tile_access_iterator_direct_conv_optimized.h
+-rw-r--r--   0 root         (0) root         (0)    20899 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_direct_conv_multistage.h
+-rw-r--r--   0 root         (0) root         (0)     8921 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_filter_tile_access_iterator_direct_conv_optimized.h
+-rw-r--r--   0 root         (0) root         (0)    12745 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_pipelined.h
+-rw-r--r--   0 root         (0) root         (0)     8097 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/depthwise_mma_base.h
+-rw-r--r--   0 root         (0) root         (0)    36697 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/depthwise_mma_core_with_lane_access_size.h
+-rw-r--r--   0 root         (0) root         (0)    30106 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/implicit_gemm_fprop_fusion_multistage.h
+-rw-r--r--   0 root         (0) root         (0)    20086 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/implicit_gemm_multistage.h
+-rw-r--r--   0 root         (0) root         (0)    12175 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/implicit_gemm_pipelined.h
+-rw-r--r--   0 root         (0) root         (0)    26320 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/implicit_gemm_wgrad_fusion_multistage.h
+-rw-r--r--   0 root         (0) root         (0)    16915 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/predicated_scale_bias_vector_access_iterator.h
+-rw-r--r--   0 root         (0) root         (0)    12476 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/predicated_scale_bias_vector_iterator.h
+-rw-r--r--   0 root         (0) root         (0)     8045 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/threadblock_swizzle.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:22.538256 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/warp/
+-rw-r--r--   0 root         (0) root         (0)    12419 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/warp/mma_depthwise_simt.h
+-rw-r--r--   0 root         (0) root         (0)    30655 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/warp/mma_depthwise_simt_tile_iterator.h
+-rw-r--r--   0 root         (0) root         (0)     8772 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/warp/scale_bias_relu_transform.h
+-rw-r--r--   0 root         (0) root         (0)    11827 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/coord.h
+-rw-r--r--   0 root         (0) root         (0)    11077 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/core_io.h
+-rw-r--r--   0 root         (0) root         (0)     8697 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/cutlass.h
+-rw-r--r--   0 root         (0) root         (0)     4216 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/device_kernel.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:48.975763 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:25.657618 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/
+-rw-r--r--   0 root         (0) root         (0)    18909 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/activation.h
+-rw-r--r--   0 root         (0) root         (0)     4691 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/conversion_op.h
+-rw-r--r--   0 root         (0) root         (0)    11563 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination.h
+-rw-r--r--   0 root         (0) root         (0)     8449 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_bias_elementwise.h
+-rw-r--r--   0 root         (0) root         (0)    13571 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_bias_relu.h
+-rw-r--r--   0 root         (0) root         (0)    23649 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_clamp.h
+-rw-r--r--   0 root         (0) root         (0)     9067 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_dgelu.h
+-rw-r--r--   0 root         (0) root         (0)    15195 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_drelu.h
+-rw-r--r--   0 root         (0) root         (0)     3669 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_gelu.h
+-rw-r--r--   0 root         (0) root         (0)     8065 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_generic.h
+-rw-r--r--   0 root         (0) root         (0)     3693 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_hardswish.h
+-rw-r--r--   0 root         (0) root         (0)     8344 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_leaky_relu.h
+-rw-r--r--   0 root         (0) root         (0)     3058 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_params.h
+-rw-r--r--   0 root         (0) root         (0)     9351 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_planar_complex.h
+-rw-r--r--   0 root         (0) root         (0)    20486 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_relu.h
+-rw-r--r--   0 root         (0) root         (0)    19348 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_relu0.h
+-rw-r--r--   0 root         (0) root         (0)    12102 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_residual_block.h
+-rw-r--r--   0 root         (0) root         (0)     3688 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_sigmoid.h
+-rw-r--r--   0 root         (0) root         (0)     3669 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_silu.h
+-rw-r--r--   0 root         (0) root         (0)     8662 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_with_elementwise.h
+-rw-r--r--   0 root         (0) root         (0)     3416 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/reduction_op.h
+-rw-r--r--   0 root         (0) root         (0)     2656 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/scale_type.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:30.602500 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/
+-rw-r--r--   0 root         (0) root         (0)     9142 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_complex_tensor_op.h
+-rw-r--r--   0 root         (0) root         (0)     9441 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_complex_tensor_op_blas3.h
+-rw-r--r--   0 root         (0) root         (0)     3234 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_direct_store.h
+-rw-r--r--   0 root         (0) root         (0)     7209 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_planar_complex.h
+-rw-r--r--   0 root         (0) root         (0)    13385 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_simt.h
+-rw-r--r--   0 root         (0) root         (0)    28290 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_tensor_op.h
+-rw-r--r--   0 root         (0) root         (0)     7129 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_tensor_op_blas3.h
+-rw-r--r--   0 root         (0) root         (0)    10846 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_volta_tensor_op.h
+-rw-r--r--   0 root         (0) root         (0)     5817 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_with_broadcast.h
+-rw-r--r--   0 root         (0) root         (0)     5763 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_with_reduction.h
+-rw-r--r--   0 root         (0) root         (0)     5947 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_wmma_tensor_op.h
+-rw-r--r--   0 root         (0) root         (0)     4409 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_simt.h
+-rw-r--r--   0 root         (0) root         (0)     7398 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_tensor_op.h
+-rw-r--r--   0 root         (0) root         (0)     7303 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_volta_tensor_op.h
+-rw-r--r--   0 root         (0) root         (0)     4098 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_wmma_tensor_op.h
+-rw-r--r--   0 root         (0) root         (0)     4678 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/direct_store_epilogue_iterator.h
+-rw-r--r--   0 root         (0) root         (0)    20099 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue.h
+-rw-r--r--   0 root         (0) root         (0)     8279 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_base.h
+-rw-r--r--   0 root         (0) root         (0)     7455 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_base_streamk.h
+-rw-r--r--   0 root         (0) root         (0)    13424 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_depthwise.h
+-rw-r--r--   0 root         (0) root         (0)    13933 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_direct_store.h
+-rw-r--r--   0 root         (0) root         (0)     7401 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_gemm_k_reduction.h
+-rw-r--r--   0 root         (0) root         (0)    14610 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_planar_complex.h
+-rw-r--r--   0 root         (0) root         (0)     9073 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_smem_accumulator.h
+-rw-r--r--   0 root         (0) root         (0)    16804 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_visitor_with_softmax.h
+-rw-r--r--   0 root         (0) root         (0)    52430 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_broadcast.h
+-rw-r--r--   0 root         (0) root         (0)    29199 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_reduction.h
+-rw-r--r--   0 root         (0) root         (0)    13454 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_visitor.h
+-rw-r--r--   0 root         (0) root         (0)     7308 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_workspace.h
+-rw-r--r--   0 root         (0) root         (0)    14359 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/interleaved_epilogue.h
+-rw-rw-r--   0 root         (0) root         (0)     2912 2022-06-02 16:47:41.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/output_iterator_parameter.h
+-rw-r--r--   0 root         (0) root         (0)    19750 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/output_tile_thread_map.h
+-rw-r--r--   0 root         (0) root         (0)    40870 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator.h
+-rw-r--r--   0 root         (0) root         (0)    18821 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_affine.h
+-rw-r--r--   0 root         (0) root         (0)     5636 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_affine_layout_params.h
+-rw-r--r--   0 root         (0) root         (0)    21249 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_blas3.h
+-rw-r--r--   0 root         (0) root         (0)    13873 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_direct_conv.h
+-rw-r--r--   0 root         (0) root         (0)    14496 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_params.h
+-rw-r--r--   0 root         (0) root         (0)     9146 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_predicates.h
+-rw-r--r--   0 root         (0) root         (0)    15534 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_strided_dgrad.h
+-rw-r--r--   0 root         (0) root         (0)     7487 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/shared_load_iterator.h
+-rw-r--r--   0 root         (0) root         (0)    17756 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/shared_load_iterator_mixed.h
+-rw-r--r--   0 root         (0) root         (0)     7394 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/shared_load_iterator_pitch_liner.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:32.129187 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/
+-rw-r--r--   0 root         (0) root         (0)     7055 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/fragment_iterator_complex_tensor_op.h
+-rw-r--r--   0 root         (0) root         (0)     7736 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/fragment_iterator_gaussian_complex_tensor_op.h
+-rw-r--r--   0 root         (0) root         (0)     5880 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/fragment_iterator_simt.h
+-rw-r--r--   0 root         (0) root         (0)     9883 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/fragment_iterator_tensor_op.h
+-rw-r--r--   0 root         (0) root         (0)     8924 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/fragment_iterator_volta_tensor_op.h
+-rw-r--r--   0 root         (0) root         (0)     6045 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/fragment_iterator_wmma_tensor_op.h
+-rw-r--r--   0 root         (0) root         (0)     4864 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/simt_policy.h
+-rw-r--r--   0 root         (0) root         (0)     5979 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/tensor_op_policy.h
+-rw-r--r--   0 root         (0) root         (0)    25658 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/tile_iterator_simt.h
+-rw-r--r--   0 root         (0) root         (0)    20290 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/tile_iterator_tensor_op.h
+-rw-r--r--   0 root         (0) root         (0)    22922 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/tile_iterator_tensor_op_mixed.h
+-rw-r--r--   0 root         (0) root         (0)    14258 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/tile_iterator_volta_tensor_op.h
+-rw-r--r--   0 root         (0) root         (0)     7704 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/tile_iterator_wmma_tensor_op.h
+-rw-r--r--   0 root         (0) root         (0)     7485 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/volta_tensor_op_policy.h
+-rw-r--r--   0 root         (0) root         (0)     3916 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/wmma_tensor_op_policy.h
+-rw-r--r--   0 root         (0) root         (0)    26026 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/fast_math.h
+-rw-r--r--   0 root         (0) root         (0)    35369 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/float8.h
+-rw-r--r--   0 root         (0) root         (0)     2645 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/floating_point_nvrtc.h
+-rw-r--r--   0 root         (0) root         (0)    12668 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/functional.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:32.194385 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:33.369206 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/
+-rw-r--r--   0 root         (0) root         (0)    17028 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/base_grouped.h
+-rw-r--r--   0 root         (0) root         (0)    24413 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/default_gemm_configuration.h
+-rw-r--r--   0 root         (0) root         (0)    27616 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/ell_gemm.h
+-rw-r--r--   0 root         (0) root         (0)    25202 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm.h
+-rw-r--r--   0 root         (0) root         (0)    22367 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_array.h
+-rw-r--r--   0 root         (0) root         (0)    22375 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_batched.h
+-rw-r--r--   0 root         (0) root         (0)    22725 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_complex.h
+-rw-r--r--   0 root         (0) root         (0)     2591 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_grouped.h
+-rw-r--r--   0 root         (0) root         (0)    13736 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_layernorm_mainloop_fusion.h
+-rw-r--r--   0 root         (0) root         (0)    17329 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_sparse.h
+-rw-r--r--   0 root         (0) root         (0)    20450 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_splitk_parallel.h
+-rw-r--r--   0 root         (0) root         (0)    14902 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_universal.h
+-rw-r--r--   0 root         (0) root         (0)    21594 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_universal_adapter.h
+-rw-r--r--   0 root         (0) root         (0)    13362 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_universal_base.h
+-rw-r--r--   0 root         (0) root         (0)    13968 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_universal_with_broadcast.h
+-rw-r--r--   0 root         (0) root         (0)    14853 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_with_k_reduction.h
+-rw-r--r--   0 root         (0) root         (0)     5690 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemv.h
+-rw-r--r--   0 root         (0) root         (0)    18127 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/rank_2k.h
+-rw-r--r--   0 root         (0) root         (0)     2747 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/rank_2k_grouped.h
+-rw-r--r--   0 root         (0) root         (0)    16719 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/rank_k.h
+-rwxr-xr-x   0 root         (0) root         (0)    21050 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/symm.h
+-rw-r--r--   0 root         (0) root         (0)    26464 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/trmm.h
+-rw-r--r--   0 root         (0) root         (0)    15946 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/gemm.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:41.653499 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/
+-rw-r--r--   0 root         (0) root         (0)    29360 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_ell_gemm.h
+-rw-r--r--   0 root         (0) root         (0)    37758 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm.h
+-rw-r--r--   0 root         (0) root         (0)    16130 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_complex.h
+-rw-r--r--   0 root         (0) root         (0)    12385 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_grouped.h
+-rw-r--r--   0 root         (0) root         (0)     6592 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_grouped_softmax_mainloop_fusion.h
+-rw-r--r--   0 root         (0) root         (0)     5848 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_layernorm_mainloop_fusion.h
+-rw-r--r--   0 root         (0) root         (0)    11104 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_planar_complex_universal.h
+-rw-r--r--   0 root         (0) root         (0)     7983 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_sparse.h
+-rw-r--r--   0 root         (0) root         (0)     4932 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_splitk_parallel.h
+-rw-r--r--   0 root         (0) root         (0)    11951 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_universal.h
+-rw-r--r--   0 root         (0) root         (0)     8125 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_with_broadcast.h
+-rw-r--r--   0 root         (0) root         (0)     6457 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_with_k_reduction.h
+-rw-r--r--   0 root         (0) root         (0)     8086 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_with_reduction.h
+-rwxr-xr-x   0 root         (0) root         (0)     5349 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemv.h
+-rw-r--r--   0 root         (0) root         (0)    11560 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_rank_2k.h
+-rw-r--r--   0 root         (0) root         (0)    20509 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_rank_2k_complex.h
+-rw-r--r--   0 root         (0) root         (0)    12470 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_rank_2k_grouped.h
+-rw-r--r--   0 root         (0) root         (0)    10620 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_rank_2k_universal.h
+-rw-r--r--   0 root         (0) root         (0)     9872 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_rank_k.h
+-rw-r--r--   0 root         (0) root         (0)    16990 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_rank_k_complex.h
+-rw-r--r--   0 root         (0) root         (0)     9444 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_rank_k_universal.h
+-rwxr-xr-x   0 root         (0) root         (0)    13375 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_symm.h
+-rwxr-xr-x   0 root         (0) root         (0)    21830 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_symm_complex.h
+-rwxr-xr-x   0 root         (0) root         (0)    10315 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_symm_universal.h
+-rw-r--r--   0 root         (0) root         (0)    10873 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_trmm.h
+-rw-r--r--   0 root         (0) root         (0)    10730 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_trmm_complex.h
+-rw-r--r--   0 root         (0) root         (0)    10850 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_trmm_universal.h
+-rw-r--r--   0 root         (0) root         (0)    28916 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/ell_gemm.h
+-rw-r--r--   0 root         (0) root         (0)    13357 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm.h
+-rw-r--r--   0 root         (0) root         (0)     8693 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_array.h
+-rw-r--r--   0 root         (0) root         (0)     8761 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_batched.h
+-rw-r--r--   0 root         (0) root         (0)    14687 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_grouped.h
+-rw-r--r--   0 root         (0) root         (0)     4691 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_grouped_problem_visitor.h
+-rw-r--r--   0 root         (0) root         (0)    15623 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_grouped_softmax_mainloop_fusion.h
+-rw-r--r--   0 root         (0) root         (0)    27281 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_layernorm_mainloop_fusion.h
+-rwxr-xr-x   0 root         (0) root         (0)     6144 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_params.h
+-rw-r--r--   0 root         (0) root         (0)     5141 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_pipelined.h
+-rw-r--r--   0 root         (0) root         (0)    22949 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_planar_complex.h
+-rw-r--r--   0 root         (0) root         (0)    18937 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_planar_complex_array.h
+-rw-r--r--   0 root         (0) root         (0)     8142 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_splitk_parallel.h
+-rw-r--r--   0 root         (0) root         (0)     4291 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_transpose_operands.h
+-rw-r--r--   0 root         (0) root         (0)    23216 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_universal.h
+-rw-r--r--   0 root         (0) root         (0)    39288 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_universal_streamk.h
+-rw-r--r--   0 root         (0) root         (0)    47186 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_with_fused_epilogue.h
+-rw-r--r--   0 root         (0) root         (0)    23605 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_with_k_reduction.h
+-rw-r--r--   0 root         (0) root         (0)     8090 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemv.h
+-rwxr-xr-x   0 root         (0) root         (0)     8979 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemv_batched_strided.h
+-rw-r--r--   0 root         (0) root         (0)    16849 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/grouped_problem_visitor.h
+-rw-r--r--   0 root         (0) root         (0)     7148 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/params_universal_base.h
+-rw-r--r--   0 root         (0) root         (0)    22938 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/rank_2k_grouped.h
+-rw-r--r--   0 root         (0) root         (0)    16101 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/rank_2k_grouped_problem_visitor.h
+-rw-r--r--   0 root         (0) root         (0)     4334 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/rank_2k_transpose_operands.h
+-rw-r--r--   0 root         (0) root         (0)    24138 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/rank_2k_universal.h
+-rw-r--r--   0 root         (0) root         (0)    17543 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/rank_k_universal.h
+-rw-r--r--   0 root         (0) root         (0)    13586 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/sparse_gemm.h
+-rwxr-xr-x   0 root         (0) root         (0)    23876 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/symm_universal.h
+-rw-r--r--   0 root         (0) root         (0)    19513 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/trmm_universal.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:42.332055 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/thread/
+-rw-r--r--   0 root         (0) root         (0)     3567 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/thread/mma.h
+-rw-r--r--   0 root         (0) root         (0)    15373 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/thread/mma_sm50.h
+-rw-r--r--   0 root         (0) root         (0)    29987 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/thread/mma_sm60.h
+-rw-r--r--   0 root         (0) root         (0)     8142 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/thread/mma_sm61.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:47.639894 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/
+-rw-r--r--   0 root         (0) root         (0)    31930 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_ell_mma.h
+-rwxr-xr-x   0 root         (0) root         (0)     6979 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_gemv_core.h
+-rw-r--r--   0 root         (0) root         (0)    34241 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma.h
+-rw-r--r--   0 root         (0) root         (0)     5123 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_core.h
+-rw-r--r--   0 root         (0) root         (0)    57426 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_core_simt.h
+-rw-r--r--   0 root         (0) root         (0)    19257 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sm70.h
+-rw-r--r--   0 root         (0) root         (0)    42310 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sm75.h
+-rw-r--r--   0 root         (0) root         (0)   103000 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sm80.h
+-rw-r--r--   0 root         (0) root         (0)    32106 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sparse_sm80.h
+-rw-r--r--   0 root         (0) root         (0)    12645 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_core_with_access_size.h
+-rw-r--r--   0 root         (0) root         (0)     7387 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_core_with_reduction.h
+-rw-r--r--   0 root         (0) root         (0)    20975 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_core_wmma.h
+-rw-r--r--   0 root         (0) root         (0)     7998 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_layernorm_mainloop_fusion.h
+-rw-r--r--   0 root         (0) root         (0)     5110 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_planar_complex_multistage.h
+-rw-r--r--   0 root         (0) root         (0)     4627 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_planar_complex_pipelined.h
+-rw-r--r--   0 root         (0) root         (0)     7113 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_softmax_mainloop_fusion.h
+-rw-r--r--   0 root         (0) root         (0)     6323 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_with_reduction.h
+-rw-r--r--   0 root         (0) root         (0)     7121 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_multistage_mma_complex.h
+-rw-r--r--   0 root         (0) root         (0)     4959 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_multistage_mma_complex_core.h
+-rw-r--r--   0 root         (0) root         (0)    65201 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_multistage_mma_complex_core_sm80.h
+-rw-r--r--   0 root         (0) root         (0)    25495 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_multistage_trmm_complex.h
+-rw-r--r--   0 root         (0) root         (0)     8509 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_sparse_mma.h
+-rw-r--r--   0 root         (0) root         (0)    19515 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_trmm.h
+-rw-r--r--   0 root         (0) root         (0)    24047 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/ell_mma_multistage.h
+-rw-r--r--   0 root         (0) root         (0)    13837 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/ell_mma_pipelined.h
+-rwxr-xr-x   0 root         (0) root         (0)     4726 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/gemv.h
+-rw-r--r--   0 root         (0) root         (0)     3652 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/index_remat.h
+-rw-r--r--   0 root         (0) root         (0)     7823 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_base.h
+-rw-r--r--   0 root         (0) root         (0)    27415 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_blas3_multistage.h
+-rw-r--r--   0 root         (0) root         (0)    32894 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_layernorm_mainloop_fusion_multistage.h
+-rw-r--r--   0 root         (0) root         (0)    28015 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_multistage.h
+-rw-r--r--   0 root         (0) root         (0)    15995 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_pipelined.h
+-rw-r--r--   0 root         (0) root         (0)     6901 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_planar_complex_base.h
+-rw-r--r--   0 root         (0) root         (0)    22653 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_planar_complex_multistage.h
+-rw-r--r--   0 root         (0) root         (0)    14747 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_planar_complex_pipelined.h
+-rw-r--r--   0 root         (0) root         (0)     9864 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_singlestage.h
+-rw-r--r--   0 root         (0) root         (0)    27061 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_softmax_mainloop_fusion_multistage.h
+-rw-r--r--   0 root         (0) root         (0)     9210 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_sparse_base.h
+-rw-r--r--   0 root         (0) root         (0)    25333 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_sparse_multistage.h
+-rw-r--r--   0 root         (0) root         (0)    20473 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_with_reduction_multistage.h
+-rw-r--r--   0 root         (0) root         (0)    15007 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/threadblock_swizzle.h
+-rw-r--r--   0 root         (0) root         (0)    26485 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/threadblock_swizzle_streamk.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:51.661875 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/
+-rw-r--r--   0 root         (0) root         (0)    20553 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/default_mma_complex_tensor_op.h
+-rw-r--r--   0 root         (0) root         (0)     6684 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/default_mma_sparse_tensor_op.h
+-rw-r--r--   0 root         (0) root         (0)     5160 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/default_mma_tensor_op.h
+-rw-r--r--   0 root         (0) root         (0)     9026 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/default_mma_tensor_op_sm80.h
+-rw-r--r--   0 root         (0) root         (0)     4053 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/default_mma_with_reduction_tensor_op.h
+-rw-r--r--   0 root         (0) root         (0)     4685 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/default_mma_wmma_tensor_op.h
+-rw-r--r--   0 root         (0) root         (0)     5725 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/layernorm_scale_bias_transform.h
+-rw-r--r--   0 root         (0) root         (0)     2619 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma.h
+-rw-r--r--   0 root         (0) root         (0)    37705 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_complex_tensor_op.h
+-rw-r--r--   0 root         (0) root         (0)    23132 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_complex_tensor_op_fast_f32.h
+-rw-r--r--   0 root         (0) root         (0)    78615 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_complex_tensor_op_tile_iterator_sm80.h
+-rw-r--r--   0 root         (0) root         (0)    21205 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_gaussian_complex_tensor_op.h
+-rw-r--r--   0 root         (0) root         (0)    14589 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_gaussian_complex_tensor_op_tile_iterator_sm80.h
+-rw-r--r--   0 root         (0) root         (0)     6144 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_planar_complex.h
+-rw-r--r--   0 root         (0) root         (0)     8446 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_simt.h
+-rw-r--r--   0 root         (0) root         (0)     3079 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_simt_policy.h
+-rw-r--r--   0 root         (0) root         (0)    59793 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_simt_tile_iterator.h
+-rw-r--r--   0 root         (0) root         (0)    11758 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_sparse_tensor_op.h
+-rw-r--r--   0 root         (0) root         (0)    14407 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op.h
+-rw-r--r--   0 root         (0) root         (0)    15721 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_fast_f32.h
+-rw-rw-r--   0 root         (0) root         (0)    18643 2022-06-02 16:47:41.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_fragment_iterator.h
+-rw-r--r--   0 root         (0) root         (0)     2939 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_policy.h
+-rw-r--r--   0 root         (0) root         (0)     8966 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_sm70.h
+-rw-r--r--   0 root         (0) root         (0)    11017 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_access_iterator.h
+-rw-r--r--   0 root         (0) root         (0)   136033 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator.h
+-rw-r--r--   0 root         (0) root         (0)    99649 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_sm70.h
+-rw-r--r--   0 root         (0) root         (0)    75179 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_sm80.h
+-rw-r--r--   0 root         (0) root         (0)    13151 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_sparse.h
+-rw-r--r--   0 root         (0) root         (0)    27101 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_wmma.h
+-rw-r--r--   0 root         (0) root         (0)     7241 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_wmma.h
+-rw-r--r--   0 root         (0) root         (0)    17303 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_with_reduction_tensor_op.h
+-rw-r--r--   0 root         (0) root         (0)    19125 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/scale_bias_tile_iterator.h
+-rw-r--r--   0 root         (0) root         (0)     4610 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/softmax_scale_bias_transform.h
+-rw-r--r--   0 root         (0) root         (0)     8728 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/tile_iterator_planar_complex.h
+-rw-r--r--   0 root         (0) root         (0)    23615 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/half.h
+-rw-r--r--   0 root         (0) root         (0)     6893 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/integer_subbyte.h
+-rw-r--r--   0 root         (0) root         (0)     2801 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/kernel_launch.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:52.721240 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/layout/
+-rw-r--r--   0 root         (0) root         (0)     3020 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/layout/layout.h
+-rw-r--r--   0 root         (0) root         (0)    35369 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/layout/matrix.h
+-rw-r--r--   0 root         (0) root         (0)     9133 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/layout/permute.h
+-rw-r--r--   0 root         (0) root         (0)     4696 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/layout/pitch_linear.h
+-rw-r--r--   0 root         (0) root         (0)    18295 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/layout/tensor.h
+-rw-r--r--   0 root         (0) root         (0)    29599 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/layout/tensor_op_multiplicand_sm70.h
+-rw-r--r--   0 root         (0) root         (0)    33137 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/layout/tensor_op_multiplicand_sm75.h
+-rw-r--r--   0 root         (0) root         (0)    29336 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/layout/tensor_op_multiplicand_sm80.h
+-rw-r--r--   0 root         (0) root         (0)     3328 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/layout/vector.h
+-rw-r--r--   0 root         (0) root         (0)   364115 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/matrix.h
+-rw-r--r--   0 root         (0) root         (0)     4991 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/matrix_coord.h
+-rw-r--r--   0 root         (0) root         (0)     2726 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/matrix_shape.h
+-rw-r--r--   0 root         (0) root         (0)    71278 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/numeric_conversion.h
+-rw-r--r--   0 root         (0) root         (0)     3505 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/numeric_types.h
+-rw-r--r--   0 root         (0) root         (0)     5492 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/pitch_linear_coord.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:52.741813 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/platform/
+-rw-r--r--   0 root         (0) root         (0)    26097 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/platform/platform.h
+-rw-r--r--   0 root         (0) root         (0)    15565 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/predicate_vector.h
+-rw-r--r--   0 root         (0) root         (0)    20900 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/quaternion.h
+-rw-r--r--   0 root         (0) root         (0)     2369 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/real.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:52.762215 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/reduction/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:53.487313 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/reduction/device/
+-rw-r--r--   0 root         (0) root         (0)     6823 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/reduction/device/reduce_split_k.h
+-rw-r--r--   0 root         (0) root         (0)     8152 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/reduction/device/tensor_reduce.h
+-rw-r--r--   0 root         (0) root         (0)    11579 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/reduction/device/tensor_reduce_affine_contiguous.h
+-rw-r--r--   0 root         (0) root         (0)    11448 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/reduction/device/tensor_reduce_affine_strided.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:53.784871 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/reduction/kernel/
+-rw-r--r--   0 root         (0) root         (0)     8762 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/reduction/kernel/reduce_softmax_final.h
+-rw-r--r--   0 root         (0) root         (0)     7897 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/reduction/kernel/reduce_split_k.h
+-rw-r--r--   0 root         (0) root         (0)    20685 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/reduction/kernel/tensor_reduce_affine_contiguous.h
+-rw-r--r--   0 root         (0) root         (0)    21662 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/reduction/kernel/tensor_reduce_affine_strided.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:53.896151 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/reduction/thread/
+-rw-r--r--   0 root         (0) root         (0)     7208 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/reduction/thread/reduce.h
+-rw-r--r--   0 root         (0) root         (0)     6790 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/reduction/thread/reduction_operators.h
+-rw-r--r--   0 root         (0) root         (0)     2936 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/reduction/threadblock_swizzle.h
+-rw-r--r--   0 root         (0) root         (0)     5929 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/relatively_equal.h
+-rw-r--r--   0 root         (0) root         (0)     4186 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/semaphore.h
+-rw-r--r--   0 root         (0) root         (0)    17243 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/subbyte_reference.h
+-rw-r--r--   0 root         (0) root         (0)     8964 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/tensor_coord.h
+-rw-r--r--   0 root         (0) root         (0)    12207 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/tensor_ref.h
+-rw-r--r--   0 root         (0) root         (0)    11201 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/tensor_ref_planar_complex.h
+-rw-r--r--   0 root         (0) root         (0)     9509 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/tensor_view.h
+-rw-r--r--   0 root         (0) root         (0)    10250 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/tensor_view_planar_complex.h
+-rw-r--r--   0 root         (0) root         (0)    13017 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/tfloat32.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:53.983443 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/thread/
+-rw-r--r--   0 root         (0) root         (0)     5931 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/thread/matrix.h
+-rw-r--r--   0 root         (0) root         (0)     2581 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/trace.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:54.078885 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/
+-rw-r--r--   0 root         (0) root         (0)    33349 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/pitch_linear_thread_map.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:54.184149 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/thread/
+-rw-r--r--   0 root         (0) root         (0)     3835 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/thread/transpose.h
+-rw-r--r--   0 root         (0) root         (0)     4309 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/thread/unary_op.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:57.198200 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/
+-rw-r--r--   0 root         (0) root         (0)     6181 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/ell_iterator.h
+-rw-r--r--   0 root         (0) root         (0)    44443 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/ell_predicated_tile_access_iterator.h
+-rw-r--r--   0 root         (0) root         (0)    44309 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/ell_predicated_tile_iterator.h
+-rw-r--r--   0 root         (0) root         (0)    12890 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_scale_bias_vector_access_iterator.h
+-rw-r--r--   0 root         (0) root         (0)    11097 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_scale_bias_vector_iterator.h
+-rw-r--r--   0 root         (0) root         (0)    70684 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator.h
+-rw-r--r--   0 root         (0) root         (0)    28232 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator_2dthreadtile.h
+-rwxr-xr-x   0 root         (0) root         (0)    10243 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator_params.h
+-rw-r--r--   0 root         (0) root         (0)    31412 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator_triangular_matrix.h
+-rw-r--r--   0 root         (0) root         (0)    62672 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_tile_iterator.h
+-rw-r--r--   0 root         (0) root         (0)    27175 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_tile_iterator_2dthreadtile.h
+-rw-r--r--   0 root         (0) root         (0)    28064 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_tile_iterator_triangular_matrix.h
+-rw-r--r--   0 root         (0) root         (0)    13088 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_vector_access_iterator.h
+-rw-r--r--   0 root         (0) root         (0)     8232 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_scale_bias_vector_access_iterator.h
+-rw-r--r--   0 root         (0) root         (0)     2638 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator.h
+-rw-r--r--   0 root         (0) root         (0)    13283 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_pitch_linear.h
+-rw-r--r--   0 root         (0) root         (0)    18623 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_pitch_linear_direct_conv.h
+-rw-r--r--   0 root         (0) root         (0)    27922 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_tensor_op.h
+-rw-r--r--   0 root         (0) root         (0)    47789 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_tensor_op_sm80.h
+-rw-r--r--   0 root         (0) root         (0)     2616 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator.h
+-rw-r--r--   0 root         (0) root         (0)    16510 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_pitch_linear.h
+-rw-r--r--   0 root         (0) root         (0)    15486 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_pitch_linear_2dthreadtile.h
+-rw-r--r--   0 root         (0) root         (0)    36050 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_tensor_op.h
+-rw-r--r--   0 root         (0) root         (0)    43663 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_tensor_op_sm70.h
+-rw-r--r--   0 root         (0) root         (0)     5226 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/vector_iterator.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:57.260827 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/warp/
+-rw-r--r--   0 root         (0) root         (0)     8828 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/warp/vector_fragment_iterator.h
+-rw-r--r--   0 root         (0) root         (0)     8179 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/uint128.h
+-rw-r--r--   0 root         (0) root         (0)     4543 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/wmma_array.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:49.077891 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:57.352559 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:35:57.480332 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/common/
+-rw-r--r--   0 root         (0) root         (0)     4900 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/common/cutlass_unit_test.h
+-rw-r--r--   0 root         (0) root         (0)     5381 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/common/filter_architecture.cpp
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:49.095984 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:36:04.483102 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/
+-rw-r--r--   0 root         (0) root         (0)    21797 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/cache_testbed_output.h
+-rw-r--r--   0 root         (0) root         (0)     5344 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm50.cu
+-rw-r--r--   0 root         (0) root         (0)     5443 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    11470 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     5239 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)     9110 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)     8485 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     5243 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     5378 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    12054 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_few_channels_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     9603 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_fixed_channels_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     5267 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm50.cu
+-rw-r--r--   0 root         (0) root         (0)     5357 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     5089 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu
+-rw-r--r--   0 root         (0) root         (0)    13690 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     5390 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     5191 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)    11136 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)     5291 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     3551 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm50.cu
+-rw-r--r--   0 root         (0) root         (0)     5157 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.cu
+-rwxr-xr-x   0 root         (0) root         (0)     8278 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_qf32nhwc_qf32nhwc_qf32nhwc_simt_f32_sm50.cu
+-rw-r--r--   0 root         (0) root         (0)    20555 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4ncxhwx_s4cxrskx_s4ncxhwx_tensor_op_s32_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)    20647 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4ncxhwx_s4cxrskx_s4ncxhwx_tensor_op_s32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     5155 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4nhwc_s4nhwc_s32nhwc_tensor_op_s32_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)     5239 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4nhwc_s4nhwc_s32nhwc_tensor_op_s32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    26114 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8ncxhwx_s8cxrskx_s8ncxhwx_tensor_op_s32_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)    26210 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8ncxhwx_s8cxrskx_s8ncxhwx_tensor_op_s32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     5111 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8nhwc_s8nhwc_s32nhwc_tensor_op_s32_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)     5194 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8nhwc_s8nhwc_s32nhwc_tensor_op_s32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     5738 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     5439 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_with_broadcast_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)     7363 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_with_broadcast_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)     3984 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_with_reduction_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)    39452 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_problems.h
+-rw-r--r--   0 root         (0) root         (0)    14471 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_strided_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     4662 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_strided_dgrad_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    26224 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_testbed.h
+-rw-r--r--   0 root         (0) root         (0)    22092 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_testbed_interleaved.h
+-rw-r--r--   0 root         (0) root         (0)     5179 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm50.cu
+-rw-r--r--   0 root         (0) root         (0)     5358 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     5264 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     3615 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)     7591 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)    10514 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     5157 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     5772 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    23526 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_with_broadcast_testbed.h
+-rw-r--r--   0 root         (0) root         (0)    21512 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_with_reduction_testbed.h
+-rw-r--r--   0 root         (0) root         (0)     5135 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_dgrad_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     5347 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_dgrad_implicit_gemm_tf32ndhwc_tf32ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     3736 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_fprop_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)     6560 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_fprop_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     5257 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_fprop_implicit_gemm_tf32ndhwc_tf32ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    12276 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_problems.h
+-rw-r--r--   0 root         (0) root         (0)    21643 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_testbed.h
+-rw-r--r--   0 root         (0) root         (0)     3622 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)     6560 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     5256 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_tf32ndhwc_tf32ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    17700 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/depthwise_conv2d_direct_conv_testbed.h
+-rw-r--r--   0 root         (0) root         (0)    18451 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_direct_conv_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu
+-rw-r--r--   0 root         (0) root         (0)    22194 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_direct_conv_fixed_stride_dilation_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu
+-rw-r--r--   0 root         (0) root         (0)     9383 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu
+-rw-r--r--   0 root         (0) root         (0)    16100 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/group_conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:36:06.039071 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/core/
+-rw-r--r--   0 root         (0) root         (0)     7365 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/core/array.cu
+-rw-r--r--   0 root         (0) root         (0)     7353 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/core/bfloat16.cu
+-rw-r--r--   0 root         (0) root         (0)     6981 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/core/complex.cu
+-rw-r--r--   0 root         (0) root         (0)     4009 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/core/float8.cu
+-rw-r--r--   0 root         (0) root         (0)    13001 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/core/functional.cu
+-rw-r--r--   0 root         (0) root         (0)     3553 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/core/half.cu
+-rw-r--r--   0 root         (0) root         (0)     5295 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/core/matrix.cu
+-rw-r--r--   0 root         (0) root         (0)     8592 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/core/matrix_coord.cu
+-rw-r--r--   0 root         (0) root         (0)    10684 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/core/numeric_conversion.cu
+-rw-r--r--   0 root         (0) root         (0)     8148 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/core/predicate_vector.cu
+-rw-r--r--   0 root         (0) root         (0)     5777 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/core/quaternion.cu
+-rw-r--r--   0 root         (0) root         (0)     6746 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/core/tensor_ref.cu
+-rw-r--r--   0 root         (0) root         (0)     8885 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/core/tensor_view.cu
+-rw-r--r--   0 root         (0) root         (0)     2050 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/core/test_unit_core.cpp
+-rw-r--r--   0 root         (0) root         (0)     7088 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/core/tfloat32.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:49.136268 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/cute/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:36:06.271239 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/cute/ampere/
+-rw-r--r--   0 root         (0) root         (0)     3527 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/cute/ampere/cp_async.cu
+-rw-r--r--   0 root         (0) root         (0)    14320 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/cute/ampere/ldsm.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:36:07.583965 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/cute/core/
+-rw-r--r--   0 root         (0) root         (0)     3332 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/cute/core/bitfield.cpp
+-rw-r--r--   0 root         (0) root         (0)     4861 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/cute/core/coalesce.cpp
+-rw-r--r--   0 root         (0) root         (0)     5620 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/cute/core/compare.cpp
+-rw-r--r--   0 root         (0) root         (0)     7178 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/cute/core/complement.cpp
+-rw-r--r--   0 root         (0) root         (0)    12569 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/cute/core/composition.cpp
+-rw-r--r--   0 root         (0) root         (0)     4856 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/cute/core/inverse_left.cpp
+-rw-r--r--   0 root         (0) root         (0)     6702 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/cute/core/inverse_right.cpp
+-rw-r--r--   0 root         (0) root         (0)     6734 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/cute/core/logical_divide.cpp
+-rw-r--r--   0 root         (0) root         (0)     5914 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/cute/core/logical_product.cpp
+-rw-r--r--   0 root         (0) root         (0)     3488 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/cute/core/mixedbits.cpp
+-rw-r--r--   0 root         (0) root         (0)     2342 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/cute/core/transform.cpp
+-rw-r--r--   0 root         (0) root         (0)    13304 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/cute/core/tuple.cpp
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:36:08.434043 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/cute/hopper/
+-rw-r--r--   0 root         (0) root         (0)    14365 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/cute/hopper/stsm.cu
+-rw-r--r--   0 root         (0) root         (0)    18990 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/cute/hopper/tma_load.cu
+-rw-r--r--   0 root         (0) root         (0)    13875 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/cute/hopper/tma_store.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:36:08.556493 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/cute/layout/
+-rw-r--r--   0 root         (0) root         (0)     4544 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/cute/layout/layout_operator.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:49.157631 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:36:08.921747 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/thread/
+-rw-r--r--   0 root         (0) root         (0)    15818 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/thread/activation.cu
+-rw-r--r--   0 root         (0) root         (0)     6534 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/thread/linear_combination.cu
+-rw-r--r--   0 root         (0) root         (0)     9964 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/thread/linear_combination_planar_complex.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:36:11.507485 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/
+-rw-r--r--   0 root         (0) root         (0)    13824 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/epilogue_planar_complex.cu
+-rw-r--r--   0 root         (0) root         (0)    27176 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/epilogue_simt.cu
+-rw-r--r--   0 root         (0) root         (0)    12061 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/epilogue_simt_sm60.cu
+-rw-r--r--   0 root         (0) root         (0)    25275 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/epilogue_simt_sm61.cu
+-rw-r--r--   0 root         (0) root         (0)    84612 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/epilogue_tensor_op.cu
+-rw-r--r--   0 root         (0) root         (0)    70486 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/epilogue_volta_tensor_op.cu
+-rw-r--r--   0 root         (0) root         (0)    25293 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/epilogue_with_reduction_tensor_op.cu
+-rw-r--r--   0 root         (0) root         (0)    13012 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/epilogue_with_reduction_testbed.h
+-rw-r--r--   0 root         (0) root         (0)     7743 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/epilogue_wmma_tensor_op_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)    19178 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/output_tile_threadmap.cu
+-rw-r--r--   0 root         (0) root         (0)    28433 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/predicated_tile_iterator.cu
+-rw-r--r--   0 root         (0) root         (0)    11038 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/testbed.h
+-rw-r--r--   0 root         (0) root         (0)    11734 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/testbed_planar_complex.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:36:12.002198 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/warp/
+-rw-r--r--   0 root         (0) root         (0)     6783 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/warp/fragment_iterator_tensor_op.cu
+-rw-r--r--   0 root         (0) root         (0)     7275 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/warp/fragment_iterator_volta_tensor_op.cu
+-rw-r--r--   0 root         (0) root         (0)     6616 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/warp/fragment_iterator_wmma_tensor_op.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:49.190262 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:36:55.329309 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/
+-rw-r--r--   0 root         (0) root         (0)    10189 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32n_tensor_op_s32_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)    17899 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32n_tensor_op_s32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     8933 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32n_wmma_tensor_op_s32_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)    10164 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32t_tensor_op_s32_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)    17984 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32t_tensor_op_s32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     8915 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32t_wmma_tensor_op_s32_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)    16447 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_bf16n_bf16n_f32t_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    16575 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_bf16t_bf16t_bf16t_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     8318 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_cf32n_cf32t_cf32t_tensor_op_tf32_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     8317 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_cf32t_cf32n_cf32t_tensor_op_tf32_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     6714 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_gaussian_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     6747 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_gaussian_sm90.cu
+-rw-r--r--   0 root         (0) root         (0)     7895 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     7930 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_sm90.cu
+-rw-r--r--   0 root         (0) root         (0)     6516 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_gaussian_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     6549 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_gaussian_sm90.cu
+-rw-r--r--   0 root         (0) root         (0)     9016 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     9053 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_sm90.cu
+-rw-r--r--   0 root         (0) root         (0)     4628 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16n_direct_store_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     6165 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16n_wmma_tensor_op_f16_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)     6124 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16n_wmma_tensor_op_f32_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)     9634 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_tensor_op_f32_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)    16357 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    13189 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_tensor_op_f32_sparse_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     8845 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_volta_tensor_op_f32_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)    13583 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_wmma_tensor_op_f16_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)    13464 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_wmma_tensor_op_f32_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)     9571 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32n_tensor_op_f32_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)    16239 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32n_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     6140 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32n_wmma_tensor_op_f32_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)     9544 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_tensor_op_f32_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)    16417 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    13075 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_tensor_op_f32_sparse_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     8775 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_volta_tensor_op_f32_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)    11470 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_wmma_tensor_op_f32_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)     6156 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16n_wmma_tensor_op_f16_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)     6116 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16n_wmma_tensor_op_f32_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)     3528 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_slicedk_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)     3539 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_slicedk_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     7965 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)    16470 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    13273 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_sparse_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     3648 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     8608 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_volta_tensor_op_f16_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)    13518 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_wmma_tensor_op_f16_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)     3645 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_wmma_tensor_op_f32_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)     6096 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32n_wmma_tensor_op_f32_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)     7845 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_tensor_op_f32_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)    18135 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    13008 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_tensor_op_f32_sparse_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     8505 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_volta_tensor_op_f32_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)    11497 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_wmma_tensor_op_f32_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)    11090 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16n_singlestage_wmma_tensor_op_f16_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)     6156 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16n_wmma_tensor_op_f16_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)     6116 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16n_wmma_tensor_op_f32_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)    11066 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_singlestage_wmma_tensor_op_f16_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)    17114 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_broadcast_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     3528 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_slicedk_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)     3540 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_slicedk_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     7964 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)    16457 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    13266 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_sparse_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     8933 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_volta_tensor_op_f16_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)    13551 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_wmma_tensor_op_f16_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)    13540 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_wmma_tensor_op_f32_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)     6130 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32n_wmma_tensor_op_f32_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)     8160 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_singlestage_wmma_tensor_op_f32_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)     7847 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_tensor_op_f32_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)    16131 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    13014 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_tensor_op_f32_sparse_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     8754 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_volta_tensor_op_f32_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)    11497 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_wmma_tensor_op_f32_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)     6147 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16n_wmma_tensor_op_f16_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)     6107 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16n_wmma_tensor_op_f32_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)    13518 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16t_wmma_tensor_op_f16_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)    13398 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16t_wmma_tensor_op_f32_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)     7845 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32n_tensor_op_f32_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)    16149 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32n_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     6119 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32n_wmma_tensor_op_f32_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)     7827 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_tensor_op_f32_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)    16101 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     9526 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_tensor_op_f32_sparse_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     7898 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_volta_tensor_op_f32_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)    11470 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_wmma_tensor_op_f32_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)     3584 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f32n_f32n_f32t_tensor_op_bf16_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     3473 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f32n_f32n_f32t_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    12967 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f32n_f32n_f32t_tensor_op_f32_sparse_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    12931 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f32n_f32t_f32t_tensor_op_f32_sparse_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    12930 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f32t_f32n_f32t_tensor_op_f32_sparse_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    12895 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f32t_f32t_f32t_tensor_op_f32_sparse_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     8349 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f64n_f64t_f64t_tensor_op_f64_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     7300 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f64n_f64t_f64t_tensor_op_f64_sm90.cu
+-rw-r--r--   0 root         (0) root         (0)     8348 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f64t_f64n_f64t_tensor_op_f64_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     7291 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f64t_f64n_f64t_tensor_op_f64_sm90.cu
+-rw-r--r--   0 root         (0) root         (0)    10240 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_grouped_scheduler_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    26146 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_grouped_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    11339 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_planar_complex_f16_f16_f32_tensor_op_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)     7346 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_planar_complex_f16_f16_f32_tensor_op_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)    12397 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_planar_complex_f16_f16_f32_tensor_op_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     6859 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4n_s4t_s4n_tensor_op_s32_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)     7239 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4n_s4t_s4n_tensor_op_s32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     8121 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32n_tensor_op_s32_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)    16882 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32n_tensor_op_s32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     8407 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32n_wmma_tensor_op_s32_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)     8103 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_tensor_op_s32_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)    17111 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_tensor_op_s32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    12637 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_tensor_op_s32_sparse_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     8388 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_wmma_tensor_op_s32_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)    10044 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4n_tensor_op_s32_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)    17544 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4n_tensor_op_s32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    10020 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4t_tensor_op_s32_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)    17544 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4t_tensor_op_s32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     9588 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8n_s8t_s8n_tensor_op_s32_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)    11288 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8n_s8t_s8n_tensor_op_s32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     7977 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32n_tensor_op_s32_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)    16531 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32n_tensor_op_s32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     5693 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32n_wmma_tensor_op_s32_sm72.cu
+-rw-r--r--   0 root         (0) root         (0)     7959 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_tensor_op_s32_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)    16691 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_tensor_op_s32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    12408 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_tensor_op_s32_sparse_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     6864 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_wmma_tensor_op_s32_sm72.cu
+-rw-r--r--   0 root         (0) root         (0)     7744 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8n_tensor_op_s32_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)    16531 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8n_tensor_op_s32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     6675 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8n_wmma_tensor_op_s32_sm72.cu
+-rw-r--r--   0 root         (0) root         (0)     7752 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8t_tensor_op_s32_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)    16484 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8t_tensor_op_s32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     6663 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8t_wmma_tensor_op_s32_sm72.cu
+-rw-r--r--   0 root         (0) root         (0)     4663 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_splitk_serial_tensor_op_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)     4945 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_splitk_simt_sm50.cu
+-rw-r--r--   0 root         (0) root         (0)     6616 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_splitk_tensor_op_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)    10581 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_splitk_tensor_op_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)    16950 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_tf32n_tf32n_f32t_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    16902 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_tf32n_tf32t_f32t_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    15131 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_tf32t_tf32n_f32t_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    16855 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_tf32t_tf32t_f32t_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     6854 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_u8t_u8n_s32t_wmma_tensor_op_s32_sm72.cu
+-rw-r--r--   0 root         (0) root         (0)     6686 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_universal_cf32n_cf32n_cf32n_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     6755 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_universal_cf64n_cf64t_cf64t_tensor_op_f64_gaussian_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     6687 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_universal_cf64n_cf64t_cf64t_tensor_op_f64_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     4726 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_universal_f16n_f16t_f32n_tensor_op_f32_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)     4718 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_universal_f16n_f16t_f32t_tensor_op_f32_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)    16715 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_with_broadcast_f16n_f16n_f16n_tensorop_f32_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)    12841 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_with_reduction_f16n_f16n_f16n_tensorop_f32_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)     4544 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_with_reduction_f16t_f16n_f16n_tensorop_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    13157 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemv.cu
+-rw-r--r--   0 root         (0) root         (0)     6028 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_f32_ls_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     6031 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_f32_rs_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     6064 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_fast_f32_ls_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     6067 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_fast_f32_rs_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     4909 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/hemm_cf64_cf64_cf64_tensor_op_f64_sm90.cu
+-rw-r--r--   0 root         (0) root         (0)     6088 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/hemm_cf64h_cf64n_cf64n_tensor_op_ls_f64_gaussian_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     6037 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/hemm_cf64h_cf64n_cf64n_tensor_op_ls_f64_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     6040 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/hemm_cf64h_cf64n_cf64n_tensor_op_rs_f64_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     5382 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/her2k_cf32h_cf32n_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     5406 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/her2k_cf32h_cf32n_tensor_op_fast_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     5402 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/her2k_cf64_cf64_tensor_op_f64_sm90.cu
+-rw-r--r--   0 root         (0) root         (0)    13055 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/her2k_cf64h_cf64n_tensor_op_f64_grouped_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    13027 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/her2k_cf64n_cf64n_tensor_op_f64_grouped_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     5388 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/her2k_cf64n_cf64n_tensor_op_f64_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     6939 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/her2k_cf64n_cf64t_tensor_op_f64_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     7677 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/herk_cf32h_cf32n_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     7725 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/herk_cf32h_cf32n_tensor_op_fast_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     3854 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/herk_cf64_cf64_tensor_op_f64_sm90.cu
+-rw-r--r--   0 root         (0) root         (0)     6396 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/herk_cf64h_cf64n_tensor_op_f64_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    10157 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/multistage_testbed.h
+-rw-r--r--   0 root         (0) root         (0)    10306 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/multistage_testbed_interleaved.h
+-rw-r--r--   0 root         (0) root         (0)    11186 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/rank_2k_grouped_scheduler_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    46795 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_cgemm_nn_sm50.cu
+-rw-r--r--   0 root         (0) root         (0)    54085 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_cgemm_nt_sm50.cu
+-rw-r--r--   0 root         (0) root         (0)     8318 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_cgemm_nt_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    46687 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_cgemm_tn_sm50.cu
+-rw-r--r--   0 root         (0) root         (0)     8411 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_cgemm_tn_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    46578 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_cgemm_tt_sm50.cu
+-rw-r--r--   0 root         (0) root         (0)    40533 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_dgemm_nn_sm50.cu
+-rw-r--r--   0 root         (0) root         (0)    47656 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_dgemm_nt_sm50.cu
+-rw-r--r--   0 root         (0) root         (0)    40441 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_dgemm_tn_sm50.cu
+-rw-r--r--   0 root         (0) root         (0)    40354 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_dgemm_tt_sm50.cu
+-rw-r--r--   0 root         (0) root         (0)     3513 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_f8gemm_tn_sm50.cu
+-rw-r--r--   0 root         (0) root         (0)    89517 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_hgemm_nn_sm50.cu
+-rw-r--r--   0 root         (0) root         (0)    89304 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_hgemm_nt_sm50.cu
+-rw-r--r--   0 root         (0) root         (0)    89304 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_hgemm_tn_sm50.cu
+-rw-r--r--   0 root         (0) root         (0)    89091 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_hgemm_tt_sm50.cu
+-rw-r--r--   0 root         (0) root         (0)    69175 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_igemm_nn_sm50.cu
+-rw-r--r--   0 root         (0) root         (0)    71438 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_igemm_nt_sm50.cu
+-rw-r--r--   0 root         (0) root         (0)    67796 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_igemm_tn_sm50.cu
+-rw-r--r--   0 root         (0) root         (0)    70056 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_igemm_tt_sm50.cu
+-rw-r--r--   0 root         (0) root         (0)     7156 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_int8_igemm_sm61.cu
+-rw-r--r--   0 root         (0) root         (0)     6067 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_int8_igemm_sm61_perf.cu
+-rw-r--r--   0 root         (0) root         (0)     9063 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_int8_igemm_sm61_sliced_k.cu
+-rw-r--r--   0 root         (0) root         (0)    35894 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_qgemm_nn_sm50.cu
+-rw-r--r--   0 root         (0) root         (0)    35813 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_qgemm_nt_sm50.cu
+-rw-r--r--   0 root         (0) root         (0)    35813 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_qgemm_tn_sm50.cu
+-rw-r--r--   0 root         (0) root         (0)    35732 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_qgemm_tt_sm50.cu
+-rw-r--r--   0 root         (0) root         (0)    70872 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_sgemm_nn_sm50.cu
+-rw-r--r--   0 root         (0) root         (0)    73136 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_sgemm_nt_sm50.cu
+-rw-r--r--   0 root         (0) root         (0)     8870 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_sgemm_nt_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    69488 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_sgemm_tn_sm50.cu
+-rw-r--r--   0 root         (0) root         (0)     8865 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_sgemm_tn_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    71755 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_sgemm_tt_sm50.cu
+-rw-r--r--   0 root         (0) root         (0)    33231 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_zgemm_nn_sm50.cu
+-rw-r--r--   0 root         (0) root         (0)    33156 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_zgemm_nt_sm50.cu
+-rw-r--r--   0 root         (0) root         (0)    33156 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_zgemm_tn_sm50.cu
+-rw-r--r--   0 root         (0) root         (0)    33081 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_zgemm_tt_sm50.cu
+-rw-r--r--   0 root         (0) root         (0)     5238 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/sm50_gemm_f32_f32_f32_simt.cu
+-rw-r--r--   0 root         (0) root         (0)     5253 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/sm50_gemm_f64_f64_f64_simt.cu
+-rw-r--r--   0 root         (0) root         (0)     5357 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/sm61_gemm_s8_s8_s32_simt.cu
+-rw-r--r--   0 root         (0) root         (0)     5479 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/sm80_gemm_f16_f16_f32_tensor_op_f32.cu
+-rw-r--r--   0 root         (0) root         (0)     5238 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/sm80_gemm_f32_f32_f32_simt.cu
+-rw-r--r--   0 root         (0) root         (0)     5253 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/sm80_gemm_f64_f64_f64_simt.cu
+-rw-r--r--   0 root         (0) root         (0)     3875 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/sm80_gemm_f64_f64_f64_tensor_op_f64.cu
+-rw-r--r--   0 root         (0) root         (0)     3734 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/sm80_gemm_s8_s8_s32_tensor_op.cu
+-rw-r--r--   0 root         (0) root         (0)     5387 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/sm80_gemm_tf32_tf32_f32_tensor_op_f32.cu
+-rw-r--r--   0 root         (0) root         (0)     7436 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/sm90_gemm_bf16_bf16_bf16_alignx_tensor_op_f32.cu
+-rw-r--r--   0 root         (0) root         (0)     7409 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/sm90_gemm_bf16_bf16_bf16_tensor_op_f32.cu
+-rw-r--r--   0 root         (0) root         (0)    17391 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_alignx_tensor_op.cu
+-rw-r--r--   0 root         (0) root         (0)    42504 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op.cu
+-rw-r--r--   0 root         (0) root         (0)    22602 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_unspecialized.cu
+-rw-r--r--   0 root         (0) root         (0)    22874 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized.cu
+-rw-r--r--   0 root         (0) root         (0)    42526 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_persistent.cu
+-rw-r--r--   0 root         (0) root         (0)     3810 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/sm90_gemm_f32_f32_f32_tensor_op_f32.cu
+-rw-r--r--   0 root         (0) root         (0)     5976 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/sm90_gemm_s8_s8_s8_alignx_tensor_op_s32.cu
+-rw-r--r--   0 root         (0) root         (0)     9313 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/sm90_gemm_s8_s8_s8_tensor_op_s32.cu
+-rw-r--r--   0 root         (0) root         (0)     5986 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/sm90_gemm_tf32_tf32_f32_alignx_tensor_op_f32.cu
+-rw-r--r--   0 root         (0) root         (0)     7268 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/sm90_gemm_tf32_tf32_f32_tensor_op_f32.cu
+-rw-r--r--   0 root         (0) root         (0)     5923 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_f32_ls_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     5926 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_f32_rs_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     5959 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_fast_f32_ls_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     5962 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_fast_f32_rs_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     4839 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_cf64_cf64_cf64_tensor_op_f64_sm90.cu
+-rw-r--r--   0 root         (0) root         (0)     5983 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_cf64n_cf64n_cf64n_tensor_op_ls_f64_gaussian_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     5932 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_cf64n_cf64n_cf64n_tensor_op_ls_f64_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     5935 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_cf64n_cf64n_cf64n_tensor_op_rs_f64_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    15203 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f32n_f32n_tensor_op_fast_f32_ls_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     8623 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f32n_f32n_tensor_op_fast_f32_rs_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    15104 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f32t_f32t_tensor_op_fast_f32_ls_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     4777 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f64_f64_tensor_op_f64_sm90.cu
+-rw-r--r--   0 root         (0) root         (0)     8103 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f64n_f64n_tensor_op_f64_ls_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     8108 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f64n_f64n_tensor_op_f64_rs_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     8088 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f64n_f64t_tensor_op_f64_ls_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     8093 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f64n_f64t_tensor_op_f64_rs_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     8073 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f64t_f64n_tensor_op_f64_ls_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     8078 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f64t_f64n_tensor_op_f64_rs_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     8058 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f64t_f64t_tensor_op_f64_ls_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     8063 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f64t_f64t_tensor_op_f64_rs_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    15071 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_tf32n_f32n_tensor_op_f32_ls_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     8551 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_tf32n_f32n_tensor_op_f32_rs_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    14972 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_tf32t_f32t_tensor_op_f32_ls_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     5362 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32n_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     5386 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32n_tensor_op_fast_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     5356 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32t_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     5380 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32t_tensor_op_fast_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     5379 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf64_cf64_tensor_op_f64_sm90.cu
+-rw-r--r--   0 root         (0) root         (0)    12952 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64n_tensor_op_f64_grouped_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     5368 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64n_tensor_op_f64_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     7208 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64t_tensor_op_f64_grouped_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     5362 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64t_tensor_op_f64_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     7199 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf64t_cf64n_tensor_op_f64_grouped_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     7190 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf64t_cf64t_tensor_op_f64_grouped_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     4794 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_f32n_f32n_tensor_op_fast_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     4783 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_f32t_f32n_tensor_op_fast_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     4740 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_f64_f64_tensor_op_f64_sm90.cu
+-rw-r--r--   0 root         (0) root         (0)    19145 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_f64n_f64n_tensor_op_f64_grouped_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     7991 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_f64n_f64n_tensor_op_f64_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    11015 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_f64n_f64t_tensor_op_f64_grouped_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     7976 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_f64n_f64t_tensor_op_f64_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    12342 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_f64t_f64n_tensor_op_f64_grouped_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     7961 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_f64t_f64n_tensor_op_f64_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    12321 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_f64t_f64t_tensor_op_f64_grouped_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     4786 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_tf32n_f32n_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     4775 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_tf32t_f32n_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     4993 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_cf32n_cf32n_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     5017 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_cf32n_cf32n_tensor_op_fast_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     4987 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_cf32n_cf32t_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     5011 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_cf32n_cf32t_tensor_op_fast_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     5024 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_cf64_cf64_tensor_op_f64_sm90.cu
+-rw-r--r--   0 root         (0) root         (0)     4996 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_cf64n_cf64n_tensor_op_f64_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     3793 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_cf64n_cf64t_tensor_op_f64_gaussian_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     4990 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_cf64n_cf64t_tensor_op_f64_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    16083 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_f32n_f32t_tensor_op_fast_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    16041 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_f32t_f32t_tensor_op_fast_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     4530 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_f64_f64_tensor_op_f64_sm90.cu
+-rw-r--r--   0 root         (0) root         (0)     7451 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_f64n_f64t_tensor_op_f64_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     9401 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_f64t_f64n_tensor_op_f64_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    16027 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_tf32n_f32t_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    15985 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_tf32t_f32t_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    20465 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed.h
+-rw-r--r--   0 root         (0) root         (0)     8264 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_complex.h
+-rw-r--r--   0 root         (0) root         (0)    20736 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_gemm_with_broadcast.h
+-rw-r--r--   0 root         (0) root         (0)    19479 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_gemm_with_reduction.h
+-rw-r--r--   0 root         (0) root         (0)    16502 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_grouped.h
+-rw-r--r--   0 root         (0) root         (0)    16562 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_grouped_rank_2k.h
+-rw-r--r--   0 root         (0) root         (0)    17002 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_grouped_rank_2k_scheduler.h
+-rw-r--r--   0 root         (0) root         (0)    14698 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_grouped_scheduler.h
+-rw-r--r--   0 root         (0) root         (0)    10262 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_interleaved.h
+-rw-r--r--   0 root         (0) root         (0)     9481 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_planar_complex.h
+-rw-r--r--   0 root         (0) root         (0)    20898 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_rank2k_universal.h
+-rw-r--r--   0 root         (0) root         (0)    15652 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_rank_k_universal.h
+-rw-r--r--   0 root         (0) root         (0)     8639 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_sanity.h
+-rw-r--r--   0 root         (0) root         (0)    15901 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_sparse.h
+-rw-r--r--   0 root         (0) root         (0)     6124 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_splitk.h
+-rw-r--r--   0 root         (0) root         (0)    19993 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_symm_universal.h
+-rw-r--r--   0 root         (0) root         (0)    20332 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_trmm_universal.h
+-rw-r--r--   0 root         (0) root         (0)    17443 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_universal.h
+-rw-r--r--   0 root         (0) root         (0)     2626 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_utils.h
+-rw-r--r--   0 root         (0) root         (0)     9916 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_cf32n_cf32n_cf32t_tensor_op_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     9988 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_cf32n_cf32n_cf32t_tensor_op_fast_f32_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     4989 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_cf64_cf64_cf64_tensor_op_f64_sm90.cu
+-rw-r--r--   0 root         (0) root         (0)     4992 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_cf64n_cf64n_cf64t_tensor_op_f64_gaussian_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     9762 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_cf64n_cf64n_cf64t_tensor_op_f64_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    15614 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_f32n_f32t_f32t_tensor_op_fast_f32_ls_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     8733 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_f32n_f32t_f32t_tensor_op_fast_f32_rs_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    14089 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_f32t_f32n_f32n_tensor_op_fast_f32_ls_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    14444 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_f32t_f32n_f32t_tensor_op_fast_f32_ls_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     4608 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_f64_f64_f64_tensor_op_f64_sm90.cu
+-rw-r--r--   0 root         (0) root         (0)    12798 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_f64n_f64n_f64t_tensor_op_f64_ls_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    12809 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_f64n_f64n_f64t_tensor_op_f64_rs_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    12764 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_f64n_f64t_f64t_tensor_op_f64_rs_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    12768 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_f64t_f64t_f64n_tensor_op_f64_ls_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    12779 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_f64t_f64t_f64n_tensor_op_f64_rs_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    15504 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_tf32n_tf32t_f32t_tensor_op_f32_ls_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     8673 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_tf32n_tf32t_f32t_tensor_op_f32_rs_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    13989 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_tf32t_tf32n_f32n_tensor_op_f32_ls_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    14344 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_tf32t_tf32n_f32t_tensor_op_f32_ls_sm80.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:36:55.535876 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/kernel/
+-rwxr-xr-x   0 root         (0) root         (0)    46470 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/kernel/batched_gemv.cu
+-rwxr-xr-x   0 root         (0) root         (0)    14362 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/kernel/testbed_gemv.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:36:55.845194 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/thread/
+-rw-r--r--   0 root         (0) root         (0)     4847 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/thread/gemm_sm50.cu
+-rw-r--r--   0 root         (0) root         (0)    12503 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/thread/gemm_sm60.cu
+-rw-r--r--   0 root         (0) root         (0)     3109 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/thread/gemm_sm61.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:36:56.090867 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/thread/host/
+-rw-r--r--   0 root         (0) root         (0)     5198 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/thread/host/gemm_sm60_host.cu
+-rw-r--r--   0 root         (0) root         (0)     7161 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/thread/host/testbed_host.h
+-rw-r--r--   0 root         (0) root         (0)     7124 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/thread/testbed.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:36:58.609679 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/
+-rw-r--r--   0 root         (0) root         (0)    25036 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/batched_gemv.cu
+-rw-r--r--   0 root         (0) root         (0)     4345 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/epilogue_workspace.cu
+-rw-r--r--   0 root         (0) root         (0)   135045 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_multistage.cu
+-rw-r--r--   0 root         (0) root         (0)     4644 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_multistage_slicedk.cu
+-rw-r--r--   0 root         (0) root         (0)    94442 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_multistage_sparse.cu
+-rw-r--r--   0 root         (0) root         (0)    17090 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_multistage_sparse_testbed.h
+-rw-r--r--   0 root         (0) root         (0)    13897 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_multistage_testbed.h
+-rw-r--r--   0 root         (0) root         (0)    14539 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_multistage_testbed_slicedk.h
+-rw-r--r--   0 root         (0) root         (0)    49052 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_pipelined_simt.cu
+-rw-r--r--   0 root         (0) root         (0)     8407 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_pipelined_slicedk.cu
+-rw-r--r--   0 root         (0) root         (0)    18705 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_pipelined_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)    78122 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_pipelined_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)    21051 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_pipelined_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    13771 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_pipelined_testbed.h
+-rw-r--r--   0 root         (0) root         (0)    14239 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_pipelined_testbed_slicedk.h
+-rw-r--r--   0 root         (0) root         (0)    29772 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_pipelined_wmma_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)    12395 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_pipelined_wmma_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)     3502 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_planar_complex_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    12138 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_planar_complex_testbed.h
+-rw-r--r--   0 root         (0) root         (0)    16308 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_singlestage_wmma_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)    12502 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_singlestage_wmma_sm75.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:00.734122 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/warp/
+-rw-r--r--   0 root         (0) root         (0)    22128 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_complex_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    10916 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_complex_sm90.cu
+-rw-r--r--   0 root         (0) root         (0)     9873 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_gaussian_complex_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    18220 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_sm50.cu
+-rw-r--r--   0 root         (0) root         (0)     4920 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_sm60.cu
+-rw-r--r--   0 root         (0) root         (0)     6291 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_sm61.cu
+-rw-r--r--   0 root         (0) root         (0)     9297 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)    37942 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_sm75.cu
+-rw-r--r--   0 root         (0) root         (0)    81659 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     9089 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_sm90.cu
+-rw-r--r--   0 root         (0) root         (0)    48928 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_sparse_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    49647 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/warp/testbed.h
+-rw-r--r--   0 root         (0) root         (0)    25780 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/warp/wmma_sm70.cu
+-rw-r--r--   0 root         (0) root         (0)     7544 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/warp/wmma_sm72.cu
+-rw-r--r--   0 root         (0) root         (0)     6487 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/warp/wmma_sm75.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:01.000637 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/layout/
+-rw-r--r--   0 root         (0) root         (0)     5788 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/layout/matrix.cu
+-rw-r--r--   0 root         (0) root         (0)     5984 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/layout/tensor.cu
+-rw-r--r--   0 root         (0) root         (0)     7081 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/layout/tensor_nhwc.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:49.235108 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/nvrtc/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:49.217939 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/nvrtc/cutlass/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:01.138979 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/nvrtc/cutlass/nvrtc/
+-rw-r--r--   0 root         (0) root         (0)     2096 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/nvrtc/cutlass/nvrtc/environment.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:49.229933 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/nvrtc/kernel/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:01.261558 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/nvrtc/kernel/thread/
+-rw-r--r--   0 root         (0) root         (0)     2915 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/nvrtc/kernel/thread/testbed_kernel.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:01.357216 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/nvrtc/stdlib/
+-rw-rw-r--   0 root         (0) root         (0)        0 2022-06-02 16:47:41.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/nvrtc/stdlib/assert.h
+-rw-r--r--   0 root         (0) root         (0)     4250 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/nvrtc/stdlib/stdint.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:01.520695 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/nvrtc/thread/
+-rw-r--r--   0 root         (0) root         (0)     5727 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/nvrtc/thread/gemm_nvrtc.cu
+-rw-r--r--   0 root         (0) root         (0)    10328 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/nvrtc/thread/testbed.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:02.247400 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/pipeline/
+-rw-r--r--   0 root         (0) root         (0)    15532 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/pipeline/pipeline_async.cu
+-rw-r--r--   0 root         (0) root         (0)    15490 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/pipeline/pipeline_tma_async.cu
+-rw-r--r--   0 root         (0) root         (0)    17098 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/pipeline/pipeline_tma_async_warp_specialized.cu
+-rw-r--r--   0 root         (0) root         (0)    20252 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/pipeline/pipeline_tma_async_warp_specialized_persistent.cu
+-rw-r--r--   0 root         (0) root         (0)     7623 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/pipeline/sequence_barrier.cu
+-rw-r--r--   0 root         (0) root         (0)     4327 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/pipeline/testbed.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:49.266743 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/reduction/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:02.574189 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/reduction/device/
+-rw-r--r--   0 root         (0) root         (0)    14684 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/reduction/device/tensor_reduce_contiguous.cu
+-rw-r--r--   0 root         (0) root         (0)    15609 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/reduction/device/tensor_reduce_strided.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:02.848722 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/reduction/kernel/
+-rw-r--r--   0 root         (0) root         (0)    11350 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/reduction/kernel/reduce_splitk.cu
+-rw-r--r--   0 root         (0) root         (0)     2228 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/reduction/kernel/reduce_splitk_testbed.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:03.014316 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/reduction/thread/
+-rw-r--r--   0 root         (0) root         (0)     3110 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/reduction/thread/reduction_thread.cu
+-rw-r--r--   0 root         (0) root         (0)     6657 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/reduction/thread/testbed.h
+-rw-r--r--   0 root         (0) root         (0)     2047 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/test_unit.cpp
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:49.278128 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/transform/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:03.173376 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/transform/threadblock/
+-rw-r--r--   0 root         (0) root         (0)    25527 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/transform/threadblock/predicated_tile_iterator.cu
+-rw-r--r--   0 root         (0) root         (0)     9501 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/transform/threadblock/regular_tile_iterator_tensor_op.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:03.339246 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/util/
+-rw-r--r--   0 root         (0) root         (0)     2663 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/util/cutlass_test_levels.cu
+-rw-r--r--   0 root         (0) root         (0)     7474 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/util/tensor_reduce.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:49.425670 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:49.395235 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:49.309388 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/include/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:49.315027 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/include/cutlass/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:04.073359 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/include/cutlass/library/
+-rw-r--r--   0 root         (0) root         (0)     4118 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/include/cutlass/library/arch_mappings.h
+-rw-r--r--   0 root         (0) root         (0)    16013 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/include/cutlass/library/handle.h
+-rw-r--r--   0 root         (0) root         (0)    38763 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/include/cutlass/library/library.h
+-rw-r--r--   0 root         (0) root         (0)     4070 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/include/cutlass/library/manifest.h
+-rw-r--r--   0 root         (0) root         (0)    17934 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/include/cutlass/library/operation_table.h
+-rw-r--r--   0 root         (0) root         (0)     2724 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/include/cutlass/library/singleton.h
+-rw-r--r--   0 root         (0) root         (0)     7904 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/include/cutlass/library/util.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:49.328210 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:49.333794 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:49.339898 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:04.860227 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/
+-rw-r--r--   0 root         (0) root         (0)     2788 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/compiler.h
+-rw-r--r--   0 root         (0) root         (0)     2460 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/cute.cpp
+-rw-r--r--   0 root         (0) root         (0)     6224 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/cutlass.cpp
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:05.469823 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/
+-rw-r--r--   0 root         (0) root         (0)     2854 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/arch.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:05.960494 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/conv/
+-rw-r--r--   0 root         (0) root         (0)     5897 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/conv/conv_problem_size.h
+-rw-r--r--   0 root         (0) root         (0)     4763 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/conv/convolution.h
+-rw-r--r--   0 root         (0) root         (0)     2650 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/conv/host.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:06.137139 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/
+-rw-r--r--   0 root         (0) root         (0)     6845 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_generic.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:07.143217 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/
+-rw-r--r--   0 root         (0) root         (0)     3003 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/binary_ops.h
+-rw-r--r--   0 root         (0) root         (0)     6103 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/unary_ops.h
+-rw-r--r--   0 root         (0) root         (0)     4698 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_accumulator.h
+-rw-r--r--   0 root         (0) root         (0)     8397 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_binary.h
+-rw-r--r--   0 root         (0) root         (0)     8830 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_column_broadcast.h
+-rw-r--r--   0 root         (0) root         (0)    12998 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_column_reduction.h
+-rw-r--r--   0 root         (0) root         (0)     9454 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_linear_combination.h
+-rw-r--r--   0 root         (0) root         (0)     9085 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_row_broadcast.h
+-rw-r--r--   0 root         (0) root         (0)    11975 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_row_reduction.h
+-rw-r--r--   0 root         (0) root         (0)     6177 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_tensor_input.h
+-rw-r--r--   0 root         (0) root         (0)     8017 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_tensor_output.h
+-rw-r--r--   0 root         (0) root         (0)     7201 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_unary.h
+-rw-r--r--   0 root         (0) root         (0)    16970 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_with_layernorm.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:07.426024 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/gemm/
+-rw-r--r--   0 root         (0) root         (0)     3674 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/gemm/gemm.h
+-rw-r--r--   0 root         (0) root         (0)    21504 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/gemm/gemm_universal_with_visitor.h
+-rw-r--r--   0 root         (0) root         (0)     2328 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/gemm/host.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:08.124976 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/layout/
+-rw-r--r--   0 root         (0) root         (0)     2115 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/layout/layout.h
+-rw-r--r--   0 root         (0) root         (0)     4337 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/layout/matrix.h
+-rw-r--r--   0 root         (0) root         (0)     3694 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/layout/tensor.h
+-rw-r--r--   0 root         (0) root         (0)     8565 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/swizzling.h
+-rw-r--r--   0 root         (0) root         (0)     3902 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/tensor_coord.h
+-rw-r--r--   0 root         (0) root         (0)     5543 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/tensor_ref_view.h
+-rw-r--r--   0 root         (0) root         (0)     4855 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/types.h
+-rw-r--r--   0 root         (0) root         (0)      811 2022-09-05 01:02:49.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/library.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:49.385392 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/test/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:08.392708 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/test/conv/
+-rw-r--r--   0 root         (0) root         (0)     2651 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/test/conv/conv_problems.h
+-rw-r--r--   0 root         (0) root         (0)     2253 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/test/conv/convolution.h
+-rw-r--r--   0 root         (0) root         (0)     8826 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/test/conv/host.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:08.672932 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/test/gemm/
+-rw-r--r--   0 root         (0) root         (0)     2139 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/test/gemm/gemm.h
+-rw-r--r--   0 root         (0) root         (0)    18930 2023-01-27 22:40:09.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/test/gemm/host.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:10.046996 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/
+-rw-r--r--   0 root         (0) root         (0)    22377 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/conv2d_operation.h
+-rw-r--r--   0 root         (0) root         (0)    13850 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/conv3d_operation.h
+-rw-r--r--   0 root         (0) root         (0)    42129 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/gemm_operation.h
+-rw-r--r--   0 root         (0) root         (0)    35777 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/handle.cu
+-rw-r--r--   0 root         (0) root         (0)    12616 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/library_internal.h
+-rw-r--r--   0 root         (0) root         (0)     3782 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/manifest.cpp
+-rw-r--r--   0 root         (0) root         (0)     5468 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/operation_table.cu
+-rw-r--r--   0 root         (0) root         (0)    12873 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/rank_2k_operation.h
+-rw-r--r--   0 root         (0) root         (0)    11367 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/rank_k_operation.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:10.567988 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/reduction/
+-rw-r--r--   0 root         (0) root         (0)     3190 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/reduction/init_reduction_operations.cu
+-rw-r--r--   0 root         (0) root         (0)     6367 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/reduction/reduction_device.cu
+-rw-r--r--   0 root         (0) root         (0)    10269 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/reduction/reduction_operation.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:11.120455 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/reference/
+-rw-r--r--   0 root         (0) root         (0)     6746 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/reference/conv2d.cu
+-rw-r--r--   0 root         (0) root         (0)     6286 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/reference/conv3d.cu
+-rw-r--r--   0 root         (0) root         (0)    17192 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/reference/conv_reference_operation.h
+-rw-r--r--   0 root         (0) root         (0)     7199 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/reference/gemm.cu
+-rw-r--r--   0 root         (0) root         (0)    14732 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/reference/gemm_reference_operation.h
+-rw-r--r--   0 root         (0) root         (0)     2857 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/reference/initialize_reference_operations.cu
+-rw-r--r--   0 root         (0) root         (0)     2669 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/singleton.cu
+-rw-r--r--   0 root         (0) root         (0)    13134 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/symm_operation.h
+-rw-r--r--   0 root         (0) root         (0)    11698 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/trmm_operation.h
+-rw-r--r--   0 root         (0) root         (0)    43707 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/util.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:49.418064 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:14.253365 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/
+-rw-r--r--   0 root         (0) root         (0)    54134 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/conv2d_operation_profiler.cu
+-rw-r--r--   0 root         (0) root         (0)    18166 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/conv2d_operation_profiler.h
+-rw-r--r--   0 root         (0) root         (0)    48660 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/conv3d_operation_profiler.cu
+-rw-r--r--   0 root         (0) root         (0)    16040 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/conv3d_operation_profiler.h
+-rw-r--r--   0 root         (0) root         (0)    36461 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/cublas_helpers.cu
+-rw-r--r--   0 root         (0) root         (0)    10623 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/cublas_helpers.h
+-rw-r--r--   0 root         (0) root         (0)    17050 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/cudnn_helpers.cpp
+-rw-r--r--   0 root         (0) root         (0)    20436 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/cudnn_helpers.h
+-rw-r--r--   0 root         (0) root         (0)     7233 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/cutlass_profiler.cu
+-rw-r--r--   0 root         (0) root         (0)     3233 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/cutlass_profiler.h
+-rw-r--r--   0 root         (0) root         (0)     2454 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/debug.h
+-rw-r--r--   0 root         (0) root         (0)    53641 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/device_allocation.cu
+-rw-r--r--   0 root         (0) root         (0)     7215 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/device_allocation.h
+-rw-r--r--   0 root         (0) root         (0)     6841 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/device_context.cu
+-rw-r--r--   0 root         (0) root         (0)     4300 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/device_context.h
+-rw-r--r--   0 root         (0) root         (0)     8296 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/enumerated_types.cpp
+-rw-r--r--   0 root         (0) root         (0)     6421 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/enumerated_types.h
+-rw-r--r--   0 root         (0) root         (0)    42366 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/gemm_operation_profiler.cu
+-rw-r--r--   0 root         (0) root         (0)     8544 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/gemm_operation_profiler.h
+-rw-r--r--   0 root         (0) root         (0)     3875 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/gpu_timer.cpp
+-rw-r--r--   0 root         (0) root         (0)     2725 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/gpu_timer.h
+-rw-r--r--   0 root         (0) root         (0)     2340 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/main.cpp
+-rw-r--r--   0 root         (0) root         (0)    22087 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/operation_profiler.cu
+-rw-r--r--   0 root         (0) root         (0)     7876 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/operation_profiler.h
+-rw-r--r--   0 root         (0) root         (0)    27171 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/options.cu
+-rw-r--r--   0 root         (0) root         (0)     8773 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/options.h
+-rw-r--r--   0 root         (0) root         (0)    14192 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/performance_report.cpp
+-rw-r--r--   0 root         (0) root         (0)     4337 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/performance_report.h
+-rw-r--r--   0 root         (0) root         (0)     2494 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/performance_result.cu
+-rw-r--r--   0 root         (0) root         (0)     3941 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/performance_result.h
+-rw-r--r--   0 root         (0) root         (0)    37487 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/problem_space.cpp
+-rw-r--r--   0 root         (0) root         (0)    27749 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/problem_space.h
+-rw-r--r--   0 root         (0) root         (0)    25014 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/rank_2k_operation_profiler.cu
+-rw-r--r--   0 root         (0) root         (0)     6891 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/rank_2k_operation_profiler.h
+-rw-r--r--   0 root         (0) root         (0)    24253 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/rank_k_operation_profiler.cu
+-rw-r--r--   0 root         (0) root         (0)     6830 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/rank_k_operation_profiler.h
+-rw-r--r--   0 root         (0) root         (0)     5452 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/reduction_operation_profiler.h
+-rw-r--r--   0 root         (0) root         (0)    20688 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/sparse_gemm_operation_profiler.cu
+-rw-r--r--   0 root         (0) root         (0)     6471 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/sparse_gemm_operation_profiler.h
+-rw-r--r--   0 root         (0) root         (0)    26610 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/symm_operation_profiler.cu
+-rw-r--r--   0 root         (0) root         (0)     6933 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/symm_operation_profiler.h
+-rw-r--r--   0 root         (0) root         (0)    24431 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/trmm_operation_profiler.cu
+-rw-r--r--   0 root         (0) root         (0)     6599 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/trmm_operation_profiler.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:49.431154 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:49.436799 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:49.442311 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:16.328277 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/
+-rw-r--r--   0 root         (0) root         (0)     9774 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/command_line.h
+-rw-r--r--   0 root         (0) root         (0)     5104 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/debug.h
+-rw-r--r--   0 root         (0) root         (0)     5953 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/device_dump.h
+-rw-r--r--   0 root         (0) root         (0)    17696 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/device_groupnorm.h
+-rw-r--r--   0 root         (0) root         (0)    20881 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/device_layernorm.h
+-rw-r--r--   0 root         (0) root         (0)    10561 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/device_memory.h
+-rw-r--r--   0 root         (0) root         (0)     5219 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/device_nchw_to_nhwc.h
+-rw-r--r--   0 root         (0) root         (0)    11075 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/device_nhwc_padding.h
+-rw-r--r--   0 root         (0) root         (0)    18653 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/device_nhwc_pooling.h
+-rw-r--r--   0 root         (0) root         (0)     5214 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/device_nhwc_to_nchw.h
+-rw-r--r--   0 root         (0) root         (0)     4007 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/device_utils.h
+-rw-r--r--   0 root         (0) root         (0)     4597 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/distribution.h
+-rw-r--r--   0 root         (0) root         (0)     2674 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/exceptions.h
+-rw-r--r--   0 root         (0) root         (0)     4821 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/host_reorder.h
+-rw-r--r--   0 root         (0) root         (0)    16745 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/host_tensor.h
+-rw-r--r--   0 root         (0) root         (0)    20354 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/host_tensor_planar_complex.h
+-rw-r--r--   0 root         (0) root         (0)     5890 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/host_uncompress.h
+-rw-r--r--   0 root         (0) root         (0)     1962 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/index_sequence.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:34:49.477545 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:16.507562 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/detail/
+-rw-r--r--   0 root         (0) root         (0)     4606 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/detail/inner_product.h
+-rw-r--r--   0 root         (0) root         (0)     3527 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/detail/linear_to_coordinate.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:17.610676 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/
+-rw-r--r--   0 root         (0) root         (0)    48350 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/convolution.h
+-rw-r--r--   0 root         (0) root         (0)    14296 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/gemm.h
+-rw-r--r--   0 root         (0) root         (0)    10524 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/gemm_complex.h
+-rw-r--r--   0 root         (0) root         (0)     9652 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/gemm_planar_complex.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:18.087770 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/kernel/
+-rw-r--r--   0 root         (0) root         (0)     5381 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/kernel/gemm.h
+-rw-r--r--   0 root         (0) root         (0)     6198 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/kernel/tensor_elementwise.h
+-rw-r--r--   0 root         (0) root         (0)     5127 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/kernel/tensor_foreach.h
+-rw-r--r--   0 root         (0) root         (0)    11615 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/rank_2k_complex.h
+-rw-r--r--   0 root         (0) root         (0)     7278 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/tensor_compare.h
+-rw-r--r--   0 root         (0) root         (0)    46445 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/tensor_fill.h
+-rw-r--r--   0 root         (0) root         (0)     5294 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/tensor_foreach.h
+-rw-r--r--   0 root         (0) root         (0)    15964 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/tensor_reduce.h
+-rw-r--r--   0 root         (0) root         (0)     4589 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/tensor_relu.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:18.111170 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/thread/
+-rw-r--r--   0 root         (0) root         (0)     5872 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/thread/gemm.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:20.036593 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/
+-rw-r--r--   0 root         (0) root         (0)    28439 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/convolution.h
+-rw-r--r--   0 root         (0) root         (0)     2766 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/error_metrics.h
+-rw-r--r--   0 root         (0) root         (0)    17163 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/gemm.h
+-rw-r--r--   0 root         (0) root         (0)     7097 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/gemm_complex.h
+-rw-r--r--   0 root         (0) root         (0)     7708 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/gemm_planar_complex.h
+-rw-r--r--   0 root         (0) root         (0)     9441 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/rank_2k.h
+-rw-r--r--   0 root         (0) root         (0)    11444 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/rank_2k_complex.h
+-rw-r--r--   0 root         (0) root         (0)     8148 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/rank_k_complex.h
+-rw-r--r--   0 root         (0) root         (0)    10509 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/symm.h
+-rw-r--r--   0 root         (0) root         (0)    12296 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/symm_complex.h
+-rw-r--r--   0 root         (0) root         (0)     8440 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/tensor_compare.h
+-rw-r--r--   0 root         (0) root         (0)     8317 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/tensor_copy.h
+-rw-r--r--   0 root         (0) root         (0)     9027 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/tensor_elementwise.h
+-rw-r--r--   0 root         (0) root         (0)    43962 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/tensor_fill.h
+-rw-r--r--   0 root         (0) root         (0)     4757 2023-03-13 04:24:26.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/tensor_foreach.h
+-rw-r--r--   0 root         (0) root         (0)     2133 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/tensor_norm.h
+-rw-r--r--   0 root         (0) root         (0)     6111 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/tensor_reduce.h
+-rw-r--r--   0 root         (0) root         (0)     7670 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/trmm.h
+-rw-r--r--   0 root         (0) root         (0)     9874 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/trmm_complex.h
+-rw-r--r--   0 root         (0) root         (0)     8285 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/tensor_view_io.h
+-rw-r--r--   0 root         (0) root         (0)     8809 2023-01-27 22:40:10.000000 flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/type_traits.h
+-rw-r--r--   0 root         (0) root         (0)    30683 2023-04-11 20:32:31.000000 flash_attn-1.0.0/csrc/flash_attn/flash_api.cpp
+-rw-r--r--   0 root         (0) root         (0)    32519 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/flash_attn/fmha_api.cpp
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:22.568727 flash_attn-1.0.0/csrc/flash_attn/src/
+-rw-r--r--   0 root         (0) root         (0)     1664 2023-04-08 17:10:55.000000 flash_attn-1.0.0/csrc/flash_attn/src/block_info.h
+-rw-r--r--   0 root         (0) root         (0)     3920 2023-04-09 19:53:14.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash.h
+-rw-r--r--   0 root         (0) root         (0)      983 2023-04-07 15:25:56.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_bwd_hdim128.cu
+-rw-r--r--   0 root         (0) root         (0)      574 2023-04-12 03:22:08.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_bwd_hdim128_bf16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     1124 2023-04-12 03:09:57.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_bwd_hdim128_fp16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)      983 2023-04-07 15:25:56.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_bwd_hdim128_sm80_fp16.cu
+-rw-r--r--   0 root         (0) root         (0)      425 2023-04-07 15:25:56.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_bwd_hdim32.cu
+-rw-r--r--   0 root         (0) root         (0)      450 2023-04-08 07:29:00.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_bwd_hdim32_bf16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)      442 2023-04-08 07:26:34.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_bwd_hdim32_fp16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)      425 2023-04-07 15:25:56.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_bwd_hdim32_sm80_fp16.cu
+-rw-r--r--   0 root         (0) root         (0)     2074 2023-04-07 15:25:56.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_bwd_hdim64.cu
+-rw-r--r--   0 root         (0) root         (0)      450 2023-04-08 07:29:20.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_bwd_hdim64_bf16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     2458 2023-04-11 20:53:27.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_bwd_hdim64_fp16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     2074 2023-04-07 15:25:56.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_bwd_hdim64_sm80_fp16.cu
+-rw-r--r--   0 root         (0) root         (0)      581 2023-04-07 15:25:56.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_bwd_hdim96.cu
+-rw-r--r--   0 root         (0) root         (0)      449 2023-04-08 07:29:33.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_bwd_hdim96_bf16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)      598 2023-04-08 07:26:34.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_bwd_hdim96_fp16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)      581 2023-04-07 15:25:56.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_bwd_hdim96_sm80_fp16.cu
+-rw-r--r--   0 root         (0) root         (0)    82323 2023-04-12 05:47:44.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_bwd_kernel.h
+-rw-r--r--   0 root         (0) root         (0)    41051 2023-03-25 22:30:12.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_bwd_kernel_bak.h
+-rw-r--r--   0 root         (0) root         (0)    39628 2023-03-25 21:25:30.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_bwd_kernel_new.h
+-rw-r--r--   0 root         (0) root         (0)    39403 2023-04-08 17:10:55.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_bwd_kernel_reverse.h
+-rw-r--r--   0 root         (0) root         (0)     8751 2023-04-12 03:19:57.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_bwd_launch_template.h
+-rw-r--r--   0 root         (0) root         (0)      645 2023-04-07 21:42:50.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_fwd_hdim128.cu
+-rw-r--r--   0 root         (0) root         (0)      592 2023-04-08 07:07:58.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_fwd_hdim128_bf16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)      662 2023-04-08 06:50:03.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_fwd_hdim128_fp16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)      662 2023-04-08 06:50:03.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_fwd_hdim128_sm80_fp16.cu
+-rw-r--r--   0 root         (0) root         (0)      990 2023-04-07 18:39:34.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_fwd_hdim160.cu
+-rw-r--r--   0 root         (0) root         (0)      495 2023-04-08 07:08:17.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_fwd_hdim160_bf16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     1007 2023-04-08 06:50:03.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_fwd_hdim160_fp16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     1007 2023-04-08 06:50:03.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_fwd_hdim160_sm80_fp16.cu
+-rw-r--r--   0 root         (0) root         (0)     1041 2023-04-07 18:40:27.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_fwd_hdim192.cu
+-rw-r--r--   0 root         (0) root         (0)      494 2023-04-08 07:08:35.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_fwd_hdim192_bf16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     1058 2023-04-08 06:50:03.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_fwd_hdim192_fp16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     1058 2023-04-08 06:50:03.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_fwd_hdim192_sm80_fp16.cu
+-rw-r--r--   0 root         (0) root         (0)      945 2023-04-07 18:37:45.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_fwd_hdim32.cu
+-rw-r--r--   0 root         (0) root         (0)      494 2023-04-08 07:06:55.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_fwd_hdim32_bf16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)      962 2023-04-08 06:50:03.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_fwd_hdim32_fp16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)      962 2023-04-08 06:50:03.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_fwd_hdim32_sm80_fp16.cu
+-rw-r--r--   0 root         (0) root         (0)     1149 2023-04-07 22:02:41.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_fwd_hdim64.cu
+-rw-r--r--   0 root         (0) root         (0)      588 2023-04-08 07:07:20.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_fwd_hdim64_bf16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     1166 2023-04-08 06:50:03.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_fwd_hdim64_fp16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)     1166 2023-04-08 06:50:03.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_fwd_hdim64_sm80_fp16.cu
+-rw-r--r--   0 root         (0) root         (0)      711 2023-04-07 22:17:50.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_fwd_hdim96.cu
+-rw-r--r--   0 root         (0) root         (0)      492 2023-04-08 07:07:36.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_fwd_hdim96_bf16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)      728 2023-04-08 06:50:03.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_fwd_hdim96_fp16_sm80.cu
+-rw-r--r--   0 root         (0) root         (0)      728 2023-04-08 06:50:03.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_fwd_hdim96_sm80_fp16.cu
+-rw-r--r--   0 root         (0) root         (0)    30219 2023-04-12 05:25:26.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_fwd_kernel.h
+-rw-r--r--   0 root         (0) root         (0)    27253 2023-04-08 17:10:55.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_fwd_kernel_old.h
+-rw-r--r--   0 root         (0) root         (0)     2346 2023-04-09 16:47:24.000000 flash_attn-1.0.0/csrc/flash_attn/src/flash_fwd_launch_template.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:22.707174 flash_attn-1.0.0/csrc/flash_attn/src/fmha/
+-rw-r--r--   0 root         (0) root         (0)    17999 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/flash_attn/src/fmha/gemm.h
+-rw-r--r--   0 root         (0) root         (0)    22872 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/flash_attn/src/fmha/gmem_tile.h
+-rw-r--r--   0 root         (0) root         (0)     5997 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/flash_attn/src/fmha/kernel_traits.h
+-rw-r--r--   0 root         (0) root         (0)     4362 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/flash_attn/src/fmha/mask.h
+-rw-r--r--   0 root         (0) root         (0)    74010 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/flash_attn/src/fmha/smem_tile.h
+-rw-r--r--   0 root         (0) root         (0)    25514 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/flash_attn/src/fmha/softmax.h
+-rw-r--r--   0 root         (0) root         (0)    41059 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/flash_attn/src/fmha/utils.h
+-rw-r--r--   0 root         (0) root         (0)     7152 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/flash_attn/src/fmha.h
+-rw-r--r--   0 root         (0) root         (0)     4118 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/flash_attn/src/fmha_block_dgrad_fp16_kernel_loop.sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    33506 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/flash_attn/src/fmha_block_dgrad_kernel_1xN_loop.h
+-rw-r--r--   0 root         (0) root         (0)     5292 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/flash_attn/src/fmha_block_fprop_fp16_kernel.sm80.cu
+-rw-r--r--   0 root         (0) root         (0)    23207 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/flash_attn/src/fmha_block_fprop_kernel_1xN.h
+-rw-r--r--   0 root         (0) root         (0)     2502 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/flash_attn/src/fmha_blockmask.h
+-rw-r--r--   0 root         (0) root         (0)      465 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/flash_attn/src/fmha_bwd_hdim128.cu
+-rw-r--r--   0 root         (0) root         (0)      727 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/flash_attn/src/fmha_bwd_hdim32.cu
+-rw-r--r--   0 root         (0) root         (0)     1713 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/flash_attn/src/fmha_bwd_hdim64.cu
+-rw-r--r--   0 root         (0) root         (0)     6453 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/flash_attn/src/fmha_bwd_launch_template.h
+-rw-r--r--   0 root         (0) root         (0)    37194 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/flash_attn/src/fmha_dgrad_kernel_1xN_loop.h
+-rw-r--r--   0 root         (0) root         (0)    30832 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/flash_attn/src/fmha_fprop_kernel_1xN.h
+-rw-r--r--   0 root         (0) root         (0)      445 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/flash_attn/src/fmha_fwd_hdim128.cu
+-rw-r--r--   0 root         (0) root         (0)      724 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/flash_attn/src/fmha_fwd_hdim32.cu
+-rw-r--r--   0 root         (0) root         (0)      725 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/flash_attn/src/fmha_fwd_hdim64.cu
+-rw-r--r--   0 root         (0) root         (0)     4393 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/flash_attn/src/fmha_fwd_launch_template.h
+-rw-r--r--   0 root         (0) root         (0)     3104 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/flash_attn/src/fmha_kernel.h
+-rw-r--r--   0 root         (0) root         (0)     4892 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/flash_attn/src/fmha_utils.h
+-rw-r--r--   0 root         (0) root         (0)    18374 2023-04-12 05:46:15.000000 flash_attn-1.0.0/csrc/flash_attn/src/kernel_traits.h
+-rw-r--r--   0 root         (0) root         (0)     2927 2023-03-31 21:49:35.000000 flash_attn-1.0.0/csrc/flash_attn/src/mask.h
+-rw-r--r--   0 root         (0) root         (0)     5462 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/flash_attn/src/philox.cuh
+-rw-r--r--   0 root         (0) root         (0)    14205 2023-04-07 21:07:49.000000 flash_attn-1.0.0/csrc/flash_attn/src/softmax.h
+-rw-r--r--   0 root         (0) root         (0)     1686 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/flash_attn/src/static_switch.h
+-rw-r--r--   0 root         (0) root         (0)    13123 2023-04-12 03:28:52.000000 flash_attn-1.0.0/csrc/flash_attn/src/utils.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:22.731281 flash_attn-1.0.0/csrc/flash_gen/
+-rw-r--r--   0 root         (0) root         (0)     7018 2022-11-21 06:35:03.000000 flash_attn-1.0.0/csrc/flash_gen/decoder_masked_multihead_attention.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:23.294732 flash_attn-1.0.0/csrc/ft_attention/
+-rw-r--r--   0 root         (0) root         (0)     8253 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/ft_attention/cuda_bf16_fallbacks.cuh
+-rw-r--r--   0 root         (0) root         (0)      867 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/ft_attention/cuda_bf16_wrapper.h
+-rw-r--r--   0 root         (0) root         (0)     7243 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/ft_attention/decoder_masked_multihead_attention.cu
+-rw-r--r--   0 root         (0) root         (0)     7463 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/ft_attention/decoder_masked_multihead_attention.h
+-rw-r--r--   0 root         (0) root         (0)    52690 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/ft_attention/decoder_masked_multihead_attention_utils.h
+-rw-r--r--   0 root         (0) root         (0)     7423 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/ft_attention/ft_attention.cpp
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:23.336155 flash_attn-1.0.0/csrc/fused_dense_lib/
+-rw-r--r--   0 root         (0) root         (0)     8215 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/fused_dense_lib/fused_dense.cpp
+-rw-r--r--   0 root         (0) root         (0)    25273 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/fused_dense_lib/fused_dense_cuda.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:23.446388 flash_attn-1.0.0/csrc/fused_softmax/
+-rw-r--r--   0 root         (0) root         (0)     5037 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/fused_softmax/fused_softmax.cpp
+-rw-r--r--   0 root         (0) root         (0)    23616 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/fused_softmax/scaled_masked_softmax.h
+-rw-r--r--   0 root         (0) root         (0)     4209 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/fused_softmax/scaled_masked_softmax_cuda.cu
+-rw-r--r--   0 root         (0) root         (0)    24659 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/fused_softmax/scaled_upper_triang_masked_softmax.h
+-rw-r--r--   0 root         (0) root         (0)     3154 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/fused_softmax/scaled_upper_triang_masked_softmax_cuda.cu
+-rw-r--r--   0 root         (0) root         (0)     1216 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/fused_softmax/type_shim.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:25.976331 flash_attn-1.0.0/csrc/layer_norm/
+-rw-r--r--   0 root         (0) root         (0)     7248 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln.h
+-rw-r--r--   0 root         (0) root         (0)    36418 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_api.cpp
+-rw-r--r--   0 root         (0) root         (0)      987 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_bwd_1024.cu
+-rw-r--r--   0 root         (0) root         (0)      987 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_bwd_1280.cu
+-rw-r--r--   0 root         (0) root         (0)      977 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_bwd_1536.cu
+-rw-r--r--   0 root         (0) root         (0)      976 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_bwd_2048.cu
+-rw-r--r--   0 root         (0) root         (0)      977 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_bwd_256.cu
+-rw-r--r--   0 root         (0) root         (0)      977 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_bwd_2560.cu
+-rw-r--r--   0 root         (0) root         (0)      976 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_bwd_3072.cu
+-rw-r--r--   0 root         (0) root         (0)      976 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_bwd_4096.cu
+-rw-r--r--   0 root         (0) root         (0)      977 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_bwd_512.cu
+-rw-r--r--   0 root         (0) root         (0)      976 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_bwd_5120.cu
+-rw-r--r--   0 root         (0) root         (0)      976 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_bwd_6144.cu
+-rw-r--r--   0 root         (0) root         (0)      976 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_bwd_7168.cu
+-rw-r--r--   0 root         (0) root         (0)      977 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_bwd_768.cu
+-rw-r--r--   0 root         (0) root         (0)      976 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_bwd_8192.cu
+-rw-r--r--   0 root         (0) root         (0)    25647 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_bwd_kernels.cuh
+-rw-r--r--   0 root         (0) root         (0)    19944 2023-01-19 07:34:02.000000 flash_attn-1.0.0/csrc/layer_norm/ln_bwd_semi_cuda_kernel_old.cu
+-rw-r--r--   0 root         (0) root         (0)      925 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_fwd_1024.cu
+-rw-r--r--   0 root         (0) root         (0)      925 2023-01-22 09:05:55.000000 flash_attn-1.0.0/csrc/layer_norm/ln_fwd_10240.cu
+-rw-r--r--   0 root         (0) root         (0)      925 2023-01-22 09:07:15.000000 flash_attn-1.0.0/csrc/layer_norm/ln_fwd_12288.cu
+-rw-r--r--   0 root         (0) root         (0)      925 2022-12-05 08:45:58.000000 flash_attn-1.0.0/csrc/layer_norm/ln_fwd_128.cu
+-rw-r--r--   0 root         (0) root         (0)      925 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_fwd_1280.cu
+-rw-r--r--   0 root         (0) root         (0)      925 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_fwd_1536.cu
+-rw-r--r--   0 root         (0) root         (0)      925 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_fwd_2048.cu
+-rw-r--r--   0 root         (0) root         (0)      925 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_fwd_256.cu
+-rw-r--r--   0 root         (0) root         (0)      925 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_fwd_2560.cu
+-rw-r--r--   0 root         (0) root         (0)      925 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_fwd_3072.cu
+-rw-r--r--   0 root         (0) root         (0)      925 2022-12-05 08:50:57.000000 flash_attn-1.0.0/csrc/layer_norm/ln_fwd_384.cu
+-rw-r--r--   0 root         (0) root         (0)      925 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_fwd_4096.cu
+-rw-r--r--   0 root         (0) root         (0)      925 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_fwd_512.cu
+-rw-r--r--   0 root         (0) root         (0)      925 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_fwd_5120.cu
+-rw-r--r--   0 root         (0) root         (0)      925 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_fwd_6144.cu
+-rw-r--r--   0 root         (0) root         (0)      925 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_fwd_7168.cu
+-rw-r--r--   0 root         (0) root         (0)      925 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_fwd_768.cu
+-rw-r--r--   0 root         (0) root         (0)      925 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_fwd_8192.cu
+-rw-r--r--   0 root         (0) root         (0)      925 2023-01-22 08:41:06.000000 flash_attn-1.0.0/csrc/layer_norm/ln_fwd_9216.cu
+-rw-r--r--   0 root         (0) root         (0)    18000 2022-12-06 21:18:58.000000 flash_attn-1.0.0/csrc/layer_norm/ln_fwd_cuda_kernel_old.cu
+-rw-r--r--   0 root         (0) root         (0)    12721 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_fwd_kernels.cuh
+-rw-r--r--   0 root         (0) root         (0)     6655 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_kernel_traits.h
+-rw-r--r--   0 root         (0) root         (0)     1095 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_parallel_bwd_1024.cu
+-rw-r--r--   0 root         (0) root         (0)     1095 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_parallel_bwd_1280.cu
+-rw-r--r--   0 root         (0) root         (0)     1085 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_parallel_bwd_1536.cu
+-rw-r--r--   0 root         (0) root         (0)     1084 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_parallel_bwd_2048.cu
+-rw-r--r--   0 root         (0) root         (0)     1085 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_parallel_bwd_256.cu
+-rw-r--r--   0 root         (0) root         (0)     1085 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_parallel_bwd_2560.cu
+-rw-r--r--   0 root         (0) root         (0)     1084 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_parallel_bwd_3072.cu
+-rw-r--r--   0 root         (0) root         (0)     1145 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_parallel_bwd_4096.cu
+-rw-r--r--   0 root         (0) root         (0)     1085 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_parallel_bwd_512.cu
+-rw-r--r--   0 root         (0) root         (0)     1145 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_parallel_bwd_5120.cu
+-rw-r--r--   0 root         (0) root         (0)     1084 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_parallel_bwd_6144.cu
+-rw-r--r--   0 root         (0) root         (0)     1084 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_parallel_bwd_7168.cu
+-rw-r--r--   0 root         (0) root         (0)     1085 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_parallel_bwd_768.cu
+-rw-r--r--   0 root         (0) root         (0)     1084 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_parallel_bwd_8192.cu
+-rw-r--r--   0 root         (0) root         (0)     1033 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_parallel_fwd_1024.cu
+-rw-r--r--   0 root         (0) root         (0)     1033 2023-03-29 20:52:04.000000 flash_attn-1.0.0/csrc/layer_norm/ln_parallel_fwd_128.cu
+-rw-r--r--   0 root         (0) root         (0)     1033 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_parallel_fwd_1280.cu
+-rw-r--r--   0 root         (0) root         (0)     1033 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_parallel_fwd_1536.cu
+-rw-r--r--   0 root         (0) root         (0)     1033 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_parallel_fwd_2048.cu
+-rw-r--r--   0 root         (0) root         (0)     1032 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_parallel_fwd_256.cu
+-rw-r--r--   0 root         (0) root         (0)     1033 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_parallel_fwd_2560.cu
+-rw-r--r--   0 root         (0) root         (0)     1033 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_parallel_fwd_3072.cu
+-rw-r--r--   0 root         (0) root         (0)     1033 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_parallel_fwd_4096.cu
+-rw-r--r--   0 root         (0) root         (0)     1033 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_parallel_fwd_512.cu
+-rw-r--r--   0 root         (0) root         (0)     1033 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_parallel_fwd_5120.cu
+-rw-r--r--   0 root         (0) root         (0)     1033 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_parallel_fwd_6144.cu
+-rw-r--r--   0 root         (0) root         (0)     1033 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_parallel_fwd_7168.cu
+-rw-r--r--   0 root         (0) root         (0)     1033 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_parallel_fwd_768.cu
+-rw-r--r--   0 root         (0) root         (0)     1033 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_parallel_fwd_8192.cu
+-rw-r--r--   0 root         (0) root         (0)    11720 2023-03-29 19:53:46.000000 flash_attn-1.0.0/csrc/layer_norm/ln_parallel_res_fwd_kernel.cuh
+-rw-r--r--   0 root         (0) root         (0)      977 2023-03-27 04:43:57.000000 flash_attn-1.0.0/csrc/layer_norm/ln_parallel_residual_bwd_512.cu
+-rw-r--r--   0 root         (0) root         (0)    24916 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_parallel_residual_bwd_kernels.cuh
+-rw-r--r--   0 root         (0) root         (0)    11515 2023-03-29 20:50:46.000000 flash_attn-1.0.0/csrc/layer_norm/ln_parallel_residual_fwd_kernel.cuh
+-rw-r--r--   0 root         (0) root         (0)    12530 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_parallel_residual_fwd_kernels.cuh
+-rw-r--r--   0 root         (0) root         (0)    29989 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/ln_utils.cuh
+-rw-r--r--   0 root         (0) root         (0)     1278 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/layer_norm/static_switch.h
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:26.016899 flash_attn-1.0.0/csrc/rotary/
+-rw-r--r--   0 root         (0) root         (0)     1806 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/rotary/rotary.cpp
+-rw-r--r--   0 root         (0) root         (0)     1984 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/rotary/rotary_cuda.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:26.057279 flash_attn-1.0.0/csrc/xentropy/
+-rw-r--r--   0 root         (0) root         (0)     2290 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/xentropy/interface.cpp
+-rw-r--r--   0 root         (0) root         (0)    25783 2023-04-12 06:28:29.000000 flash_attn-1.0.0/csrc/xentropy/xentropy_kernel.cu
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:26.495990 flash_attn-1.0.0/flash_attn/
+-rw-r--r--   0 root         (0) root         (0)        0 2022-07-04 00:53:37.000000 flash_attn-1.0.0/flash_attn/__init__.py
+-rw-rw-r--   0 root         (0) root         (0)    20845 2022-10-31 02:25:05.000000 flash_attn-1.0.0/flash_attn/attention_kernl.py
+-rw-r--r--   0 root         (0) root         (0)     5898 2023-04-12 06:28:29.000000 flash_attn-1.0.0/flash_attn/bert_padding.py
+-rw-r--r--   0 root         (0) root         (0)     4722 2023-04-12 06:28:29.000000 flash_attn-1.0.0/flash_attn/flash_attention.py
+-rw-r--r--   0 root         (0) root         (0)    21496 2023-04-12 06:28:29.000000 flash_attn-1.0.0/flash_attn/flash_attn_interface.py
+-rw-r--r--   0 root         (0) root         (0)    38148 2023-04-12 06:28:29.000000 flash_attn-1.0.0/flash_attn/flash_attn_triton.py
+-rw-r--r--   0 root         (0) root         (0)    10593 2023-04-12 06:28:29.000000 flash_attn-1.0.0/flash_attn/flash_attn_triton_og.py
+-rw-r--r--   0 root         (0) root         (0)     8255 2022-11-18 03:30:00.000000 flash_attn-1.0.0/flash_attn/flash_attn_triton_single_query.py
+-rw-r--r--   0 root         (0) root         (0)    37797 2023-03-17 09:16:10.000000 flash_attn-1.0.0/flash_attn/flash_attn_triton_tmp.py
+-rw-r--r--   0 root         (0) root         (0)    10640 2023-03-12 08:48:14.000000 flash_attn-1.0.0/flash_attn/flash_attn_triton_tmp_og.py
+-rw-rw-r--   0 root         (0) root         (0)    22919 2022-10-31 00:28:55.000000 flash_attn-1.0.0/flash_attn/flash_attn_triton_varlen.py
+-rw-r--r--   0 root         (0) root         (0)     6819 2022-06-26 00:59:43.000000 flash_attn-1.0.0/flash_attn/flash_blocksparse_attention.py
+-rw-r--r--   0 root         (0) root         (0)     7036 2022-06-26 00:59:43.000000 flash_attn-1.0.0/flash_attn/flash_blocksparse_attn_interface.py
+-rw-r--r--   0 root         (0) root         (0)     7902 2023-04-12 06:28:29.000000 flash_attn-1.0.0/flash_attn/fused_softmax.py
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:26.631366 flash_attn-1.0.0/flash_attn/layers/
+-rw-r--r--   0 root         (0) root         (0)        0 2023-04-12 06:28:29.000000 flash_attn-1.0.0/flash_attn/layers/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     2039 2023-04-12 06:28:29.000000 flash_attn-1.0.0/flash_attn/layers/patch_embed.py
+-rw-r--r--   0 root         (0) root         (0)    10656 2023-04-12 06:28:29.000000 flash_attn-1.0.0/flash_attn/layers/rotary.py
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:26.700488 flash_attn-1.0.0/flash_attn/losses/
+-rw-r--r--   0 root         (0) root         (0)        0 2023-04-12 06:28:29.000000 flash_attn-1.0.0/flash_attn/losses/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     6697 2023-04-12 06:28:29.000000 flash_attn-1.0.0/flash_attn/losses/cross_entropy.py
+-rw-r--r--   0 root         (0) root         (0)     2122 2022-12-18 05:19:38.000000 flash_attn-1.0.0/flash_attn/losses/cross_entropy_apex.py
+-rw-r--r--   0 root         (0) root         (0)     6649 2022-12-23 22:38:19.000000 flash_attn-1.0.0/flash_attn/losses/cross_entropy_parallel.py
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:26.840552 flash_attn-1.0.0/flash_attn/models/
+-rw-r--r--   0 root         (0) root         (0)        0 2023-04-12 06:28:29.000000 flash_attn-1.0.0/flash_attn/models/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    26630 2023-04-12 06:28:29.000000 flash_attn-1.0.0/flash_attn/models/bert.py
+-rw-r--r--   0 root         (0) root         (0)    34989 2023-04-12 06:28:29.000000 flash_attn-1.0.0/flash_attn/models/gpt.py
+-rw-r--r--   0 root         (0) root         (0)     4863 2023-03-22 21:08:53.000000 flash_attn-1.0.0/flash_attn/models/gpt_j.py
+-rw-r--r--   0 root         (0) root         (0)     5025 2023-04-12 06:28:29.000000 flash_attn-1.0.0/flash_attn/models/gpt_neox.py
+-rw-r--r--   0 root         (0) root         (0)     4387 2023-04-12 06:28:29.000000 flash_attn-1.0.0/flash_attn/models/gptj.py
+-rw-r--r--   0 root         (0) root         (0)     5174 2023-04-12 06:28:29.000000 flash_attn-1.0.0/flash_attn/models/opt.py
+-rw-r--r--   0 root         (0) root         (0)    13621 2023-04-12 06:28:29.000000 flash_attn-1.0.0/flash_attn/models/vit.py
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:26.932755 flash_attn-1.0.0/flash_attn/modules/
+-rw-r--r--   0 root         (0) root         (0)        0 2023-04-12 06:28:29.000000 flash_attn-1.0.0/flash_attn/modules/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    15244 2023-04-12 06:28:29.000000 flash_attn-1.0.0/flash_attn/modules/block.py
+-rw-r--r--   0 root         (0) root         (0)     8620 2023-04-12 06:28:29.000000 flash_attn-1.0.0/flash_attn/modules/embedding.py
+-rw-r--r--   0 root         (0) root         (0)    32394 2023-04-12 06:28:29.000000 flash_attn-1.0.0/flash_attn/modules/mha.py
+-rw-r--r--   0 root         (0) root         (0)     1023 2023-04-12 06:28:29.000000 flash_attn-1.0.0/flash_attn/modules/mlp.py
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:27.023232 flash_attn-1.0.0/flash_attn/ops/
+-rw-r--r--   0 root         (0) root         (0)        0 2023-04-12 06:28:29.000000 flash_attn-1.0.0/flash_attn/ops/__init__.py
+-rw-r--r--   0 root         (0) root         (0)    25573 2023-04-12 06:28:29.000000 flash_attn-1.0.0/flash_attn/ops/fused_dense.py
+-rw-r--r--   0 root         (0) root         (0)     2685 2023-04-12 06:28:29.000000 flash_attn-1.0.0/flash_attn/ops/gelu_activation.py
+-rw-r--r--   0 root         (0) root         (0)    18374 2023-04-12 06:28:29.000000 flash_attn-1.0.0/flash_attn/ops/layer_norm.py
+-rw-r--r--   0 root         (0) root         (0)     3159 2023-04-12 06:28:29.000000 flash_attn-1.0.0/flash_attn/ops/rms_norm.py
+-rw-r--r--   0 root         (0) root         (0)     5855 2023-04-07 15:25:56.000000 flash_attn-1.0.0/flash_attn/rotary.py
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:27.058243 flash_attn-1.0.0/flash_attn/triton/
+-rw-rw-r--   0 root         (0) root         (0)        0 2022-11-18 00:51:48.000000 flash_attn-1.0.0/flash_attn/triton/__init__.py
+-rw-rw-r--   0 root         (0) root         (0)    14332 2022-10-23 23:52:09.000000 flash_attn-1.0.0/flash_attn/triton/fused_attention.py
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:27.155247 flash_attn-1.0.0/flash_attn/utils/
+-rw-r--r--   0 root         (0) root         (0)        0 2023-04-12 06:28:29.000000 flash_attn-1.0.0/flash_attn/utils/__init__.py
+-rw-r--r--   0 root         (0) root         (0)     5909 2023-04-12 06:28:29.000000 flash_attn-1.0.0/flash_attn/utils/benchmark.py
+-rw-r--r--   0 root         (0) root         (0)     5545 2023-04-12 06:28:29.000000 flash_attn-1.0.0/flash_attn/utils/distributed.py
+-rw-r--r--   0 root         (0) root         (0)    13140 2023-04-12 06:28:29.000000 flash_attn-1.0.0/flash_attn/utils/generation.py
+-rw-r--r--   0 root         (0) root         (0)     1824 2023-04-12 06:28:29.000000 flash_attn-1.0.0/flash_attn/utils/pretrained.py
+drwxrwxr-x   0 root         (0) root         (0)        0 2023-04-12 06:37:26.575750 flash_attn-1.0.0/flash_attn.egg-info/
+-rw-rw-r--   0 root         (0) root         (0)    10037 2023-04-12 06:34:34.000000 flash_attn-1.0.0/flash_attn.egg-info/PKG-INFO
+-rw-rw-r--   0 root         (0) root         (0)   112777 2023-04-12 06:34:48.000000 flash_attn-1.0.0/flash_attn.egg-info/SOURCES.txt
+-rw-rw-r--   0 root         (0) root         (0)        1 2023-04-12 06:34:34.000000 flash_attn-1.0.0/flash_attn.egg-info/dependency_links.txt
+-rw-rw-r--   0 root         (0) root         (0)       13 2023-04-12 06:34:34.000000 flash_attn-1.0.0/flash_attn.egg-info/requires.txt
+-rw-rw-r--   0 root         (0) root         (0)       27 2023-04-12 06:34:34.000000 flash_attn-1.0.0/flash_attn.egg-info/top_level.txt
+-rw-rw-r--   0 root         (0) root         (0)       38 2023-04-12 06:37:27.167858 flash_attn-1.0.0/setup.cfg
+-rw-r--r--   0 root         (0) root         (0)     7541 2023-04-12 06:30:02.000000 flash_attn-1.0.0/setup.py
```

### Comparing `flash_attn-0.2.8/LICENSE` & `flash_attn-1.0.0/LICENSE`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/PKG-INFO` & `flash_attn-1.0.0/README.md`

 * *Files 15% similar despite different names*

```diff
@@ -1,24 +1,7 @@
-Metadata-Version: 2.1
-Name: flash_attn
-Version: 0.2.8
-Summary: Flash Attention: Fast and Memory-Efficient Exact Attention
-Home-page: https://github.com/HazyResearch/flash-attention
-Author: Tri Dao
-Author-email: trid@stanford.edu
-License: UNKNOWN
-Platform: UNKNOWN
-Classifier: Programming Language :: Python :: 3
-Classifier: License :: OSI Approved :: BSD License
-Classifier: Operating System :: Unix
-Requires-Python: >=3.7
-Description-Content-Type: text/markdown
-License-File: LICENSE
-License-File: AUTHORS
-
 # FlashAttention
 This repository provides the official implementation of FlashAttention from the
 following paper.
 
 **FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness**  
 Tri Dao, Daniel Y. Fu, Stefano Ermon, Atri Rudra, Christopher R  
 Paper: https://arxiv.org/abs/2205.14135  
@@ -51,17 +34,21 @@
 https://github.com/openai/triton/blob/master/python/tutorials/06-fused-attention.py  
 
 As Triton is a higher-level language than CUDA, it might be easier to understand
 and experiment with. The notations in the Triton implementation are also closer
 to what's used in our paper.
 
 
-## Beta release (0.2).
+## Installation and features
+
+Requirements:
+- CUDA 11.4 and above.
+- PyTorch 1.12 and above.
 
-To install (requiring CUDA 11, NVCC, and an Turing or Ampere GPU):
+To install:
 ```sh
 pip install flash-attn
 ```
 
 Alternatively you can compile from source:
 ```
 python setup.py install
@@ -71,29 +58,95 @@
 
 To run the benchmark against PyTorch standard attention: 
 ```
 PYTHONPATH=$PWD python benchmarks/benchmark_flash_attention.py
 ```
 
 FlashAttention currently supports:
-1. Turing or Ampere GPUs (e.g., A100, RTX 3090, T4, RTX 2080).
-2. fp16 and bf16 (bf16 requires Ampere GPUs).
-3. Head dimensions that are multiples of 8, up to 128 (e.g., 8, 16, 24, ..., 128). Head dim > 64 backward requires A100.
+1. Turing, Ampere, Ada, or Hopper GPUs (e.g., H100, A100, RTX 3090, T4, RTX 2080).
+2. fp16 and bf16 (bf16 requires Ampere, Ada, or Hopper GPUs).
+3. Head dimensions that are multiples of 8, up to 128 (e.g., 8, 16, 24, ...,
+   128). Head dim > 64 backward requires A100 or H100.
 
 Our tentative roadmap:
 1. ~~[Jun 2022] Make package pip-installable~~[Done, thanks to lucidrains].
 2. ~~[Jun 2022] Support SM86 GPUs (e.g., RTX 3080, 3090)~~[Done].
-3. [Jun 2022] Refactor to use Cutlass.
-4. ~~[Jun 2022] Support SM75 GPUs (e.g. T4)~~[Done].
-5. ~~[Jun 2022] Support bf16~~[Done].
-6. ~~[Jul 2022] Implement cross-attention~~[Done].
-7. ~~[Jul 2022] Support head dimension 128~~[Done].
-8. [Jul 2022] Support SM70 GPUs (V100).
-9. ~~[Aug 2022] Fuse rotary embedding~~[Done].
-10. [Aug 2022] Support attention bias (e.g. ALiBi, relative positional encoding).
+3. ~~[Jun 2022] Support SM75 GPUs (e.g. T4)~~[Done].
+4. ~~[Jun 2022] Support bf16~~[Done].
+5. ~~[Jul 2022] Implement cross-attention~~[Done].
+6. ~~[Jul 2022] Support head dimension 128~~[Done].
+7. ~~[Aug 2022] Fuse rotary embedding~~[Done].
+8. ~~[Mar 2023] Support SM90 GPUs (H100)~~[Done].
+9. [Apr 2023] Refactor to use Cutlass 3.x.
+10. [May 2023] Support attention bias (e.g. ALiBi, relative positional encoding).
+11. [Jun 2023] Support SM70 GPUs (V100).
+12. [Jun 2023] Support fp8 (H100).
+
+
+## How to use FlashAttention
+
+Here's a simple example:
+```python
+import torch
+from flash_attn.flash_attention import FlashMHA
+
+# Replace this with your correct GPU device
+device = "cuda:0"
+
+# Create attention layer. This is similar to torch.nn.MultiheadAttention,
+# and it includes the input and output linear layers
+flash_mha = FlashMHA(
+    embed_dim=128, # total channels (= num_heads * head_dim)
+    num_heads=8, # number of heads
+    device=device,
+    dtype=torch.float16,
+)
+
+# Run forward pass with dummy data
+x = torch.randn(
+    (64, 256, 128), # (batch, seqlen, embed_dim)
+    device=device,
+    dtype=torch.float16
+)
+
+output = flash_mha(x)[0]
+```
+
+Alternatively, you can import the inner attention layer only (so that the input
+and output linear layers are not included):
+```python
+from flash_attn.flash_attention import FlashAttention
+
+# Create the nn.Module
+flash_attention = FlashAttention()
+```
+
+Or, if you need more fine-grained control, you can import one of the lower-level
+functions (this is more similar to the `torch.nn.functional` style):
+```python
+from flash_attn.flash_attn_interface import flash_attn_unpadded_func
+
+# or
+
+from flash_attn.flash_attn_interface import flash_attn_unpadded_qkvpacked_split_func
+
+# etc.
+```
+
+There are also separate Python files with various FlashAttention extensions:
+```python
+# Import the triton implementation (torch.nn.functional version only)
+from flash_attn.flash_attn_triton import flash_attn_func
+
+# Import block sparse attention (nn.Module version)
+from flash_attn.flash_blocksparse_attention import FlashBlocksparseMHA, FlashBlocksparseAttention
+
+# Import block sparse attention (torch.nn.functional version)
+from flash_attn.flash_blocksparse_attn_interface import flash_blocksparse_attn_func
+```
 
 ## Speedup and Memory Savings
 
 We present expected speedup (combined forward + backward pass) and memory savings from using FlashAttention against PyTorch standard attention, depending on sequence length, on different GPUs (speedup depends on memory bandwidth - we see more speedup on slower GPU memory).
 
 We currently have benchmarks for these GPUs:
 * [A100](#a100)
@@ -193,9 +246,7 @@
 @inproceedings{dao2022flashattention,
   title={Flash{A}ttention: Fast and Memory-Efficient Exact Attention with {IO}-Awareness},
   author={Dao, Tri and Fu, Daniel Y. and Ermon, Stefano and Rudra, Atri and R{\'e}, Christopher},
   booktitle={Advances in Neural Information Processing Systems},
   year={2022}
 }
 ```
-
-
```

### Comparing `flash_attn-0.2.8/README.md` & `flash_attn-1.0.0/flash_attn.egg-info/PKG-INFO`

 * *Files 21% similar despite different names*

```diff
@@ -1,7 +1,24 @@
+Metadata-Version: 2.1
+Name: flash-attn
+Version: 1.0.0
+Summary: Flash Attention: Fast and Memory-Efficient Exact Attention
+Home-page: https://github.com/HazyResearch/flash-attention
+Author: Tri Dao
+Author-email: trid@stanford.edu
+License: UNKNOWN
+Platform: UNKNOWN
+Classifier: Programming Language :: Python :: 3
+Classifier: License :: OSI Approved :: BSD License
+Classifier: Operating System :: Unix
+Requires-Python: >=3.7
+Description-Content-Type: text/markdown
+License-File: LICENSE
+License-File: AUTHORS
+
 # FlashAttention
 This repository provides the official implementation of FlashAttention from the
 following paper.
 
 **FlashAttention: Fast and Memory-Efficient Exact Attention with IO-Awareness**  
 Tri Dao, Daniel Y. Fu, Stefano Ermon, Atri Rudra, Christopher R  
 Paper: https://arxiv.org/abs/2205.14135  
@@ -34,17 +51,21 @@
 https://github.com/openai/triton/blob/master/python/tutorials/06-fused-attention.py  
 
 As Triton is a higher-level language than CUDA, it might be easier to understand
 and experiment with. The notations in the Triton implementation are also closer
 to what's used in our paper.
 
 
-## Beta release (0.2).
+## Installation and features
+
+Requirements:
+- CUDA 11.4 and above.
+- PyTorch 1.12 and above.
 
-To install (requiring CUDA 11, NVCC, and an Turing or Ampere GPU):
+To install:
 ```sh
 pip install flash-attn
 ```
 
 Alternatively you can compile from source:
 ```
 python setup.py install
@@ -54,29 +75,95 @@
 
 To run the benchmark against PyTorch standard attention: 
 ```
 PYTHONPATH=$PWD python benchmarks/benchmark_flash_attention.py
 ```
 
 FlashAttention currently supports:
-1. Turing or Ampere GPUs (e.g., A100, RTX 3090, T4, RTX 2080).
-2. fp16 and bf16 (bf16 requires Ampere GPUs).
-3. Head dimensions that are multiples of 8, up to 128 (e.g., 8, 16, 24, ..., 128). Head dim > 64 backward requires A100.
+1. Turing, Ampere, Ada, or Hopper GPUs (e.g., H100, A100, RTX 3090, T4, RTX 2080).
+2. fp16 and bf16 (bf16 requires Ampere, Ada, or Hopper GPUs).
+3. Head dimensions that are multiples of 8, up to 128 (e.g., 8, 16, 24, ...,
+   128). Head dim > 64 backward requires A100 or H100.
 
 Our tentative roadmap:
 1. ~~[Jun 2022] Make package pip-installable~~[Done, thanks to lucidrains].
 2. ~~[Jun 2022] Support SM86 GPUs (e.g., RTX 3080, 3090)~~[Done].
-3. [Jun 2022] Refactor to use Cutlass.
-4. ~~[Jun 2022] Support SM75 GPUs (e.g. T4)~~[Done].
-5. ~~[Jun 2022] Support bf16~~[Done].
-6. ~~[Jul 2022] Implement cross-attention~~[Done].
-7. ~~[Jul 2022] Support head dimension 128~~[Done].
-8. [Jul 2022] Support SM70 GPUs (V100).
-9. ~~[Aug 2022] Fuse rotary embedding~~[Done].
-10. [Aug 2022] Support attention bias (e.g. ALiBi, relative positional encoding).
+3. ~~[Jun 2022] Support SM75 GPUs (e.g. T4)~~[Done].
+4. ~~[Jun 2022] Support bf16~~[Done].
+5. ~~[Jul 2022] Implement cross-attention~~[Done].
+6. ~~[Jul 2022] Support head dimension 128~~[Done].
+7. ~~[Aug 2022] Fuse rotary embedding~~[Done].
+8. ~~[Mar 2023] Support SM90 GPUs (H100)~~[Done].
+9. [Apr 2023] Refactor to use Cutlass 3.x.
+10. [May 2023] Support attention bias (e.g. ALiBi, relative positional encoding).
+11. [Jun 2023] Support SM70 GPUs (V100).
+12. [Jun 2023] Support fp8 (H100).
+
+
+## How to use FlashAttention
+
+Here's a simple example:
+```python
+import torch
+from flash_attn.flash_attention import FlashMHA
+
+# Replace this with your correct GPU device
+device = "cuda:0"
+
+# Create attention layer. This is similar to torch.nn.MultiheadAttention,
+# and it includes the input and output linear layers
+flash_mha = FlashMHA(
+    embed_dim=128, # total channels (= num_heads * head_dim)
+    num_heads=8, # number of heads
+    device=device,
+    dtype=torch.float16,
+)
+
+# Run forward pass with dummy data
+x = torch.randn(
+    (64, 256, 128), # (batch, seqlen, embed_dim)
+    device=device,
+    dtype=torch.float16
+)
+
+output = flash_mha(x)[0]
+```
+
+Alternatively, you can import the inner attention layer only (so that the input
+and output linear layers are not included):
+```python
+from flash_attn.flash_attention import FlashAttention
+
+# Create the nn.Module
+flash_attention = FlashAttention()
+```
+
+Or, if you need more fine-grained control, you can import one of the lower-level
+functions (this is more similar to the `torch.nn.functional` style):
+```python
+from flash_attn.flash_attn_interface import flash_attn_unpadded_func
+
+# or
+
+from flash_attn.flash_attn_interface import flash_attn_unpadded_qkvpacked_split_func
+
+# etc.
+```
+
+There are also separate Python files with various FlashAttention extensions:
+```python
+# Import the triton implementation (torch.nn.functional version only)
+from flash_attn.flash_attn_triton import flash_attn_func
+
+# Import block sparse attention (nn.Module version)
+from flash_attn.flash_blocksparse_attention import FlashBlocksparseMHA, FlashBlocksparseAttention
+
+# Import block sparse attention (torch.nn.functional version)
+from flash_attn.flash_blocksparse_attn_interface import flash_blocksparse_attn_func
+```
 
 ## Speedup and Memory Savings
 
 We present expected speedup (combined forward + backward pass) and memory savings from using FlashAttention against PyTorch standard attention, depending on sequence length, on different GPUs (speedup depends on memory bandwidth - we see more speedup on slower GPU memory).
 
 We currently have benchmarks for these GPUs:
 * [A100](#a100)
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/cmake/nop.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/cmake/nop.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/00_basic_gemm/basic_gemm.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/00_basic_gemm/basic_gemm.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -43,15 +43,15 @@
 
   https://devblogs.nvidia.com/cutlass-linear-algebra-cuda/
 
   Aside from defining and launching the SGEMM kernel, this example does not use any other components
   or utilities within CUTLASS. Such utilities are demonstrated elsewhere in other examples and are
   prevalent in the CUTLASS unit tests.
 
-  This example has delibrately been kept similar to the basic_gemm example from cutass-1.3 to 
+  This example has delibrately been kept similar to the basic_gemm example from cutlass-1.3 to
   highlight the minimum amount of differences needed to transition to cutlass-2.0.
 
   Cutlass-1.3 sgemm: https://github.com/NVIDIA/cutlass/blob/master/examples/00_basic_gemm/basic_gemm.cu
 */
 
 // Standard Library includes
 #include <iostream>
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/01_cutlass_utilities/cutlass_utilities.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/01_cutlass_utilities/cutlass_utilities.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/02_dump_reg_shmem/dump_reg_shmem.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/02_dump_reg_shmem/dump_reg_shmem.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/03_visualize_layout/options.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/03_visualize_layout/options.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/03_visualize_layout/register_layout.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/03_visualize_layout/register_layout.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/03_visualize_layout/register_layout.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/03_visualize_layout/register_layout.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/03_visualize_layout/visualize_layout.cpp` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/03_visualize_layout/visualize_layout.cpp`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/03_visualize_layout/visualize_layout.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/03_visualize_layout/visualize_layout.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/04_tile_iterator/tile_iterator.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/04_tile_iterator/tile_iterator.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/05_batched_gemm/batched_gemm.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/05_batched_gemm/batched_gemm.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/06_splitK_gemm/splitk_gemm.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/06_splitK_gemm/splitk_gemm.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/07_volta_tensorop_gemm/volta_tensorop_gemm.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/07_volta_tensorop_gemm/volta_tensorop_gemm.cu`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -71,15 +71,15 @@
 beta * C).
 
 Now that we setup the properties of data, we have to setup properties of computation.
 
 Second, we create template variables of tile sizes for thread-block, warp and mma-op to 128x128x32,
 64x64x32, 8x8x4 (MxNxK) respectively. When passed to instantiate CUTLASS GEMM kernel, it internally
 deduce the amount of threads needed per thread-block, amount of shared memory, storing data in
-bank-conflict free manner, and ton of other variables required to compose, intialize and launch a
+bank-conflict free manner, and ton of other variables required to compose, initialize and launch a
 high performance GEMM kernel. This is the beauty of CUTLASS, it relieves developer from
 understanding and coding complicated hardware optimizations which can easily go wrong.
 
 CUTLASS also supports multiple MMA pipelines in a CTA. What are MMA pipelines? MMA pipelines
 constitute the whole process of loading input data from global memory to shared memory, loading data
 from shared memory to registers, doing matrix multiplication, store to global memory. The below flow
 sequence shows a typical mma pipeline.
@@ -103,23 +103,23 @@
 
 There are few more template variables initialized such as, which threadblock tile of output matrix
 is done which threadblock launched on an SM, CUDA SM architecture of GPU you want to run on.
 
 These are all put together to create a template variable which describes CUTLASS GEMM kernel using
 cutlass::gemm::device::Gemm template.
 
-The next step is to intialize physical data, instantiate and initialize CUTLASS kernel and run it.
+The next step is to initialize physical data, instantiate and initialize CUTLASS kernel and run it.
 We use CUTLASS utilities to initialize, fill, compare matrices as they are simple and doesn't come
 in the way of learning CUTLASS.
 
 Once all the matrices are initialized and filled with data, create arguments tuple to launch CUTLASS
 kernel which takes problem size (M = 5120, N = 4096 and K = 4096), matrices, alpha, beta and the
 important one, split k-dimension factor. Along with that, we query CUTLASS if any scratch-space
 memory required by the kernel we instantiated. If yes, we create it and pass it along with other
-arguments created to intialize CUTLASS kernel then, the kernel is launched.
+arguments created to initialize CUTLASS kernel then, the kernel is launched.
 
 In this example, we later on launch a reference gemm kernel (from CUTLASS utilities) to compare if
 the output from CUTLASS kernel is same as reference GEMM kernel.
 */
 
 #include <iostream>
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/08_turing_tensorop_gemm/turing_tensorop_gemm.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/08_turing_tensorop_gemm/turing_tensorop_gemm.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -70,15 +70,15 @@
 and data type of computation of linear combination (alpha * X + beta * C).
 
 Now that we setup the properties of data, we have to setup properties of computation.
 
 Second, we create template variables of tile sizes for thread-block, warp and mma-op to 128x256x64,
 64x64x16, 8x8x16 (MxNxK) respectively. When passed to instantiate CUTLASS GEMM kernel, it internally
 deduce the amount of threads needed per thread-block, amount of shared memory, storing data in
-bank-conflict free manner, and ton of other variables required to compose, intialize and launch a
+bank-conflict free manner, and ton of other variables required to compose, initialize and launch a
 high performance GEMM kernel. This is the beauty of CUTLASS, it relieves developer from
 understanding and coding complicated hardware optimizations which can easily go wrong.
 
 CUTLASS also supports multiple MMA pipelines in a threadblock. What are MMA pipelines? MMA pipelines
 constitute the whole process of loading input data from global memory to shared memory, loading data
 from shared memory to registers, doing matrix multiplication, store to global memory. The below flow
 sequence shows a typical mma pipeline.
@@ -102,23 +102,23 @@
 
 There are few more template variables initialized such as, which threadblock tile of output matrix
 is done which threadblock launched on an SM, CUDA SM architecture of GPU you want to run on.
 
 These are all put together to create a template variable which describes CUTLASS GEMM kernel using
 cutlass::gemm::device::Gemm template.
 
-The next step is to intialize physical data, instantiate and initialize CUTLASS kernel and run it.
+The next step is to initialize physical data, instantiate and initialize CUTLASS kernel and run it.
 We use CUTLASS utilities to initialize, fill, compare matrices as they are simple and doesn't come
 in the way of learning CUTLASS.
 
 Once all the matrices are initialized and filled with data, create arguments tuple to launch CUTLASS
 kernel which takes problem size (M = 5120, N = 4096 and K = 4096), matrices, alpha, beta and the
 important one, split k-dimension factor. Along with that, we query CUTLASS if any scratch-space
 memory required by the kernel we instantiated. If yes, we create it and pass it along with other
-arguments created to intialize CUTLASS kernel then, the kernel is launched.
+arguments created to initialize CUTLASS kernel then, the kernel is launched.
 
 In this example, we later on launch a reference gemm kernel (from CUTLASS utilities) to compare if
 the output from CUTLASS kernel is same as reference GEMM kernel.
 */
 
 #include <iostream>
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/09_turing_tensorop_conv2dfprop/turing_tensorop_conv2dfprop.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/09_turing_tensorop_conv2dfprop/turing_tensorop_conv2dfprop.cu`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -72,15 +72,15 @@
 computation of linear combination (alpha * X + beta * C).
 
 Now that we setup the properties of data, we have to setup properties of computation.
 
 Second, we create template variables of tile sizes for thread-block, warp and mma-op to 128x128x128,
 64x64x128, 8x8x32 (MxNxK) respectively. When passed to instantiate CUTLASS Implicit GEMM kernel, it
 internally deduces the amount of threads needed per thread-block, amount of shared memory, storing
-data in bank-conflict free manner, and ton of other variables required to compose, intialize and
+data in bank-conflict free manner, and ton of other variables required to compose, initialize and
 launch a high performance Implicit GEMM kernel. This is the beauty of CUTLASS, it relieves developer
 from understanding and coding complicated hardware optimizations which can easily go wrong.
 
 CUTLASS also supports multiple MMA pipelines in a threadblock. What are MMA pipelines? MMA pipelines
 constitute the whole process of loading input data from global memory to shared memory, loading data
 from shared memory to registers, doing matrix multiplication, store to global memory. The below flow
 sequence shows a typical mma pipeline.
@@ -104,24 +104,24 @@
 
 There are few more template variables initialized such as, which threadblock tile of output matrix
 is done which threadblock launched on an SM, CUDA SM architecture of GPU you want to run on.
 
 These are all put together to create a template variable which describes CUTLASS Implicit GEMM
 kernel using cutlass::conv::device::ImplicitGemm template.
 
-The next step is to intialize physical data, instantiate and initialize CUTLASS kernel and run it.
+The next step is to initialize physical data, instantiate and initialize CUTLASS kernel and run it.
 We use CUTLASS utilities to initialize, fill, compare tensors as they are simple and doesn't come
 in the way of learning CUTLASS.
 
 Once all the tensors are initialized and filled with data, create arguments tuple to launch CUTLASS
 kernel which takes problem size (N = 1, H = 64, W = 64, C = 128), filter size (K = 64,
 R = 3, S = 3, C = 128 ), padding, strides, dilation, tensors, alpha, beta and the
 important one, split k-dimension factor. Along with that, we query CUTLASS if any scratch-space
 memory required by the kernel we instantiated. If yes, we create it and pass it along with other
-arguments created to intialize CUTLASS kernel then, the kernel is launched.
+arguments created to initialize CUTLASS kernel then, the kernel is launched.
 
 In this example, we later on launch a reference convolution kernel (from CUTLASS utilities) to
 compare if the output from CUTLASS kernel is same as the reference implicit GEMM kernel.
 */
 
 #include <iostream>
 #include <fstream>
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/10_planar_complex/planar_complex.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/10_planar_complex/planar_complex.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/11_planar_complex_array/planar_complex_array.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/11_planar_complex_array/planar_complex_array.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/12_gemm_bias_relu/gemm_bias_relu.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/12_gemm_bias_relu/gemm_bias_relu.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/b2b_conv2d_run.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/b2b_conv2d_run.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/b2b_gemm_run.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/b2b_gemm_run.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/b2b_interleaved_conv2d_run.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/b2b_interleaved_conv2d_run.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/b2b_interleaved_gemm_run.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/b2b_interleaved_gemm_run.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/device/b2b_gemm.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/device/b2b_gemm.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/device/b2b_implicit_gemm_convolution.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/device/b2b_implicit_gemm_convolution.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm75_rf.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm75_rf.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm75_shmem.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm75_shmem.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm80_rf.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm80_rf.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm80_shmem.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_f16_sm80_shmem.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm75_rf.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm75_rf.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm75_shmem.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm75_shmem.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm80_rf.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm80_rf.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm80_shmem.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_convs_s8_sm80_shmem.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm75_rf.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm75_rf.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm75_shmem.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm75_shmem.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm80_rf.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm80_rf.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm80_shmem.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_f16_sm80_shmem.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm75_rf.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm75_rf.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm75_shmem.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm75_shmem.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm80_rf.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm80_rf.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm80_shmem.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/fused_two_gemms_s8_sm80_shmem.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/kernel/b2b_gemm.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/kernel/b2b_gemm.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/kernel/b2b_implicit_gemm_convolution.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/kernel/b2b_implicit_gemm_convolution.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_sm75.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_sm75.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_sm80.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_sm80.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_smem_accumulator_sm75.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_smem_accumulator_sm75.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_smem_accumulator_sm80.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_conv2d_fprop_smem_accumulator_sm80.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_gemm.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_gemm.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_gemm_smem_accumulator.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/kernel/default_b2b_gemm_smem_accumulator.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/reference/device/tensor_scale_bias.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/reference/device/tensor_scale_bias.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/test_run.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/test_run.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_multistage.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_multistage.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_multistage_smem_accumulator.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_multistage_smem_accumulator.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_pipelined.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_pipelined.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -317,15 +317,15 @@
     ++this->warp_tile_iterator_B0_;
 
     Operator0 warp_mma0;
 
     int smem_write_stage_idx = 1;
 
     // Issue loads during the first warp-level matrix multiply-add *AFTER* issuing 
-    // shared memory loads (which have the tighest latency requirement).
+    // shared memory loads (which have the tightest latency requirement).
 
     //
     // Mainloop
     //
 
     // Note: The main loop does not support Base::kWarpGemmIterations == 2.
     CUTLASS_GEMM_LOOP
@@ -457,15 +457,15 @@
     Operator1 warp_mma1;
 
     smem_write_stage_idx = 1;
     
     int gemm_k_iterations_1 = FragmentIteratorA1::Policy::kIterations / Base::kWarpGemmIterations1;
 
     // Issue loads during the first warp-level matrix multiply-add *AFTER* issuing 
-    // shared memory loads (which have the tighest latency requirement).
+    // shared memory loads (which have the tightest latency requirement).
 
     //
     // Mainloop
     //
 
     // Note: The main loop does not support Base::kWarpGemmIterations == 2.
     CUTLASS_PRAGMA_UNROLL
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_pipelined_smem_accumulator.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_implicit_gemm_pipelined_smem_accumulator.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -337,15 +337,15 @@
     ++this->warp_tile_iterator_B0_;
 
     Operator0 warp_mma0;
 
     int smem_write_stage_idx = 1;
 
     // Issue loads during the first warp-level matrix multiply-add *AFTER* issuing 
-    // shared memory loads (which have the tighest latency requirement).
+    // shared memory loads (which have the tightest latency requirement).
 
     //
     // Mainloop
     //
 
     // Note: The main loop does not support Base::kWarpGemmIterations == 2.
     CUTLASS_GEMM_LOOP
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_base.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_base.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_base_smem_accumulator.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_base_smem_accumulator.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_multistage.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_multistage.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -195,39 +195,39 @@
                   "The pipelined structure requires at least two warp-level "
                   "GEMM operations.");
     static_assert(Base::kWarpGemmIterations1 > 1,
                   "The pipelined structure requires at least two warp-level "
                   "GEMM operations.");
 
     /// Number of cp.async instructions to load one stage of operand A
-    static int const TBLDGSTSIterationsA0 =
+    static int const TBLoadIterationsA0 =
         IteratorA0::ThreadMap::Iterations::kCount;
 
     /// Number of cp.async instructions to load one stage of operand B
-    static int const TBLDGSTSIterationsB0 =
+    static int const TBLoadIterationsB0 =
         IteratorB0::ThreadMap::Iterations::kCount;
 
     /// Number of cp.async instructions to load one stage of operand B
-    static int const TBLDGSTSIterationsB1 =
+    static int const TBLoadIterationsB1 =
         IteratorB1::ThreadMap::Iterations::kCount;
 
     /// Number of stages
     static int const kStages = Stages;
 
     /// Number of cp.async instructions to load on group of operand A
     static int const kAccessesPerGroupA0 =
-        (TBLDGSTSIterationsA0 + Base::kWarpGemmIterations0 - 1) / Base::kWarpGemmIterations0;
+        (TBLoadIterationsA0 + Base::kWarpGemmIterations0 - 1) / Base::kWarpGemmIterations0;
 
     /// Number of cp.async instructions to load on group of operand B
     static int const kAccessesPerGroupB0 =
-        (TBLDGSTSIterationsB0 + Base::kWarpGemmIterations0 - 1) / Base::kWarpGemmIterations0;
+        (TBLoadIterationsB0 + Base::kWarpGemmIterations0 - 1) / Base::kWarpGemmIterations0;
 
     /// Number of cp.async instructions to load on group of operand B
     static int const kAccessesPerGroupB1 =
-        (TBLDGSTSIterationsB1 + Base::kWarpGemmIterations1 - 1) / Base::kWarpGemmIterations1;
+        (TBLoadIterationsB1 + Base::kWarpGemmIterations1 - 1) / Base::kWarpGemmIterations1;
   };
 
  private:
 
   using WarpLoadedFragmentA0 = typename Operator0::FragmentA;
   using WarpLoadedFragmentB0 = typename Operator0::FragmentB;
   /// Warp Fragment of operand A1 loaded from accmulator tile
@@ -300,18 +300,18 @@
   CUTLASS_DEVICE
   void copy_tiles_and_advance_0(IteratorA0 &iterator_A0, IteratorB0 &iterator_B0,
                               int group_start_A0 = 0, int group_start_B0 = 0) {
     iterator_A0.set_iteration_index(group_start_A0 *
                                    IteratorA0::kAccessesPerVector);
     this->smem_iterator_A0_.set_iteration_index(group_start_A0);
 
-    // LDGSTS for operand A
+    // Load for operand A
     CUTLASS_PRAGMA_UNROLL
     for (int j = 0; j < Detail::kAccessesPerGroupA0; ++j) {
-      if (group_start_A0 + j < Detail::TBLDGSTSIterationsA0) {
+      if (group_start_A0 + j < Detail::TBLoadIterationsA0) {
         typename IteratorA0::AccessType *dst_ptr =
             reinterpret_cast<typename IteratorA0::AccessType *>(
                 this->smem_iterator_A0_.get());
 
         int const kSrcBytes = sizeof_bits<typename IteratorA0::Element>::value *
                               IteratorA0::ThreadMap::kElementsPerAccess /
                               IteratorA0::kAccessesPerVector / 8;
@@ -330,18 +330,18 @@
       }
     }
 
     iterator_B0.set_iteration_index(group_start_B0 *
                                    IteratorB0::kAccessesPerVector);
     this->smem_iterator_B0_.set_iteration_index(group_start_B0);
 
-    // LDGSTS for operand B
+    // Load for operand B
     CUTLASS_PRAGMA_UNROLL
     for (int j = 0; j < Detail::kAccessesPerGroupB0; ++j) {
-      if (group_start_B0 + j < Detail::TBLDGSTSIterationsB0) {
+      if (group_start_B0 + j < Detail::TBLoadIterationsB0) {
         typename IteratorB0::AccessType *dst_ptr =
             reinterpret_cast<typename IteratorB0::AccessType *>(
                 this->smem_iterator_B0_.get());
 
         int const kSrcBytes = sizeof_bits<typename IteratorB0::Element>::value *
                               IteratorB0::ThreadMap::kElementsPerAccess /
                               IteratorB0::kAccessesPerVector / 8;
@@ -363,18 +363,18 @@
   CUTLASS_DEVICE
   void copy_tiles_and_advance_1(IteratorB1 &iterator_B1,
                               int group_start_B1 = 0) {
     iterator_B1.set_iteration_index(group_start_B1 *
                                    IteratorB1::kAccessesPerVector);
     this->smem_iterator_B1_.set_iteration_index(group_start_B1);
 
-    // LDGSTS for operand B
+    // Load for operand B
     CUTLASS_PRAGMA_UNROLL
     for (int j = 0; j < Detail::kAccessesPerGroupB1; ++j) {
-      if (group_start_B1 + j < Detail::TBLDGSTSIterationsB1) {
+      if (group_start_B1 + j < Detail::TBLoadIterationsB1) {
         typename IteratorB1::AccessType *dst_ptr =
             reinterpret_cast<typename IteratorB1::AccessType *>(
                 this->smem_iterator_B1_.get());
 
         int const kSrcBytes = sizeof_bits<typename IteratorB1::Element>::value *
                               IteratorB1::ThreadMap::kElementsPerAccess /
                               IteratorB1::kAccessesPerVector / 8;
@@ -426,17 +426,17 @@
 
       iterator_A0.clear_mask(gemm_k_iterations_0 == 0);
       iterator_B0.clear_mask(gemm_k_iterations_0 == 0);
 
       iterator_A0.set_iteration_index(0);
       this->smem_iterator_A0_.set_iteration_index(0);
 
-      // LDGSTS for operand A
+      // Load for operand A
       CUTLASS_PRAGMA_UNROLL
-      for (int j = 0; j < Detail::TBLDGSTSIterationsA0; ++j) {
+      for (int j = 0; j < Detail::TBLoadIterationsA0; ++j) {
         typename IteratorA0::AccessType *dst_ptr =
             reinterpret_cast<typename IteratorA0::AccessType *>(
                 this->smem_iterator_A0_.get());
 
         CUTLASS_PRAGMA_UNROLL
         for (int v = 0; v < IteratorA0::kAccessesPerVector; ++v) {
           int const kSrcBytes =
@@ -454,17 +454,17 @@
 
         ++this->smem_iterator_A0_;
       }
 
       iterator_B0.set_iteration_index(0);
       this->smem_iterator_B0_.set_iteration_index(0);
 
-      // LDGSTS for operand B
+      // Load for operand B
       CUTLASS_PRAGMA_UNROLL
-      for (int j = 0; j < Detail::TBLDGSTSIterationsB0; ++j) {
+      for (int j = 0; j < Detail::TBLoadIterationsB0; ++j) {
         typename IteratorB0::AccessType *dst_ptr =
             reinterpret_cast<typename IteratorB0::AccessType *>(
                 this->smem_iterator_B0_.get());
 
         CUTLASS_PRAGMA_UNROLL
         for (int v = 0; v < IteratorB0::kAccessesPerVector; ++v) {
           int const kSrcBytes =
@@ -670,17 +670,17 @@
          ++stage, --gemm_k_iterations_1) {
 
       iterator_B1.clear_mask(gemm_k_iterations_1 == 0);
 
       iterator_B1.set_iteration_index(0);
       this->smem_iterator_B1_.set_iteration_index(0);
 
-      // LDGSTS for operand B
+      // Load for operand B
       CUTLASS_PRAGMA_UNROLL
-      for (int j = 0; j < Detail::TBLDGSTSIterationsB1; ++j) {
+      for (int j = 0; j < Detail::TBLoadIterationsB1; ++j) {
         typename IteratorB1::AccessType *dst_ptr =
             reinterpret_cast<typename IteratorB1::AccessType *>(
                 this->smem_iterator_B1_.get());
 
         CUTLASS_PRAGMA_UNROLL
         for (int v = 0; v < IteratorB1::kAccessesPerVector; ++v) {
           int const kSrcBytes =
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_multistage_smem_accumulator.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_multistage_smem_accumulator.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -201,39 +201,39 @@
                   "The pipelined structure requires at least two warp-level "
                   "GEMM operations.");
     static_assert(Base::kWarpGemmIterations1 > 1,
                   "The pipelined structure requires at least two warp-level "
                   "GEMM operations.");
 
     /// Number of cp.async instructions to load one stage of operand A
-    static int const TBLDGSTSIterationsA0 =
+    static int const TBLoadIterationsA0 =
         IteratorA0::ThreadMap::Iterations::kCount;
 
     /// Number of cp.async instructions to load one stage of operand B
-    static int const TBLDGSTSIterationsB0 =
+    static int const TBLoadIterationsB0 =
         IteratorB0::ThreadMap::Iterations::kCount;
 
     /// Number of cp.async instructions to load one stage of operand B
-    static int const TBLDGSTSIterationsB1 =
+    static int const TBLoadIterationsB1 =
         IteratorB1::ThreadMap::Iterations::kCount;
 
     /// Number of stages
     static int const kStages = Stages;
 
     /// Number of cp.async instructions to load on group of operand A
     static int const kAccessesPerGroupA0 =
-        (TBLDGSTSIterationsA0 + Base::kWarpGemmIterations0 - 1) / Base::kWarpGemmIterations0;
+        (TBLoadIterationsA0 + Base::kWarpGemmIterations0 - 1) / Base::kWarpGemmIterations0;
 
     /// Number of cp.async instructions to load on group of operand B
     static int const kAccessesPerGroupB0 =
-        (TBLDGSTSIterationsB0 + Base::kWarpGemmIterations0 - 1) / Base::kWarpGemmIterations0;
+        (TBLoadIterationsB0 + Base::kWarpGemmIterations0 - 1) / Base::kWarpGemmIterations0;
 
     /// Number of cp.async instructions to load on group of operand B
     static int const kAccessesPerGroupB1 =
-        (TBLDGSTSIterationsB1 + Base::kWarpGemmIterations1 - 1) / Base::kWarpGemmIterations1;
+        (TBLoadIterationsB1 + Base::kWarpGemmIterations1 - 1) / Base::kWarpGemmIterations1;
   };
 
  private:
 
   using WarpLoadedFragmentA0 = typename Operator0::FragmentA;
   using WarpLoadedFragmentB0 = typename Operator0::FragmentB;
   using WarpLoadedFragmentA1 = typename Operator1::FragmentA;
@@ -323,18 +323,18 @@
   CUTLASS_DEVICE
   void copy_tiles_and_advance_0(IteratorA0 &iterator_A0, IteratorB0 &iterator_B0,
                               int group_start_A0 = 0, int group_start_B0 = 0) {
     iterator_A0.set_iteration_index(group_start_A0 *
                                    IteratorA0::kAccessesPerVector);
     this->smem_iterator_A0_.set_iteration_index(group_start_A0);
 
-    // LDGSTS for operand A
+    // cp.async for operand A
     CUTLASS_PRAGMA_UNROLL
     for (int j = 0; j < Detail::kAccessesPerGroupA0; ++j) {
-      if (group_start_A0 + j < Detail::TBLDGSTSIterationsA0) {
+      if (group_start_A0 + j < Detail::TBLoadIterationsA0) {
         typename IteratorA0::AccessType *dst_ptr =
             reinterpret_cast<typename IteratorA0::AccessType *>(
                 this->smem_iterator_A0_.get());
 
         int const kSrcBytes = sizeof_bits<typename IteratorA0::Element>::value *
                               IteratorA0::ThreadMap::kElementsPerAccess /
                               IteratorA0::kAccessesPerVector / 8;
@@ -353,18 +353,18 @@
       }
     }
 
     iterator_B0.set_iteration_index(group_start_B0 *
                                    IteratorB0::kAccessesPerVector);
     this->smem_iterator_B0_.set_iteration_index(group_start_B0);
 
-    // LDGSTS for operand B
+    // cp.async for operand B
     CUTLASS_PRAGMA_UNROLL
     for (int j = 0; j < Detail::kAccessesPerGroupB0; ++j) {
-      if (group_start_B0 + j < Detail::TBLDGSTSIterationsB0) {
+      if (group_start_B0 + j < Detail::TBLoadIterationsB0) {
         typename IteratorB0::AccessType *dst_ptr =
             reinterpret_cast<typename IteratorB0::AccessType *>(
                 this->smem_iterator_B0_.get());
 
         int const kSrcBytes = sizeof_bits<typename IteratorB0::Element>::value *
                               IteratorB0::ThreadMap::kElementsPerAccess /
                               IteratorB0::kAccessesPerVector / 8;
@@ -386,18 +386,18 @@
   CUTLASS_DEVICE
   void copy_tiles_and_advance_1(IteratorB1 &iterator_B1,
                               int group_start_B1 = 0) {
     iterator_B1.set_iteration_index(group_start_B1 *
                                    IteratorB1::kAccessesPerVector);
     this->smem_iterator_B1_.set_iteration_index(group_start_B1);
 
-    // LDGSTS for operand B
+    // cp.async for operand B
     CUTLASS_PRAGMA_UNROLL
     for (int j = 0; j < Detail::kAccessesPerGroupB1; ++j) {
-      if (group_start_B1 + j < Detail::TBLDGSTSIterationsB1) {
+      if (group_start_B1 + j < Detail::TBLoadIterationsB1) {
         typename IteratorB1::AccessType *dst_ptr =
             reinterpret_cast<typename IteratorB1::AccessType *>(
                 this->smem_iterator_B1_.get());
 
         int const kSrcBytes = sizeof_bits<typename IteratorB1::Element>::value *
                               IteratorB1::ThreadMap::kElementsPerAccess /
                               IteratorB1::kAccessesPerVector / 8;
@@ -449,17 +449,17 @@
 
       iterator_A0.clear_mask(gemm_k_iterations_0 == 0);
       iterator_B0.clear_mask(gemm_k_iterations_0 == 0);
 
       iterator_A0.set_iteration_index(0);
       this->smem_iterator_A0_.set_iteration_index(0);
 
-      // LDGSTS for operand A
+      // cp.async for operand A
       CUTLASS_PRAGMA_UNROLL
-      for (int j = 0; j < Detail::TBLDGSTSIterationsA0; ++j) {
+      for (int j = 0; j < Detail::TBLoadIterationsA0; ++j) {
         typename IteratorA0::AccessType *dst_ptr =
             reinterpret_cast<typename IteratorA0::AccessType *>(
                 this->smem_iterator_A0_.get());
 
         CUTLASS_PRAGMA_UNROLL
         for (int v = 0; v < IteratorA0::kAccessesPerVector; ++v) {
           int const kSrcBytes =
@@ -477,17 +477,17 @@
 
         ++this->smem_iterator_A0_;
       }
 
       iterator_B0.set_iteration_index(0);
       this->smem_iterator_B0_.set_iteration_index(0);
 
-      // LDGSTS for operand B
+      // cp.async for operand B
       CUTLASS_PRAGMA_UNROLL
-      for (int j = 0; j < Detail::TBLDGSTSIterationsB0; ++j) {
+      for (int j = 0; j < Detail::TBLoadIterationsB0; ++j) {
         typename IteratorB0::AccessType *dst_ptr =
             reinterpret_cast<typename IteratorB0::AccessType *>(
                 this->smem_iterator_B0_.get());
 
         CUTLASS_PRAGMA_UNROLL
         for (int v = 0; v < IteratorB0::kAccessesPerVector; ++v) {
           int const kSrcBytes =
@@ -685,17 +685,17 @@
          ++stage, --gemm_k_iterations_1) {
 
       iterator_B1.clear_mask(gemm_k_iterations_1 == 0);
 
       iterator_B1.set_iteration_index(0);
       this->smem_iterator_B1_.set_iteration_index(0);
 
-      // LDGSTS for operand B
+      // cp.async for operand B
       CUTLASS_PRAGMA_UNROLL
-      for (int j = 0; j < Detail::TBLDGSTSIterationsB1; ++j) {
+      for (int j = 0; j < Detail::TBLoadIterationsB1; ++j) {
         typename IteratorB1::AccessType *dst_ptr =
             reinterpret_cast<typename IteratorB1::AccessType *>(
                 this->smem_iterator_B1_.get());
 
         CUTLASS_PRAGMA_UNROLL
         for (int v = 0; v < IteratorB1::kAccessesPerVector; ++v) {
           int const kSrcBytes =
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_pipelined.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_pipelined.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -321,15 +321,15 @@
     int smem_write_stage_idx = 1;
 
     // Avoid reading out of bounds
     iterator_A.clear_mask(gemm_k_iterations_0 <= 1);
     iterator_B0.clear_mask(gemm_k_iterations_0 <= 1);
 
     // Issue loads during the first warp-level matrix multiply-add *AFTER* issuing 
-    // shared memory loads (which have the tighest latency requirement).
+    // shared memory loads (which have the tightest latency requirement).
 
     //
     // Mainloop
     //
 
     // Note: The main loop does not support Base::kWarpGemmIterations == 2.
     CUTLASS_GEMM_LOOP
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_pipelined_smem_accumulator.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/b2b_mma_pipelined_smem_accumulator.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -342,15 +342,15 @@
     int smem_write_stage_idx = 1;
 
     // Avoid reading out of bounds
     iterator_A.clear_mask(gemm_k_iterations_0 <= 1);
     iterator_B0.clear_mask(gemm_k_iterations_0 <= 1);
 
     // Issue loads during the first warp-level matrix multiply-add *AFTER* issuing 
-    // shared memory loads (which have the tighest latency requirement).
+    // shared memory loads (which have the tightest latency requirement).
 
     //
     // Mainloop
     //
 
     // Note: The main loop does not support Base::kWarpGemmIterations == 2.
     CUTLASS_GEMM_LOOP
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/default_b2b_mma.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/default_b2b_mma.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/default_b2b_mma_smem_accumulator.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/13_two_tensor_op_fusion/threadblock/default_b2b_mma_smem_accumulator.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/14_ampere_tf32_tensorop_gemm/ampere_tf32_tensorop_gemm.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/14_ampere_tf32_tensorop_gemm/ampere_tf32_tensorop_gemm.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/15_ampere_sparse_tensorop_gemm/ampere_sparse_tensorop_gemm.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/15_ampere_sparse_tensorop_gemm/ampere_sparse_tensorop_gemm.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/16_ampere_tensorop_conv2dfprop/ampere_tensorop_conv2dfprop.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/16_ampere_tensorop_conv2dfprop/ampere_tensorop_conv2dfprop.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -69,15 +69,15 @@
 computation of linear combination (alpha * X + beta * C).
 
 Now that we setup the properties of data, we have to setup properties of computation.
 
 Second, we create template variables of tile sizes for thread-block, warp and mma-op to 128x128x64,
 64x64x64, 16x8x16 (MxNxK) respectively. When passed to instantiate CUTLASS Implicit GEMM kernel, it
 internally deduces the amount of threads needed per thread-block, amount of shared memory, storing
-data in bank-conflict free manner, and ton of other variables required to compose, intialize and
+data in bank-conflict free manner, and ton of other variables required to compose, initialize and
 launch a high performance Implicit GEMM kernel. This is the beauty of CUTLASS, it relieves developer
 from understanding and coding complicated hardware optimizations which can easily go wrong.
 
 CUTLASS also supports multiple MMA pipelines in a threadblock. What are MMA pipelines? MMA pipelines
 constitute the whole process of loading input data from global memory to shared memory, loading data
 from shared memory to registers, doing matrix multiplication, store to global memory. The below flow
 sequence shows a typical mma multistage pipeline.
@@ -91,24 +91,24 @@
 
 There are few more template variables initialized such as, which threadblock tile of output matrix
 is done which threadblock launched on an SM, CUDA SM architecture of GPU you want to run on.
 
 These are all put together to create a template variable which describes CUTLASS Implicit GEMM
 kernel using cutlass::conv::device::ImplicitGemm template.
 
-The next step is to intialize physical data, instantiate and initialize CUTLASS kernel and run it.
+The next step is to initialize physical data, instantiate and initialize CUTLASS kernel and run it.
 We use CUTLASS utilities to initialize, fill, compare tensors as they are simple and doesn't come
 in the way of learning CUTLASS.
 
 Once all the tensors are initialized and filled with data, create arguments tuple to launch CUTLASS
 kernel which takes problem size (N = 1, H = 64, W = 64, C = 128), filter size (K = 64,
 R = 3, S = 3, C = 128 ), padding, strides, dilation, tensors, alpha, beta and the
 important one, split k-dimension factor. Along with that, we query CUTLASS if any scratch-space
 memory required by the kernel we instantiated. If yes, we create it and pass it along with other
-arguments created to intialize CUTLASS kernel then, the kernel is launched.
+arguments created to initialize CUTLASS kernel then, the kernel is launched.
 
 In this example, we later on launch a reference convolution kernel (from CUTLASS utilities) to
 compare if the output from CUTLASS kernel is same as the reference implicit GEMM kernel.
 */
 
 #include <iostream>
 #include <fstream>
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/17_fprop_per_channel_bias/fprop_per_channel_bias.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/17_fprop_per_channel_bias/fprop_per_channel_bias.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/18_ampere_fp64_tensorop_affine2_gemm/ampere_fp64_tensorop_affine2_gemm.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/18_ampere_fp64_tensorop_affine2_gemm/ampere_fp64_tensorop_affine2_gemm.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/19_tensorop_canonical/tensorop_canonical.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/19_tensorop_canonical/tensorop_canonical.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/20_simt_canonical/simt_canonical.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/20_simt_canonical/simt_canonical.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/21_quaternion_gemm/quaternion_gemm.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/21_quaternion_gemm/quaternion_gemm.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/22_quaternion_conv/quaternion_conv.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/22_quaternion_conv/quaternion_conv.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/23_ampere_gemm_operand_reduction_fusion/ampere_gemm_operand_reduction_fusion.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/23_ampere_gemm_operand_reduction_fusion/ampere_gemm_operand_reduction_fusion.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -32,15 +32,15 @@
 /**
 The example demenstrates how to reduce one of the operands of the GEMM along the k-dimension when
 computing GEMM.  So the output also contains either a Mx1 or 1XN vector.  It only works with Ampere
 16x8x16 FP16/BF16 tensor cores, though it is not difficult to apply to other Turing/Ampere tensor
 core instructions.
 
 Most of the reduction is done in gemm/warp level, see gemm/warp/mma_with_reduction_tensor_op.h
-A few bit of reduction is done in the epilouge before storing the vector, see
+A few bit of reduction is done in the epilogue before storing the vector, see
 epilogue/threadblock/epilogue_gemm_k_reduction.h 
 */
 
 #include <iostream>
 #include <fstream>
 #include <sstream>
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/24_gemm_grouped/gemm_grouped.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/24_gemm_grouped/gemm_grouped.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -1483,16 +1483,16 @@
 
   using LayoutA = cutlass::layout::ColumnMajor;
   using LayoutB = cutlass::layout::ColumnMajor;
   using LayoutC = cutlass::layout::ColumnMajor;
 
   // Gemm operator cutlass_tensorop_f16_s16816gemm_f16_128x128_32x4_nt_align8
   using GemmBatched = cutlass::gemm::device::GemmUniversal<
-    cutlass::half_t, LayoutA,
-    cutlass::half_t, LayoutB,
+    ElementA, LayoutA,
+    ElementB, LayoutB,
     ElementOutput,   LayoutC,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm80,
     cutlass::gemm::GemmShape<128, 128, 32>,
     cutlass::gemm::GemmShape<64, 64, 32>,
     cutlass::gemm::GemmShape<16, 8, 16>,
@@ -1506,19 +1506,19 @@
     4
   >;
 
   // Define a grouped GEMM kernel with all template parameters set except
   // for scheduling mode. This will be used as the template for all scheduling
   // modes executed.
   using GemmKernel = typename cutlass::gemm::kernel::DefaultGemmGrouped<
-    cutlass::half_t, 
+    ElementA,
     LayoutA,
     cutlass::ComplexTransform::kNone,
     8,
-    cutlass::half_t,
+    ElementB,
     LayoutB,
     cutlass::ComplexTransform::kNone,
     8,
     ElementOutput, LayoutC,
     ElementAccumulator, 
     cutlass::arch::OpClassTensorOp, 
     cutlass::arch::Sm80,
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/25_ampere_fprop_mainloop_fusion/ampere_3d_fprop_mainloop_fusion.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/25_ampere_fprop_mainloop_fusion/ampere_3d_fprop_mainloop_fusion.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/25_ampere_fprop_mainloop_fusion/ampere_fprop_mainloop_fusion.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/25_ampere_fprop_mainloop_fusion/ampere_fprop_mainloop_fusion.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/26_ampere_wgrad_mainloop_fusion/ampere_wgrad_mainloop_fusion.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/26_ampere_wgrad_mainloop_fusion/ampere_wgrad_mainloop_fusion.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/27_ampere_3xtf32_fast_accurate_tensorop_gemm/27_ampere_3xtf32_fast_accurate_tensorop_gemm.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/27_ampere_3xtf32_fast_accurate_tensorop_gemm/27_ampere_3xtf32_fast_accurate_tensorop_gemm.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/28_ampere_3xtf32_fast_accurate_tensorop_fprop/ampere_3xtf32_fast_accurate_tensorop_fprop.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/28_ampere_3xtf32_fast_accurate_tensorop_fprop/ampere_3xtf32_fast_accurate_tensorop_fprop.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/29_ampere_3xtf32_fast_accurate_tensorop_complex_gemm/29_ampere_3xtf32_fast_accurate_tensorop_complex_gemm.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/29_ampere_3xtf32_fast_accurate_tensorop_complex_gemm/29_ampere_3xtf32_fast_accurate_tensorop_complex_gemm.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/30_wgrad_split_k/30_wgrad_split_k.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/30_wgrad_split_k/30_wgrad_split_k.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/31_basic_syrk/basic_syrk.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/31_basic_syrk/basic_syrk.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/32_basic_trmm/basic_trmm.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/32_basic_trmm/basic_trmm.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/33_ampere_3xtf32_tensorop_symm/ampere_3xtf32_tensorop_symm.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/33_ampere_3xtf32_tensorop_symm/ampere_3xtf32_tensorop_symm.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/34_transposed_conv2d/34_transposed_conv2d.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/34_transposed_conv2d/34_transposed_conv2d.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/35_gemm_softmax/gemm_softmax.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/35_gemm_softmax/gemm_softmax.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/35_gemm_softmax/gemm_with_epilogue_visitor.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/35_gemm_softmax/gemm_with_epilogue_visitor.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/35_gemm_softmax/gemm_with_softmax.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/35_gemm_softmax/gemm_with_softmax.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/36_gather_scatter_fusion/gather_scatter_fusion.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/36_gather_scatter_fusion/gather_scatter_fusion.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/37_gemm_layernorm_gemm_fusion/gemm_layernorm.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/37_gemm_layernorm_gemm_fusion/gemm_layernorm.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/37_gemm_layernorm_gemm_fusion/gemm_with_epilogue_visitor.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/37_gemm_layernorm_gemm_fusion/gemm_with_epilogue_visitor.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/37_gemm_layernorm_gemm_fusion/gemm_with_layernorm.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/37_gemm_layernorm_gemm_fusion/gemm_with_layernorm.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -31,15 +31,15 @@
 
 /*! \file
     \brief A file contains all functioning classes needed by GemmLayernorm.
 
     GemmLayernorm example =  GEMM0 with partial reduction fused in epilogue (EpilogueVisitorLayerNorm)
                           +  lightweight full reduction kernel (ApplyFinalReduction)
                           +  GEMM1 with elemenwise operations fused in mainloop (GemmLayernormMainloopFusion)
-                          
+
 */
 
 #pragma once
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 #include <cmath>
@@ -73,29 +73,29 @@
 
 template <
   typename ElementVariance_,
   typename ElementMean_,
   typename ElementLayernormCompute_,
   typename ElementOutput,
   typename ThreadblockShape_,
-  bool IsShiftedVariance_ = false 
+  bool IsShiftedVariance_ = false
 >
 class ApplyFinalReduction {
 public:
 
   using ElementVariance = ElementVariance_;
   using ElementMean = ElementMean_;
   using ElementLayernormCompute = ElementLayernormCompute_;
   using ThreadblockShape = ThreadblockShape_;
 
   // Pre-processing has ensured the layout equivelent to RowMajor
   using Layout = cutlass::layout::RowMajor;
 
   using TensorVariance = TensorRef<ElementVariance, Layout>;
-  using TensorMean = TensorRef<ElementMean, Layout>;  
+  using TensorMean = TensorRef<ElementMean, Layout>;
 
   static bool const kIsShiftedVariance = IsShiftedVariance_;
 
   //
   // Arguments
   //
 
@@ -459,15 +459,15 @@
       CUTLASS_PRAGMA_UNROLL
       for (int iter_idx = 0; iter_idx < kIterations; ++iter_idx) {
         int step_offset = iter_idx * OutputTileIterator::Shape::kRow;
         CUTLASS_PRAGMA_UNROLL
         for (int rid = 0; rid < kRowIterations; ++rid) {
           int row_step_offset = rid * kDeltaRow;
           int row_offset = thread_offset_row_base + step_offset + row_step_offset;
-          bool is_load = (row_offset < extent_.row());  
+          bool is_load = (row_offset < extent_.row());
           shift_k_frag_[iter_idx * kRowIterations + rid] = load_shift_k_(row_offset, is_load);
         }
 
       }
 
     }
 
@@ -500,17 +500,17 @@
     int frag_idx,
     AccumulatorFragment const &accum) {
 
     using Mul = cutlass::multiplies<ElementLayernormCompute>;
     using Minus = cutlass::minus<ElementLayernormCompute>;
     using Exp   = cutlass::fast_exp_op<ElementLayernormCompute>;
 
-    Minus     minus;
-    Mul       mul;
-    Exp       exponential;
+    [[maybe_unused]] Minus minus;
+    [[maybe_unused]] Mul   mul;
+    [[maybe_unused]] Exp   exponential;
 
     LayernormFragment result;
 
     thread_offset_ =
       iterator_D_.thread_start() +
       OutputTileIterator::ThreadMap::iteration_offset(frag_idx);
 
@@ -601,24 +601,24 @@
   }
 
 private:
 
   CUTLASS_DEVICE
   ElementLayernormCompute load_shift_k_(int row_offset, bool is_load) {
     using ConvertShiftK = cutlass::NumericConverter<ElementLayernormCompute, ElementOutput>;
-    ConvertShiftK convert_shift_k;    
+    ConvertShiftK convert_shift_k;
     ElementOutput shift_k_val;
 
     // Computes the address to load shift_k element
     ElementOutput *curr_ptr_shift_k = params_.ptr_Shifted_K + row_offset;
     // Conditionally loads from global memory
     arch::global_load<ElementOutput, sizeof(ElementOutput)>(shift_k_val, (void *)curr_ptr_shift_k, is_load);
     // Converts data type to return
     ElementLayernormCompute converted_shift_k_val = convert_shift_k(shift_k_val);
-    
+
     return converted_shift_k_val;
   }
 
   CUTLASS_DEVICE
   ElementLayernormCompute square_sum_accumulator_(LayernormFragment const &accum) {
     ElementLayernormCompute sum_ = ElementLayernormCompute(0);
 
@@ -685,46 +685,46 @@
 public:
 
   ///////////////////////////////////////////////////////////////////////////////////////////////
 
   //
   // Type definitions
   //
-  
+
   static bool const kInternalTranspose = cutlass::platform::is_same<LayoutOutput_, cutlass::layout::ColumnMajor>::value;
   static bool const kIsShiftedVariance = IsShiftedVariance_;
 
   // These is mandatory layout.
   using LayoutInputScaleBias = cutlass::layout::RowMajor;
 
   // These are mandatory data types.
   using ElementLayernormCompute = float;
   using ElementInputScaleBias = cutlass::half_t;
 
   // These are mandatory params required by mainloop fusion
   using OperatorClass       = cutlass::arch::OpClassTensorOp;
   using ArchTag             = cutlass::arch::Sm80;
 
-  // These are mandatory layouts and data types 
+  // These are mandatory layouts and data types
   // that are inheritated from pre-defined params
-  
+
   using LayoutSumSqr = LayoutInputScaleBias;
   using LayoutSum = LayoutInputScaleBias;
 
   using ElementMean = ElementInputScaleBias;
-  using ElementVariance = ElementInputScaleBias;  
+  using ElementVariance = ElementInputScaleBias;
 
   ///////////////////////////////////////////////////////////////////////////////////////////////
 
   using LayoutInputA0 = LayoutInputA0_;
   using LayoutInputB0 = LayoutInputB0_;
   using LayoutInputA1 = LayoutOutput_;
   using LayoutInputB1 = LayoutOutput_;
   using LayoutOutputC0 = LayoutOutput_;
-  using LayoutOutputC1 = LayoutOutput_;  
+  using LayoutOutputC1 = LayoutOutput_;
 
   using ElementInputA0 = ElementInputA0_;
   using ElementInputB0 = ElementInputB0_;
   using ElementOutputC0 = ElementOutput_;
   using ElementCompute = ElementCompute_;
   using ElementInputB1 = ElementInputB0_;
 
@@ -743,15 +743,15 @@
   using WarpShape        = WarpShape_;
   using InstructionShape = InstructionShape_;
 
   static int const kStages0 = Stages0;
   static int const kStages1 = Stages1;
 
   using SwizzleThreadBlock = cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>;
-  
+
   ///////////////////////////////////////////////////////////////////////////////////////////////
 
   using MapArguments = cutlass::gemm::kernel::detail::MapArguments<
     ElementInputA0,
     LayoutInputA0,
     cutlass::ComplexTransform::kNone,
     128 / cutlass::sizeof_bits<ElementInputA0>::value,
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/38_syr2k_grouped/syr2k_grouped.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/38_syr2k_grouped/syr2k_grouped.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/39_gemm_permute/gemm_permute.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/39_gemm_permute/gemm_permute.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/attention_scaling_coefs_updater.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/attention_scaling_coefs_updater.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/default_fmha_grouped.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/default_fmha_grouped.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -46,17 +46,16 @@
 
 #include "cutlass/complex.h"
 #include "cutlass/layout/matrix.h"
 #include "cutlass/numeric_types.h"
 
 #include "fmha_grouped.h"
 #include "gemm_kernel_utils.h"
-#include "find_default_mma.h"
-#include "attention_scaling_coefs_updater.h"
-#include "mma_from_smem.h"
+#include "gemm/find_default_mma.h"
+#include "gemm/mma_from_smem.h"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace gemm {
 namespace kernel {
 
@@ -150,18 +149,18 @@
         Operator
         >::DefaultMma;
 
     using MmaCore = typename DefaultMma::MmaCore;
     using IteratorA = typename DefaultMma::IteratorA;
     using IteratorB = typename DefaultMma::IteratorB;
     using Mma = typename DefaultMma::ThreadblockMma;
-    using ScalingCoefsUpdater = typename DefaultAttentionScalingCoefsUpdater<
+    using AccumLambdaIterator = typename DefaultMmaAccumLambdaIterator<
         typename Mma::Operator::IteratorC,
         ElementAccumulator,
-        kWarpSize>::Updater;
+        kWarpSize>::Iterator;
 
     static_assert(MmaCore::WarpCount::kCount == kNumWarpsPerBlock, "");
 
     // Epilogue to store to shared-memory in a format that we can use later for
     // the second matmul
     using B2bGemm = typename cutlass::gemm::threadblock::B2bGemm<
         typename Mma::Operator::IteratorC,
@@ -236,15 +235,16 @@
         kStages,
         kSplitKSerial,
         Operator>;
 
     using DefaultMmaFromSmem =
         typename cutlass::gemm::threadblock::DefaultMmaFromSharedMemory<
             typename DefaultGemm::Mma,
-            typename MM0::AccumulatorSharedStorage>;
+            typename MM0::AccumulatorSharedStorage,
+            false>; // kScaleOperandA
 
     using Mma = typename DefaultMmaFromSmem::Mma;
     using IteratorB = typename Mma::IteratorB;
     using WarpCount = typename Mma::WarpCount;
     static_assert(WarpCount::kCount == kNumWarpsPerBlock, "");
 
     using DefaultEpilogue = typename DefaultGemm::Epilogue;
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/epilogue_pipelined.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/epilogue/epilogue_pipelined.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights
  *reserved. SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice,
  *this list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/epilogue_rescale_output.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/epilogue/epilogue_rescale_output.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/epilogue_thread_apply_logsumexp.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/epilogue/epilogue_thread_apply_logsumexp.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights
  *reserved. SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice,
  *this list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/find_default_mma.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/find_default_mma.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/fmha_grouped.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/fmha_grouped.h`

 * *Files 10% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -44,15 +44,26 @@
 
 #include "cutlass/layout/matrix.h"
 #include "cutlass/trace.h"
 #include "cutlass/gemm/kernel/gemm_transpose_operands.h"
 
 #include "fmha_grouped_problem_visitor.h"
 #include "gemm_kernel_utils.h"
-#include "epilogue_rescale_output.h"
+#include "gemm/mma_accum_lambda_iterator.h"
+#include "epilogue/epilogue_rescale_output.h"
+
+
+namespace {
+  static CUTLASS_DEVICE float atomicMaxFloat(float* addr, float value) {
+  // source: https://stackoverflow.com/a/51549250
+  return (value >= 0)
+      ? __int_as_float(atomicMax((int*)addr, __float_as_int(value)))
+      : __uint_as_float(atomicMin((unsigned int*)addr, __float_as_uint(value)));
+}
+}
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace gemm {
 namespace kernel {
 
@@ -124,14 +135,17 @@
   static int const kAlignmentV = 1;
 
   using ThreadblockShape = typename MM0::ThreadblockShape;
 
   static int const kQueriesPerBlock = ThreadblockShape::kM;
   static int const kKeysPerBlock = ThreadblockShape::kN;
 
+  static constexpr bool kSupportsDropout = false;
+  static constexpr bool kSupportsBias = false;
+
   /// Warp count (concept: GemmShape)
   using WarpCount = typename MM1::WarpCount;
   static int const kThreadsPerWarp = 32;
   static int const kThreadCount = kThreadsPerWarp * WarpCount::kCount;
 
   using ProblemVisitor = FMHAGroupedProblemVisitor<
                             ThreadblockShape,
@@ -164,48 +178,52 @@
     ElementOAccum ** ptr_O_accum;
 
     typename LayoutQ::Stride::LongIndex *ldq;
     typename LayoutK::Stride::LongIndex *ldk;
     typename LayoutP::Stride::LongIndex *ldv;
     typename LayoutO::Stride::LongIndex *ldo;
 
+    // Scale
+    ElementAccumulator scale;
+
     // Whether causal masking is to be performed
     bool causal;
 
     // Only used by device-level operator
     GemmCoord *host_problem_sizes;
 
     //
     // Methods
     //
 
     /// Default ctor
     CUTLASS_HOST_DEVICE
-    Arguments(): 
+    Arguments():
       problem_count(0),
-      threadblock_count(0), 
+      threadblock_count(0),
       ptr_Q(nullptr),
       ptr_K(nullptr),
       ptr_P(nullptr),
       ptr_V(nullptr),
       ptr_O(nullptr),
       ptr_O_accum(nullptr),
       ldq(nullptr),
       ldk(nullptr),
       ldv(nullptr),
       ldo(nullptr),
+      scale(0),
       causal(false),
       host_problem_sizes(nullptr)
     {
 
     }
 
     /// Ctor
     CUTLASS_HOST_DEVICE
-    Arguments(    
+    Arguments(
       GemmCoord *problem_sizes0,
       GemmCoord *problem_sizes1,
       int problem_count,
       int threadblock_count,
       ElementQ ** ptr_Q,
       ElementK ** ptr_K,
       ElementP ** ptr_P,
@@ -214,16 +232,17 @@
       ElementOAccum ** ptr_O_accum,
       typename LayoutQ::Stride::LongIndex *ldq,
       typename LayoutK::Stride::LongIndex *ldk,
       typename LayoutP::Stride::LongIndex *ldp,
       typename LayoutV::Stride::LongIndex *ldv,
       typename LayoutO::Stride::LongIndex *ldo,
       bool causal,
+      ElementAccumulator scale,
       GemmCoord *host_problem_sizes=nullptr
-    ): 
+    ):
       problem_sizes0(problem_sizes0),
       problem_sizes1(problem_sizes1),
       problem_count(problem_count),
       threadblock_count(threadblock_count),
       ptr_Q(ptr_Q),
       ptr_K(ptr_K),
       ptr_P(ptr_P),
@@ -231,14 +250,15 @@
       ptr_O(ptr_O),
       ptr_O_accum(kNeedsOutputAccumulatorBuffer ? ptr_O_accum : (accum_t**)ptr_O),
       ldq(ldq),
       ldk(ldk),
       ldv(ldv),
       ldo(ldo),
       causal(causal),
+      scale(scale),
       host_problem_sizes(host_problem_sizes)
     {
 
     }
 
     bool __host__ check_supported() {
       CHECK_ALIGNED_PTR(ptr_Q, kAlignmentQ);
@@ -269,14 +289,15 @@
     ElementOAccum ** ptr_O_accum;
 
     typename LayoutQ::Stride::LongIndex *ldq;
     typename LayoutK::Stride::LongIndex *ldk;
     typename LayoutP::Stride::LongIndex *ldv;
     typename LayoutO::Stride::LongIndex *ldo;
 
+    ElementAccumulator scale;
     bool causal;
 
     //
     // Methods
     //
 
     CUTLASS_HOST_DEVICE
@@ -287,15 +308,16 @@
       ptr_V(nullptr),
       ptr_O(nullptr),
       ptr_O_accum(nullptr),
       ldq(nullptr),
       ldk(nullptr),
       ldv(nullptr),
       ldo(nullptr),
-      causal(false)
+      causal(false),
+      scale(0)
     { }
 
     CUTLASS_HOST_DEVICE
     Params(Arguments const &args,
           void *workspace = nullptr,
           int tile_count = 0):
       problem_visitor(args.problem_sizes0, args.problem_sizes1, args.problem_count, workspace, tile_count),
@@ -306,15 +328,16 @@
       ptr_V(args.ptr_V),
       ptr_O(args.ptr_O),
       ptr_O_accum(kNeedsOutputAccumulatorBuffer ? args.ptr_O_accum : (accum_t**)args.ptr_O),
       ldq(args.ldq),
       ldk(args.ldk),
       ldv(args.ldv),
       ldo(args.ldo),
-      causal(args.causal)
+      causal(args.causal),
+      scale(args.scale)
     { 
 
     }
 
     CUTLASS_HOST_DEVICE
     void update(
       Arguments const &args,
@@ -333,14 +356,15 @@
       ptr_O = args.ptr_O;
       ptr_O_accum = kNeedsOutputAccumulatorBuffer ? args.ptr_O_accum : (accum_t**)args.ptr_O;
       ldq = args.ldq;
       ldk = args.ldk;
       ldv = args.ldv;
       ldo = args.ldo;
       causal = args.causal;
+      scale = args.scale;
     }
   };
 
   // Shared storage - depends on kernel params
   struct ScalingCoefs {
     cutlass::Array<ElementAccumulator, kQueriesPerBlock> m_prime;
     cutlass::Array<ElementAccumulator, kQueriesPerBlock> s_prime;
@@ -460,15 +484,15 @@
   }
 
   /// Executes one GEMM
   CUTLASS_DEVICE
   void operator()(Params const &params, SharedStorage &shared_storage) {
     auto& m_prime = shared_storage.m_prime;
     auto& s_prime = shared_storage.s_prime;
-    auto& si = shared_storage.after_mm0.si;
+    [[maybe_unused]] auto& si = shared_storage.after_mm0.si;
     auto& mi = shared_storage.mi;
 
     ProblemVisitor problem_visitor(
       params.problem_visitor,
       shared_storage.problem_visitor,
       blockIdx.x);
 
@@ -605,18 +629,18 @@
           iteratorC_tile_offset = {
               (warp_id() % MM0::Mma::WarpCount::kM),
               (warp_id() / MM0::Mma::WarpCount::kM)
             };
 
         // Mask out last if causal
         if (params.causal && num_keys - iter_key_start <= kKeysPerBlock) {
-          auto lane_offset = MM0::ScalingCoefsUpdater::get_lane_offset(
+          auto lane_offset = MM0::AccumLambdaIterator::get_lane_offset(
               lane_id(), warp_id(), iteratorC_tile_offset);
           int32_t last_col;
-          MM0::ScalingCoefsUpdater::iterateRows(
+          MM0::AccumLambdaIterator::iterateRows(
               lane_offset,
               [&](int accum_m) {
                 last_col = TileParams::query_start(threadblock_idx) + accum_m - iter_key_start;
               },
               [&](int accum_m, int accum_n, int idx) {
                 if (accum_n > last_col) {
                   accum[idx] =
@@ -627,33 +651,30 @@
         }
         DISPATCH_BOOL(iter_key_start == 0, kIsFirst, ([&] {
                 DISPATCH_BOOL(
                     num_keys - iter_key_start >= kKeysPerBlock,
                     kFullColumns,
                     ([&] {
                       // Update `mi` from accum stored in registers
-                      // Also updates `accum` with accum[i] <-
-                      // exp(accum[i] * scale
-                      // - mi)
-                      MM0::ScalingCoefsUpdater::update<
-                          kQueriesPerBlock,
+                      // Also does accum[i] <- exp(accum[i] - mi)
+                      iterative_softmax<
+                          typename MM0::Mma::Operator::IteratorC,
                           kFullColumns,
-                          kIsFirst,
-                          kKeepOutputInRF>(
+                          kIsFirst>(
                           accum_o,
                           accum,
                           mi,
                           m_prime,
                           s_prime,
                           lane_id(),
                           thread_id(),
                           warp_id(),
                           num_keys - iter_key_start,
                           iteratorC_tile_offset,
-                          1.0f / cutlass::fast_sqrt(float(problem_size0.k())));
+                          kSupportsBias ? 1.0f : params.scale);
                     }));
               }));
 
         // Output results to shared-memory
         int warp_idx_mn_0 = warp_id() %
             (MM0::Mma::Base::WarpCount::kM * MM0::Mma::Base::WarpCount::kN);
         auto output_tile_coords = cutlass::MatrixCoord{
@@ -824,14 +845,124 @@
         epilogue(rescale, dest_iter, accum_o);
       }
 
       // Next tile
       problem_visitor.advance(gridDim.x);
     }
   }
+
+  template <
+      typename WarpIteratorC,
+      bool kFullColumns,
+      bool kIsFirst>
+  CUTLASS_DEVICE static void iterative_softmax(
+      typename WarpIteratorC::Fragment& frag_o, // output so far
+      typename WarpIteratorC::Fragment& frag,
+      cutlass::Array<accum_t, kQueriesPerBlock>& mi,
+      cutlass::Array<accum_t, kQueriesPerBlock>& m_prime,
+      cutlass::Array<accum_t, kQueriesPerBlock>& s_prime,
+      int8_t lane_id,
+      int8_t thread_id,
+      int8_t warp_id,
+      int16_t max_col,
+      typename WarpIteratorC::TensorCoord const& tile_offset,
+      float scaling) {
+    /* Iterates on the accumulator and corresponding position on result matrix
+
+    (1) Update `mi[r]` to the max value of the row `r`
+    (2) In a second iteration do the following:
+        (a) accum   <- exp(accum - mi)
+        (b) m_prime <- exp(m_prime - mi)
+        (c) s_prime <- s_prime * m_prime + sum(accum)
+
+    All of this is done on registers, before we store all of this
+    on shared memory for the next matmul with Value.
+    */
+    using Fragment = typename WarpIteratorC::Fragment;
+    using LambdaIterator = typename DefaultMmaAccumLambdaIterator<
+        WarpIteratorC,
+        accum_t,
+        kThreadsPerWarp>::Iterator;
+    // Convert to `accum_t` (rather than double)
+    constexpr float kLog2e = 1.4426950408889634074; // log_2(e) = M_LOG2E
+    if (!kIsFirst) {
+      if (thread_id < kQueriesPerBlock) {
+        m_prime[thread_id] = mi[thread_id];
+      }
+      __syncthreads();
+    }
+
+    auto lane_offset =
+        LambdaIterator::get_lane_offset(lane_id, warp_id, tile_offset);
+
+    // First update `mi` to the max per-row
+    {
+      accum_t max;
+      LambdaIterator::iterateRows(
+          lane_offset,
+          [&](int accum_m) {
+            max = -cutlass::platform::numeric_limits<accum_t>::infinity();
+          },
+          [&](int accum_m, int accum_n, int idx) {
+            if (kFullColumns || accum_n < max_col) {
+              max = cutlass::fast_max(max, frag[idx]);
+            }
+          },
+          [&](int accum_m) {
+            // Having 4x atomicMax seems faster than reduce within warp
+            // first...
+            atomicMaxFloat(&mi[accum_m], max * scaling);
+          });
+    }
+    frag = cutlass::multiplies<Fragment>()(scaling * kLog2e, frag);
+
+    // Make sure we all share the update values for `mi`
+    __syncthreads();
+
+    if (thread_id < kQueriesPerBlock) {
+      auto m_prime_exp = exp2f(kLog2e * (m_prime[thread_id] - mi[thread_id]));
+      m_prime[thread_id] = m_prime_exp;
+      s_prime[thread_id] *= m_prime_exp;
+    }
+    __syncthreads(); // Update output fragments
+    if (kKeepOutputInRF && !kIsFirst) {
+      accum_t mp;
+      LambdaIterator::iterateRows(
+          lane_offset,
+          [&](int accum_m) { mp = m_prime[accum_m]; },
+          [&](int accum_m, int accum_n, int idx) { frag_o[idx] *= mp; },
+          [&](int accum_m) {});
+      __syncthreads();
+    }
+    // Update accum_m, accum_n, ...
+    {
+      accum_t mi_row, total_row;
+      LambdaIterator::iterateRows(
+          lane_offset,
+          [&](int accum_m) { mi_row = kLog2e * mi[accum_m]; },
+          [&](int accum_m, int accum_n, int idx) {
+            frag[idx] = (kFullColumns || accum_n < max_col)
+                ? exp2f(frag[idx] - mi_row)
+                : accum_t(0.0);
+          },
+          [&](int accum_m) {});
+      LambdaIterator::iterateRows(
+          lane_offset,
+          [&](int accum_m) { total_row = 0.0; },
+          [&](int accum_m, int accum_n, int idx) { total_row += frag[idx]; },
+          [&](int accum_m) {
+            if (LambdaIterator::reduceSameRow(
+                    lane_id, total_row, [](accum_t a, accum_t b) {
+                      return a + b;
+                    })) {
+              atomicAdd(&s_prime[accum_m], total_row);
+            }
+          });
+    }
+  }
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 } // namespace kernel
 } // namespace gemm
 } // namespace cutlass
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/fmha_grouped_problem_visitor.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/fmha_grouped_problem_visitor.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/fused_multihead_attention_fixed_seqlen.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/fused_multihead_attention_fixed_seqlen.cu`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -500,45 +500,59 @@
     ldq_host.resize(problem_count());
     ldk_host.resize(problem_count());
     ldp_host.resize(problem_count());
     ldv_host.resize(problem_count());
     ldo_host.resize(problem_count());
     seqlen_host.resize(problem_count());
 
-    for (int32_t i = 0; i < problem_count(); ++i) {
-
-      auto problem0 = options.problem_sizes0.at(i);
-      auto problem1 = options.problem_sizes1.at(i);
-
-      ldq_host.at(i) = LayoutQ::packed({problem0.m(), problem0.k()}).stride(0);
-      ldk_host.at(i) = LayoutK::packed({problem0.k(), problem0.n()}).stride(0);
-      ldp_host.at(i) = LayoutP::packed({problem0.m(), problem0.n()}).stride(0);
-      ldv_host.at(i) = LayoutV::packed({problem1.k(), problem1.n()}).stride(0);
-      ldo_host.at(i) = LayoutO::packed({problem1.m(), problem1.n()}).stride(0);
-
-      // m = n for attention problems.
-      seqlen_host.at(i) = problem0.m();
-
-      offset_Q.push_back(total_elements_Q);
-      offset_K.push_back(total_elements_K);
-      offset_P.push_back(total_elements_P);
-      offset_V.push_back(total_elements_V);
-      offset_O.push_back(total_elements_O);
-
-      int64_t elements_Q = problem0.m() * problem0.k();
-      int64_t elements_K = problem0.k() * problem0.n();
-      int64_t elements_P = problem0.m() * problem0.n();
-      int64_t elements_V = problem1.k() * problem1.n();
-      int64_t elements_O = problem1.m() * problem1.n();
-
-      total_elements_Q += elements_Q;
-      total_elements_K += elements_K;
-      total_elements_P += elements_P;
-      total_elements_V += elements_V;
-      total_elements_O += elements_O;
+    // Create tensors in BMHK format, where
+    // B = batch_size
+    // M = sequence length
+    // H = num_heads
+    // K = embedding size per head
+    int64_t batch_offset_Q, batch_offset_K, batch_offset_V, batch_offset_O;
+
+    for (int32_t b = 0; b < options.batch_size; ++b) {
+      batch_offset_Q = total_elements_Q;
+      batch_offset_K = total_elements_K;
+      batch_offset_V = total_elements_V;
+      batch_offset_O = total_elements_O;
+      for (int32_t h = 0; h < options.head_number; ++h) {
+        int32_t i = h + b * options.head_number;
+
+        auto problem0 = options.problem_sizes0.at(i);
+        auto problem1 = options.problem_sizes1.at(i);
+
+        ldq_host.at(i) = LayoutQ::packed({problem0.m(), options.head_number * problem0.k()}).stride(0);
+        ldk_host.at(i) = LayoutK::packed({options.head_number * problem0.k(), problem0.n()}).stride(0);
+        ldp_host.at(i) = LayoutP::packed({problem0.m(), problem0.n()}).stride(0);
+        ldv_host.at(i) = LayoutV::packed({problem1.k(), options.head_number * problem1.n()}).stride(0);
+        ldo_host.at(i) = LayoutO::packed({problem1.m(), options.head_number * problem1.n()}).stride(0);
+
+        // m = n for attention problems.
+        seqlen_host.at(i) = problem0.m();
+
+        offset_Q.push_back(batch_offset_Q + h * problem0.k());
+        offset_K.push_back(batch_offset_K + h * problem0.k());
+        offset_P.push_back(total_elements_P);
+        offset_V.push_back(batch_offset_V + h * problem0.k());
+        offset_O.push_back(batch_offset_O + h * problem1.n());
+
+        int64_t elements_Q = problem0.m() * problem0.k();
+        int64_t elements_K = problem0.k() * problem0.n();
+        int64_t elements_P = problem0.m() * problem0.n();
+        int64_t elements_V = problem1.k() * problem1.n();
+        int64_t elements_O = problem1.m() * problem1.n();
+
+        total_elements_Q += elements_Q;
+        total_elements_K += elements_K;
+        total_elements_P += elements_P;
+        total_elements_V += elements_V;
+        total_elements_O += elements_O;
+      }
     }
 
     problem_sizes_device0.reset(problem_count());
     problem_sizes_device1.reset(problem_count());
     problem_sizes_device0.copy_from_host(options.problem_sizes0.data());
     problem_sizes_device1.copy_from_host(options.problem_sizes1.data());
 
@@ -645,138 +659,141 @@
   }
 
   /// Verifies the result is a GEMM
   bool verify_() {
 
     bool passed = true;
 
-    for (int32_t i = 0; i < problem_count(); ++i) {
-      cutlass::gemm::GemmCoord problem0 = options.problem_sizes0.at(i);
-      cutlass::gemm::GemmCoord problem1 = options.problem_sizes1.at(i);
-
-      LayoutQ layout_Q(ldq_host.at(i));
-      LayoutK layout_K(ldk_host.at(i));
-      LayoutP layout_P(ldp_host.at(i));
-      LayoutV layout_V(ldv_host.at(i));
-      LayoutO layout_O(ldo_host.at(i));
+    for (int32_t b = 0; b < options.batch_size; ++b) {
+      int32_t i = b * options.head_number;
+      // Problem size is the same for all heads
+      cutlass::gemm::GemmCoord problem0 = options.problem_sizes0.at(b * options.head_number);
+      cutlass::gemm::GemmCoord problem1 = options.problem_sizes1.at(b * options.head_number);
 
       MatrixCoord extent_Q{problem0.m(), problem0.k()};
       MatrixCoord extent_K{problem0.k(), problem0.n()};
       MatrixCoord extent_P{problem0.m(), problem0.n()};
       MatrixCoord extent_V{problem1.k(), problem1.n()};
       MatrixCoord extent_O{problem1.m(), problem1.n()};
 
-      cutlass::TensorView<ElementQ, LayoutQ> view_Q(block_Q.get() + offset_Q.at(i), layout_Q, extent_Q);
-      cutlass::TensorView<ElementK, LayoutK> view_K(block_K.get() + offset_K.at(i), layout_K, extent_K);
-      cutlass::TensorView<ElementP, LayoutP> view_P(block_P.get() + offset_P.at(i), layout_P, extent_P);
-      cutlass::TensorView<ElementV, LayoutV> view_V(block_V.get() + offset_V.at(i), layout_V, extent_V);
+      LayoutO layout_O(ldo_host.at(i));
+      std::vector<ElementO> matrix_O(layout_O.capacity(extent_O));
+      cutlass::device_memory::copy_to_host(matrix_O.data(),   block_O.get() + offset_O.at(i), matrix_O.size());
+      cutlass::DeviceAllocation<ElementO>    block_Ref_O(layout_O.capacity(extent_O));
 
-      cutlass::DeviceAllocation<ElementP>    block_Ref(layout_P.capacity(extent_P));
-      cutlass::TensorView<ElementP, LayoutP> view_Ref_device(block_Ref.get(), layout_P, extent_P);
+      for (int32_t h = 0; h < options.head_number; ++h) {
+        i = h + b * options.head_number;
 
-      cutlass::DeviceAllocation<ElementO>    block_Ref_O(layout_O.capacity(extent_O));
-      cutlass::TensorView<ElementO, LayoutO> view_Ref_O_device(block_Ref_O.get(), layout_O, extent_O);
+        LayoutQ layout_Q(ldq_host.at(i));
+        LayoutK layout_K(ldk_host.at(i));
+        LayoutP layout_P(ldp_host.at(i));
+        LayoutV layout_V(ldv_host.at(i));
+
+        cutlass::TensorView<ElementQ, LayoutQ> view_Q(block_Q.get() + offset_Q.at(i), layout_Q, extent_Q);
+        cutlass::TensorView<ElementK, LayoutK> view_K(block_K.get() + offset_K.at(i), layout_K, extent_K);
+        cutlass::TensorView<ElementV, LayoutV> view_V(block_V.get() + offset_V.at(i), layout_V, extent_V);
+        cutlass::TensorView<ElementO, LayoutO> view_Ref_O_device(block_Ref_O.get() + offset_O.at(i) - offset_O.at(b * options.head_number), layout_O, extent_O);
+
+        cutlass::DeviceAllocation<ElementP>    block_Ref_P(layout_P.capacity(extent_P));
+        cutlass::TensorView<ElementP, LayoutP> view_Ref_P_device(block_Ref_P.get(), layout_P, extent_P);
+
+        // Reference GEMM
+        cutlass::reference::device::GemmComplex<
+            ElementQ, LayoutQ,
+            ElementK, LayoutK,
+            ElementP, LayoutP, 
+            ElementCompute, ElementAccumulator
+        >(
+          problem0,
+          ElementAccumulator(options.alpha0), 
+          view_Q,
+          Attention::MM0::Mma::kTransformA,
+          view_K,
+          Attention::MM0::Mma::kTransformB,
+          ElementAccumulator(options.beta), 
+          view_Ref_P_device, 
+          view_Ref_P_device, 
+          ElementAccumulator(0)
+        );
+
+        // Compute softmax for P. We need to explicitly compute softmax
+        // over P because softmax is fused to the second GEMM in the
+        // profiled implementation.
+        std::vector<ElementP> matrix_Ref(layout_P.capacity(extent_P));
+        cutlass::device_memory::copy_to_host(matrix_Ref.data(), block_Ref_P.get(), matrix_Ref.size());
+        cutlass::TensorView<ElementP, LayoutP> view_Ref_host(matrix_Ref.data(), layout_P, extent_P);
+        std::vector<ElementNorm> vector_Norm_Ref(problem0.m());
+        std::vector<ElementSum> vector_Sum_Ref(problem0.m());
 
-      // Reference GEMM
-      cutlass::reference::device::GemmComplex<
-          ElementQ, LayoutQ,
-          ElementK, LayoutK,
-          ElementP, LayoutP, 
-          ElementCompute, ElementAccumulator
-      >(
-        problem0,
-        ElementAccumulator(options.alpha0), 
-        view_Q,
-        Attention::MM0::Mma::kTransformA,
-        view_K,
-        Attention::MM0::Mma::kTransformB,
-        ElementAccumulator(options.beta), 
-        view_P, 
-        view_Ref_device, 
-        ElementAccumulator(0)
-      );
-
-      // Compute softmax for P. We need to explicitly compute softmax
-      // over P because softmax is fused to the second GEMM in the
-      // profiled implementation.
-      std::vector<ElementP> matrix_Ref(layout_P.capacity(extent_P));
-      cutlass::device_memory::copy_to_host(matrix_Ref.data(), block_Ref.get(), matrix_Ref.size());
-      cutlass::TensorView<ElementP, LayoutP> view_Ref_host(matrix_Ref.data(), layout_P, extent_P);
-      std::vector<ElementNorm> vector_Norm_Ref(problem0.m());
-      std::vector<ElementSum> vector_Sum_Ref(problem0.m());
-
-      int n_dim = options.use_mask ? options.problem_sizes0_real.at(i).n() : problem0.n();
-
-      // Compute softmax for referece matrix
-      for (int m = 0; m < problem0.m(); m++) {
-        int n_dim_row = n_dim;
-        if (options.causal) {
-          n_dim_row = std::min(m + 1, n_dim);
-        }
-        ElementSoftmaxCompute max = ElementSoftmaxCompute(view_Ref_host.ref().at({m, 0}));
-        for (int n = 1; n < n_dim_row; n++) {
-           max = std::max(max, ElementSoftmaxCompute(view_Ref_host.ref().at({m, n})));
-        }
+        int n_dim = options.use_mask ? options.problem_sizes0_real.at(i).n() : problem0.n();
+
+        // Compute softmax for reference matrix
+        for (int m = 0; m < problem0.m(); m++) {
+          int n_dim_row = n_dim;
+          if (options.causal) {
+            n_dim_row = std::min(m + 1, n_dim);
+          }
+          ElementSoftmaxCompute max = ElementSoftmaxCompute(view_Ref_host.ref().at({m, 0}));
+          for (int n = 1; n < n_dim_row; n++) {
+            max = std::max(max, ElementSoftmaxCompute(view_Ref_host.ref().at({m, n})));
+          }
 
-        vector_Norm_Ref.at(m) = ElementNorm(max);
+          vector_Norm_Ref.at(m) = ElementNorm(max);
 
-        ElementSoftmaxCompute sum = ElementSoftmaxCompute();
-        for (int n = 0; n < n_dim_row; n++) {
-          sum += std::exp( ElementSoftmaxCompute(view_Ref_host.ref().at({m, n})) - max );
-        }
-        ElementSoftmaxCompute inv_sum = ElementSoftmaxCompute(1.0f / sum);
+          ElementSoftmaxCompute sum = ElementSoftmaxCompute();
+          for (int n = 0; n < n_dim_row; n++) {
+            sum += std::exp( ElementSoftmaxCompute(view_Ref_host.ref().at({m, n})) - max );
+          }
+          ElementSoftmaxCompute inv_sum = ElementSoftmaxCompute(1.0f / sum);
 
-        vector_Sum_Ref.at(m) = ElementSum(inv_sum);
+          vector_Sum_Ref.at(m) = ElementSum(inv_sum);
 
-        for (int n = 0; n < n_dim_row; n++) {
-          view_Ref_host.ref().at({m, n}) = ElementP(
-            std::exp( ElementSoftmaxCompute(view_Ref_host.ref().at({m, n})) - max ) * inv_sum
-          );
-        }
-        // Mask out the rest of the attention matrix
-        for (int n = n_dim_row; n < n_dim; ++n) {
-          view_Ref_host.ref().at({m, n}) = ElementP(0);
+          for (int n = 0; n < n_dim_row; n++) {
+            view_Ref_host.ref().at({m, n}) = ElementP(
+              std::exp( ElementSoftmaxCompute(view_Ref_host.ref().at({m, n})) - max ) * inv_sum
+            );
+          }
+          // Mask out the rest of the attention matrix
+          for (int n = n_dim_row; n < n_dim; ++n) {
+            view_Ref_host.ref().at({m, n}) = ElementP(0);
+          }
         }
-      }
 
-      // when not using mask, problem_real and problem share the same sizes
-      if (options.use_mask) {
-        for (int m = 0; m < problem0.m(); m++) {
-          for (int n = n_dim; n < problem0.n(); n++) {
-            view_Ref_host.ref().at({m, n}) = ElementP(0);
+        // when not using mask, problem_real and problem share the same sizes
+        if (options.use_mask) {
+          for (int m = 0; m < problem0.m(); m++) {
+            for (int n = n_dim; n < problem0.n(); n++) {
+              view_Ref_host.ref().at({m, n}) = ElementP(0);
+            }
           }
         }
-      }
 
-      cutlass::device_memory::copy_to_device(block_P.get() + offset_P.at(i), matrix_Ref.data(), matrix_Ref.size());
+        cutlass::device_memory::copy_to_device(block_Ref_P.get(), matrix_Ref.data(), matrix_Ref.size());
 
-      // Reference GEMM
-      cutlass::reference::device::GemmComplex<
-          ElementP, LayoutP,
-          ElementV, LayoutV,
-          ElementO, LayoutO, 
-          ElementCompute, ElementAccumulator
-      >(
-        problem1,
-        ElementAccumulator(options.alpha1), 
-        view_P,
-        Attention::MM0::Mma::kTransformA,
-        view_V,
-        Attention::MM0::Mma::kTransformB,
-        ElementAccumulator(options.beta), 
-        view_Ref_O_device, 
-        view_Ref_O_device, 
-        ElementAccumulator(0)
-      );
+        // Reference GEMM
+        cutlass::reference::device::GemmComplex<
+            ElementP, LayoutP,
+            ElementV, LayoutV,
+            ElementO, LayoutO, 
+            ElementCompute, ElementAccumulator
+        >(
+          problem1,
+          ElementAccumulator(options.alpha1), 
+          view_Ref_P_device,
+          Attention::MM0::Mma::kTransformA,
+          view_V,
+          Attention::MM0::Mma::kTransformB,
+          ElementAccumulator(options.beta), 
+          view_Ref_O_device, 
+          view_Ref_O_device, 
+          ElementAccumulator(0)
+        );
+      }
 
       // Copy to host memory
-      cutlass::TensorView<ElementP, LayoutP> view_Ref(matrix_Ref.data(), layout_P, extent_P);
-
-      std::vector<ElementO> matrix_O(layout_O.capacity(extent_O));
-      cutlass::device_memory::copy_to_host(matrix_O.data(),   block_O.get() + offset_O.at(i), matrix_O.size());
       std::vector<ElementO> matrix_Ref_O(layout_O.capacity(extent_O));
       cutlass::device_memory::copy_to_host(matrix_Ref_O.data(), block_Ref_O.get(), matrix_Ref_O.size());
 
       // printf("Pb %d: \n    Q=(offset=%d, ldq=%d)\n    K=(offset=%d, ldk=%d)\n    O=(offset=%d, ldo=%d)\n",
       //   int(i), int(offset_Q[i]), int(ldq_host[i]), int(offset_K[i]), int(ldk_host[i]), int(offset_O[i]), int(ldo_host[i]));
   
       bool verified_O = false;
@@ -784,15 +801,15 @@
       if (!verified_O) {
         verified_O = verify_tensor_<ElementO>(matrix_O, matrix_Ref_O);
       }
 
       passed = passed && verified_O;
 
       if (!passed) {
-        std::cerr << "\n***\nError - problem " << i << " failed the QA check\n***\n" << std::endl;
+        std::cerr << "\n***\nError - problem " << i << " (batch " << b << ") failed the QA check\n***\n" << std::endl;
 
         if (!verified_O) {
           std::cout << "Final matrix output is incorrect" << std::endl;
         }
 
         return passed;
       }
@@ -827,34 +844,37 @@
 
       // TODO: support arbitrary seq lengths
       // if (cu_seqlens_q.has_value()) {
       //   p.cu_seqlens_q_ptr = (int32_t*)cu_seqlens_q->data_ptr();
       //   p.cu_seqlens_k_ptr = (int32_t*)cu_seqlens_k->data_ptr();
       // }
 
+      p.scale = options.alpha0;
+
       p.num_heads = options.head_number;
       p.num_batches = options.batch_size;
       p.head_dim = options.head_size;
       p.head_dim_value = options.head_size_v;
       p.num_queries = options.seq_length;
       p.num_keys = options.seq_length_kv;
-      p.causal = options.causal;
+      if (options.causal) {
+        p.custom_mask_type = Attention::CausalFromTopLeft;
+      }
 
-      // TODO: This might overflow for big tensors
+      // All tensors are in BMHK shapes
+      p.q_strideH = options.head_size;
+      p.k_strideH = options.head_size;
+      p.v_strideH = options.head_size_v;
       p.q_strideM = int32_t(ldq_host[0]);
       p.k_strideM = int32_t(ldk_host[0]);
       p.v_strideM = int32_t(ldv_host[0]);
-      p.q_strideH = p.q_strideM * options.seq_length;
-      p.k_strideH = p.k_strideM * options.seq_length_kv;
-      p.v_strideH = p.v_strideM * options.seq_length_kv;
-      p.o_strideH = options.head_size_v * options.seq_length;
-      p.q_strideB = p.q_strideH * options.head_number;
-      p.k_strideB = p.k_strideH * options.head_number;
-      p.v_strideB = p.v_strideH * options.head_number;
-      p.o_strideB = options.head_size_v * options.seq_length * options.head_number;
+      p.q_strideB = p.q_strideM * options.seq_length;
+      p.k_strideB = p.k_strideM * options.seq_length_kv;
+      p.v_strideB = p.v_strideM * options.seq_length_kv;
+      p.o_strideM = p.head_dim_value * p.num_heads;
     }
 
     // launch kernel :)
     constexpr auto kernel_fn = attention_kernel_batched_impl<Attention>;
     int smem_bytes = sizeof(typename Attention::SharedStorage);
     if (smem_bytes > 0xc000) {
       cudaFuncSetAttribute(kernel_fn, cudaFuncAttributeMaxDynamicSharedMemorySize, smem_bytes);
@@ -984,15 +1004,17 @@
 int run_attention(Options& options) {
   using Attention = AttentionKernel<
     cutlass::half_t,      // scalar_t
     cutlass::arch::Sm80,  // ArchTag
     true,                 // Memory is aligned
     kQueriesPerBlock,
     kKeysPerBlock,
-    kSingleValueIteration
+    kSingleValueIteration,
+    false,                // Supports dropout
+    false                 // Supports bias
   >;
 
   //
   // Test and profile
   //
 
   TestbedAttention<Attention> testbed(options);
@@ -1062,15 +1084,15 @@
   if (options.alignment != 1) {
     std::cerr << "--alignment=1 is the only supported value\n";
     return -2;
   }
 
   // Determine kernel configuration based on head size.
   // If head size is less than or equal to 64, each block operates over 64 queries and
-  // 64 keys, and parital results can be stored in the register file.
+  // 64 keys, and partial results can be stored in the register file.
   // If head size is greater than 64, each block operates over 32 queries and 128 keys,
   // and partial results are stored in shared memory.
   if (options.head_size_v > 64) {
     static int const kQueriesPerBlock = 32;
     static int const kKeysPerBlock = 128;
     if (options.head_size_v <= kKeysPerBlock) {
       return run_attention<kQueriesPerBlock, kKeysPerBlock, true>(options);
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/fused_multihead_attention_variable_seqlen.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/fused_multihead_attention_variable_seqlen.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -917,14 +917,15 @@
       ptr_O_accumulate.get(),
       ldq.get(),
       ldk.get(),
       ldp.get(),
       ldv.get(),
       ldo.get(),
       options.causal,
+      options.alpha0,
       options.problem_sizes1.data()
     );
 
     Attention fmha;
 
     size_t workspace_size = fmha.get_workspace_size(args);
     cutlass::DeviceAllocation<uint8_t> workspace(workspace_size);
@@ -1168,15 +1169,15 @@
   if (options.alignment != 1) {
     std::cerr << "--alignment=1 is the only supported value\n";
     return -2;
   }
 
   // Determine kernel configuration based on head size.
   // If head size is less than or equal to 64, each block operates over 64 queries and
-  // 64 keys, and parital results can be stored in the register file.
+  // 64 keys, and partial results can be stored in the register file.
   // If head size is greater than 64, each block operates over 32 queries and 128 keys,
   // and partial results are stored in shared memory.
   if (options.head_size_v > 64) {
     static int const kQueriesPerBlock = 32;
     static int const kKeysPerBlock = 128;
     if (options.head_size_v <= kKeysPerBlock) {
       return run_attention<kQueriesPerBlock, kKeysPerBlock, true>(options);
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma_base.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma_base.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights
  *reserved. SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice,
  *this list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma_multistage.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma_multistage.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights
  *reserved. SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice,
  *this list of conditions and the following disclaimer.
@@ -745,15 +745,15 @@
         platform::is_same<
             typename Operator::MathOperator,
             arch::OpMultiplyAddComplexFastF32>::value) {
       accum = plus_accum(accum, tmp_accum);
     }
 
     if (SharedMemoryClear == SharedMemoryClearOption::kZfill) {
-      // commit and drain all pending and predicated LDGSTS pnz from the GEMM
+      // commit and drain all pending and predicated cp.async pnz from the GEMM
       // mainloop
       cutlass::arch::cp_async_fence();
       cutlass::arch::cp_async_wait<0>();
       __syncthreads();
     }
   }
 };
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma_pipelined.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma_pipelined.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights
  *reserved. SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice,
  *this list of conditions and the following disclaimer.
@@ -306,15 +306,15 @@
     int smem_write_stage_idx = 1;
 
     // Avoid reading out of bounds
     iterator_A.clear_mask(gemm_k_iterations <= 1);
     iterator_B.clear_mask(gemm_k_iterations <= 1);
 
     // Issue loads during the first warp-level matrix multiply-add *AFTER*
-    // issuing shared memory loads (which have the tighest latency requirement).
+    // issuing shared memory loads (which have the tightest latency requirement).
 
     //
     // Mainloop
     //
 
     // Note: The main loop does not support Base::kWarpGemmIterations == 2.
     CUTLASS_GEMM_LOOP
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/gemm_kernel_utils.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/gemm_kernel_utils.h`

 * *Files 14% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -32,28 +32,28 @@
 #pragma once
 
 #include "cutlass/arch/mma.h"
 
 ////////////////////////////////////////////////////////////////////////////////
 // Some helper functions
 ////////////////////////////////////////////////////////////////////////////////
-#define DISPATCH_TYPES(tensor, func)                                        \
-  {                                                                         \
-    if (query.scalar_type() == at::ScalarType::Float) {                     \
-      using scalar_t = float;                                               \
-      func();                                                               \
-    } else if (query.scalar_type() == at::ScalarType::Half) {               \
-      using scalar_t = cutlass::half_t;                                     \
-      func();                                                               \
-    } else if (query.scalar_type() == at::ScalarType::BFloat16) {           \
-      using scalar_t = cutlass::bfloat16_t;                                 \
-      func();                                                               \
-    } else {                                                                \
-      TORCH_CHECK(false, "Only fp32, half & bf16 supported at the moment"); \
-    }                                                                       \
+#define DISPATCH_TYPES(tensor, func)                                           \
+  {                                                                            \
+    if (query.scalar_type() == at::ScalarType::Float) {                        \
+      using scalar_t = float;                                                  \
+      func();                                                                  \
+    } else if (query.scalar_type() == at::ScalarType::Half) {                  \
+      using scalar_t = cutlass::half_t;                                        \
+      func();                                                                  \
+    } else if (query.scalar_type() == at::ScalarType::BFloat16) {              \
+      using scalar_t = cutlass::bfloat16_t;                                    \
+      func();                                                                  \
+    } else {                                                                   \
+      XFORMERS_CHECK(false, "Only fp32, half & bf16 supported at the moment"); \
+    }                                                                          \
   }
 
 #define DISPATCH_BOOL(BOOL_V, BOOL_NAME, F) \
   {                                         \
     if (BOOL_V) {                           \
       constexpr bool BOOL_NAME = true;      \
       F();                                  \
@@ -73,125 +73,78 @@
     } else if (CC >= 70) {                                                \
       using ArchTag = cutlass::arch::Sm70;                                \
       func();                                                             \
     } else if (CC >= 50) {                                                \
       using ArchTag = cutlass::arch::Sm50;                                \
       func();                                                             \
     } else {                                                              \
-      TORCH_CHECK(                                                        \
+      XFORMERS_CHECK(                                                     \
           false,                                                          \
           "Your device is too old. We require compute capability >= 50"); \
     }                                                                     \
   }
 
-#define CHECK_NOSPARSE_CONTIGUOUS_CUDA(TENSOR)                         \
-  TORCH_CHECK(TENSOR.is_cuda(), #TENSOR " must be a CUDA tensor");     \
-  TORCH_CHECK(!TENSOR.is_sparse(), #TENSOR " must be a dense tensor"); \
-  TORCH_CHECK(TENSOR.is_contiguous());
-
-#define CHECK_NOSPARSE_LASTCONTIGUOUS_CUDA(TENSOR)                     \
-  TORCH_CHECK(TENSOR.is_cuda(), #TENSOR " must be a CUDA tensor");     \
-  TORCH_CHECK(!TENSOR.is_sparse(), #TENSOR " must be a dense tensor"); \
-  TORCH_CHECK(                                                         \
+#define CHECK_NOSPARSE_CONTIGUOUS_CUDA(TENSOR)                            \
+  XFORMERS_CHECK(TENSOR.is_cuda(), #TENSOR " must be a CUDA tensor");     \
+  XFORMERS_CHECK(!TENSOR.is_sparse(), #TENSOR " must be a dense tensor"); \
+  XFORMERS_CHECK(TENSOR.is_contiguous());
+
+#define CHECK_NOSPARSE_LASTCONTIGUOUS_CUDA(TENSOR)                        \
+  XFORMERS_CHECK(TENSOR.is_cuda(), #TENSOR " must be a CUDA tensor");     \
+  XFORMERS_CHECK(!TENSOR.is_sparse(), #TENSOR " must be a dense tensor"); \
+  XFORMERS_CHECK(                                                         \
       TENSOR.stride(-1) == 1, #TENSOR ": last dimension must be contiguous");
 
-#ifdef HAS_PYTORCH
+#ifdef TORCH_CHECK
 #define CHECK_ALIGNED_PTR(PTR, ALIGNMENT) \
-  TORCH_CHECK(uint64_t(PTR) % ALIGNMENT == 0, #PTR " is not correctly aligned")
+  XFORMERS_CHECK(                         \
+      uint64_t(PTR) % ALIGNMENT == 0, #PTR " is not correctly aligned")
 #define XFORMERS_CHECK TORCH_CHECK
 #elif defined(__CUDACC_RTC__)
 #define CHECK_ALIGNED_PTR(PTR, ALIGNMENT)  \
   if (!(uint64_t(PTR) % ALIGNMENT == 0)) { \
     return false;                          \
   }
 #define XFORMERS_CHECK(COND, ERR) \
   if (!(COND)) {                  \
     return false;                 \
   }
 #else
+#include <iostream>
 #define CHECK_ALIGNED_PTR(PTR, ALIGNMENT)            \
   if (!(uint64_t(PTR) % ALIGNMENT == 0)) {           \
     std::cerr << #PTR " is not correctly aligned\n"; \
     return false;                                    \
   }
 #define XFORMERS_CHECK(COND, ERR)   \
   if (!(COND)) {                    \
     std::cerr << #COND " failed\n"; \
     return false;                   \
   }
 #endif
 
-#define ASSIGN_CHECK_OVERFLOW(A, B)                                \
-  {                                                                \
-    A = B;                                                         \
-    TORCH_CHECK(                                                   \
-        B < cutlass::platform::numeric_limits<decltype(A)>::max(), \
-        #B " overflows");                                          \
+#define ASSIGN_CHECK_OVERFLOW(A, B)                                    \
+  {                                                                    \
+    A = B;                                                             \
+    XFORMERS_CHECK(                                                    \
+        B < std::numeric_limits<decltype(A)>::max(), #B " overflows"); \
   }
 
 namespace gemm_kernel_utils {
 
-#ifdef HAS_PYTORCH
-template <typename scalar_t>
-struct TypeTraits;
-
-template <>
-struct TypeTraits<cutlass::half_t> {
-  using scalar_t = cutlass::half_t;
-
-  static constexpr __host__ at::ScalarType atScalarType() {
-    return at::ScalarType::Half;
-  }
-  template <int nDim>
-  static __host__ at::PackedTensorAccessor32<scalar_t, nDim> packed_accessor(
-      at::Tensor const& tensor) {
-    return at::PackedTensorAccessor32<scalar_t, nDim>(
-        (scalar_t*)(tensor.data_ptr()),
-        tensor.sizes().data(),
-        tensor.strides().data());
-  }
-};
-
-template <>
-struct TypeTraits<cutlass::bfloat16_t> {
-  using scalar_t = cutlass::bfloat16_t;
-
-  static constexpr __host__ at::ScalarType atScalarType() {
-    return at::ScalarType::BFloat16;
-  }
-  template <int nDim>
-  static __host__ at::PackedTensorAccessor32<scalar_t, nDim> packed_accessor(
-      at::Tensor const& tensor) {
-    return at::PackedTensorAccessor32<scalar_t, nDim>(
-        (scalar_t*)(tensor.data_ptr()),
-        tensor.sizes().data(),
-        tensor.strides().data());
-  }
-};
-
-template <>
-struct TypeTraits<float> {
-  using scalar_t = float;
-
-  static constexpr __host__ at::ScalarType atScalarType() {
-    return at::ScalarType::Float;
-  }
-  template <int nDim>
-  static __host__ at::PackedTensorAccessor32<scalar_t, nDim> packed_accessor(
-      at::Tensor const& tensor) {
-    return tensor.packed_accessor32<scalar_t, nDim>();
-  }
-};
-#endif
-
 template <typename integer>
 constexpr CUTLASS_HOST_DEVICE integer ceil_div(integer n, integer m) {
   return (n + m - 1) / m;
 }
 
+template <typename integer>
+constexpr CUTLASS_HOST_DEVICE integer align_up(integer n, integer m) {
+  return ((n + m - 1) / m) * m;
+}
+
 ////////////////////////////////////////////////////////////////////////////////
 // Determine the type of GEMM we do (TensorCores or not, Shapes ...)
 // TODO: Maybe we could rely on Cutlass's DefaultGemm templates
 ////////////////////////////////////////////////////////////////////////////////
 
 // Fallback to Simt (FMA on cuda cores) if not in a special case below
 template <typename ArchTag, typename scalar_t_, typename Enable = void>
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/iterators/epilogue_predicated_tile_iterator.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/iterators/epilogue_predicated_tile_iterator.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights
  *reserved. SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice,
  *this list of conditions and the following disclaimer.
@@ -307,17 +307,17 @@
 
           CUTLASS_PRAGMA_UNROLL
           for (int column = 0; column < ThreadMap::Iterations::kColumn;
                ++column) {
             // on windows using unsigned long here gives the error
             // error: asm operand type size(4) does not match
             // type/size implied by constraint 'l'
-            uint64_t addr = (uint64_t)(
-                (void*)&memory_pointer
-                    [column * ThreadMap::Delta::kColumn / kElementsPerAccess]);
+            uint64_t addr = (uint64_t)((void*)&memory_pointer
+                                           [column * ThreadMap::Delta::kColumn /
+                                            kElementsPerAccess]);
             asm volatile("prefetch.global.L1 [ %1 ];" : "=l"(addr) : "l"(addr));
           }
 
           if (row + 1 < ThreadMap::Iterations::kRow) {
             if (!ScatterD) {
               byte_pointer += params_.increment_row;
             }
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/iterators/make_residual_last.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/iterators/make_residual_last.h`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/iterators/predicated_tile_access_iterator_residual_last.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/iterators/predicated_tile_access_iterator_residual_last.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights
  *reserved. SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice,
  *this list of conditions and the following disclaimer.
@@ -177,15 +177,15 @@
   /// Parameters object with precomputed internal state
   Params const& params_;
 
   /// Internal pointer to first access of tile
   BytePointer pointer_;
 
   /// Below is used when Gather is turned on.  We need to record strided_offset
-  /// and contiguous_offset seperated to compute the offset by using
+  /// and contiguous_offset separated to compute the offset by using
   ///
   /// offset = contiguous_offset + indices[strided_offset]
   ///
 
   /// Gather indices
   int const* indices_;
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/iterators/predicated_tile_iterator_residual_last.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/iterators/predicated_tile_iterator_residual_last.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights
  *reserved. SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice,
  *this list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/kernel_forward.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/kernel_forward.h`

 * *Files 17% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -28,30 +28,31 @@
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 
 #pragma once
 
 #ifdef HAS_PYTORCH
-#include <ATen/ATen.h>
-#include <ATen/cuda/CUDAContext.h>
-#include <c10/cuda/CUDAGuard.h>
-#include <torch/library.h>
+#include <ATen/cuda/CUDAGeneratorImpl.h>
+#include <ATen/cuda/CUDAGraphsUtils.cuh>
 #endif
 
+#include <curand_kernel.h>
 #include <cmath>
 #include <vector>
 
 #include "cutlass/bfloat16.h"
+#include "cutlass/fast_math.h"
 #include "cutlass/gemm/gemm.h"
 #include "cutlass/layout/matrix.h"
 #include "cutlass/layout/vector.h"
+#include "cutlass/matrix.h"
 #include "cutlass/numeric_types.h"
+#include "cutlass/tensor_ref.h"
 
-#include "attention_scaling_coefs_updater.h"
 #include "cutlass/epilogue/threadblock/default_epilogue_simt.h"
 #include "cutlass/epilogue/threadblock/default_epilogue_tensor_op.h"
 #include "cutlass/epilogue/threadblock/default_epilogue_volta_tensor_op.h"
 #include "cutlass/gemm/device/default_gemm_configuration.h"
 #include "cutlass/gemm/kernel/default_gemm.h"
 #include "cutlass/gemm/threadblock/default_mma.h"
 #include "cutlass/gemm/threadblock/default_mma_core_simt.h"
@@ -59,56 +60,77 @@
 #include "cutlass/gemm/threadblock/default_mma_core_sm75.h"
 #include "cutlass/gemm/threadblock/default_mma_core_sm80.h"
 #include "cutlass/gemm/threadblock/threadblock_swizzle.h"
 #include "cutlass/matrix_shape.h"
 #include "cutlass/platform/platform.h"
 #include "cutlass/transform/threadblock/predicated_tile_iterator.h"
 #include "debug_utils.h"
-#include "epilogue_pipelined.h"
-#include "epilogue_rescale_output.h"
-#include "find_default_mma.h"
+#include "epilogue/epilogue_pipelined.h"
+#include "epilogue/epilogue_rescale_output.h"
+#include "gemm/find_default_mma.h"
+#include "gemm/mma_from_smem.h"
 #include "gemm_kernel_utils.h"
-#include "mma_from_smem.h"
+#include "transform/tile_smem_loader.h"
 
 #include <inttypes.h>
 
 using namespace gemm_kernel_utils;
 
 namespace {
 template <typename scalar_t, typename Arch>
 constexpr int getWarpsPerSm() {
   return (
       Arch::kMinComputeCapability >= 80 &&
               !cutlass::platform::is_same<scalar_t, float>::value
           ? 16
           : 12);
 }
+static CUTLASS_DEVICE float atomicMaxFloat(float* addr, float value) {
+  // source: https://stackoverflow.com/a/51549250
+  return (value >= 0)
+      ? __int_as_float(atomicMax((int*)addr, __float_as_int(value)))
+      : __uint_as_float(atomicMin((unsigned int*)addr, __float_as_uint(value)));
+}
 } // namespace
 
 template <
     // The datatype of Q/K/V
     typename scalar_t_,
     // Architecture we are targeting (eg `cutlass::arch::Sm80`)
     typename ArchTag,
     // If Q/K/V are correctly aligned in memory and we can run a fast kernel
     bool isAligned_,
     int kQueriesPerBlock,
-    int kKeysPerBlock,
-    bool kSingleValueIteration // = `value.shape[-1] <= kKeysPerBlock`
-    >
+    int kKeysPerBlock_,
+    bool kSingleValueIteration_, // = `value.shape[-1] <= kKeysPerBlock`
+    // This is quite slower on V100 for some reason
+    // Set to false if you know at compile-time you will never need dropout
+    bool kSupportsDropout_ = true,
+    bool kSupportsBias_ = true>
 struct AttentionKernel {
+  enum CustomMaskType {
+    NoCustomMask = 0,
+    CausalFromTopLeft = 1,
+    CausalFromBottomRight = 2,
+    NumCustomMaskTypes,
+  };
+
   using scalar_t = scalar_t_;
   using accum_t = float;
   using lse_scalar_t = float;
   using output_t = scalar_t;
   // Accumulator between 2 iterations
   // Using `accum_t` improves perf on f16 at the cost of
   // numerical errors
   using output_accum_t = accum_t;
+  static constexpr bool kSupportsDropout = kSupportsDropout_;
+  static constexpr bool kSupportsBias = kSupportsBias_;
+  static constexpr int kKeysPerBlock = kKeysPerBlock_;
   static constexpr bool kIsAligned = isAligned_;
+  static constexpr bool kSingleValueIteration = kSingleValueIteration_;
   static constexpr int32_t kAlignLSE = 32; // block size of backward
   static constexpr bool kPreloadV = ArchTag::kMinComputeCapability >= 80 &&
       cutlass::sizeof_bits<scalar_t>::value == 16;
   static constexpr bool kKeepOutputInRF = kSingleValueIteration;
   static constexpr bool kNeedsOutputAccumulatorBuffer = !kKeepOutputInRF &&
       !cutlass::platform::is_same<output_accum_t, output_t>::value;
 
@@ -122,139 +144,215 @@
   static constexpr int kNumThreads = kWarpSize * kNumWarpsPerBlock;
   static constexpr int kMinBlocksPerSm =
       getWarpsPerSm<scalar_t, ArchTag>() / kNumWarpsPerBlock;
 
   struct Params {
     // Input tensors
     scalar_t* query_ptr; // [num_queries, num_heads, head_dim]
-    scalar_t* key_ptr;   // [num_keys, num_heads, head_dim]
+    scalar_t* key_ptr; // [num_keys, num_heads, head_dim]
     scalar_t* value_ptr; // [num_keys, num_heads, head_dim_value]
-    int32_t* cu_seqlens_q_ptr = nullptr;
-    int32_t* cu_seqlens_k_ptr = nullptr;
+    scalar_t* attn_bias_ptr = nullptr; // [num_heads, num_queries, num_keys]
+    int32_t* seqstart_q_ptr = nullptr;
+    int32_t* seqstart_k_ptr = nullptr;
+
+    int32_t* causal_diagonal_ptr = nullptr;
+    int32_t* seqlen_k_ptr = nullptr;
+    uint32_t causal_diagonal_offset = 0;
 
     // Output tensors
     output_t* output_ptr; // [num_queries, num_heads, head_dim_value]
     output_accum_t*
         output_accum_ptr; // [num_queries, num_heads, head_dim_value]
     lse_scalar_t* logsumexp_ptr; // [num_heads, num_queries] - can be null
 
+    // Scale
+    accum_t scale;
+
     // Dimensions/strides
     int32_t head_dim;
     int32_t head_dim_value;
     int32_t num_queries;
     int32_t num_keys;
 
-    bool causal;
+    uint8_t custom_mask_type = NoCustomMask;
 
     int32_t q_strideM;
     int32_t k_strideM;
     int32_t v_strideM;
+    int32_t bias_strideM = 0;
+
+    int32_t o_strideM = 0;
 
     // Everything below is only used in `advance_to_block`
     // and shouldn't use registers
     int32_t q_strideH;
     int32_t k_strideH;
     int32_t v_strideH;
-    int32_t o_strideH;
+    int32_t bias_strideH = 0;
+
     int64_t q_strideB;
     int64_t k_strideB;
     int64_t v_strideB;
-    int64_t o_strideB;
+    int32_t bias_strideB = 0;
+
     int32_t num_batches;
     int32_t num_heads;
 
-    CUTLASS_HOST_DEVICE int32_t o_strideM() const {
-      return head_dim_value;
-    }
+    // dropout
+    bool use_dropout;
+    unsigned long long dropout_batch_head_rng_offset;
+    float dropout_prob;
+#ifdef HAS_PYTORCH
+    at::PhiloxCudaState rng_engine_inputs;
+#endif
 
     // Moves pointers to what we should process
     // Returns "false" if there is no work to do
     CUTLASS_DEVICE bool advance_to_block() {
       auto batch_id = blockIdx.z;
       auto head_id = blockIdx.y;
       auto query_start = blockIdx.x * kQueriesPerBlock;
 
       auto lse_dim = ceil_div((int32_t)num_queries, kAlignLSE) * kAlignLSE;
 
+      if (kSupportsDropout) {
+        dropout_batch_head_rng_offset =
+            batch_id * num_heads * num_queries * num_keys +
+            head_id * num_queries * num_keys;
+      }
+
       int64_t q_start, k_start;
       // Advance to current batch - in case of different sequence lengths
-      if (cu_seqlens_q_ptr != nullptr) {
-        assert(cu_seqlens_k_ptr != nullptr);
-        cu_seqlens_q_ptr += batch_id;
-        cu_seqlens_k_ptr += batch_id;
-        q_start = cu_seqlens_q_ptr[0];
-        k_start = cu_seqlens_k_ptr[0];
-        int64_t q_next_start = cu_seqlens_q_ptr[1];
-        int64_t k_next_start = cu_seqlens_k_ptr[1];
+      if (seqstart_q_ptr != nullptr) {
+        assert(seqstart_k_ptr != nullptr);
+        seqstart_q_ptr += batch_id;
+
+        q_start = seqstart_q_ptr[0];
+        int64_t q_next_start = seqstart_q_ptr[1];
+        int64_t k_end;
+        seqstart_k_ptr += batch_id;
+
+        if (seqlen_k_ptr) {
+          k_start = seqstart_k_ptr[0];
+          k_end = k_start + seqlen_k_ptr[batch_id];
+        } else {
+          k_start = seqstart_k_ptr[0];
+          k_end = seqstart_k_ptr[1];
+        }
+
         num_queries = q_next_start - q_start;
-        num_keys = k_next_start - k_start;
+        num_keys = k_end - k_start;
 
         if (query_start >= num_queries) {
           return false;
         }
       } else {
         query_ptr += batch_id * q_strideB;
         key_ptr += batch_id * k_strideB;
         value_ptr += batch_id * v_strideB;
-        output_ptr += batch_id * o_strideB;
+        output_ptr += int64_t(batch_id * num_queries) * o_strideM;
         if (output_accum_ptr != nullptr) {
-          output_accum_ptr += batch_id * o_strideB;
+          output_accum_ptr +=
+              int64_t(batch_id * num_queries) * (head_dim_value * num_heads);
         }
         q_start = 0;
         k_start = 0;
       }
 
       // Advance to the current batch / head / query_start
       query_ptr += (q_start + query_start) * q_strideM + head_id * q_strideH;
       key_ptr += k_start * k_strideM + head_id * k_strideH;
+
       value_ptr += k_start * v_strideM + head_id * v_strideH;
-      output_ptr += int64_t(q_start + query_start) * o_strideM() +
-          head_id * o_strideH;
+      output_ptr +=
+          int64_t(q_start + query_start) * o_strideM + head_id * head_dim_value;
 
+      if (kSupportsBias && attn_bias_ptr != nullptr) {
+        attn_bias_ptr += (batch_id * bias_strideB) + (head_id * bias_strideH);
+      }
       if (output_accum_ptr != nullptr) {
-        output_accum_ptr += int64_t(q_start + query_start) * o_strideM() +
-            head_id * o_strideH;
+        output_accum_ptr +=
+            int64_t(q_start + query_start) * (head_dim_value * num_heads) +
+            head_id * head_dim_value;
       } else {
         // Accumulate directly in the destination buffer (eg for f32)
         output_accum_ptr = (accum_t*)output_ptr;
       }
+
       if (logsumexp_ptr != nullptr) {
         // lse[batch_id, head_id, query_start]
         logsumexp_ptr +=
             batch_id * lse_dim * num_heads + head_id * lse_dim + query_start;
       }
 
-      num_queries -= query_start;
-      if (causal) {
+      // Custom masking
+      if (causal_diagonal_ptr) {
+        causal_diagonal_offset = causal_diagonal_ptr[batch_id];
+      }
+      if (custom_mask_type == CausalFromBottomRight) {
+        causal_diagonal_offset += num_keys - num_queries;
+      }
+      if (custom_mask_type == CausalFromTopLeft ||
+          custom_mask_type == CausalFromBottomRight) {
+        // the bottom row of the current block is query_start + kQueriesPerBlock
+        // the last active key is then query_start + causal_diagonal_offset +
+        // kQueriesPerBlock so num_keys is the min between actual num_keys and
+        // this to avoid extra computations
         num_keys = cutlass::fast_min(
-            int32_t(query_start + kQueriesPerBlock), num_keys);
+            int32_t(query_start + causal_diagonal_offset + kQueriesPerBlock),
+            num_keys);
       }
+
+      num_queries -= query_start;
       num_batches = 0; // no longer used after
 
+      // If num_queries == 1, and there is only one key head we're wasting
+      // 15/16th of tensor core compute In that case :
+      //  - we only launch kernels for head_id % kQueriesPerBlock == 0
+      //  - we iterate over heads instead of queries (strideM = strideH)
+      if (num_queries == 1 && k_strideH == 0 && v_strideH == 0) {
+        if (head_id % kQueriesPerBlock != 0)
+          return false;
+        q_strideM = q_strideH;
+        num_queries = num_heads;
+        num_heads = 1; // unused but here for intent
+        // remove causal since n_query = 1
+        // otherwise, offset would change with head !
+        custom_mask_type = NoCustomMask;
+        o_strideM = head_dim_value;
+      }
+
       // Make sure the compiler knows these variables are the same on all
       // the threads of the warp.
       query_ptr = warp_uniform(query_ptr);
       key_ptr = warp_uniform(key_ptr);
       value_ptr = warp_uniform(value_ptr);
+      if (kSupportsBias) {
+        attn_bias_ptr = warp_uniform(attn_bias_ptr);
+      }
       output_ptr = warp_uniform(output_ptr);
       output_accum_ptr = warp_uniform(output_accum_ptr);
       logsumexp_ptr = warp_uniform(logsumexp_ptr);
       num_queries = warp_uniform(num_queries);
       num_keys = warp_uniform(num_keys);
+      num_heads = warp_uniform(num_heads);
       head_dim = warp_uniform(head_dim);
       head_dim_value = warp_uniform(head_dim_value);
+      o_strideM = warp_uniform(o_strideM);
+      custom_mask_type = warp_uniform(custom_mask_type);
       return true;
     }
 
     __host__ dim3 getBlocksGrid() const {
       return dim3(
           ceil_div(num_queries, (int32_t)kQueriesPerBlock),
           num_heads,
           num_batches);
     }
+
     __host__ dim3 getThreadsGrid() const {
       return dim3(kWarpSize, kNumWarpsPerBlock, 1);
     }
   };
 
   struct MM0 {
     /*
@@ -301,24 +399,32 @@
                                 // uses too much smem
         typename GemmType::Operator // Operator
         >::DefaultMma;
     using MmaCore = typename DefaultMma::MmaCore;
     using IteratorA = typename DefaultMma::IteratorA;
     using IteratorB = typename DefaultMma::IteratorB;
     using Mma = typename DefaultMma::ThreadblockMma;
-    using ScalingCoefsUpdater = typename DefaultAttentionScalingCoefsUpdater<
+    using AccumLambdaIterator = typename DefaultMmaAccumLambdaIterator<
         typename Mma::Operator::IteratorC,
         accum_t,
-        kWarpSize>::Updater;
+        kWarpSize>::Iterator;
     static_assert(
         MmaCore::WarpCount::kM * MmaCore::WarpCount::kN *
                 MmaCore::WarpCount::kK ==
             kNumWarpsPerBlock,
         "");
 
+    // used for efficient load of bias tile Bij from global to shared memory
+    using BiasLoader = TileSmemLoader<
+        scalar_t,
+        cutlass::MatrixShape<kQueriesPerBlock, kKeysPerBlock>,
+        MmaCore::kThreads,
+        // input restriction: kv_len has to be a multiple of this value
+        128 / cutlass::sizeof_bits<scalar_t>::value>;
+
     // Epilogue to store to shared-memory in a format that we can use later for
     // the second matmul
     using B2bGemm = typename cutlass::gemm::threadblock::B2bGemm<
         typename Mma::Operator::IteratorC,
         typename Mma::Operator,
         scalar_t,
         WarpShape,
@@ -372,15 +478,16 @@
         DefaultConfig::kStages,
         false, // SplitKSerial
         typename GemmType::Operator>;
 
     using DefaultMmaFromSmem =
         typename cutlass::gemm::threadblock::DefaultMmaFromSharedMemory<
             typename DefaultGemm::Mma,
-            typename MM0::AccumulatorSharedStorage>;
+            typename MM0::AccumulatorSharedStorage,
+            false>; // kScaleOperandA
     using Mma = typename DefaultMmaFromSmem::Mma;
     using IteratorB = typename Mma::IteratorB;
     using WarpCount = typename Mma::WarpCount;
     static_assert(
         WarpCount::kM * WarpCount::kN * WarpCount::kK == kNumWarpsPerBlock,
         "");
 
@@ -409,15 +516,18 @@
     cutlass::Array<accum_t, kQueriesPerBlock> s_prime;
     cutlass::Array<accum_t, kQueriesPerBlock> mi;
   };
 
   struct SharedStorageEpilogueAtEnd : ScalingCoefs {
     struct SharedStorageAfterMM0 {
       // Everything here might be overwritten during MM0
-      typename MM0::AccumulatorSharedStorage si;
+      union {
+        typename MM0::BiasLoader::SmemTile bias;
+        typename MM0::AccumulatorSharedStorage si;
+      };
       typename MM1::SharedStorageMM1 mm1;
     };
 
     union {
       typename MM0::Mma::SharedStorage mm0;
       SharedStorageAfterMM0 after_mm0;
       typename MM1::DefaultEpilogue::SharedStorage epilogue;
@@ -428,15 +538,18 @@
       return epilogue;
     }
   };
 
   struct SharedStorageEpilogueInLoop : ScalingCoefs {
     struct SharedStorageAfterMM0 {
       // Everything here might be overwritten during MM0
-      typename MM0::AccumulatorSharedStorage si;
+      union {
+        typename MM0::BiasLoader::SmemTile bias;
+        typename MM0::AccumulatorSharedStorage si;
+      };
       typename MM1::SharedStorageMM1 mm1;
       typename MM1::DefaultEpilogue::SharedStorage epilogue;
     };
 
     union {
       typename MM0::Mma::SharedStorage mm0;
       SharedStorageAfterMM0 after_mm0;
@@ -453,74 +566,114 @@
       SharedStorageEpilogueAtEnd,
       SharedStorageEpilogueInLoop>::type;
 
   static bool __host__ check_supported(Params const& p) {
     CHECK_ALIGNED_PTR(p.query_ptr, kAlignmentQ);
     CHECK_ALIGNED_PTR(p.key_ptr, kAlignmentK);
     CHECK_ALIGNED_PTR(p.value_ptr, kAlignmentV);
+    if (kSupportsBias) {
+      CHECK_ALIGNED_PTR(p.attn_bias_ptr, kAlignmentQ);
+      XFORMERS_CHECK(
+          p.bias_strideB % kAlignmentQ == 0,
+          "attn_bias is not correctly aligned");
+      XFORMERS_CHECK(
+          p.bias_strideH % kAlignmentQ == 0,
+          "attn_bias is not correctly aligned");
+      XFORMERS_CHECK(
+          p.bias_strideM % kAlignmentQ == 0,
+          "attn_bias is not correctly aligned");
+    }
     XFORMERS_CHECK(
         p.q_strideM % kAlignmentQ == 0, "query is not correctly aligned");
     XFORMERS_CHECK(
         p.k_strideM % kAlignmentK == 0, "key is not correctly aligned");
     XFORMERS_CHECK(
         p.v_strideM % kAlignmentV == 0, "value is not correctly aligned");
     XFORMERS_CHECK(
         p.q_strideH % kAlignmentQ == 0, "query is not correctly aligned");
     XFORMERS_CHECK(
         p.k_strideH % kAlignmentK == 0, "key is not correctly aligned");
     XFORMERS_CHECK(
         p.v_strideH % kAlignmentV == 0, "value is not correctly aligned");
+    XFORMERS_CHECK(
+        p.causal_diagonal_ptr == nullptr || p.custom_mask_type != NoCustomMask,
+        "`causal_diagonal_ptr` is only useful when `custom_mask_type` is causal");
+    XFORMERS_CHECK(
+        p.custom_mask_type < NumCustomMaskTypes,
+        "invalid value for `custom_mask_type`");
     return true;
   }
 
   static void CUTLASS_DEVICE attention_kernel(Params& p) {
     // In this block, we will only ever:
     // - read query[query_start:query_end, :]
     // - write to output[query_start:query_end, :]
 
     extern __shared__ char smem_buffer[];
     SharedStorage& shared_storage = *((SharedStorage*)smem_buffer);
     auto& m_prime = shared_storage.m_prime;
     auto& s_prime = shared_storage.s_prime;
-    auto& si = shared_storage.after_mm0.si;
     auto& mi = shared_storage.mi;
+    const uint32_t query_start = blockIdx.x * kQueriesPerBlock;
 
     static_assert(kQueriesPerBlock < kNumWarpsPerBlock * kWarpSize, "");
     if (thread_id() < kQueriesPerBlock) {
       s_prime[thread_id()] = accum_t(0);
       m_prime[thread_id()] =
           -cutlass::platform::numeric_limits<accum_t>::infinity();
       mi[thread_id()] = -cutlass::platform::numeric_limits<accum_t>::infinity();
     }
     typename MM1::Mma::FragmentC accum_o;
     accum_o.clear();
 
     auto createOutputIter = [&](int col) -> typename MM1::OutputTileIterator {
       using OutputTileIterator = typename MM1::OutputTileIterator;
       return OutputTileIterator(
-          typename OutputTileIterator::Params{(int32_t)p.o_strideM()},
+          typename OutputTileIterator::Params{(int32_t)p.o_strideM},
           p.output_ptr,
           typename OutputTileIterator::TensorCoord{
               p.num_queries, p.head_dim_value},
           thread_id(),
           {0, col});
     };
 
     auto createOutputAccumIter = [&](int col) ->
         typename MM1::OutputTileIteratorAccum {
           using OutputTileIteratorAccum = typename MM1::OutputTileIteratorAccum;
           return OutputTileIteratorAccum(
-              typename OutputTileIteratorAccum::Params{(int32_t)p.o_strideM()},
+              typename OutputTileIteratorAccum::Params{
+                  (int32_t)(p.head_dim_value * p.num_heads)},
               p.output_accum_ptr,
               typename OutputTileIteratorAccum::TensorCoord{
                   p.num_queries, p.head_dim_value},
               thread_id(),
               {0, col});
         };
 
+#ifdef HAS_PYTORCH
+    curandStatePhilox4_32_10_t curand_state_init;
+    if (kSupportsDropout && p.use_dropout) {
+      const auto seeds = at::cuda::philox::unpack(p.rng_engine_inputs);
+
+      // each element of the attention matrix P with shape
+      // (batch_sz, n_heads, n_queries, n_keys) is associated with a single
+      // offset in RNG sequence. we initialize the RNG state with offset that
+      // starts at the beginning of a (n_queries, n_keys) matrix for this
+      // block's batch_id and head_id
+      // initializing rng state is very expensive, so we run once per kernel,
+      // rather than once per iteration. each iteration takes a copy of the
+      // initialized RNG state and offsets it as needed.
+      curand_init(
+          std::get<0>(seeds),
+          0,
+          std::get<1>(seeds) + p.dropout_batch_head_rng_offset,
+          &curand_state_init);
+    }
+#endif
+
     // Iterate through keys
     for (int32_t iter_key_start = 0; iter_key_start < p.num_keys;
          iter_key_start += kKeysPerBlock) {
       int32_t problem_size_0_m =
           cutlass::fast_min((int32_t)kQueriesPerBlock, p.num_queries);
       int32_t problem_size_0_n = cutlass::fast_min(
           int32_t(kKeysPerBlock), p.num_keys - iter_key_start);
@@ -605,24 +758,73 @@
       typename MM0::Mma::Operator::IteratorC::TensorCoord
           iteratorC_tile_offset = {
               (tb_tile_offset.m() * MM0::Mma::WarpCount::kM) +
                   (my_warp_id % MM0::Mma::WarpCount::kM),
               (tb_tile_offset.n() * MM0::Mma::WarpCount::kN) +
                   (my_warp_id / MM0::Mma::WarpCount::kM)};
 
+      // multiply by scaling factor
+      if (kSupportsBias) {
+        accum =
+            cutlass::multiplies<typename MM0::Mma::FragmentC>()(p.scale, accum);
+      }
+
+      // apply attention bias if applicable
+      if (kSupportsBias && p.attn_bias_ptr != nullptr) {
+        // load bias tile Bij into shared memory
+        typename MM0::BiasLoader::GmemTileIterator bias_iter(
+            {cutlass::layout::RowMajor(p.bias_strideM)},
+            // attn_bias_pointer points to matrix of size (n_queries, n_keys)
+            // for the relevant batch_id and head_id
+            p.attn_bias_ptr + query_start * p.bias_strideM + iter_key_start,
+            {problem_size_0_m, problem_size_0_n},
+            thread_id());
+        cutlass::TensorRef<scalar_t, cutlass::layout::RowMajor> bias_tensor_ref(
+            shared_storage.after_mm0.bias.data(),
+            cutlass::layout::RowMajor(MM0::ThreadblockShape::kN));
+        typename MM0::BiasLoader::SmemTileIterator smem_tile_iter(
+            bias_tensor_ref, thread_id());
+        MM0::BiasLoader::load(bias_iter, smem_tile_iter);
+
+        // Pij += Bij, Pij is in register fragment and Bij is in shared memory
+        auto lane_offset = MM0::AccumLambdaIterator::get_lane_offset(
+            lane_id(), warp_id(), iteratorC_tile_offset);
+        MM0::AccumLambdaIterator::iterateRows(
+            lane_offset,
+            [&](int accum_m) {},
+            [&](int accum_m, int accum_n, int idx) {
+              if (accum_m < problem_size_0_m && accum_n < problem_size_0_n) {
+                accum[idx] += bias_tensor_ref.at({accum_m, accum_n});
+              }
+            },
+            [&](int accum_m) {});
+      }
+
       // Mask out last if causal
-      if (p.causal && p.num_keys - iter_key_start <= kKeysPerBlock) {
+      // This is only needed if upper-right corner of current query / key block
+      // intersects the mask Coordinates of upper-right corner of current block
+      // is y=query_start x=min(iter_key_start + kKeysPerBlock, num_keys)) The
+      // first masked element is x = y + offset -> query_start + offset There is
+      // intersection (and we need to mask) if min(iter_key_start +
+      // kKeysPerBlock, num_keys)) >= query_start + offset
+      if (p.custom_mask_type &&
+          cutlass::fast_min(iter_key_start + kKeysPerBlock, p.num_keys) >=
+              (query_start + p.causal_diagonal_offset)) {
         auto query_start = blockIdx.x * kQueriesPerBlock;
-        auto lane_offset = MM0::ScalingCoefsUpdater::get_lane_offset(
+        auto lane_offset = MM0::AccumLambdaIterator::get_lane_offset(
             lane_id(), warp_id(), iteratorC_tile_offset);
         int32_t last_col;
-        MM0::ScalingCoefsUpdater::iterateRows(
+        MM0::AccumLambdaIterator::iterateRows(
             lane_offset,
             [&](int accum_m) {
-              last_col = query_start + accum_m - iter_key_start;
+              // last absolute col is (last absolute query + offset)
+              // last local col is (last absolute query + offset -
+              // iter_key_start)
+              last_col = query_start + accum_m + p.causal_diagonal_offset -
+                  iter_key_start;
             },
             [&](int accum_m, int accum_n, int idx) {
               if (accum_n > last_col) {
                 accum[idx] =
                     -cutlass::platform::numeric_limits<accum_t>::infinity();
               }
             },
@@ -630,33 +832,30 @@
       }
       DISPATCH_BOOL(iter_key_start == 0, kIsFirst, ([&] {
                       DISPATCH_BOOL(
                           p.num_keys - iter_key_start >= kKeysPerBlock,
                           kFullColumns,
                           ([&] {
                             // Update `mi` from accum stored in registers
-                            // Also updates `accum` with accum[i] <-
-                            // exp(accum[i] * scale
-                            // - mi)
-                            MM0::ScalingCoefsUpdater::update<
-                                kQueriesPerBlock,
+                            // Also does accum[i] <- exp(accum[i] - mi)
+                            iterative_softmax<
+                                typename MM0::Mma::Operator::IteratorC,
                                 kFullColumns,
-                                kIsFirst,
-                                kKeepOutputInRF>(
+                                kIsFirst>(
                                 accum_o,
                                 accum,
                                 mi,
                                 m_prime,
                                 s_prime,
                                 lane_id(),
                                 thread_id(),
                                 warp_id(),
                                 p.num_keys - iter_key_start,
                                 iteratorC_tile_offset,
-                                1.0f / cutlass::fast_sqrt(float(p.head_dim)));
+                                kSupportsBias ? 1.0f : p.scale);
                           }));
                     }));
 
       // Output results to shared-memory
       int warp_idx_mn_0 = my_warp_id %
           (MM0::Mma::Base::WarpCount::kM * MM0::Mma::Base::WarpCount::kN);
       auto output_tile_coords = cutlass::MatrixCoord{
@@ -664,14 +863,77 @@
           warp_idx_mn_0 / MM0::Mma::Base::WarpCount::kM};
 
       MM0::B2bGemm::accumToSmem(
           shared_storage.after_mm0.si, accum, my_lane_id, output_tile_coords);
 
       __syncthreads();
 
+#ifdef HAS_PYTORCH
+      // apply dropout (if applicable) after we've written Pij to smem.
+      // dropout is applied by multiplying each element of Pij by:
+      // - 0 with probability dropout_p
+      // - 1 / (1 - dropout_p) with probability 1 - dropout_p
+      //
+      // for backward purposes we want to be able to map each element of the
+      // attention matrix to the same random uniform number as the one we used
+      // in forward, without needing to use the same iteration order or having
+      // to store the dropout matrix. its possible to do this in registers but
+      // it ends up being very slow because each thread having noncontiguous
+      // strips of the Pij tile means we have to skip around a lot, and also
+      // have to generate a single random number at a time
+      if (kSupportsDropout && p.use_dropout) {
+        auto si = shared_storage.after_mm0.si.accum_ref();
+        // each thread handles a contiguous sequence of elements from Sij, all
+        // coming from the same row. the reason they have to come from the same
+        // row is that the sampling random numbers from a contiguous random
+        // number sequence is much more efficient than jumping around, and the
+        // linear offset of each element of S (the global matrix) maps to an
+        // offset in a random number sequence. for S, the end of a row and the
+        // beginning of the next have adjacent offsets, but for Sij, this is not
+        // necessarily the case.
+        const int num_threads = blockDim.x * blockDim.y * blockDim.z;
+        const int threads_per_row =
+            cutlass::fast_min(num_threads / problem_size_0_m, problem_size_0_n);
+        const int elts_per_thread = cutlass::round_nearest(
+            cutlass::ceil_div(problem_size_0_n, threads_per_row), 4);
+
+        const int thread_i = thread_id() / threads_per_row;
+        const int thread_start_j =
+            (thread_id() % threads_per_row) * elts_per_thread;
+
+        if (thread_i < problem_size_0_m && thread_start_j < problem_size_0_n) {
+          curandStatePhilox4_32_10_t curand_state = curand_state_init;
+          skipahead(
+              static_cast<unsigned long long>(
+                  (query_start + thread_i) * p.num_keys +
+                  (iter_key_start + thread_start_j)),
+              &curand_state);
+          const float dropout_scale = 1.0 / (1.0 - p.dropout_prob);
+
+          // apply dropout scaling to elements this thread is responsible for,
+          // in chunks of 4
+          for (int sij_start_col_idx = thread_start_j; sij_start_col_idx <
+               cutlass::fast_min(thread_start_j + elts_per_thread,
+                                 problem_size_0_n);
+               sij_start_col_idx += 4) {
+            const float4 rand_uniform_quad = curand_uniform4(&curand_state);
+
+            CUTLASS_PRAGMA_UNROLL
+            for (int quad_idx = 0; quad_idx < 4; ++quad_idx) {
+              si.at({thread_i, sij_start_col_idx + quad_idx}) *=
+                  static_cast<scalar_t>(
+                      dropout_scale *
+                      ((&rand_uniform_quad.x)[quad_idx] > p.dropout_prob));
+            }
+          }
+        }
+        __syncthreads(); // p.use_dropout should have same value kernel-wide
+      }
+#endif
+
       //
       // MATMUL: Attn . V
       // Run the matmul `attn @ V` for a block of attn and V.
       // `attn` is read from shared memory (in `shared_storage_si`)
       // `V` is read from global memory (with iterator_B)
       //
 
@@ -835,14 +1097,124 @@
       } else if (thread_id() < lse_dim) {
         p.logsumexp_ptr[thread_id()] =
             cutlass::platform::numeric_limits<accum_t>::infinity();
       }
     }
   }
 
+  template <
+      typename WarpIteratorC,
+      bool kFullColumns,
+      bool kIsFirst>
+  CUTLASS_DEVICE static void iterative_softmax(
+      typename WarpIteratorC::Fragment& frag_o, // output so far
+      typename WarpIteratorC::Fragment& frag,
+      cutlass::Array<accum_t, kQueriesPerBlock>& mi,
+      cutlass::Array<accum_t, kQueriesPerBlock>& m_prime,
+      cutlass::Array<accum_t, kQueriesPerBlock>& s_prime,
+      int8_t lane_id,
+      int8_t thread_id,
+      int8_t warp_id,
+      int16_t max_col,
+      typename WarpIteratorC::TensorCoord const& tile_offset,
+      float scaling) {
+    /* Iterates on the accumulator and corresponding position on result matrix
+
+    (1) Update `mi[r]` to the max value of the row `r`
+    (2) In a second iteration do the following:
+        (a) accum   <- exp(accum - mi)
+        (b) m_prime <- exp(m_prime - mi)
+        (c) s_prime <- s_prime * m_prime + sum(accum)
+
+    All of this is done on registers, before we store all of this
+    on shared memory for the next matmul with Value.
+    */
+    using Fragment = typename WarpIteratorC::Fragment;
+    using LambdaIterator = typename DefaultMmaAccumLambdaIterator<
+        WarpIteratorC,
+        accum_t,
+        kWarpSize>::Iterator;
+    // Convert to `accum_t` (rather than double)
+    constexpr float kLog2e = 1.4426950408889634074; // log_2(e) = M_LOG2E
+    if (!kIsFirst) {
+      if (thread_id < kQueriesPerBlock) {
+        m_prime[thread_id] = mi[thread_id];
+      }
+      __syncthreads();
+    }
+
+    auto lane_offset =
+        LambdaIterator::get_lane_offset(lane_id, warp_id, tile_offset);
+
+    // First update `mi` to the max per-row
+    {
+      accum_t max;
+      LambdaIterator::iterateRows(
+          lane_offset,
+          [&](int accum_m) {
+            max = -cutlass::platform::numeric_limits<accum_t>::infinity();
+          },
+          [&](int accum_m, int accum_n, int idx) {
+            if (kFullColumns || accum_n < max_col) {
+              max = cutlass::fast_max(max, frag[idx]);
+            }
+          },
+          [&](int accum_m) {
+            // Having 4x atomicMax seems faster than reduce within warp
+            // first...
+            atomicMaxFloat(&mi[accum_m], max * scaling);
+          });
+    }
+    frag = cutlass::multiplies<Fragment>()(scaling * kLog2e, frag);
+
+    // Make sure we all share the update values for `mi`
+    __syncthreads();
+
+    if (thread_id < kQueriesPerBlock) {
+      auto m_prime_exp = exp2f(kLog2e * (m_prime[thread_id] - mi[thread_id]));
+      m_prime[thread_id] = m_prime_exp;
+      s_prime[thread_id] *= m_prime_exp;
+    }
+    __syncthreads(); // Update output fragments
+    if (kKeepOutputInRF && !kIsFirst) {
+      accum_t mp;
+      LambdaIterator::iterateRows(
+          lane_offset,
+          [&](int accum_m) { mp = m_prime[accum_m]; },
+          [&](int accum_m, int accum_n, int idx) { frag_o[idx] *= mp; },
+          [&](int accum_m) {});
+      __syncthreads();
+    }
+    // Update accum_m, accum_n, ...
+    {
+      accum_t mi_row, total_row;
+      LambdaIterator::iterateRows(
+          lane_offset,
+          [&](int accum_m) { mi_row = kLog2e * mi[accum_m]; },
+          [&](int accum_m, int accum_n, int idx) {
+            frag[idx] = (kFullColumns || accum_n < max_col)
+                ? exp2f(frag[idx] - mi_row)
+                : accum_t(0.0);
+          },
+          [&](int accum_m) {});
+      LambdaIterator::iterateRows(
+          lane_offset,
+          [&](int accum_m) { total_row = 0.0; },
+          [&](int accum_m, int accum_n, int idx) { total_row += frag[idx]; },
+          [&](int accum_m) {
+            if (LambdaIterator::reduceSameRow(
+                    lane_id, total_row, [](accum_t a, accum_t b) {
+                      return a + b;
+                    })) {
+              atomicAdd(&s_prime[accum_m], total_row);
+            }
+          });
+    }
+  }
+
   static CUTLASS_DEVICE int8_t lane_id() {
     return threadIdx.x;
   }
   static CUTLASS_DEVICE int8_t warp_id() {
     return threadIdx.y;
   }
   static CUTLASS_DEVICE int16_t thread_id() {
@@ -858,93 +1230,7 @@
   }
   AK::attention_kernel(p);
 }
 
 template <typename AK>
 __global__ void __launch_bounds__(AK::kNumThreads, AK::kMinBlocksPerSm)
     attention_kernel_batched(typename AK::Params params);
-
-#define _ATTENTION_KERNEL_FORWARD_BEGIN(...)                                  \
-  template <>                                                                 \
-  __global__ void __launch_bounds__(                                          \
-      __VA_ARGS__::kNumThreads, __VA_ARGS__::kMinBlocksPerSm)                 \
-      attention_kernel_batched<__VA_ARGS__>(typename __VA_ARGS__::Params p) { \
-    using Kernel = __VA_ARGS__;
-#define _ATTENTION_KERNEL_FORWARD_END() }
-
-#ifdef __CUDA_ARCH__
-#define __CUDA_ARCH_OR_ZERO__ __CUDA_ARCH__
-#else
-#define __CUDA_ARCH_OR_ZERO__ 0
-#endif
-
-#define INSTANTIATE_ATTENTION_KERNEL_FORWARD(              \
-    ARCH,                                                  \
-    SCALAR_T,                                              \
-    IS_ALIGNED,                                            \
-    QUERIES_PER_BLOCK,                                     \
-    KEYS_PER_BLOCK,                                        \
-    SINGLE_VALUE_ITER)                                     \
-  _ATTENTION_KERNEL_FORWARD_BEGIN(AttentionKernel<         \
-                                  SCALAR_T,                \
-                                  cutlass::arch::Sm##ARCH, \
-                                  IS_ALIGNED,              \
-                                  QUERIES_PER_BLOCK,       \
-                                  KEYS_PER_BLOCK,          \
-                                  SINGLE_VALUE_ITER>)      \
-  if (!p.advance_to_block()) {                             \
-    return;                                                \
-  }                                                        \
-  Kernel::attention_kernel(p);                             \
-  _ATTENTION_KERNEL_FORWARD_END();
-
-#define INSTANTIATE_ATTENTION_KERNEL_FORWARD_DISABLED(              \
-    ARCH,                                                           \
-    SCALAR_T,                                                       \
-    IS_ALIGNED,                                                     \
-    QUERIES_PER_BLOCK,                                              \
-    KEYS_PER_BLOCK,                                                 \
-    SINGLE_VALUE_ITER)                                              \
-  _ATTENTION_KERNEL_FORWARD_BEGIN(AttentionKernel<                  \
-                                  SCALAR_T,                         \
-                                  cutlass::arch::Sm##ARCH,          \
-                                  IS_ALIGNED,                       \
-                                  QUERIES_PER_BLOCK,                \
-                                  KEYS_PER_BLOCK,                   \
-                                  SINGLE_VALUE_ITER>)               \
-  printf(                                                           \
-      "FATAL: this function is for sm%d, but was built for sm%d\n", \
-      int(ARCH),                                                    \
-      int(__CUDA_ARCH_OR_ZERO__));                                  \
-  _ATTENTION_KERNEL_FORWARD_END();
-
-// All kernels are disabled by default
-#define INSTANTIATE_ATTENTION_KERNEL_FORWARD_SM50(...) \
-  INSTANTIATE_ATTENTION_KERNEL_FORWARD_DISABLED(50, __VA_ARGS__)
-#define INSTANTIATE_ATTENTION_KERNEL_FORWARD_SM70(...) \
-  INSTANTIATE_ATTENTION_KERNEL_FORWARD_DISABLED(70, __VA_ARGS__)
-#define INSTANTIATE_ATTENTION_KERNEL_FORWARD_SM75(...) \
-  INSTANTIATE_ATTENTION_KERNEL_FORWARD_DISABLED(75, __VA_ARGS__)
-#define INSTANTIATE_ATTENTION_KERNEL_FORWARD_SM80(...) \
-  INSTANTIATE_ATTENTION_KERNEL_FORWARD_DISABLED(80, __VA_ARGS__)
-
-// Enable the right one based on __CUDA_ARCH__
-#ifndef __CUDA_ARCH__
-#elif __CUDA_ARCH__ < 500
-#error "Need cuda arch at least 5.0"
-#elif __CUDA_ARCH__ < 700
-#undef INSTANTIATE_ATTENTION_KERNEL_FORWARD_SM50
-#define INSTANTIATE_ATTENTION_KERNEL_FORWARD_SM50(...) \
-  INSTANTIATE_ATTENTION_KERNEL_FORWARD(50, __VA_ARGS__)
-#elif __CUDA_ARCH__ < 750
-#undef INSTANTIATE_ATTENTION_KERNEL_FORWARD_SM70
-#define INSTANTIATE_ATTENTION_KERNEL_FORWARD_SM70(...) \
-  INSTANTIATE_ATTENTION_KERNEL_FORWARD(70, __VA_ARGS__)
-#elif __CUDA_ARCH__ < 800
-#undef INSTANTIATE_ATTENTION_KERNEL_FORWARD_SM75
-#define INSTANTIATE_ATTENTION_KERNEL_FORWARD_SM75(...) \
-  INSTANTIATE_ATTENTION_KERNEL_FORWARD(75, __VA_ARGS__)
-#elif __CUDA_ARCH__ >= 800
-#undef INSTANTIATE_ATTENTION_KERNEL_FORWARD_SM80
-#define INSTANTIATE_ATTENTION_KERNEL_FORWARD_SM80(...) \
-  INSTANTIATE_ATTENTION_KERNEL_FORWARD(80, __VA_ARGS__)
-#endif
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/mma_from_smem.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/mma_from_smem.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights
  *reserved. SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice,
  *this list of conditions and the following disclaimer.
@@ -380,15 +380,15 @@
         {Base::kWarpGemmIterations * warp_idx_k, warp_idx_n});
   }
 
   // For API compatibility with MmaMultistageFromSharedMemory
   // but not supported as it worsens perf: older gpus < sm80 don't
   // support async tranfers and have to waste registers
   CUTLASS_DEVICE
-  bool set_prologue_done(bool value) {}
+  void set_prologue_done(bool value) {}
   CUTLASS_DEVICE
   static void prologue(
       typename Base::SharedStorage& shared_storage,
       IteratorB iterator_B1,
       int thread_idx,
       int problem_size_0_n) {}
 
@@ -616,20 +616,20 @@
   struct Detail {
     static_assert(
         Base::kWarpGemmIterations1 > 1,
         "The pipelined structure requires at least two warp-level "
         "GEMM operations.");
 
     /// Number of cp.async instructions to load one stage of operand B
-    static int const TBLDGSTSIterationsB1 =
+    static int const TBLoadIterationsB1 =
         IteratorB1::ThreadMap::Iterations::kCount;
 
     /// Number of cp.async instructions to load on group of operand B
     static int const kAccessesPerGroupB1 =
-        (TBLDGSTSIterationsB1 + Base::kWarpGemmIterations1 - 1) /
+        (TBLoadIterationsB1 + Base::kWarpGemmIterations1 - 1) /
         Base::kWarpGemmIterations1;
   };
 
   static constexpr int kNumStagesConcurrentLoad =
       kSmemContainsEntireB ? Base::kStages : Base::kStages - 1;
 
  private:
@@ -691,15 +691,15 @@
     warp_tile_iterator_A1_.add_tile_offset(
         {warp_idx_m_1, Base::kWarpGemmIterations1 * warp_idx_k_1});
     this->warp_tile_iterator_B_.add_tile_offset(
         {Base::kWarpGemmIterations1 * warp_idx_k_1, warp_idx_n_1});
   }
 
   CUTLASS_DEVICE
-  bool set_prologue_done(bool value) {
+  void set_prologue_done(bool value) {
     prologue_done_ = value;
   }
 
   CUTLASS_DEVICE
   static void prologue(
       typename Base::SharedStorage& shared_storage,
       IteratorB iterator_B1,
@@ -716,18 +716,18 @@
   void copy_tiles_and_advance_1(
       IteratorB1& iterator_B1,
       int group_start_B1 = 0) {
     iterator_B1.set_iteration_index(
         group_start_B1 * IteratorB1::kAccessesPerVector);
     this->smem_iterator_B1_.set_iteration_index(group_start_B1);
 
-    // LDGSTS for operand B
+    // Load for operand B
     CUTLASS_PRAGMA_UNROLL
     for (int j = 0; j < Detail::kAccessesPerGroupB1; ++j) {
-      if (group_start_B1 + j < Detail::TBLDGSTSIterationsB1) {
+      if (group_start_B1 + j < Detail::TBLoadIterationsB1) {
         typename IteratorB1::AccessType* dst_ptr =
             reinterpret_cast<typename IteratorB1::AccessType*>(
                 this->smem_iterator_B1_.get());
 
         int const kSrcBytes = sizeof_bits<typename IteratorB1::Element>::value *
             IteratorB1::ThreadMap::kElementsPerAccess /
             IteratorB1::kAccessesPerVector / 8;
@@ -757,17 +757,17 @@
          ++stage, --gemm_k_iterations_1) {
       iterator_B1.set_residual_tile(gemm_k_iterations_1 == 1);
       iterator_B1.clear_mask(gemm_k_iterations_1 == 0);
 
       iterator_B1.set_iteration_index(0);
       smem_iterator_B1_.set_iteration_index(0);
 
-      // LDGSTS for operand B
+      // Load for operand B
       CUTLASS_PRAGMA_UNROLL
-      for (int j = 0; j < Detail::TBLDGSTSIterationsB1; ++j) {
+      for (int j = 0; j < Detail::TBLoadIterationsB1; ++j) {
         typename IteratorB1::AccessType* dst_ptr =
             reinterpret_cast<typename IteratorB1::AccessType*>(
                 smem_iterator_B1_.get());
 
         CUTLASS_PRAGMA_UNROLL
         for (int v = 0; v < IteratorB1::kAccessesPerVector; ++v) {
           int const kSrcBytes =
@@ -824,17 +824,17 @@
       // Issue several complete stages
       CUTLASS_PRAGMA_UNROLL
       for (int stage = 0; stage < kNumStagesConcurrentLoad;
            ++stage, --gemm_k_iterations_1) {
         iterator_B1.set_iteration_index(0);
         this->smem_iterator_B1_.set_iteration_index(0);
 
-        // LDGSTS for operand B
+        // Load for operand B
         CUTLASS_PRAGMA_UNROLL
-        for (int j = 0; j < Detail::TBLDGSTSIterationsB1; ++j) {
+        for (int j = 0; j < Detail::TBLoadIterationsB1; ++j) {
           CUTLASS_PRAGMA_UNROLL
           for (int v = 0; v < IteratorB1::kAccessesPerVector; ++v) {
             ++iterator_B1;
           }
           ++this->smem_iterator_B1_;
         }
         iterator_B1.add_tile_offset({1, 0});
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_multi_head_attention/fused_multihead_attention.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/handle.cu`

 * *Files 25% similar despite different names*

```diff
@@ -1,22 +1,22 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
  *
  * 2. Redistributions in binary form must reproduce the above copyright notice,
  * this list of conditions and the following disclaimer in the documentation
  * and/or other materials provided with the distribution.
  *
- * 3. Neither the name of the copyright holdvr nor the names of its
+ * 3. Neither the name of the copyright holder nor the names of its
  * contributors may be used to endorse or promote products derived from
  * this software without specific prior written permission.
  *
  * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
  * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
  * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
@@ -26,1120 +26,1147 @@
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 
 /*! \file
-    \brief CUTLASS Attention Example.
+    \brief CUTLASS Library handle.
+*/
+#include <iostream> 
+#include <stdexcept>
+#include <cstdint>
+
+#include "cutlass/library/handle.h"
+#include "cutlass/library/singleton.h"
+#include "cutlass/library/util.h"
 
-    This workload computes an attention example with non-fixed sequence length input. Pointers of arrays
-    are fed into grouped-GEMM functions fused with softmax for computation.
+namespace cutlass {
+namespace library {
 
-    Examples:
+///////////////////////////////////////////////////////////////////////////////////////////////////
 
-      # Run an attention example with default setup (max sequence length = 1024, batch size = 16, head size = 64, head number = 12)
-      $ ./examples/41_multi_head_attention/41_multi_head_attention
+/// Constructor
+Handle::Handle(
+  cudaStream_t stream, 
+  size_t workspace_size
+):
+  provider_(Provider::kCUTLASS), 
+  stream_(stream), 
+  workspace_(nullptr), 
+  workspace_size_(0), 
+  scalar_pointer_mode_(ScalarPointerMode::kHost), 
+  last_operation_(nullptr) {
 
-      # Run an attention example with batch size = 64 and head number = 16 without checking the correctness
-      $ ./examples/41_multi_head_attention/41_multi_head_attention --head_number=16 --batch_size=64 --reference-check=false
+  int device_idx = -1;
 
-*/
+  cudaError_t error = cudaGetDevice(&device_idx);
+  if (error != cudaSuccess) {
+    throw std::runtime_error("cudaGetDevice() failed");
+  }
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+  error = cudaGetDeviceProperties(&device_, device_idx);
+  if (error != cudaSuccess) {
+    throw std::runtime_error("cudaGetDeviceProperties() failed");
+  }
 
-#include <iostream>
-#include <fstream>
-#include <sstream>
-#include <vector>
-#include <map>
-#include <unordered_map>
-
-#include "cutlass/cutlass.h"
-#include "cutlass/gemm/gemm.h"
-#include "cutlass/gemm/kernel/gemm_grouped.h"
-#include "cutlass/gemm/kernel/default_gemm_grouped.h"
-#include "cutlass/gemm/device/gemm_grouped.h"
-#include "cutlass/gemm/device/gemm_universal.h"
-
-#include "cutlass/util/command_line.h"
-#include "cutlass/util/distribution.h"
-#include "cutlass/util/device_memory.h"
-#include "cutlass/util/tensor_view_io.h"
-#include "cutlass/util/host_tensor.h"
-#include "cutlass/util/reference/host/gemm_complex.h"
-#include "cutlass/util/reference/device/gemm_complex.h"
-#include "cutlass/util/reference/host/tensor_compare.h"
-#include "cutlass/util/reference/host/tensor_copy.h"
-#include "cutlass/util/reference/device/tensor_fill.h"
-#include "cutlass/util/reference/host/tensor_norm.h"
-
-#include "cutlass/layout/matrix.h"
-#include "cutlass/gemm/kernel/gemm_grouped.h"
-#include "cutlass/gemm/kernel/gemm_transpose_operands.h"
-#include "cutlass/gemm/kernel/default_gemm.h"
-#include "cutlass/gemm/kernel/default_gemm_complex.h"
-#include "cutlass/gemm/device/default_gemm_configuration.h"
-#include "cutlass/gemm/gemm.h"
-
-#include "cutlass/epilogue/threadblock/epilogue_with_visitor.h"
-#include "cutlass/fast_math.h"
-#include "gemm_attention.h"
+  set_workspace_size(workspace_size);
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+  Singleton::get();
+}
 
-/// Result structure
-struct Result {
+/// Destructor
+Handle::~Handle() {
+  if (workspace_) {
 
-  double runtime_ms;
-  double gflops;
-  cutlass::Status status;
-  cudaError_t error;
-  bool passed;
-
-  //
-  // Methods
-  //
-
-  Result(
-    double runtime_ms = 0,
-    double gflops = 0,
-    cutlass::Status status = cutlass::Status::kSuccess,
-    cudaError_t error = cudaSuccess
-  ):
-    runtime_ms(runtime_ms), gflops(gflops), status(status), error(error), passed(true) { }
-};
+    if (workspace_) {
+      cudaFree(workspace_);
+    }
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+    workspace_ = nullptr;
+    workspace_size_ = 0;
+  }
+}
 
-// Command line options parsing
-struct Options {
+/// Move constructor
+Handle::Handle(Handle && handle) {
+  device_ = handle.device_;
+  workspace_size_ = handle.workspace_size_;
+  workspace_ = handle.workspace_;
+  stream_ = handle.stream_;
+  scalar_pointer_mode_ = handle.scalar_pointer_mode_;
+  
+  handle.workspace_ = nullptr;
+  handle.workspace_size_ = 0;
+}
 
-  bool help;
-  bool error;
-  bool reference_check;
-  bool use_mask;
-
-  std::vector<cutlass::gemm::GemmCoord> problem_sizes0;
-  std::vector<cutlass::gemm::GemmCoord> problem_sizes1;
-
-  std::vector<cutlass::gemm::GemmCoord> problem_sizes0_real;
-  std::vector<cutlass::gemm::GemmCoord> problem_sizes1_real;
-
-  int alignment;
-  int head_number;
-  int batch_size;
-  int head_size;
-  int seq_length;
-  int iterations;
-  int cuda_streams;
-
-  // alpha0, alpha1 and beta are fixed 
-  // in this multi-head attention example
-  float alpha0;
-  float alpha1;
-  float beta;
-
-  //
-  // Methods
-  // 
-
-  Options():
-    help(false),
-    error(false),
-    alignment(16),
-    reference_check(true),
-    head_number(12),
-    batch_size(16),
-    head_size(64),
-    seq_length(1024),
-    use_mask(false),
-    iterations(20),
-    cuda_streams(0)
-  { }
-
-  // Parses the command line
-  void parse(int argc, char const **args) {
-    cutlass::CommandLine cmd(argc, args);
-
-    if (cmd.check_cmd_line_flag("help")) {
-      help = true;
-      return;
-    }
+/// Move assignment operator
+Handle & Handle::operator=(Handle && handle) {
 
-    cmd.get_cmd_line_argument("alignment", alignment, 16);
-    cmd.get_cmd_line_argument("head_number", head_number, 12);
-    cmd.get_cmd_line_argument("batch_size", batch_size, 16);
-    cmd.get_cmd_line_argument("head_size", head_size, 64);
-    cmd.get_cmd_line_argument("seq_length", seq_length, 1024);
-    cmd.get_cmd_line_argument("use_mask", use_mask, false);
-    cmd.get_cmd_line_argument("iterations", iterations, 20);
-    cmd.get_cmd_line_argument("streams", cuda_streams, 0);
-    cmd.get_cmd_line_argument("reference-check", reference_check, true);
+  provider_ = handle.provider_;
+  device_ = handle.device_;
+  workspace_size_ = handle.workspace_size_;
+  workspace_ = handle.workspace_;
+  stream_ = handle.stream_;
+  scalar_pointer_mode_ = handle.scalar_pointer_mode_;
 
-    randomize_problems();
+  handle.workspace_ = nullptr;
+  handle.workspace_size_ = 0;
 
-  }
+  return *this;
+}
 
-  void randomize_problems() {
+int Handle::compute_capability() const {
+  return device_.major * 10 + device_.minor;
+}
 
-    int problem_count = head_number * batch_size;
+/// Sets the current CUDA stream
+void Handle::set_stream(cudaStream_t stream) {
+  stream_ = stream;
+}
 
-    problem_sizes0.reserve(problem_count);
-    problem_sizes1.reserve(problem_count);
+/// Gets the current CUDA stream
+cudaStream_t Handle::get_stream() const {
+  return stream_;
+}
 
-    // When using mask, the original inputs are not padded
-    // and we need to save these info.
-    if (use_mask) {
-      problem_sizes0_real.reserve(problem_count);
-      problem_sizes1_real.reserve(problem_count);
-    }
+/// Gets the current provider
+Provider Handle::get_provider() const {
+  return provider_;
+}
 
-    for (int i = 0; i < batch_size; ++i) {
-      // problems belonging to the same batch share the same seq len
-      int m_real = (rand() % seq_length);
-      int m = (m_real + 1 + alignment - 1) / alignment * alignment;
-      int n = m;
-      int k = head_size;
-
-      for (int j = 0; j < head_number; ++j) {
-        cutlass::gemm::GemmCoord problem0(m, n, k);
-        cutlass::gemm::GemmCoord problem1(m, k, n);
-        problem_sizes0.push_back(problem0);
-        problem_sizes1.push_back(problem1);
-
-        if (use_mask) {
-          cutlass::gemm::GemmCoord problem0_real(m_real, m_real, k);
-          cutlass::gemm::GemmCoord problem1_real(m_real, k, m_real);
-          problem_sizes0_real.push_back(problem0_real);
-          problem_sizes1_real.push_back(problem1_real);
-        }
+/// Sets the provider of operations
+void Handle::set_provider(Provider provider) {
+  provider_ = provider;
+}
 
+/// Gets the device workspace size
+size_t Handle::get_workspace_size() const {
+  return workspace_size_;
+}
+
+/// Gets a pointer to the device workspace allocation in Global Memory
+void *Handle::get_workspace() const {
+  return workspace_;
+}
+
+/// Sets the size of device workspace, invalidating previous calls to get_device_workspace()
+void Handle::set_workspace_size(size_t bytes) {
+  if (bytes != workspace_size_) {
+
+    if (workspace_) {
+      cudaFree(workspace_);
+    }
+      
+    workspace_ = nullptr;
+    workspace_size_ = bytes;
+
+    if (workspace_size_) {
+  
+      cudaError_t error = cudaMalloc((void **)&workspace_, workspace_size_);
+  
+      if (error != cudaSuccess) {
+        throw std::runtime_error("Failed to allocate workspace");
       }
     }
   }
 
-  /// Prints the usage statement.
-  std::ostream & print_usage(std::ostream &out) const {
+  if (workspace_) {
+    cudaError_t error = cudaMemset(workspace_, 0, workspace_size_);
 
-    out << "41_multi_head_attention\n\n"
-      << "Options:\n\n"
-      << "  --help                      If specified, displays this usage statement.\n\n"
-      << "  --head_number=<int>         Head number in multi-head attention (default: --head_number=12)\n"
-      << "  --batch_size=<int>          Batch size in multi-head attention (default: --batch_size=16)\n"
-      << "  --head_size=<int>           Head size in multi-head attention (default: --head_size=64)\n"
-      << "  --seq_length=<int>          Max sequence length in multi-head attention (default: --seq_length=1024)\n"
-      << "  --use_mask=<bool>           If true, performs padding-like masking in softmax.\n"
-      << "  --iterations=<int>          Number of profiling iterations to perform.\n"
-      << "  --reference-check=<bool>    If true, performs reference check.\n";
-
-    return out;
-  }
-
-  /// Compute performance in GFLOP/s
-  double gflops(double runtime_s) const {
-
-    // Number of real-valued multiply-adds 
-    int64_t fmas = int64_t();
-
-    for (auto const & problem : problem_sizes0) {
-      // Two flops per multiply-add
-      fmas += problem.product() * 2;
+    if (error != cudaSuccess) {
+      throw std::runtime_error("Failed to clear workspace");
     }
-    
-    // Multiply another '2' because of the back-to-back GEMM problems in attention
-    return 2.0 * double(fmas) / double(1.0e9) / runtime_s;
   }
-};
+}
 
+/// Gets the scalar pointer mode
+ScalarPointerMode Handle::get_scalar_pointer_mode() const {
+  return scalar_pointer_mode_;
+}
 
+/// Sets the scalar pointer mode
+void Handle::set_scalar_pointer_mode(ScalarPointerMode mode) {
+  scalar_pointer_mode_ = mode;
+}
+
+/// Gets the last operation
+Operation const *Handle::get_last_operation() const {
+  return last_operation_;
+}
 
 ///////////////////////////////////////////////////////////////////////////////////////////////////
 
-template <typename Attention>
-class TestbedAttention {
-public:
-
-  //
-  // Type definitions
-  //
-
-  using ElementQ = typename Attention::ElementQ;
-  using ElementK = typename Attention::ElementK;
-  using ElementP = typename Attention::ElementP;
-  using ElementAccumulator = typename Attention::GemmGrouped0::ElementAccumulator;
-  using ElementV = typename Attention::ElementV;
-  using ElementO = typename Attention::ElementOutput;
-
-  using EpilogueOutputOp = typename Attention::GemmGrouped0::GemmKernel::EpilogueVisitor::ElementwiseFunctor;
-  using ElementCompute = typename EpilogueOutputOp::ElementCompute;
-
-  using ElementNorm = typename Attention::ElementNorm;
-  using ElementSum = typename Attention::ElementSum;
-  using ElementSoftmaxCompute = typename Attention::ElementSoftmaxCompute;
-
-  using LayoutQ = typename Attention::LayoutQ;
-  using LayoutK = typename Attention::LayoutK;
-  using LayoutP = typename Attention::LayoutP;
-  using LayoutV = typename Attention::LayoutV;
-  using LayoutO = typename Attention::LayoutO;
-
-  using MatrixCoord = typename LayoutP::TensorCoord;
-
-  using ProblemVisitor0 = typename Attention::GemmKernel0::ProblemVisitor;
-  using ProblemVisitor1 = typename Attention::GemmKernel1::ProblemVisitor;
-
-private:
-
-  //
-  // Data members
-  //
-
-  Options & options;
-
-  /// Initialization
-  cutlass::Distribution::Kind init_Q;
-  cutlass::Distribution::Kind init_K;
-  cutlass::Distribution::Kind init_P;
-  cutlass::Distribution::Kind init_V;
-  cutlass::Distribution::Kind init_O;
-  uint32_t seed;
-
-  cutlass::DeviceAllocation<cutlass::gemm::GemmCoord> problem_sizes_device0;
-  cutlass::DeviceAllocation<cutlass::gemm::GemmCoord> problem_sizes_device1;
-  cutlass::DeviceAllocation<cutlass::gemm::GemmCoord> problem_sizes_device0_real;
-
-  std::vector<int64_t> offset_Q;
-  std::vector<int64_t> offset_K;
-  std::vector<int64_t> offset_P;
-  std::vector<int64_t> offset_V;
-  std::vector<int64_t> offset_O;
-  std::vector<int64_t> offset_Norm;
-  std::vector<int64_t> offset_Sum;
-
-  std::vector<int64_t> ldq_host;
-  std::vector<int64_t> ldk_host;
-  std::vector<int64_t> ldp_host;
-  std::vector<int64_t> ldv_host;
-  std::vector<int64_t> ldo_host;
-  std::vector<int64_t> seqlen_host;
-
-  cutlass::DeviceAllocation<int64_t> ldq;
-  cutlass::DeviceAllocation<int64_t> ldk;
-  cutlass::DeviceAllocation<int64_t> ldp;
-  cutlass::DeviceAllocation<int64_t> ldv;
-  cutlass::DeviceAllocation<int64_t> ldo;
-  cutlass::DeviceAllocation<int64_t> seqlen;
-
-  cutlass::DeviceAllocation<ElementQ> block_Q;
-  cutlass::DeviceAllocation<ElementK> block_K;
-  cutlass::DeviceAllocation<ElementP> block_P;
-  cutlass::DeviceAllocation<ElementV> block_V;
-  cutlass::DeviceAllocation<ElementO> block_O;
-  cutlass::DeviceAllocation<ElementNorm> block_Norm;
-  cutlass::DeviceAllocation<ElementSum> block_Sum;
-
-  cutlass::DeviceAllocation<int64_t> offset_P_Device;
-  cutlass::DeviceAllocation<int64_t> offset_Norm_Device;
-  cutlass::DeviceAllocation<int64_t> offset_Sum_Device;
-
-  cutlass::DeviceAllocation<ElementQ *> ptr_Q;
-  cutlass::DeviceAllocation<ElementK *> ptr_K;
-  cutlass::DeviceAllocation<ElementP *> ptr_P;
-  cutlass::DeviceAllocation<ElementV *> ptr_V;
-  cutlass::DeviceAllocation<ElementO *> ptr_O;
-  cutlass::DeviceAllocation<ElementNorm *> ptr_Max;
-  cutlass::DeviceAllocation<ElementSum *> ptr_Sum;
-
-public:
-
-  //
-  // Methods
-  //
-
-  TestbedAttention(
-    Options &options_,
-    cutlass::Distribution::Kind init_Q_ = cutlass::Distribution::Uniform,
-    cutlass::Distribution::Kind init_K_ = cutlass::Distribution::Uniform,
-    cutlass::Distribution::Kind init_P_ = cutlass::Distribution::Uniform,
-    cutlass::Distribution::Kind init_V_ = cutlass::Distribution::Uniform,
-    cutlass::Distribution::Kind init_O_ = cutlass::Distribution::Uniform,
-    uint32_t seed_ = 3080
-  ):
-    options(options_), init_Q(init_Q_), init_K(init_K_), init_P(init_P_), init_V(init_V_), init_O(init_O_), seed(seed_) { }
-
-  int problem_count() const {
-    return (options.head_number * options.batch_size);
-  }
-
-private:
-
-  /// Helper to initialize a tensor view
-  template <typename Element>
-  void initialize_tensor_(
-    Element *ptr,
-    size_t capacity, 
-    cutlass::Distribution::Kind dist_kind,
-    uint32_t seed) {
-
-    if (dist_kind == cutlass::Distribution::Uniform) {
-
-      Element scope_max, scope_min;
-      int bits_input = cutlass::sizeof_bits<Element>::value;
-      int bits_output = cutlass::sizeof_bits<typename Attention::ElementP>::value;
-
-      if (bits_input == 1) {
-        scope_max = 2;
-        scope_min = 0;
-      } else if (bits_input <= 8) {
-        scope_max = 2;
-        scope_min = -2;
-      } else if (bits_output == 16) {
-        scope_max = 8;
-        scope_min = -8;
-      } else {
-        scope_max = 8;
-        scope_min = -8;
-      }
+/// Returns the maximum required alignment for each operator
+static int maximum_alignment_requirement(GemmDescription const &desc) {
+  return std::max(
+    std::max(desc.A.alignment, desc.B.alignment), desc.C.alignment);
+}
 
-      cutlass::reference::device::BlockFillRandomUniform(
-        ptr, capacity, seed, scope_max, scope_min, 0);
-    } 
-    else if (dist_kind == cutlass::Distribution::Gaussian) {
+/// Returns the largest alignment (in units of elements) the problem satisfies, starting from a
+/// given upper limit.
+static int gemm_problem_alignment(
+  int M,
+  int N,
+  int K,
+  NumericTypeID element_A,
+  void const *ptr_A,
+  int64_t lda,
+  int64_t batch_stride_A,
+  NumericTypeID element_B,
+  void const *ptr_B,
+  int64_t ldb,
+  int64_t batch_stride_B,
+  NumericTypeID element_C,
+  void const * ptr_C,
+  int64_t ldc,
+  int64_t batch_stride_C,
+  void const * ptr_D,
+  int64_t ldd,
+  int64_t batch_stride_D,
+  int max_alignment_in_bytes = 16
+) {
+
+  void const *pointers[] = {
+    ptr_A, ptr_B, ptr_C, ptr_D
+  };
+
+  int64_t extents[] = {
+    M, N, K, lda, ldb, ldc, ldd, batch_stride_A, batch_stride_B, batch_stride_C, batch_stride_D
+  };
+
+  NumericTypeID elements[] = {
+    element_A, element_B, element_C
+  };
 
-      cutlass::reference::device::BlockFillRandomGaussian(
-        ptr, capacity, seed, Element(), Element(0.5f));
-    }
-    else if (dist_kind == cutlass::Distribution::Sequential) {
+  for (; max_alignment_in_bytes > 0; max_alignment_in_bytes /= 2) {
+    
+    bool satisfied = true;
 
-      // Fill with increasing elements
-      cutlass::reference::device::BlockFillSequential(
-        ptr, capacity, Element(1), Element());
-    } 
-    else {
-
-      // Fill with all 1s
-      cutlass::reference::device::BlockFillSequential(
-        ptr, capacity, Element(), Element(1));
+    // Can pointers satisfy this?
+    for (void const *ptr : pointers) {
+      std::uintptr_t int_ptr = reinterpret_cast<std::uintptr_t>(ptr);
+
+      if (int_ptr % max_alignment_in_bytes) {
+        satisfied = false;
+        break;
+      }
     }
-  }
 
-  /// Initializes data structures
-  void initialize_() {
+    if (!satisfied) {
+      continue;
+    }
 
-    //
-    // Set scalors for the mha example
-    //
-
-    options.alpha0 = 1.0f / sqrt(float(options.head_size));
-    options.alpha1 = 1.0f;
-    options.beta = 0;
-
-    //
-    // Choose random problem sizes
-    //
-
-    // construct a few problems of random sizes
-    srand(seed);
-
-    int64_t total_elements_Q = 0;
-    int64_t total_elements_K = 0;
-    int64_t total_elements_P = 0;
-    int64_t total_elements_V = 0;
-    int64_t total_elements_O = 0;
-
-    int64_t total_elements_partial_norm = 0;
-
-    ldq_host.resize(problem_count());
-    ldk_host.resize(problem_count());
-    ldp_host.resize(problem_count());
-    ldv_host.resize(problem_count());
-    ldo_host.resize(problem_count());
-    seqlen_host.resize(problem_count());
-
-    for (int32_t i = 0; i < problem_count(); ++i) {
-
-      auto problem = options.problem_sizes0.at(i);
-
-      ldq_host.at(i) = LayoutQ::packed({problem.m(), problem.k()}).stride(0);
-      ldk_host.at(i) = LayoutK::packed({problem.k(), problem.n()}).stride(0);
-      ldp_host.at(i) = LayoutP::packed({problem.m(), problem.n()}).stride(0);
-      ldv_host.at(i) = LayoutV::packed({problem.n(), problem.k()}).stride(0);
-      ldo_host.at(i) = LayoutO::packed({problem.m(), problem.k()}).stride(0);
-
-      // m = n for attention problems.
-      int64_t non_leading_dim = ldp_host.at(i);
-      int64_t threadblock_n = Attention::GemmGrouped0::GemmKernel::EpilogueVisitor::ThreadblockShape::kN;
-      int64_t threadblock_num = (ldp_host.at(i) + threadblock_n - 1) / threadblock_n;
-
-      seqlen_host.at(i) = problem.m();
-
-      offset_Q.push_back(total_elements_Q);
-      offset_K.push_back(total_elements_K);
-      offset_P.push_back(total_elements_P);
-      offset_V.push_back(total_elements_V);
-      offset_O.push_back(total_elements_O);
-      offset_Norm.push_back(total_elements_partial_norm);
-      offset_Sum.push_back(total_elements_partial_norm);
-
-      int64_t elements_Q = problem.m() * problem.k();
-      int64_t elements_K = problem.k() * problem.n();
-      int64_t elements_P = problem.m() * problem.n();
-      int64_t elements_V = problem.n() * problem.k();
-      int64_t elements_O = problem.m() * problem.k();
-      int64_t elements_norm = non_leading_dim * threadblock_num;
-
-      total_elements_Q += elements_Q;
-      total_elements_K += elements_K;
-      total_elements_P += elements_P;
-      total_elements_V += elements_V;
-      total_elements_O += elements_O;
-      total_elements_partial_norm += elements_norm;
+    // Compute the maximum alignment based on element data types
+    int max_element_alignment = 0;
 
+    for (NumericTypeID type_id : elements) {
+      int element_alignment = max_alignment_in_bytes * 8 / library::sizeof_bits(type_id); 
+      max_element_alignment = std::max(max_element_alignment, element_alignment);
     }
 
-    problem_sizes_device0.reset(problem_count());
-    problem_sizes_device1.reset(problem_count());
-    problem_sizes_device0.copy_from_host(options.problem_sizes0.data());
-    problem_sizes_device1.copy_from_host(options.problem_sizes1.data());
-
-    if (options.use_mask) {
-      problem_sizes_device0_real.reset(problem_count());
-      problem_sizes_device0_real.copy_from_host(options.problem_sizes0_real.data());
+    // Can the problem size and leading dimensions satisfy this?
+    for (int64_t extent : extents) {
+      if (extent % max_element_alignment) {
+        satisfied = false;
+        break;
+      }
     }
 
-    ldq.reset(problem_count());
-    ldk.reset(problem_count());
-    ldp.reset(problem_count());
-    ldv.reset(problem_count());
-    ldo.reset(problem_count());
-    seqlen.reset(problem_count());
-
-    ldq.copy_from_host(ldq_host.data());
-    ldk.copy_from_host(ldk_host.data());
-    ldp.copy_from_host(ldp_host.data());
-    ldv.copy_from_host(ldv_host.data());
-    ldo.copy_from_host(ldo_host.data());
-    seqlen.copy_from_host(seqlen_host.data());
-
-    //
-    // Assign pointers
-    //
-
-    block_Q.reset(total_elements_Q);
-    block_K.reset(total_elements_K);
-    block_P.reset(total_elements_P);
-    block_V.reset(total_elements_V);
-    block_O.reset(total_elements_O);
-    block_Norm.reset(total_elements_partial_norm);
-    block_Sum.reset(total_elements_partial_norm);
-
-    offset_P_Device.reset(problem_count());
-    offset_Norm_Device.reset(problem_count());
-    offset_Sum_Device.reset(problem_count());
-
-    // sync offset with device
-    cutlass::device_memory::copy_to_device(offset_P_Device.get(), offset_P.data(), offset_P.size());
-    cutlass::device_memory::copy_to_device(offset_Norm_Device.get(), offset_Norm.data(), offset_Norm.size());
-    cutlass::device_memory::copy_to_device(offset_Sum_Device.get(), offset_Sum.data(), offset_Sum.size());
-
-    std::vector<ElementQ *> ptr_Q_host(problem_count());
-    std::vector<ElementK *> ptr_K_host(problem_count());
-    std::vector<ElementP *> ptr_P_host(problem_count());
-    std::vector<ElementV *> ptr_V_host(problem_count());
-    std::vector<ElementO *> ptr_O_host(problem_count());
-    std::vector<ElementNorm *> ptr_norm_host(problem_count());
-    std::vector<ElementSum *> ptr_sum_host(problem_count());
-
-    for (int32_t i = 0; i < problem_count(); ++i) {
-      ptr_Q_host.at(i) = block_Q.get() + offset_Q.at(i);
-      ptr_K_host.at(i) = block_K.get() + offset_K.at(i);
-      ptr_P_host.at(i) = block_P.get() + offset_P.at(i);
-      ptr_V_host.at(i) = block_V.get() + offset_V.at(i);
-      ptr_O_host.at(i) = block_O.get() + offset_O.at(i);
-      ptr_norm_host.at(i) = block_Norm.get() + offset_Norm.at(i);
-      ptr_sum_host.at(i) = block_Sum.get() + offset_Sum.at(i);
+    if (!satisfied) {
+      continue;
     }
 
-    ptr_Q.reset(problem_count());
-    ptr_Q.copy_from_host(ptr_Q_host.data());
-    
-    ptr_K.reset(problem_count());
-    ptr_K.copy_from_host(ptr_K_host.data());
-    
-    ptr_P.reset(problem_count());
-    ptr_P.copy_from_host(ptr_P_host.data());
+    // Yes
+    return max_element_alignment;
+  }
 
-    ptr_V.reset(problem_count());
-    ptr_V.copy_from_host(ptr_V_host.data());
+  // No alignment satisfies this problem
+  return 0;
+}
 
-    ptr_O.reset(problem_count());
-    ptr_O.copy_from_host(ptr_O_host.data());
+/// Find the best kernel in descending order of preference.
+static Operation const * find_gemm_operation(
+  GemmOperationFunctionalMap::const_iterator operators_it, 
+  GemmPreferenceKey const preference_key) {
 
-    ptr_Max.reset(problem_count());
-    ptr_Max.copy_from_host(ptr_norm_host.data());
-
-    ptr_Sum.reset(problem_count());
-    ptr_Sum.copy_from_host(ptr_sum_host.data());
-
-    //
-    // Initialize the problems of the workspace
-    //
-
-    initialize_tensor_(block_Q.get(), total_elements_Q, init_Q, seed + 1);
-    initialize_tensor_(block_K.get(), total_elements_K, init_K, seed + 2);
-    initialize_tensor_(block_V.get(), total_elements_V, init_V, seed + 3);
+  auto cc_it = operators_it->second.upper_bound(preference_key);
 
+  if (cc_it == operators_it->second.begin()) {
+    return nullptr;
   }
 
-  template<typename Element>
-  bool verify_tensor_(std::vector<Element> vector_Input, \
-                       std::vector<Element> vector_Input_Ref,
-                       int64_t verify_length = -1) {
-
-    int64_t size = (vector_Input.size() < vector_Input_Ref.size()) ? vector_Input.size() : vector_Input_Ref.size();
-    size = (verify_length == -1) ? size : verify_length;
-
-    // 0.05 for absolute error
-    float abs_tol = 5e-2f;
-    // 10% for relative error
-    float rel_tol = 1e-1f;
-    for (int64_t i = 0; i < size; ++i) {
-      float diff = (float)(vector_Input.at(i) - vector_Input_Ref.at(i));
-      float abs_diff = fabs(diff);
-      float abs_ref = fabs((float)vector_Input_Ref.at(i) + 1e-5f);
-      float relative_diff = abs_diff / abs_ref;
-      if ( (isnan(abs_diff) || isinf(abs_diff)) ||  (abs_diff > abs_tol && relative_diff > rel_tol)) {
-        printf("diff = %f, rel_diff = %f, {%f, %f}.\n", abs_diff, relative_diff, (float)(vector_Input.at(i)), (float)(vector_Input_Ref.at(i)));
-        return false;
-      }
+  Operation const *operation = nullptr;
 
-    }
+  // Search in descending order of compute capability
+  do {
+    --cc_it;
 
-    return true;
-  }
+    // Search tile sizes in order, for now.
+    for (auto const * op : cc_it->second) {
 
-  /// Verifies the result is a GEMM
-  bool verify_() {
+      GemmDescription const &desc = static_cast<GemmDescription const &>(op->description());
 
-    bool passed = true;
+      int min_cc = desc.tile_description.minimum_compute_capability;
+      int max_cc = desc.tile_description.maximum_compute_capability;
 
-    for (int32_t i = 0; i < problem_count(); ++i) {
-      cutlass::gemm::GemmCoord problem = options.problem_sizes0.at(i);
-      cutlass::gemm::GemmCoord problem1 = options.problem_sizes1.at(i);
-
-      LayoutQ layout_Q(ldq_host.at(i));
-      LayoutK layout_K(ldk_host.at(i));
-      LayoutP layout_P(ldp_host.at(i));
-      LayoutV layout_V(ldv_host.at(i));
-      LayoutO layout_O(ldo_host.at(i));
-
-      MatrixCoord extent_Q{problem.m(), problem.k()};
-      MatrixCoord extent_K{problem.k(), problem.n()};
-      MatrixCoord extent_P{problem.m(), problem.n()};
-      MatrixCoord extent_V{problem.n(), problem.k()};
-      MatrixCoord extent_O{problem.m(), problem.k()};
-
-      cutlass::TensorView<ElementQ, LayoutQ> view_Q(block_Q.get() + offset_Q.at(i), layout_Q, extent_Q);
-      cutlass::TensorView<ElementK, LayoutK> view_K(block_K.get() + offset_K.at(i), layout_K, extent_K);
-      cutlass::TensorView<ElementP, LayoutP> view_P(block_P.get() + offset_P.at(i), layout_P, extent_P);
-      cutlass::TensorView<ElementV, LayoutV> view_V(block_V.get() + offset_V.at(i), layout_V, extent_V);
-
-      cutlass::DeviceAllocation<ElementP>    block_Ref(layout_P.capacity(extent_P));
-      cutlass::TensorView<ElementP, LayoutP> view_Ref_device(block_Ref.get(), layout_P, extent_P);
-
-      cutlass::DeviceAllocation<ElementO>    block_Ref_O(layout_O.capacity(extent_O));
-      cutlass::TensorView<ElementO, LayoutO> view_Ref_O_device(block_Ref_O.get(), layout_O, extent_O);
-
-      // Reference GEMM
-      cutlass::reference::device::GemmComplex<
-          ElementQ, LayoutQ,
-          ElementK, LayoutK,
-          ElementP, LayoutP, 
-          ElementCompute, ElementAccumulator
-      >(
-        problem,
-        ElementAccumulator(options.alpha0), 
-        view_Q,
-        Attention::GemmGrouped0::kTransformA,
-        view_K,
-        Attention::GemmGrouped0::kTransformB,
-        ElementAccumulator(options.beta), 
-        view_P, 
-        view_Ref_device, 
-        ElementAccumulator(0)
-      );
-
-      // Compute softmax for P. We need to explicitly compute softmax
-      // over P because softmax is fused to the second GEMM in the
-      // profiled implementation.
-      std::vector<ElementP> matrix_Ref(layout_P.capacity(extent_P));
-      cutlass::device_memory::copy_to_host(matrix_Ref.data(), block_Ref.get(), matrix_Ref.size());
-      cutlass::TensorView<ElementP, LayoutP> view_Ref_host(matrix_Ref.data(), layout_P, extent_P);
-      std::vector<ElementNorm> vector_Norm_Ref(problem.m());
-      std::vector<ElementSum> vector_Sum_Ref(problem.m());
-
-      int n_dim = options.use_mask ? options.problem_sizes0_real.at(i).n() : problem.n();
-
-      // Compute softmax for referece matrix
-      // Assumed a row-major storage
-      for (int m = 0; m < problem.m(); m++) {
-        ElementSoftmaxCompute max = ElementSoftmaxCompute(view_Ref_host.ref().at({m, 0}));
-        for (int n = 1; n < n_dim; n++) {
-           max = std::max(max, ElementSoftmaxCompute(view_Ref_host.ref().at({m, n})));
-        }
-
-        vector_Norm_Ref.at(m) = ElementNorm(max);
-
-        ElementSoftmaxCompute sum = ElementSoftmaxCompute();
-        for (int n = 0; n < n_dim; n++) {
-          sum += std::exp( ElementSoftmaxCompute(view_Ref_host.ref().at({m, n})) - max );
-        }
-        ElementSoftmaxCompute inv_sum = ElementSoftmaxCompute(1.0f / sum);
-
-        vector_Sum_Ref.at(m) = ElementSum(inv_sum);
-
-        for (int n = 0; n < n_dim; n++) {
-          view_Ref_host.ref().at({m, n}) = ElementP(
-            std::exp( ElementSoftmaxCompute(view_Ref_host.ref().at({m, n})) - max ) * inv_sum
-          );
-        }
+      int op_alignment = maximum_alignment_requirement(desc);
 
-      }
+      if ((min_cc <= preference_key.compute_capability) &&
+        (preference_key.compute_capability <= max_cc) &&
+        (op_alignment <= preference_key.alignment)) {
 
-      // when not using mask, problem_real and problem share the same sizes
-      if (options.use_mask) {
-        for (int m = 0; m < problem.m(); m++) {
-          for (int n = n_dim; n < problem.n(); n++) {
-            view_Ref_host.ref().at({m, n}) = ElementP(0);
-          }
-        }
+        operation = op;
+        break;
       }
+    }
+  } while (!operation && cc_it != operators_it->second.begin());
 
-      cutlass::device_memory::copy_to_device(block_P.get() + offset_P.at(i), matrix_Ref.data(), matrix_Ref.size());
+  return operation;
+}
 
-      // Reference GEMM
-      cutlass::reference::device::GemmComplex<
-          ElementP, LayoutP,
-          ElementV, LayoutV,
-          ElementO, LayoutO, 
-          ElementCompute, ElementAccumulator
-      >(
-        problem1,
-        ElementAccumulator(options.alpha1), 
-        view_P,
-        Attention::GemmGrouped0::kTransformA,
-        view_V,
-        Attention::GemmGrouped0::kTransformB,
-        ElementAccumulator(options.beta), 
-        view_Ref_O_device, 
-        view_Ref_O_device, 
-        ElementAccumulator(0)
-      );
-
-      // Copy to host memory
-
-      int64_t threadblock_n = Attention::GemmGrouped0::GemmKernel::EpilogueVisitor::ThreadblockShape::kN;
-      int64_t threadblock_num = (problem.m() + threadblock_n - 1) / threadblock_n;
-
-      std::vector<ElementNorm> vector_Norm(problem.m() * threadblock_num);
-      std::vector<ElementSum> vector_Sum(problem.m() * threadblock_num);
-
-      cutlass::device_memory::copy_to_host(vector_Norm.data(),   block_Norm.get() + offset_Norm.at(i), vector_Norm.size());
-      cutlass::device_memory::copy_to_host(vector_Sum.data(),   block_Sum.get() + offset_Sum.at(i), vector_Sum.size());
-
-      cutlass::TensorView<ElementP, LayoutP> view_Ref(matrix_Ref.data(), layout_P, extent_P);
-
-      std::vector<ElementO> matrix_O(layout_O.capacity(extent_O));
-      cutlass::device_memory::copy_to_host(matrix_O.data(),   block_O.get() + offset_O.at(i), matrix_O.size());
-      std::vector<ElementP> matrix_Ref_O(layout_O.capacity(extent_O));
-      cutlass::device_memory::copy_to_host(matrix_Ref_O.data(), block_Ref_O.get(), matrix_Ref_O.size());
-
-      bool verified_N = false;
-      bool verified_S = false;
-      bool verified_O = false;
+///////////////////////////////////////////////////////////////////////////////////////////////////
 
-      if (!verified_N) {
-        verified_N = verify_tensor_<ElementNorm>(vector_Norm, vector_Norm_Ref);
-      }
-      
-      if (!verified_S) {
-        verified_S = verify_tensor_<ElementSum>(vector_Sum, vector_Sum_Ref);
-      }
+/// Executes a GEMM computation: D <= alpha * A*B + beta * C
+Status Handle::gemm(
 
+  int M,                                    /// GEMM M dimension
+  int N,                                    /// GEMM N dimension
+  int K,                                    /// GEMM K dimension
 
-      if (!verified_O) {
-        verified_O = verify_tensor_<ElementO>(matrix_O, matrix_Ref_O);
-      }
+  NumericTypeID element_compute,            /// Data type of internal accumulation
 
-      passed = passed && verified_N && verified_S && verified_O;
+  NumericTypeID element_scalar,             /// Data type of alpha/beta scalars
 
-      if (!passed) {
-        std::cerr << "\n***\nError - problem " << i << " failed the QA check\n***\n" << std::endl;
+  void const *alpha,                        /// Pointer to alpha scalar
 
-        if (!verified_O) {
-          std::cout << "Final matrix output is incorrect" << std::endl;
-        }
+  NumericTypeID element_A,                  /// Data type of A matrix elements
+  LayoutTypeID layout_A,                    /// Layout of A matrix
+  ComplexTransform transform_A,             /// Complex transformation applied to A matrix - ignored for real-valued matrices
 
-        if (!verified_N) {
-          std::cout << "Max is incorrect" << std::endl;
-        }
+  void const * ptr_A,                       /// Pointer to A matrix in Global Memory
+  int64_t lda,                              /// Leading dimension of A matrix
 
-        if (!verified_S) {
-          std::cout << "Sum is incorrect" << std::endl;
-        }
+  NumericTypeID element_B,                  /// Data type of B matrix elements
+  LayoutTypeID layout_B,                    /// Layout of B matrix
+  ComplexTransform transform_B,             /// Complex transformation applied to B matrix - ignored for real-valued matrices
 
-        return passed;
-      }
+  void const * ptr_B,                       /// Pointer to B matrix in Global Memory
+  int64_t ldb,                              /// Leading dimension of B matrix
 
-    }
+  void const * beta,                        /// Pointer to beta scalar
 
-    return passed;
+  NumericTypeID element_C,                  /// Data type of C and D matrices
+
+  void const * ptr_C,                       /// Pointer to C matrix
+  int64_t ldc,                              /// Leading dimension of C matrix
+
+  void * ptr_D,                             /// Pointer to D matrix
+  int64_t ldd                               /// Leading dimension of D matrix
+) {
+  
+  //
+  // Find the operation
+  //
+
+  GemmFunctionalKey key(
+    provider_,
+    GemmKind::kGemm,
+    element_compute,
+    element_scalar,
+    element_A,
+    layout_A,
+    transform_A,
+    element_B,
+    layout_B,
+    transform_B,
+    element_C
+  );
+
+  auto operators_it = Singleton::get().operation_table.gemm_operations.find(key);
+
+  if (operators_it == Singleton::get().operation_table.gemm_operations.end()) {
+    return cutlass::Status::kErrorNotSupported;
+  }
+  
+  if (operators_it->second.empty()) {
+    return cutlass::Status::kErrorNotSupported;
   }
 
-public:
+  //
+  // Compute the largest alignment restriction the kernel can satisfy.
+  //
 
-  /// Returns the number of threadblocks to launch if the kernel can run on the target
-  /// device. Otherwise, returns zero.
-  int sufficient() const {
-    cudaDeviceProp properties;
-    int device_idx;
-    cudaError_t result = cudaGetDevice(&device_idx);
+  // Maximum alignment expectation among all kernels (in units of bytes)
+  int const kMaximumAlignmentSize = 16;
 
-    if (result != cudaSuccess) {
-      throw std::runtime_error("cudaGetDevice() API call failed.");
-    }
+  int alignment = gemm_problem_alignment(
+    M, N, K, 
+    element_A, ptr_A, lda, 0,
+    element_B, ptr_B, ldb, 0,
+    element_C, ptr_C, ldc, 0,
+    ptr_D, ldd, 0, kMaximumAlignmentSize
+  );
 
-    result = cudaGetDeviceProperties(&properties, device_idx);
+  //
+  // Find the best kernel in descending order of preference.
+  //
 
-    if (result != cudaSuccess) {
-      throw std::runtime_error("cudaGetDeviceProperties() failed");
-    }
+  GemmPreferenceKey preference_key(compute_capability(), alignment);
 
-    int occupancy = Attention::GemmGrouped0::maximum_active_blocks();
+  Operation const *operation = find_gemm_operation(operators_it, preference_key);
 
-    return properties.multiProcessorCount * occupancy;
+  if (!operation) {
+    return cutlass::Status::kErrorNotSupported;
+  }
 
+  last_operation_ = operation;
+
+  //
+  // Configure operation
+  //
+
+  GemmConfiguration configuration{
+    {M, N, K},
+    lda,
+    ldb,
+    ldc,
+    ldd,
+    1
+  };
+
+  // Query host work space size
+  uint64_t host_workspace_size_needed = operation->get_host_workspace_size(&configuration);
+
+  if (uint64_t(kHostWorkspaceSize) < host_workspace_size_needed) {
+    return cutlass::Status::kErrorNotSupported;
   }
 
+  char host_workspace[kHostWorkspaceSize];
 
-  /// Executes a CUTLASS Attention kernel and measures runtime.
-  Result profile_grouped() {
+  // Query device workspace size
+  uint64_t device_workspace_size_needed = operation->get_device_workspace_size(&configuration);
 
-    Result result;
+  if (uint64_t(workspace_size_) < device_workspace_size_needed) {
+    return cutlass::Status::kErrorNotSupported;
+  }
 
-    int threadblock_count = sufficient();
+  // Initialize host and device workspaces
+  Status status = operation->initialize(
+    &configuration,
+    host_workspace,
+    workspace_,
+    stream_);
 
-    // Early exit
-    if (!threadblock_count) {
-      std::cout << "Active CUDA device lacks hardware resources to run CUTLASS Attention kernel." << std::endl;
-      return result;
-    }
+  if (status != cutlass::Status::kSuccess) {
+    return status;
+  }
 
-    result.passed = false;
+  // Run the operator
+  GemmArguments arguments{
+    ptr_A,
+    ptr_B,
+    ptr_C,
+    ptr_D,
+    alpha,
+    beta,
+    scalar_pointer_mode_
+  };
 
-    // Initialize the problem
-    initialize_();
+  return operation->run(&arguments, host_workspace, workspace_, stream_);
+}
 
-    typename Attention::Arguments args(
-      problem_sizes_device0.get(),
-      problem_sizes_device1.get(),
-      problem_count(),
-      threadblock_count,
-      ptr_Q.get(),
-      ptr_K.get(),
-      ptr_P.get(),
-      ptr_V.get(),
-      ptr_O.get(),
-      ptr_Max.get(),
-      ptr_Sum.get(),
-      block_P.get(),
-      block_Norm.get(),
-      block_Sum.get(),
-      offset_P_Device.get(),
-      offset_Norm_Device.get(),
-      offset_Sum_Device.get(),
-      ldq.get(),
-      ldk.get(),
-      ldp.get(),
-      ldv.get(),
-      ldo.get(),
-      ElementAccumulator(options.alpha0),
-      ElementAccumulator(options.alpha1),
-      ElementAccumulator(options.beta),
-      options.head_number,
-      options.batch_size,
-      options.seq_length,
-      options.problem_sizes0.data(),
-      options.problem_sizes1.data(),
-      problem_sizes_device0_real.get()
-    );
-
-    size_t workspace_size0 = ProblemVisitor0::kRequiresPrecomputation ?\
-      ProblemVisitor0::get_workspace_size(options.problem_sizes0.data(),\
-                                          problem_count(),\
-                                          threadblock_count)\
-      : 0;
-
-    size_t workspace_size1 = ProblemVisitor1::kRequiresPrecomputation ?\
-      ProblemVisitor1::get_workspace_size(options.problem_sizes1.data(),\
-                                          problem_count(),\
-                                          threadblock_count)\
-      : 0;
-
-    cutlass::DeviceAllocation<uint8_t> workspace0(workspace_size0);
-    cutlass::DeviceAllocation<uint8_t> workspace1(workspace_size1);
-
-    Attention attention;
-
-    result.status = attention.initialize(args, workspace0.get(), workspace1.get());
-
-    if (result.status != cutlass::Status::kSuccess) {
-      std::cerr << "Failed to initialize CUTLASS Attention kernel." << std::endl;
-      return result;
-    }
+///////////////////////////////////////////////////////////////////////////////////////////////////
 
-    result.status = attention.run();
+/// Executes a GEMM computation: D <= alpha * A*B + beta * C.
+//
+// Supports batched-strided, batched array or split-K serial or split-K parallel.
+//
+Status Handle::gemm_universal(
 
-    if (result.status != cutlass::Status::kSuccess) {
-      std::cerr << "Failed to initialize CUTLASS Attention kernel." << std::endl;
-      return result;
-    }
+  GemmUniversalMode mode,                   /// indicates the mode in which the kUniversal GEMM is launched
 
-    // Wait for completion
-    result.error = cudaDeviceSynchronize();
+  int M,                                    /// GEMM M dimension
+  int N,                                    /// GEMM N dimension
+  int K,                                    /// GEMM K dimension
 
-    if (result.error != cudaSuccess)  {
-      std::cerr << "Kernel execution error: " << cudaGetErrorString(result.error);
-      return result;
-    }
+  NumericTypeID element_compute,            /// Data type of internal accumulation
 
-    //
-    // Verify correctness
-    //
-    result.passed = true;
+  NumericTypeID element_scalar,             /// Data type of alpha/beta scalars
 
-    if (options.reference_check) {
-      result.passed = verify_();
-    }
+  void const *alpha,                        /// Pointer to alpha scalar
 
-    //
-    // Warm-up run of the grouped GEMM object
-    //
-
-    result.status = attention.run();
-
-    if (result.status != cutlass::Status::kSuccess) {
-      std::cerr << "Failed to run CUTLASS Attention kernel." << std::endl;
-      return result;
-    }
+  NumericTypeID element_A,                  /// Data type of A matrix elements
+  LayoutTypeID layout_A,                    /// Layout of A matrix
+  ComplexTransform transform_A,             /// Complex transformation applied to A matrix - ignored for real-valued matrices
 
-    //
-    // Construct events
-    //
-
-    cudaEvent_t events[2];
-
-    for (auto & event : events) {
-      result.error = cudaEventCreate(&event);
-      if (result.error != cudaSuccess) {
-        std::cerr << "cudaEventCreate() failed: " << cudaGetErrorString(result.error) << std::endl;
-        return -1;
-      }
-    }
+  void const * ptr_A,                       /// Pointer to A matrix in Global Memory
+  int64_t lda,                                  /// Leading dimension of A matrix
 
-    // Record an event at the start of a series of GEMM operations
-    result.error = cudaEventRecord(events[0]);
-    if (result.error != cudaSuccess) {
-      std::cerr << "cudaEventRecord() failed: " << cudaGetErrorString(result.error) << std::endl;
-      return result;
-    }
+  NumericTypeID element_B,                  /// Data type of B matrix elements
+  LayoutTypeID layout_B,                    /// Layout of B matrix
+  ComplexTransform transform_B,             /// Complex transformation applied to B matrix - ignored for real-valued matrices
 
-    //
-    // Run profiling loop
-    //
+  void const * ptr_B,                       /// Pointer to B matrix in Global Memory
+  int64_t ldb,                                  /// Leading dimension of B matrix
 
-    for (int iter = 0; iter < options.iterations; ++iter) {
-      attention();
-    }
+  void const * beta,                        /// Pointer to beta scalar
 
-    //
-    // Stop profiling loop
-    //
-
-    // Record an event when the GEMM operations have been launched.
-    result.error = cudaEventRecord(events[1]);
-    if (result.error != cudaSuccess) {
-      std::cerr << "cudaEventRecord() failed: " << cudaGetErrorString(result.error) << std::endl;
-      return result;
-    }
+  NumericTypeID element_C,                  /// Data type of C and D matrices
 
-    // Wait for work on the device to complete.
-    result.error = cudaEventSynchronize(events[1]);
-    if (result.error != cudaSuccess) {
-      std::cerr << "cudaEventSynchronize() failed: " << cudaGetErrorString(result.error) << std::endl;
-      return result;
-    }
+  void const * ptr_C,                       /// Pointer to C matrix
+  int64_t ldc,                                  /// Leading dimension of C matrix
 
-    // Measure elapsed runtime
-    float runtime_ms = 0;
-    result.error = cudaEventElapsedTime(&runtime_ms, events[0], events[1]);
-    if (result.error != cudaSuccess) {
-      std::cerr << "cudaEventElapsed() failed: " << cudaGetErrorString(result.error) << std::endl;
-      return result;
-    }
+  void * ptr_D,                             /// Pointer to D matrix
+  int64_t ldd,                                  /// Leading dimension of D matrix
 
-    // Compute average runtime and GFLOPs.
-    result.runtime_ms = double(runtime_ms) / double(options.iterations);
-    result.gflops = options.gflops(result.runtime_ms / 1000.0);
-
-    //
-    // Cleanup
-    //
+  int batch_count,                          /// Batch count or number of split-K slices
 
-    for (auto event : events) {
-      (void)cudaEventDestroy(event);
-    }
+  int64_t batch_stride_A,                   /// Batch stride of A operand
+  int64_t batch_stride_B,                   /// Batch stride of B operand
+  int64_t batch_stride_C,                   /// Batch stride of C operand
+  int64_t batch_stride_D                    /// Batch stride of D operand
+) {
+  
+  //
+  // Find the operation
+  //
 
-    std::cout << std::endl;
-    std::cout << "CUTLASS Attention:\n"
-      << "====================================================" << std::endl;
-    std::cout << "    " << " {max sequence length, head size, head number, batch size} = {" << options.seq_length \
-      << ", " << options.head_size << ", " << options.head_number << ", " << options.batch_size << "}." << std::endl;
-    std::cout << std::endl;
-    std::cout << "    " << "Runtime: " << result.runtime_ms << " ms" << std::endl;
-    std::cout << "    " << "GFLOPs: " << result.gflops << std::endl;
+  GemmFunctionalKey key(
+    provider_,
+    GemmKind::kUniversal,
+    element_compute,
+    element_scalar,
+    element_A,
+    layout_A,
+    transform_A,
+    element_B,
+    layout_B,
+    transform_B,
+    element_C
+  );
 
-    return result;
+  auto operators_it = Singleton::get().operation_table.gemm_operations.find(key);
+
+  if (operators_it == Singleton::get().operation_table.gemm_operations.end()) {
+    return cutlass::Status::kErrorNotSupported;
+  }
+  
+  if (operators_it->second.empty()) {
+    return cutlass::Status::kErrorNotSupported;
   }
 
+  //
+  // Compute the largest alignment restriction the kernel can satisfy.
+  //
 
-};
+  // Maximum alignment expectation among all kernels (in units of bytes)
+  int const kMaximumAlignmentSize = 16;
 
-///////////////////////////////////////////////////////////////////////////////////////////////////
+  void const *ptr_A_check = ptr_A;
+  void const *ptr_B_check = ptr_B;
+  void const *ptr_C_check = ptr_C;
+  void *      ptr_D_check = ptr_D;
+
+  // Ignore alignment of pointers to pointers. We can't check this from the host,
+  // as each batch index has its own pointer in device memory.
+  if (mode == GemmUniversalMode::kArray) {
+    ptr_A_check = nullptr; 
+    ptr_B_check = nullptr; 
+    ptr_C_check = nullptr; 
+    ptr_D_check = nullptr; 
+  }
 
-int main(int argc, char const **args) {
+  int alignment = gemm_problem_alignment(
+    M, N, K, 
+    element_A, ptr_A_check, lda, 0,
+    element_B, ptr_B_check, ldb, 0,
+    element_C, ptr_C_check, ldc, 0,
+    ptr_D_check, ldd, 0, kMaximumAlignmentSize
+  );
 
   //
-  // This example uses mma.sync to directly access Tensor Cores to achieve peak performance.
+  // Find the best kernel in descending order of preference.
   //
 
-  cudaDeviceProp props;
+  GemmPreferenceKey preference_key(compute_capability(), alignment);
 
-  cudaError_t error = cudaGetDeviceProperties(&props, 0);
-  if (error != cudaSuccess) {
-    std::cerr << "cudaGetDeviceProperties() returned an error: " << cudaGetErrorString(error) << std::endl;
-    return -1;
+  Operation const *operation = find_gemm_operation(operators_it, preference_key);
+
+  if (!operation) {
+    return cutlass::Status::kErrorNotSupported;
+  }
+
+  last_operation_ = operation;
+
+  //
+  // Configure operation
+  //
+
+  GemmUniversalConfiguration configuration{
+    mode,
+    {M, N, K},
+    batch_count,
+    lda,
+    ldb,
+    ldc,
+    ldd
+  };
+
+  // Query host work space size
+  uint64_t host_workspace_size_needed = operation->get_host_workspace_size(&configuration);
+
+  if (uint64_t(kHostWorkspaceSize) < host_workspace_size_needed) {
+    return cutlass::Status::kErrorNotSupported;
+  }
+
+  char host_workspace[kHostWorkspaceSize];
+
+  GemmUniversalArguments arguments{
+    {M, N, K},
+    batch_count,
+    ptr_A,
+    ptr_B,
+    ptr_C,
+    ptr_D,
+    alpha,
+    beta,
+    scalar_pointer_mode_,
+    lda,
+    ldb,
+    ldc,
+    ldd,
+    batch_stride_A,
+    batch_stride_B,
+    batch_stride_C,
+    batch_stride_D
+  };
+
+  // Query device workspace size
+  uint64_t device_workspace_size_needed = operation->get_device_workspace_size(&configuration, &arguments);
+
+  if (uint64_t(workspace_size_) < device_workspace_size_needed) {
+    return cutlass::Status::kErrorNotSupported;
   }
 
-  if (__CUDACC_VER_MAJOR__ < 11 || props.major < 8) {
+  // Initialize host and device workspaces
+  Status status = operation->initialize(
+    &configuration,
+    host_workspace,
+    workspace_,
+    stream_);
+
+  if (status != cutlass::Status::kSuccess) {
+    return status;
+  }
+
+  // Run the operator
+
+  return operation->run(&arguments, host_workspace, workspace_, stream_);
+}
+
+///////////////////////////////////////////////////////////////////////////////////////////////////
+
+/// Planar complex GEMM
+Status Handle::gemm_planar_complex(
+
+  int M,                                    /// GEMM M dimension
+  int N,                                    /// GEMM N dimension
+  int K,                                    /// GEMM K dimension
+
+  NumericTypeID element_compute,            /// Data type of internal accumulation
+
+  NumericTypeID element_scalar,             /// Data type of alpha/beta scalars
+
+  void const *alpha,                        /// Pointer to alpha scalar
+
+  NumericTypeID element_A,                  /// Data type of A matrix elements
+  LayoutTypeID layout_A,                    /// Layout of A matrix
+  ComplexTransform transform_A,             /// Complex transformation applied to A matrix
+
+  void const * ptr_A_real,                  /// Pointer to real part of A matrix
+  void const * ptr_A_imag,                  /// Pointer to imaginary part of A matrix
+  int64_t lda_real,                         /// Leading dimension of real part of A matrix
+  int64_t lda_imag,                         /// Leading dimension of imaginary part of A matrix
+
+  NumericTypeID element_B,                  /// Data type of B matrix elements
+  LayoutTypeID layout_B,                    /// Layout of B matrix
+  ComplexTransform transform_B,             /// Complex transformation applied to B matrix
+
+  void const * ptr_B_real,                  /// Pointer to real part of B matrix
+  void const * ptr_B_imag,                  /// Pointer to imaginary part of B matrix
+  int64_t ldb_real,                             /// Leading dimension of real part of B matrix
+  int64_t ldb_imag,                             /// Leading dimension of imaginary part of B matrix
+
+  void const * beta,                        /// Pointer to beta scalar
+
+  NumericTypeID element_C,                  /// Data type of C and D matrix
+
+  void const * ptr_C_real,                  /// Pointer to real part of C matrix
+  void const * ptr_C_imag,                  /// Pointer to imaginary part of C matrix
+  int64_t ldc_real,                             /// Leading dimension of real part of C matrix
+  int64_t ldc_imag,                             /// Leading dimension of imaginary part of C matrix
+
+  void * ptr_D_real,                        /// Pointer to real part of D matrix
+  void * ptr_D_imag,                        /// Pointer to imaginary part of D matrix
+  int64_t ldd_real,                             /// Leading dimension of real part of D matrix
+  int64_t ldd_imag,                             /// Leading dimension of imaginary part of D matrix
+
+  int batch_count,                          /// Number of batched GEMMs to execute
+
+  int64_t batch_stride_A_real,
+  int64_t batch_stride_A_imag,
+
+  int64_t batch_stride_B_real,
+  int64_t batch_stride_B_imag,
+
+  int64_t batch_stride_C_real,
+  int64_t batch_stride_C_imag,
+
+  int64_t batch_stride_D_real,
+  int64_t batch_stride_D_imag
+) {
+
+  //
+  // Find the operation
+  //
+
+  GemmFunctionalKey key(
+    provider_,
+    GemmKind::kPlanarComplex,
+    element_compute,
+    element_scalar,
+    element_A,
+    layout_A,
+    transform_A,
+    element_B,
+    layout_B,
+    transform_B,
+    element_C
+  );
+
+  auto operators_it = Singleton::get().operation_table.gemm_operations.find(key);
+
+  if (operators_it == Singleton::get().operation_table.gemm_operations.end()) {
+    return cutlass::Status::kErrorNotSupported;
+  }
   
-    //
-    // This example requires an NVIDIA Ampere-architecture GPU.
-    //
+  if (operators_it->second.empty()) {
+    return cutlass::Status::kErrorNotSupported;
+  }
 
-    std::cout 
-      << "CUTLASS's CUTLASS Attention example requires a GPU of NVIDIA's Ampere Architecture or "
-      << "later (compute capability 80 or greater).\n";
+  //
+  // Compute the largest alignment restriction the kernel can satisfy.
+  //
+
+  // Maximum alignment expectation among all kernels (in units of bytes)
+  int const kMaximumAlignmentSize = 16;
+
+  int alignment = std::max(
+    gemm_problem_alignment(
+      M, N, K, 
+      element_A, ptr_A_real, lda_real, batch_stride_A_real,
+      element_B, ptr_B_real, ldb_real, batch_stride_B_real,
+      element_C, ptr_C_real, ldc_real, batch_stride_C_real,
+      ptr_D_real, ldd_real, batch_stride_D_real, kMaximumAlignmentSize
+    ),
+    gemm_problem_alignment(
+      M, N, K, 
+      element_A, ptr_A_imag, lda_imag, batch_stride_A_imag,
+      element_B, ptr_B_imag, ldb_imag, batch_stride_B_imag,
+      element_C, ptr_C_imag, ldc_imag, batch_stride_C_imag,
+      ptr_D_imag, ldd_imag, batch_stride_D_imag, kMaximumAlignmentSize
+    )
+  );
 
-    return 0;
+  //
+  // Find the best kernel in descending order of preference.
+  //
+
+  GemmPreferenceKey preference_key(compute_capability(), alignment);
+
+  Operation const *operation = find_gemm_operation(operators_it, preference_key);
+
+  if (!operation) {
+    return cutlass::Status::kErrorNotSupported;
   }
 
+  last_operation_ = operation;
+
   //
-  // Parse options
+  // Configure operation
   //
 
-  Options options;
+  GemmPlanarComplexConfiguration configuration{
+    GemmUniversalMode::kBatched,
+    {M, N, K},
+    batch_count,
+    lda_real,
+    lda_imag,
+    ldb_real,
+    ldb_imag,
+    ldc_real,
+    ldc_imag,
+    ldd_real,
+    ldd_imag
+  };
+
+  // Query host work space size
+  uint64_t host_workspace_size_needed = operation->get_host_workspace_size(&configuration);
+
+  if (uint64_t(kHostWorkspaceSize) < host_workspace_size_needed) {
+    return cutlass::Status::kErrorNotSupported;
+  }
+
+  char host_workspace[kHostWorkspaceSize];
+
+  // Query device workspace size
+  uint64_t device_workspace_size_needed = operation->get_device_workspace_size(&configuration);
+
+  if (uint64_t(workspace_size_) < device_workspace_size_needed) {
+    return cutlass::Status::kErrorNotSupported;
+  }
+
+  // Initialize host and device workspaces
+  Status status = operation->initialize(
+    &configuration,
+    host_workspace,
+    workspace_,
+    stream_);
+
+  if (status != cutlass::Status::kSuccess) {
+    return status;
+  }
+
+  // Run the operator
+  GemmPlanarComplexArguments arguments{
+    ptr_A_real,
+    ptr_A_imag,
+    ptr_B_real,
+    ptr_B_imag,
+    ptr_C_real,
+    ptr_C_imag,
+    ptr_D_real,
+    ptr_D_imag,
+    alpha,
+    beta,
+    scalar_pointer_mode_,
+    batch_stride_A_real,
+    batch_stride_A_imag,
+    batch_stride_B_real,
+    batch_stride_B_imag,
+    batch_stride_C_real,
+    batch_stride_C_imag,
+    batch_stride_D_real,
+    batch_stride_D_imag
+  };
+
+  return operation->run(&arguments, host_workspace, workspace_, stream_);
+}
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+/// Planar complex batched GEMM loading pointers from arrays in global memory
+Status Handle::gemm_planar_complex_array(
+
+  int expected_M,                           /// Expected GEMM M dimension (used for sizing CUDA grid)
+  int expected_N,                           /// Expected GEMM N dimension (used for sizing CUDA grid)
+  int expected_K,                           /// Expected GEMM K dimension
+  int batch_count,                          /// Number of independent GEMM computations to execute
+
+  int const *M,                             /// Array containing the GEMM M dimension for each batch index
+  int const *N,                             /// Array containing the GEMM N dimension for each batch index
+  int const *K,                             /// Array containing the GEMM K dimension for each batch index
+
+  NumericTypeID element_compute,            /// Data type of internal accumulation
+
+  NumericTypeID element_scalar,             /// Data type of alpha/beta scalars
+
+  void const *alpha,                        /// Pointer to alpha scalar
+
+  NumericTypeID element_A,                  /// Data type of A matrix elements
+  LayoutTypeID layout_A,                    /// Layout of A matrix
+  ComplexTransform transform_A,             /// Complex transformation applied to A matrix
+
+  void const * const * ptr_A_real,          /// Pointer to array containing pointers to real part of A matrices
+  void const * const * ptr_A_imag,          /// Pointer to array containing pointers to imaginary part of A matrices
+
+  int64_t lda_real,                             /// Leading dimension of real part of A matrix
+  int64_t lda_imag,                             /// Leading dimension of imaginary part of A matrix
+
+  NumericTypeID element_B,                  /// Data type of B matrix elements
+  LayoutTypeID layout_B,                    /// Layout of B matrix
+  ComplexTransform transform_B,             /// Complex transformation applied to B matrix
+
+  void const * const * ptr_B_real,          /// Pointer to array containing pointers to real part of B matrices
+  void const * const * ptr_B_imag,          /// Pointer to array containing pointers to imaginary part of B matrices
+
+  int64_t ldb_real,                             /// Leading dimension of real part of B matrix
+  int64_t ldb_imag,                             /// Leading dimension of imaginary part of B matrix
+
+  void const * beta,                        /// Pointer to beta scalar
+
+  NumericTypeID element_C,                  /// Data type of C and D matrix
+
+  void const * const * ptr_C_real,          /// Pointer to array containing pointers to real part of C matrices
+  void const * const * ptr_C_imag,          /// Pointer to array containing pointers to imaginary part of C matrices
+
+  int64_t ldc_real,                             /// Leading dimension of real part of C matrix
+  int64_t ldc_imag,                             /// Leading dimension of imaginary part of C matrix
+
+  void * const * ptr_D_real,                /// Pointer to array containing pointers to real part of D matrices
+  void * const * ptr_D_imag,                /// Pointer to array containing pointers to imaginary part of D matrices
+
+  int64_t ldd_real,                             /// Leading dimension of real part of D matrix
+  int64_t ldd_imag                              /// Leading dimension of imaginary part of D matrix
+) {
   
-  options.parse(argc, args);
+  //
+  // Find the operation
+  //
+
+  GemmFunctionalKey key(
+    provider_,
+    GemmKind::kPlanarComplexArray,
+    element_compute,
+    element_scalar,
+    element_A,
+    layout_A,
+    transform_A,
+    element_B,
+    layout_B,
+    transform_B,
+    element_C
+  );
+
+  auto operators_it = Singleton::get().operation_table.gemm_operations.find(key);
 
-  if (options.help) {
-    options.print_usage(std::cout) << std::endl;
-    return 0;
+  if (operators_it == Singleton::get().operation_table.gemm_operations.end()) {
+    return cutlass::Status::kErrorNotSupported;
+  }
+  
+  if (operators_it->second.empty()) {
+    return cutlass::Status::kErrorNotSupported;
   }
 
-  if (options.error) {
-    std::cerr << "Aborting execution." << std::endl;
-    return -1;
+  //
+  // Compute the largest alignment restriction the kernel can satisfy.
+  //
+
+  // Maximum alignment expectation among all kernels (in units of bytes)
+  int const kMaximumAlignmentSize = 16;
+
+  int alignment = std::max(
+    gemm_problem_alignment(
+      expected_M, expected_N, expected_K, 
+      element_A, nullptr, lda_real, 0,
+      element_B, nullptr, ldb_real, 0,
+      element_C, nullptr, ldc_real, 0,
+      nullptr, ldd_real, 0, kMaximumAlignmentSize
+    ),
+    gemm_problem_alignment(
+      expected_M, expected_N, expected_K, 
+      element_A, nullptr, lda_imag, 0,
+      element_B, nullptr, ldb_imag, 0,
+      element_C, nullptr, ldc_imag, 0,
+      nullptr, ldd_imag, 0, kMaximumAlignmentSize
+    )
+  );
+
+  //
+  // Find the best kernel in descending order of preference.
+  //
+
+  GemmPreferenceKey preference_key(compute_capability(), alignment);
+
+  Operation const *operation = find_gemm_operation(operators_it, preference_key);
+
+  if (!operation) {
+    return cutlass::Status::kErrorNotSupported;
   }
 
+  last_operation_ = operation;
+
   //
-  // Define the CUTLASS Attention type
+  // Configure operation
   //
 
-  using ElementOutput = cutlass::half_t;
-  using ElementAccumulator = cutlass::half_t;
+  GemmPlanarComplexArrayConfiguration configuration{
+    {expected_M, expected_N, expected_K},
+    batch_count,
+    lda_real,
+    lda_imag,
+    ldb_real,
+    ldb_imag,
+    ldc_real,
+    ldc_imag,
+    ldd_real,
+    ldd_imag
+  };
+
+  // Query host work space size
+  uint64_t host_workspace_size_needed = operation->get_host_workspace_size(&configuration);
+
+  if (uint64_t(kHostWorkspaceSize) < host_workspace_size_needed) {
+    return cutlass::Status::kErrorNotSupported;
+  }
+
+  char host_workspace[kHostWorkspaceSize];
+
+  // Query device workspace size
+  uint64_t device_workspace_size_needed = operation->get_device_workspace_size(&configuration);
+
+  if (uint64_t(workspace_size_) < device_workspace_size_needed) {
+    return cutlass::Status::kErrorNotSupported;
+  }
+
+  // Initialize host and device workspaces
+  Status status = operation->initialize(
+    &configuration,
+    host_workspace,
+    workspace_,
+    stream_);
 
-  using ElementQ = cutlass::half_t;
-  using ElementK = cutlass::half_t;
-  using ElementP = ElementOutput;
+  if (status != cutlass::Status::kSuccess) {
+    return status;
+  }
 
-  using LayoutQ = cutlass::layout::RowMajor;
-  using LayoutK = cutlass::layout::ColumnMajor;
-  using LayoutP = cutlass::layout::RowMajor;
+  // Run the operator
+  GemmPlanarComplexArrayArguments arguments{
+    M, N, K,
+    ptr_A_real,
+    ptr_A_imag,
+    ptr_B_real,
+    ptr_B_imag,
+    ptr_C_real,
+    ptr_C_imag,
+    ptr_D_real,
+    ptr_D_imag,
+    alpha,
+    beta,
+    scalar_pointer_mode_
+  };
 
-  static bool const UseMask = false;
+  return operation->run(&arguments, host_workspace, workspace_, stream_);
+}
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
-  if (UseMask != options.use_mask) {
-    std::cerr << "UseMask and user-defined use_mask need to be consistant, "
-    << " aborted execution.\n";
-    return -2;
+/// Finds conv operation instances with Conv::ElementC = Reduction::ElementWorkspace
+Operation const* find_conv_operation_for_parallel_reduction(Operation const *operation) {
+
+  ConvDescription const &conv_desc = 
+    static_cast<ConvDescription const &>(operation->description());
+
+  // if the curren conv operation accumulator and output data type match return operation
+  if(conv_desc.tile_description.math_instruction.element_accumulator == conv_desc.C.element) {
+    return operation;
   }
 
-  using OperatorClass = cutlass::arch::OpClassTensorOp;
-  using ArchTag = cutlass::arch::Sm80;
+  // find conv operation to match conv output and reduction workspace data type
+  ConvFunctionalKey key(
+    library::Provider::kCUTLASS,
+    conv_desc.conv_kind,        
+    conv_desc.A.element,
+    conv_desc.A.layout,
+    conv_desc.B.element,
+    conv_desc.B.layout,
+    conv_desc.tile_description.math_instruction.element_accumulator,
+    conv_desc.C.layout,
+    conv_desc.tile_description.math_instruction.element_accumulator, 
+    conv_desc.element_epilogue);
+
+  // conv operation table for conv2d or conv3d
+  auto conv_operations = (conv_desc.kind == OperationKind::kConv2d) ? 
+                          Singleton::get().operation_table.conv2d_operations : 
+                          Singleton::get().operation_table.conv3d_operations;
 
-  using ThreadblockShape0 = cutlass::gemm::GemmShape<128, 128, 32>;
-  using WarpShape0 = cutlass::gemm::GemmShape<64, 64, 32>;
+  // find ConvFunctionalKey in convolution operation table
+  auto operators_it = conv_operations.find(key);
 
-  using ThreadblockShape1 = cutlass::gemm::GemmShape<64, 64, 32>;
-  using WarpShape1 = cutlass::gemm::GemmShape<32, 32, 32>;
+  if (operators_it == conv_operations.end()) {
+    return nullptr;
+  }
   
-  static int const Stages0 = 3;
-  static int const Stages1 = 4;
+  if (operators_it->second.empty()) {
+    return nullptr;
+  }
 
-  using InstructionShape = cutlass::gemm::GemmShape<16, 8, 16>;
+  // conv operation for same compute capability and iterator algorithm
+  ConvPreferenceKey preference_key(
+    conv_desc.tile_description.minimum_compute_capability, 
+    conv_desc.iterator_algorithm);
 
-  using Attention = cutlass::FusedMultiHeadAttention<
-    ElementQ,
-    LayoutQ,
-    ElementK,
-    LayoutK,
-    ElementP,
-    LayoutP,
-    ElementAccumulator,
-    OperatorClass,
-    ArchTag,
-    ThreadblockShape0,
-    ThreadblockShape1,
-    WarpShape0,
-    WarpShape1,
-    InstructionShape,
-    Stages0,
-    Stages1,
-    UseMask
-  >;
-
-  //
-  // Test and profile
-  //
-
-  TestbedAttention<Attention> testbed(options);
-
-  if (!testbed.sufficient()) {
-    std::cout << "The active CUDA device lacks sufficient hardware resources to execute this kernel.\n";
-    return 0;
-  }
-
-  Result result = testbed.profile_grouped();
-  if (!result.passed) {
-    std::cout << "Profiling CUTLASS attention has failed.\n";
-    std::cout << "\nFailed\n";
-    return -1;
+  auto it = operators_it->second.find(preference_key);
+  
+  if(it == operators_it->second.end()) {
+    return nullptr;
   }
 
-  std::cout << "\nPassed\n";
+  // return matching conv opertion (same tile sizes and instruction)
+  for (auto op : it->second) {
+    if (op->description().tile_description == operation->description().tile_description) {
+      return op;
+    }
+  }
 
-  return 0;
+  return nullptr;
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
+
+/// Finds gemm operation instances with Gemm::ElementC = Reduction::ElementWorkspace
+Operation const* find_gemm_operation_for_parallel_reduction(Operation const *operation) {
+
+  GemmDescription const &gemm_desc = 
+    static_cast<GemmDescription const &>(operation->description());
+
+  // if the curren gemm operation accumulator and output data type match return operation
+  if(gemm_desc.tile_description.math_instruction.element_accumulator == gemm_desc.C.element) {
+    return operation;
+  }
+
+  // find gemm operation to match gemm output and reduction workspace data type
+  GemmFunctionalKey key(
+    library::Provider::kCUTLASS,
+    gemm_desc.gemm_kind,
+    gemm_desc.tile_description.math_instruction.element_accumulator,
+    gemm_desc.element_epilogue,
+    gemm_desc.A.element,
+    gemm_desc.A.layout,
+    gemm_desc.transform_A,
+    gemm_desc.B.element,
+    gemm_desc.B.layout,
+    gemm_desc.transform_B,
+    gemm_desc.tile_description.math_instruction.element_accumulator);
+
+  // gemm operation table
+  auto gemm_operations = Singleton::get().operation_table.gemm_operations;
+
+  // find ConvFunctionalKey in gemm operation table
+  auto operators_it = gemm_operations.find(key);
+
+  if (operators_it == gemm_operations.end()) {
+    return nullptr;
+  }
+
+  if (operators_it->second.empty()) {
+    return nullptr;
+  }
+
+  // A and B uses the same alignment in the generator.py
+  int alignment = gemm_desc.A.alignment;
+
+  // gemm operation for same compute capability and iterator algorithm
+  GemmPreferenceKey preference_key(
+    gemm_desc.tile_description.minimum_compute_capability, 
+    alignment);
+
+  return find_gemm_operation(operators_it, preference_key);
+}
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+} // namespace library
+} // namespace cutlass
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_multi_head_attention/gemm_attention.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_splitk_parallel.h`

 * *Files 23% similar despite different names*

```diff
@@ -1,22 +1,22 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
  *
  * 2. Redistributions in binary form must reproduce the above copyright notice,
  * this list of conditions and the following disclaimer in the documentation
  * and/or other materials provided with the distribution.
  *
- * 3. Neither the name of the copyright holdvr nor the names of its
+ * 3. Neither the name of the copyright holder nor the names of its
  * contributors may be used to endorse or promote products derived from
  * this software without specific prior written permission.
  *
  * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
  * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
  * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
@@ -24,603 +24,615 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
-
 /*! \file
-    \brief Defines the FusedMultiHeadAttention Class
-
-    The class contains the following:
-    1) GEMM0 with epilogue fusion,
-    2) GEMM1 with mainloop fusion, and 
-    3) A lightweight full softmax reduction kernel.
-
+    \brief Template for GEMM performing a reduction over K partitions in parallel.
 */
 
 #pragma once
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
-
-#include <cmath>
-#include <iostream>
-#include <vector>
-#include <limits>
-
 #include "cutlass/cutlass.h"
-#include "cutlass/arch/memory.h"
-#include "cutlass/arch/memory_sm75.h"
-#include "cutlass/epilogue/threadblock/epilogue_visitor_with_softmax.h"
-#include "cutlass/epilogue/thread/scale_type.h"
-#include "cutlass/gemm/kernel/default_gemm_grouped_softmax_mainloop_fusion.h"
-#include "cutlass/reduction/kernel/reduce_softmax_final.h"
-#include "gemm_grouped_with_softmax_visitor.h"
+#include "cutlass/numeric_types.h"
+#include "cutlass/arch/arch.h"
+#include "cutlass/device_kernel.h"
 
-namespace cutlass {
+#include "cutlass/gemm/threadblock/threadblock_swizzle.h"
+#include "cutlass/gemm/kernel/gemm.h"
 
-template <
-  typename ElementQ_,
-  typename LayoutQ_,
-  typename ElementK_,
-  typename LayoutK_,
-  typename ElementP_,
-  typename LayoutP_,
-  typename ElementCompute_,
-  typename OperatorClass_,
-  typename ArchTag_,
-  typename ThreadblockShape0_,
-  typename ThreadblockShape1_,
-  typename WarpShape0_,
-  typename WarpShape1_,
-  typename InstructionShape_,
-  int kStages0_,
-  int kStages1_,
-  bool UseMasking_ = false,
-  cutlass::gemm::kernel::GroupScheduleMode GroupScheduleMode0_ = cutlass::gemm::kernel::GroupScheduleMode::kHostPrecompute,
-  cutlass::gemm::kernel::GroupScheduleMode GroupScheduleMode1_ = cutlass::gemm::kernel::GroupScheduleMode::kHostPrecompute,
-  int Alignment = 128 / cutlass::sizeof_bits<ElementQ_>::value,
-  typename ElementSoftmax_ = ElementP_
->
-class FusedMultiHeadAttention {
-public:
+#include "cutlass/gemm/kernel/default_gemm_splitk_parallel.h"
+#include "cutlass/gemm/device/default_gemm_configuration.h"
 
-  using ElementQ = ElementQ_;
-  using ElementK = ElementK_;
-  using ElementP = ElementP_;
-  using ElementV = ElementK;
-  using ElementOutput = ElementP;
-  using ElementAccumulator = ElementCompute_;
-
-  using LayoutQ = LayoutQ_;
-  using LayoutK = LayoutK_;
-  using LayoutP = LayoutP_;
-  using LayoutV = LayoutK;
-  using LayoutO = LayoutP;
-
-  using ElementNorm = cutlass::half_t;
-  using ElementSum = cutlass::half_t;
-  using ElementSoftmaxCompute = float;
-  using LayoutNorm = cutlass::layout::RowMajor;
+#include "cutlass/epilogue/thread/conversion_op.h"
+#include "cutlass/reduction/kernel/reduce_split_k.h"
+#include "cutlass/reduction/thread/reduction_operators.h"
 
-  using ThreadblockSwizzle = cutlass::gemm::threadblock::GemmBatchedIdentityThreadblockSwizzle;
+////////////////////////////////////////////////////////////////////////////////
 
-  using OperatorClass = OperatorClass_;
-  using ArchTag = ArchTag_;
+namespace cutlass {
+namespace gemm {
+namespace device {
 
-  using ThreadblockShape0 = ThreadblockShape0_;
-  using WarpShape0 = WarpShape0_;
+////////////////////////////////////////////////////////////////////////////////
 
-  using ThreadblockShape1 = ThreadblockShape1_;
-  using WarpShape1 = WarpShape1_;
-  
-  static int const Stages0 = kStages0_;
-  static int const Stages1 = kStages1_;
+/*! 
+  Gemm device-level operator performing parallel reduction over the K partition.
 
+*/
+template <
+    /// Element type for A matrix operand
+    typename ElementA_,
+    /// Layout type for A matrix operand
+    typename LayoutA_,
+    /// Element type for B matrix operand
+    typename ElementB_,
+    /// Layout type for B matrix operand
+    typename LayoutB_,
+    /// Element type for C and D matrix operands
+    typename ElementC_,
+    /// Layout type for C and D matrix operands
+    typename LayoutC_,
+    /// Element type for internal accumulation
+    typename ElementAccumulator_ = ElementC_,
+    /// Operator class tag
+    typename OperatorClass_ = arch::OpClassSimt,
+    /// Tag indicating architecture to tune for.  This is the minimum SM that
+      /// supports the intended feature. The device kernel can be built
+      /// targeting any SM larger than this number.
+    typename ArchTag_ = arch::Sm70,
+    /// Threadblock-level tile size (concept: GemmShape)
+    typename ThreadblockShape_ = typename DefaultGemmConfiguration<
+        OperatorClass_, ArchTag_, ElementA_, ElementB_, ElementC_,
+        ElementAccumulator_>::ThreadblockShape,
+    /// Warp-level tile size (concept: GemmShape)
+    typename WarpShape_ = typename DefaultGemmConfiguration<
+        OperatorClass_, ArchTag_, ElementA_, ElementB_, ElementC_,
+        ElementAccumulator_>::WarpShape,
+    /// Instruction-level tile size (concept: GemmShape)
+    typename InstructionShape_ = typename DefaultGemmConfiguration<
+        OperatorClass_, ArchTag_, ElementA_, ElementB_, ElementC_,
+        ElementAccumulator_>::InstructionShape,
+    /// Epilogue output operator
+    typename EpilogueOutputOp_ = typename DefaultGemmConfiguration<
+        OperatorClass_, ArchTag_, ElementA_, ElementB_, ElementC_,
+        ElementAccumulator_>::EpilogueOutputOp,
+    /// Epilogue output operator
+    typename ConvertScaledOp_ = cutlass::epilogue::thread::Convert<
+        ElementAccumulator_,
+        DefaultGemmConfiguration<OperatorClass_, ArchTag_, ElementA_, ElementB_,
+                                 ElementAccumulator_,
+                                 ElementAccumulator_>::EpilogueOutputOp::kCount,
+        ElementAccumulator_>,
+    /// Reduction operator
+    typename ReductionOp_ = cutlass::reduction::thread::ReduceAdd<
+        ElementAccumulator_, typename EpilogueOutputOp_::ElementAccumulator,
+        EpilogueOutputOp_::kCount>,
+    /// Threadblock-level swizzling operator
+    typename ThreadblockSwizzle_ =
+        threadblock::GemmSplitKHorizontalThreadblockSwizzle,
+    /// Number of stages used in the pipelined mainloop
+    int Stages =
+        DefaultGemmConfiguration<OperatorClass_, ArchTag_, ElementA_, ElementB_,
+                                 ElementC_, ElementAccumulator_>::kStages,
+    /// Access granularity of A matrix in units of elements
+    int kAlignmentA =
+        DefaultGemmConfiguration<OperatorClass_, ArchTag_, ElementA_, ElementB_,
+                                 ElementC_, ElementAccumulator_>::kAlignmentA,
+    /// Access granularity of B matrix in units of elements
+    int kAlignmentB =
+        DefaultGemmConfiguration<OperatorClass_, ArchTag_, ElementA_, ElementB_,
+                                 ElementC_, ElementAccumulator_>::kAlignmentB,
+    /// Operation performed by GEMM
+    typename Operator_ = typename DefaultGemmConfiguration<
+        OperatorClass_, ArchTag_, ElementA_, ElementB_, ElementC_,
+        ElementAccumulator_>::Operator>
+class GemmSplitKParallel {
+ public:
+
+  using ElementA = ElementA_;
+  using LayoutA = LayoutA_;
+  using ElementB = ElementB_;
+  using LayoutB = LayoutB_;
+  using ElementC = ElementC_;
+  using LayoutC = LayoutC_;
+  using ElementAccumulator = ElementAccumulator_;
+  using OperatorClass = OperatorClass_;
+  using ArchTag = ArchTag_;
+  using ThreadblockShape = ThreadblockShape_;
+  using WarpShape = WarpShape_;
   using InstructionShape = InstructionShape_;
-
-  using EpilogueOutputOp0 = cutlass::epilogue::thread::LinearCombination<
-        ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
-        ElementAccumulator, ElementAccumulator, cutlass::epilogue::thread::ScaleType::OnlyAlphaScaling>;
-
-  using EpilogueOutputOp1 = cutlass::epilogue::thread::LinearCombination<
-        ElementOutput, 128 / cutlass::sizeof_bits<ElementOutput>::value,
-        ElementAccumulator, ElementAccumulator, cutlass::epilogue::thread::ScaleType::Nothing>;
-
-  using Operator = typename cutlass::gemm::device::DefaultGemmConfiguration<
-        OperatorClass, ArchTag, ElementQ, ElementK, ElementP,
-        ElementAccumulator>::Operator;
-  static bool const kInternalTranspose = cutlass::platform::is_same<LayoutP, cutlass::layout::ColumnMajor>::value;
-
-  static bool const kUseMasking = UseMasking_;
-
-  static cutlass::gemm::kernel::GroupScheduleMode const kGroupScheduleMode0 = GroupScheduleMode0_;
-  static cutlass::gemm::kernel::GroupScheduleMode const kGroupScheduleMode1 = GroupScheduleMode1_;
-
-  using MapArguments = cutlass::gemm::kernel::detail::MapArguments<
-    ElementQ,
-    LayoutQ,
-    cutlass::ComplexTransform::kNone,
-    8,
-    ElementK,
-    LayoutK,
-    cutlass::ComplexTransform::kNone,
-    8,
-    LayoutP,
-    kInternalTranspose
-  >;
-
-  using DefaultGemmKernel = typename cutlass::gemm::kernel::DefaultGemm<
-    typename MapArguments::ElementA,
-    typename MapArguments::LayoutA,
-    MapArguments::kAlignmentA,
-    typename MapArguments::ElementB,
-    typename MapArguments::LayoutB,
-    MapArguments::kAlignmentB,
-    ElementP,
-    typename MapArguments::LayoutC,
+  using ConvertScaledOp = ConvertScaledOp_;
+  using EpilogueOutputOp = EpilogueOutputOp_;
+  using ReductionOp = ReductionOp_;
+  using ThreadblockSwizzle = ThreadblockSwizzle_;
+  using Operator = Operator_;
+  static int const kStages = Stages;
+
+  /// GEMM kernel 
+  using GemmKernel = typename kernel::DefaultGemmSplitKParallel<
+    ElementA,
+    LayoutA,
+    kAlignmentA,
+    ElementB,
+    LayoutB,
+    kAlignmentB,
+    ElementAccumulator,
+    LayoutC,
     ElementAccumulator,
     OperatorClass,
     ArchTag,
-    ThreadblockShape0,
-    WarpShape0,
+    ThreadblockShape,
+    WarpShape,
     InstructionShape,
-    EpilogueOutputOp0,
+    ConvertScaledOp,
     ThreadblockSwizzle,
-    Stages0,
-    true,
-    Operator,
-    cutlass::gemm::SharedMemoryClearOption::kNone
+    kStages,
+    Operator
   >::GemmKernel;
 
-  using EpilogueVisitor = typename cutlass::epilogue::threadblock::EpilogueVisitorSoftmax<
-    ThreadblockShape0,
-    DefaultGemmKernel::kThreadCount,
-    typename DefaultGemmKernel::Epilogue::OutputTileIterator,
-    typename EpilogueOutputOp0::ElementCompute,
-    ElementNorm,
-    ElementSum,
-    ElementSoftmaxCompute,
-    EpilogueOutputOp0,
-    kUseMasking
-  >;
-
-  using Epilogue = typename cutlass::epilogue::threadblock::EpilogueWithVisitorFromExistingEpilogue<
-    EpilogueVisitor,
-    typename DefaultGemmKernel::Epilogue
-  >::Epilogue;
-
-  using GemmKernel0 = cutlass::gemm::kernel::GemmGroupedWithEpilogueVistor<
-    typename DefaultGemmKernel::Mma,
-    Epilogue,
-    ThreadblockSwizzle,
-    kGroupScheduleMode0,
-    kInternalTranspose,
-    kUseMasking
-  >;
-
-  using GemmGrouped0 = cutlass::gemm::device::GemmGrouped<GemmKernel0>;
-
-  using ApplyFinalReductionDevice = cutlass::reduction::kernel::ApplySoftmaxFinalReduction<
-    ElementNorm,
-    ElementSum,
-    typename GemmGrouped0::GemmKernel::EpilogueVisitor::ElementSoftmaxCompute,
-    typename GemmGrouped0::GemmKernel::EpilogueVisitor::ThreadblockShape,
-    true
+  /// Reduction kernel
+  using ReductionKernel = cutlass::reduction::kernel::ReduceSplitK<
+    cutlass::MatrixShape<4, 32 * EpilogueOutputOp::kCount>,
+    EpilogueOutputOp,
+    ReductionOp
   >;
 
-  using GemmKernel1 = typename cutlass::gemm::kernel::DefaultGemmGroupedSoftmaxMainloopFusion<
-    ElementP, 
-    LayoutP,
-    cutlass::ComplexTransform::kNone,
-    128 / cutlass::sizeof_bits<ElementQ>::value,
-    ElementV,
-    LayoutV,
-    cutlass::ComplexTransform::kNone,
-    128 / cutlass::sizeof_bits<ElementK>::value,
-    ElementNorm,
-    LayoutNorm,
-    ElementOutput,
-    LayoutO,
-    ElementAccumulator,
-    OperatorClass, 
-    ArchTag,
-    ThreadblockShape1,
-    WarpShape1,
-    InstructionShape,
-    EpilogueOutputOp1,
-    ThreadblockSwizzle, 
-    Stages1,
-    kGroupScheduleMode1
-  >::GemmKernel;
+  //
+  //
+  //
 
-  using GemmGrouped1 = cutlass::gemm::device::GemmGrouped<GemmKernel1>;
-
-public:
-
-  /// Arguments class
+  /// Argument structure
   struct Arguments {
-    cutlass::gemm::GemmCoord *problem_sizes0;
-    cutlass::gemm::GemmCoord *problem_sizes0_real;
-    cutlass::gemm::GemmCoord *problem_sizes1;
-    int problem_count;
-    int threadblock_count;
-
-    ElementQ ** ptr_Q;
-    ElementK ** ptr_K;
-    ElementP ** ptr_P;
-    ElementP ** ptr_V;
-    ElementP ** ptr_O;
-
-    ElementNorm **ptr_Max;
-    ElementSum **ptr_Sum;
-
-    ElementP *block_P;
-    ElementNorm *block_Norm;
-    ElementSum *block_Sum;
-    int64_t *offset_P;
-    int64_t *offset_Norm_Device;
-    int64_t *offset_Sum_Device;
-
-    typename LayoutQ::Stride::LongIndex *ldq;
-    typename LayoutK::Stride::LongIndex *ldk;
-    typename LayoutP::Stride::LongIndex *ldp;
-    typename LayoutP::Stride::LongIndex *ldv;
-    typename LayoutP::Stride::LongIndex *ldo;
-
-    cutlass::gemm::GemmCoord *problem_sizes0_host;
-    cutlass::gemm::GemmCoord *problem_sizes1_host;
-
-    ElementAccumulator alpha0;
-    ElementAccumulator alpha1;
-    ElementAccumulator beta;
-
-    int head_number;
-    int batch_size;
-    int seq_length;
 
-    typename ApplyFinalReductionDevice::Arguments reduction;
+    //
+    // Data members
+    //
+
+    GemmCoord problem_size;
+    TensorRef<ElementA const, LayoutA> ref_A;
+    TensorRef<ElementB const, LayoutB> ref_B;
+    TensorRef<ElementC const, LayoutC> ref_C;
+    TensorRef<ElementC, LayoutC> ref_D;
+    typename EpilogueOutputOp::Params epilogue;
+    int split_k_slices;
+    typename ConvertScaledOp::Params convert;
+    typename ReductionOp::Params reduction;
 
     //
     // Methods
     //
-    Arguments(): 
-      problem_count(0), 
-      threadblock_count(0), 
-      ptr_Q(nullptr),
-      ptr_K(nullptr),
-      ptr_P(nullptr),
-      ptr_V(nullptr),
-      ptr_O(nullptr),
-      ptr_Max(nullptr),
-      ptr_Sum(nullptr),
-      block_P(nullptr),
-      block_Norm(nullptr),
-      block_Sum(nullptr),
-      offset_P(nullptr),
-      offset_Norm_Device(nullptr),
-      offset_Sum_Device(nullptr),
-      ldq(nullptr),
-      ldk(nullptr),
-      ldp(nullptr),
-      ldv(nullptr),
-      ldo(nullptr),
-      head_number(0),
-      batch_size(0),
-      seq_length(0)
-    {
 
-    }
+    /// Default ctor
+    CUTLASS_HOST_DEVICE
+    Arguments() { }
 
+    /// Constructs an Arguments structure 
+    CUTLASS_HOST_DEVICE
     Arguments(
-      cutlass::gemm::GemmCoord *problem_sizes0,
-      cutlass::gemm::GemmCoord *problem_sizes1,
-      int problem_count,
-      int threadblock_count,
-      ElementQ ** ptr_Q,
-      ElementK ** ptr_K,
-      ElementP ** ptr_P,
-      ElementP ** ptr_V,
-      ElementP ** ptr_O,
-      ElementNorm **ptr_Max,
-      ElementSum **ptr_Sum,
-      ElementP *block_P,
-      ElementNorm *block_Norm,
-      ElementSum *block_Sum,
-      int64_t *offset_P,
-      int64_t *offset_Norm_Device,
-      int64_t *offset_Sum_Device,
-      typename LayoutQ::Stride::LongIndex *ldq,
-      typename LayoutK::Stride::LongIndex *ldk,
-      typename LayoutP::Stride::LongIndex *ldp,
-      typename LayoutP::Stride::LongIndex *ldv,
-      typename LayoutP::Stride::LongIndex *ldo,
-      ElementAccumulator alpha0,
-      ElementAccumulator alpha1,
-      ElementAccumulator beta,
-      int head_number,
-      int batch_size,
-      int seq_length,
-      cutlass::gemm::GemmCoord *problem_sizes0_host = nullptr,
-      cutlass::gemm::GemmCoord *problem_sizes1_host = nullptr,
-      cutlass::gemm::GemmCoord *problem_sizes0_real = nullptr
+      GemmCoord problem_size_,
+      TensorRef<ElementA const, LayoutA> ref_A_,
+      TensorRef<ElementB const, LayoutB> ref_B_,
+      TensorRef<ElementC const, LayoutC> ref_C_,
+      TensorRef<ElementC, LayoutC> ref_D_,
+      typename EpilogueOutputOp::Params epilogue_ = 
+        typename EpilogueOutputOp::Params(),
+      int split_k_slices = 1,
+      typename ConvertScaledOp::Params convert_ = 
+        typename ConvertScaledOp::Params(),
+      typename ReductionOp::Params reduction_ =
+        typename ReductionOp::Params()
     ):
-      problem_sizes0(problem_sizes0),
-      problem_sizes1(problem_sizes1),
-      problem_count(problem_count),
-      threadblock_count(threadblock_count),
-      ptr_Q(ptr_Q),
-      ptr_K(ptr_K),
-      ptr_P(ptr_P),
-      ptr_V(ptr_V),
-      ptr_O(ptr_O),
-      ptr_Max(ptr_Max),
-      ptr_Sum(ptr_Sum),
-      block_P(block_P),
-      block_Norm(block_Norm),
-      block_Sum(block_Sum),
-      offset_P(offset_P),
-      offset_Norm_Device(offset_Norm_Device),
-      offset_Sum_Device(offset_Sum_Device),
-      ldq(ldq),
-      ldk(ldk),
-      ldp(ldp),
-      ldv(ldv),
-      ldo(ldo),
-      alpha0(alpha0),
-      alpha1(alpha1),
-      beta(beta),
-      head_number(head_number),
-      batch_size(batch_size),
-      seq_length(seq_length),
-      problem_sizes0_host(problem_sizes0_host),
-      problem_sizes1_host(problem_sizes1_host),
-      problem_sizes0_real(problem_sizes0_real),
-      reduction(
-        problem_sizes0,
-        block_Norm,
-        block_Sum,
-        offset_Norm_Device,
-        offset_Sum_Device
-      )
-    {
-        
-    }
+      problem_size(problem_size_),
+      ref_A(ref_A_),
+      ref_B(ref_B_),
+      ref_C(ref_C_),
+      ref_D(ref_D_),
+      epilogue(epilogue_),
+      split_k_slices(split_k_slices),
+      convert(convert_),
+      reduction(reduction_) { }
+  };
 
+private:
 
-  };
+  /// Kernel parameters object
+  typename GemmKernel::Params gemm_params_;
 
-  struct Params {
-    cutlass::gemm::GemmCoord *problem_sizes0;
-    cutlass::gemm::GemmCoord *problem_sizes0_real;
-    cutlass::gemm::GemmCoord *problem_sizes1;
-    int problem_count;
-    int threadblock_count;
-
-    ElementQ ** ptr_Q;
-    ElementK ** ptr_K;
-    ElementP ** ptr_P;
-    ElementP ** ptr_V;
-    ElementP ** ptr_O;
-
-    ElementNorm **ptr_Max;
-    ElementSum **ptr_Sum;
-
-    ElementP *block_P;
-    ElementNorm *block_Norm;
-    ElementSum *block_Sum;
-    int64_t *offset_P;
-    int64_t *offset_Norm_Device;
-    int64_t *offset_Sum_Device;
-
-    typename LayoutQ::Stride::LongIndex *ldq;
-    typename LayoutK::Stride::LongIndex *ldk;
-    typename LayoutP::Stride::LongIndex *ldp;
-    typename LayoutP::Stride::LongIndex *ldv;
-    typename LayoutP::Stride::LongIndex *ldo;
-
-    cutlass::gemm::GemmCoord *problem_sizes0_host;
-    cutlass::gemm::GemmCoord *problem_sizes1_host;
-
-    ElementAccumulator alpha0;
-    ElementAccumulator alpha1;
-    ElementAccumulator beta;
-
-    int head_number;
-    int batch_size;
-    int seq_length;
-
-    typename ApplyFinalReductionDevice::Params reduction;
-
-    Params(): 
-      problem_count(0), 
-      threadblock_count(0), 
-      ptr_Q(nullptr),
-      ptr_K(nullptr),
-      ptr_P(nullptr),
-      ptr_V(nullptr),
-      ptr_O(nullptr),
-      ptr_Max(nullptr),
-      ptr_Sum(nullptr),
-      block_P(nullptr),
-      block_Norm(nullptr),
-      block_Sum(nullptr),
-      offset_P(nullptr),
-      offset_Norm_Device(nullptr),
-      offset_Sum_Device(nullptr),
-      ldq(nullptr),
-      ldk(nullptr),
-      ldp(nullptr),
-      ldv(nullptr),
-      ldo(nullptr),
-      problem_sizes0(nullptr),
-      problem_sizes1(nullptr),
-      problem_sizes0_real(nullptr),
-      head_number(0),
-      batch_size(0),
-      seq_length(0)
-    {
+  /// Reduction kernel parameters object
+  typename ReductionKernel::Params reduction_params_;
 
-    }
+public:
 
-    Params(Arguments const &args, void *workspace = nullptr):
-      problem_sizes0(args.problem_sizes0),
-      problem_sizes1(args.problem_sizes1),
-      problem_count(args.problem_count),
-      threadblock_count(args.threadblock_count),
-      ptr_Q(args.ptr_Q),
-      ptr_K(args.ptr_K),
-      ptr_P(args.ptr_P),
-      ptr_V(args.ptr_V),
-      ptr_O(args.ptr_O),
-      ptr_Max(args.ptr_Max),
-      ptr_Sum(args.ptr_Sum),
-      block_P(args.block_P),
-      block_Norm(args.block_Norm),
-      block_Sum(args.block_Sum),
-      offset_P(args.offset_P),
-      offset_Norm_Device(args.offset_Norm_Device),
-      offset_Sum_Device(args.offset_Sum_Device),
-      ldq(args.ldq),
-      ldk(args.ldk),
-      ldp(args.ldp),
-      ldv(args.ldv),
-      ldo(args.ldo),
-      problem_sizes0_host(args.problem_sizes0_host),
-      problem_sizes1_host(args.problem_sizes1_host),
-      problem_sizes0_real(args.problem_sizes0_real),
-      alpha0(args.alpha0),
-      alpha1(args.alpha1),
-      beta(args.beta),
-      head_number(args.head_number),
-      batch_size(args.batch_size),
-      seq_length(args.seq_length),
-      reduction(args.reduction)
-    {
+  /// Constructs the GEMM.
+  GemmSplitKParallel() { }
 
-    }
-  };
+  /// Determines whether the GEMM can execute the given problem.
+  static Status can_implement(Arguments const &args) {
 
+    // TODO
 
-private:
+    return Status::kSuccess;
+  }
 
-  Params params_;
-  GemmGrouped0 gemm_grouped0;
-  GemmGrouped1 gemm_grouped1;
+  /// Gets the workspace size
+  static size_t get_workspace_size(Arguments const &args) {
+    
+    // Determine grid shape
+    ThreadblockSwizzle threadblock_swizzle;
+
+    cutlass::gemm::GemmCoord grid_shape = threadblock_swizzle.get_tiled_shape(
+      args.problem_size, 
+      {ThreadblockShape::kM, ThreadblockShape::kN, ThreadblockShape::kK},
+      args.split_k_slices);
 
+    return sizeof(ElementAccumulator_) * size_t(args.problem_size.m()) * size_t(args.problem_size.n()) * grid_shape.k();
+  }
 
-public:
+  /// Initializes GEMM state from arguments.
+  Status initialize(Arguments const &args, void *workspace) {
 
-  /// Ctor
-  FusedMultiHeadAttention() {
+    // Determine grid shape
+    ThreadblockSwizzle threadblock_swizzle;
 
+    cutlass::gemm::GemmCoord grid_shape = threadblock_swizzle.get_tiled_shape(
+      args.problem_size, 
+      {ThreadblockShape::kM, ThreadblockShape::kN, ThreadblockShape::kK},
+      args.split_k_slices);
+
+    // Define a reference to the workspace - this is an aligned region in device memory.
+    if (!workspace) {
+      return Status::kErrorWorkspaceNull;
+    }
+    
+    TensorRef<ElementAccumulator_, layout::RowMajor> ref_workspace(
+      static_cast<ElementAccumulator_ *>(workspace), 
+      args.problem_size.n());
+
+    int64_t partition_stride = int64_t(args.problem_size.m()) * int64_t(args.problem_size.n());
+
+    // Initialize the Params structure
+    gemm_params_ = typename GemmKernel::Params{
+      args.problem_size,
+      grid_shape,
+      args.ref_A.non_const_ref(),
+      args.ref_B.non_const_ref(),
+      ref_workspace,
+      args.convert,
+      partition_stride
+    };
+
+    reduction_params_ = typename ReductionKernel::Params(
+      args.problem_size.mn(),
+      grid_shape.k(),
+      partition_stride,
+      ref_workspace,
+      args.ref_D,
+      args.ref_C.non_const_ref(),
+      args.epilogue
+    );
+
+    return Status::kSuccess;
   }
 
-  /// Initialize
-  Status initialize(Arguments const &args, 
-                    void *workspace0 = nullptr,
-                    void *workspace1 = nullptr) {
-
-    params_ = Params(args);
-
-    typename GemmGrouped0::Arguments args_gemm0(
-      params_.problem_sizes0,
-      params_.problem_count,
-      params_.threadblock_count,
-      params_.ptr_Q,
-      params_.ptr_K,
-      params_.ptr_P,
-      params_.ptr_P,
-      params_.ptr_Max,
-      params_.ptr_Sum,
-      params_.ldq,
-      params_.ldk,
-      params_.ldp,
-      params_.ldp,
-      typename GemmGrouped0::GemmKernel::EpilogueVisitor::Arguments(
-        {
-          params_.alpha0,
-          params_.beta
-        }
-      ),
-      params_.problem_sizes0_host,
-      params_.problem_sizes0_real
-    );
+  /// Lightweight update given a subset of arguments
+  Status update(Arguments const &args, void *workspace = nullptr) {
 
+    if (!workspace) {
+      return Status::kErrorWorkspaceNull;
+    }
 
-    Status result0 = gemm_grouped0.initialize(args_gemm0, workspace0);
+    gemm_params_.ref_A.reset(args.ref_A.data());
+    gemm_params_.ref_B.reset(args.ref_B.data());
+    gemm_params_.ref_D.reset(workspace);     
 
-    typename EpilogueOutputOp1::Params epilogue_op1(params_.alpha1, params_.beta);
+    reduction_params_.ref_D.reset(args.ref_D.data());
+    reduction_params_.ref_C.reset(args.ref_C.data());
 
-    typename GemmGrouped1::Arguments args_gemm1(
-      params_.problem_sizes1,
-      params_.problem_count,
-      params_.threadblock_count,
-      epilogue_op1,
-      params_.ptr_P,
-      params_.ptr_V,
-      params_.ptr_O,
-      params_.ptr_O,
-      (void**)params_.ptr_Max,
-      (void**)params_.ptr_Sum,
-      params_.ldp,
-      params_.ldv,
-      params_.ldo,
-      params_.ldo,
-      params_.problem_sizes1_host
-    );
+    return Status::kSuccess;
+  }
+
+  /// Runs the kernel using initialized state.
+  Status run(cudaStream_t stream = nullptr) {
+
+    //
+    // Launch GEMM kernel
+    //
+
+    ThreadblockSwizzle threadblock_swizzle;
+
+    dim3 grid = threadblock_swizzle.get_grid_shape(gemm_params_.grid_tiled_shape);
+    dim3 block(GemmKernel::kThreadCount, 1, 1);
 
-    Status result1 = gemm_grouped1.initialize(args_gemm1, workspace1);
+    cudaError_t result;
 
-    if ((result0 == cutlass::Status::kSuccess) && (result1 == cutlass::Status::kSuccess) ) {
-      return cutlass::Status::kSuccess;
-    }else{
-      if (result0 != cutlass::Status::kSuccess) {
-        return result0;
-      }else{
-        return result1;
+    int smem_size = int(sizeof(typename GemmKernel::SharedStorage));
+    if (smem_size >= (48 << 10)) {
+
+      result = cudaFuncSetAttribute(
+        Kernel<GemmKernel>,
+        cudaFuncAttributeMaxDynamicSharedMemorySize,
+        smem_size);
+
+      if (result != cudaSuccess) {
+        return Status::kErrorInternal;
       }
     }
-  }
 
-  /// Run
-  Status run(cudaStream_t stream = nullptr) {
+    Kernel<GemmKernel><<<grid, block, smem_size, stream>>>(gemm_params_);
 
-    Status result = gemm_grouped0.run();
-    cudaError_t error_info;
+    result = cudaGetLastError();
 
-    if (result != cutlass::Status::kSuccess) {
-      return cutlass::Status::kErrorInternal;
+    if (result != cudaSuccess) {
+      return Status::kErrorInternal;
     }
 
-    int thread_per_block = 1024;
+    //
+    // Launch reduction kernel
+    //
 
-    dim3 final_reduction_grid(params_.head_number * params_.batch_size);
-    dim3 final_reduction_block(thread_per_block);
+    block = ReductionKernel::block_shape();
+    grid = ReductionKernel::grid_shape(gemm_params_.problem_size.mn());
 
-    cutlass::Kernel<ApplyFinalReductionDevice><<<
-        final_reduction_grid, final_reduction_block, sizeof(typename ApplyFinalReductionDevice::SharedStorage), stream
-      >>>(params_.reduction);
+    Kernel<ReductionKernel><<< grid, block, 0, stream >>>(reduction_params_);
 
-    error_info = cudaGetLastError();
+    result = cudaGetLastError();
 
-    if (error_info != cudaSuccess) {
-      return cutlass::Status::kErrorInternal;
+    if (result != cudaSuccess) {
+      return Status::kErrorInternal;
     }
 
-    result = gemm_grouped1.run();
+    return result == cudaSuccess ? Status::kSuccess : Status::kErrorInternal;
+  }
 
-    if (result != cutlass::Status::kSuccess) {
-      return cutlass::Status::kErrorInternal;
+  /// Runs the kernel using initialized state.
+  Status operator()(cudaStream_t stream = nullptr) {
+    return run(stream);
+  }
+
+  /// Runs the kernel using initialized state.
+  Status operator()(
+    Arguments const &args, 
+    void *workspace = nullptr, 
+    cudaStream_t stream = nullptr) {
+    
+    Status status = initialize(args, workspace);
+    
+    if (status == Status::kSuccess) {
+      status = run(stream);
     }
 
-    return cutlass::Status::kSuccess;
+    return status;
+  }
+};
+
+////////////////////////////////////////////////////////////////////////////////
+
+/// Partial specialization for column-major output
+template <
+    /// Element type for A matrix operand
+    typename ElementA_,
+    /// Layout type for A matrix operand
+    typename LayoutA_,
+    /// Element type for B matrix operand
+    typename ElementB_,
+    /// Layout type for B matrix operand
+    typename LayoutB_,
+    /// Element type for C and D matrix operands
+    typename ElementC_,
+    /// Element type for internal accumulation
+    typename ElementAccumulator_,
+    /// Operator class tag
+    typename OperatorClass_,
+    /// Tag indicating architecture to tune for.  This is the minimum SM that
+      /// supports the intended feature. The device kernel can be built
+      /// targeting any SM larger than this number.
+    typename ArchTag_,
+    /// Threadblock-level tile size (concept: GemmShape)
+    typename ThreadblockShape_,
+    /// Warp-level tile size (concept: GemmShape)
+    typename WarpShape_,
+    /// Instruction-level tile size (concept: GemmShape)
+    typename InstructionShape_,
+    /// Epilogue output operator
+    typename EpilogueOutputOp_,
+    /// Epilogue output operator
+    typename ConvertScaledOp_,
+    /// Reduction operator
+    typename ReductionOp_,
+    /// Threadblock-level swizzling operator
+    typename ThreadblockSwizzle_,
+    /// Number of stages used in the pipelined mainloop
+    int Stages, int kAlignmentA, int kAlignmentB,
+    /// Operation performed by GEMM
+    typename Operator_>
+class GemmSplitKParallel<ElementA_, LayoutA_, ElementB_, LayoutB_, ElementC_,
+                         layout::ColumnMajor, ElementAccumulator_,
+                         OperatorClass_, ArchTag_, ThreadblockShape_,
+                         WarpShape_, InstructionShape_, EpilogueOutputOp_,
+                         ConvertScaledOp_, ReductionOp_, ThreadblockSwizzle_,
+                         Stages, kAlignmentA, kAlignmentB, Operator_> {
+ public:
+
+  using ElementA = ElementA_;
+  using LayoutA = LayoutA_;
+  using ElementB = ElementB_;
+  using LayoutB = LayoutB_;
+  using ElementC = ElementC_;
+  using LayoutC = layout::ColumnMajor;
+  using ElementAccumulator = ElementAccumulator_;
+  using OperatorClass = OperatorClass_;
+  using ArchTag = ArchTag_;
+  using ThreadblockShape = ThreadblockShape_;
+  using WarpShape = WarpShape_;
+  using InstructionShape = InstructionShape_;
+  using ConvertScaledOp = ConvertScaledOp_;
+  using EpilogueOutputOp = EpilogueOutputOp_;
+  using ReductionOp = ReductionOp_;
+  using ThreadblockSwizzle = ThreadblockSwizzle_;
+  using Operator = Operator_;
+  static int const kStages = Stages;
+
+  using UnderlyingOperator = GemmSplitKParallel< 
+    ElementB,
+    typename layout::LayoutTranspose<LayoutB>::type,
+    ElementA,
+    typename layout::LayoutTranspose<LayoutA>::type,
+    ElementC,
+    layout::RowMajor,    
+    ElementAccumulator,
+    OperatorClass,
+    ArchTag,
+    ThreadblockShape,
+    WarpShape,
+    InstructionShape,
+    EpilogueOutputOp,
+    ConvertScaledOp,
+    ReductionOp,
+    ThreadblockSwizzle,
+    Stages,
+    kAlignmentA,
+    kAlignmentB,
+    Operator
+  >;
+
+  using UnderlyingArguments = typename UnderlyingOperator::Arguments;
+  using GemmKernel = typename UnderlyingOperator::GemmKernel;
+  using ReductionKernel = typename UnderlyingOperator::ReductionKernel;
+
+  /// Argument structure
+  struct Arguments {
+
+    //
+    // Data members
+    //
+
+    GemmCoord problem_size;
+    TensorRef<ElementA const, LayoutA> ref_A;
+    TensorRef<ElementB const, LayoutB> ref_B;
+    TensorRef<ElementC const, LayoutC> ref_C;
+    TensorRef<ElementC, LayoutC> ref_D;
+    typename EpilogueOutputOp::Params epilogue;
+    int split_k_slices;
+    typename ConvertScaledOp::Params convert;
+    typename ReductionOp::Params reduction;
+
+    //
+    // Methods
+    //
+
+    /// Default ctor
+    CUTLASS_HOST_DEVICE
+    Arguments() { }
+
+    /// Constructs an Arguments structure 
+    CUTLASS_HOST_DEVICE
+    Arguments(
+      GemmCoord problem_size_,
+      TensorRef<ElementA const, LayoutA> ref_A_,
+      TensorRef<ElementB const, LayoutB> ref_B_,
+      TensorRef<ElementC const, LayoutC> ref_C_,
+      TensorRef<ElementC, LayoutC> ref_D_,
+      typename EpilogueOutputOp::Params epilogue_ = 
+        typename EpilogueOutputOp::Params(),
+      int split_k_slices = 1,
+      typename ConvertScaledOp::Params convert_ = 
+        typename ConvertScaledOp::Params(),
+      typename ReductionOp::Params reduction_ =
+        typename ReductionOp::Params()
+    ):
+      problem_size(problem_size_),
+      ref_A(ref_A_),
+      ref_B(ref_B_),
+      ref_C(ref_C_),
+      ref_D(ref_D_),
+      epilogue(epilogue_),
+      split_k_slices(split_k_slices),
+      convert(convert_),
+      reduction(reduction_) { }
+  };
+
+private:
+
+  /// Kernel parameters object
+  UnderlyingOperator underlying_operator_;
+
+public:
+
+  /// Constructs the GEMM.
+  GemmSplitKParallel() { }
+
+  /// Helper to construct a transposed equivalent for the underying GEMM operator
+  static UnderlyingArguments to_underlying_arguments(Arguments const &args) {
+    return UnderlyingArguments(
+      {args.problem_size.n(), args.problem_size.m(), args.problem_size.k()},
+      {args.ref_B.data(), args.ref_B.stride(0)},
+      {args.ref_A.data(), args.ref_A.stride(0)},
+      {args.ref_C.data(), args.ref_C.stride(0)},
+      {args.ref_D.data(), args.ref_D.stride(0)},
+      args.epilogue,
+      args.split_k_slices,
+      args.convert,
+      args.reduction
+    );
+  }
+
+  /// Determines whether the GEMM can execute the given problem.
+  static Status can_implement(Arguments const &args) {
+
+    return UnderlyingOperator::can_implement(to_underlying_arguments(args));
+  }
+
+  /// Gets the workspace size
+  static size_t get_workspace_size(Arguments const &args) {
+    
+    return UnderlyingOperator::get_workspace_size(to_underlying_arguments(args));
   }
 
-  /// Function call operator
+  /// Initializes GEMM state from arguments.
+  Status initialize(Arguments const &args, void *workspace) {
+
+    return underlying_operator_.initialize(to_underlying_arguments(args), workspace);
+  }
+
+  /// Lightweight update given a subset of arguments
+  Status update(Arguments const &args, void *workspace = nullptr) {
+
+    return underlying_operator_.update(to_underlying_arguments(args), workspace);
+  }
+
+  /// Runs the kernel using initialized state.
+  Status run(cudaStream_t stream = nullptr) {
+
+    return underlying_operator_.run(stream);
+  }
+
+  /// Runs the kernel using initialized state.
   Status operator()(cudaStream_t stream = nullptr) {
     return run(stream);
   }
+
+  /// Runs the kernel using initialized state.
+  Status operator()(
+    Arguments const &args, 
+    void *workspace = nullptr, 
+    cudaStream_t stream = nullptr) {
+    
+    Status status = initialize(args, workspace, stream);
+    
+    if (status == Status::kSuccess) {
+      status = run(stream);
+    }
+
+    return status;
+  }
 };
 
-}
+////////////////////////////////////////////////////////////////////////////////
+
+} // namespace device
+} // namespace gemm
+} // namespace cutlass
+
+////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/41_multi_head_attention/gemm_grouped_with_softmax_visitor.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_grouped_softmax_mainloop_fusion.h`

 * *Files 7% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -26,59 +26,55 @@
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 
 /*! \file
-    \brief Grouped GEMM kernel with epilogue visitor customized for softmax
+    \brief Problem visitor for grouped GEMMs with a softmax fused beforehand
 */
 
 #pragma once
 
 #include "cutlass/cutlass.h"
 #include "cutlass/fast_math.h"
 #include "cutlass/gemm/gemm.h"
 #include "cutlass/matrix_coord.h"
 #include "cutlass/complex.h"
 #include "cutlass/semaphore.h"
-#include "cutlass/util/device_memory.h"
+
 #include "cutlass/layout/matrix.h"
 #include "cutlass/trace.h"
 #include "cutlass/gemm/kernel/gemm_transpose_operands.h"
 #include "cutlass/gemm/kernel/gemm_grouped_problem_visitor.h"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace gemm {
 namespace kernel {
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 template <
-  typename Mma_,                  ///! Threadblock-scoped matrix multiply-accumulate 
-  typename Epilogue_,             ///! Epilogue
-  typename ThreadblockSwizzle_,   ///! Threadblock swizzling function
-  GroupScheduleMode GroupScheduleMode_, ///! Type of scheduling to perform
-  bool Transposed_ = false,
-  bool UseMask_ = false
+  typename Mma_,                           ///! Threadblock-scoped matrix multiply-accumulate
+  typename Epilogue_,                      ///! Epilogue
+  typename ThreadblockSwizzle_,            ///! Threadblock swizzling function
+  GroupScheduleMode GroupScheduleMode_,    ///! Type of scheduling to perform
+  bool Transposed = false
 >
-struct GemmGroupedWithEpilogueVistor {
+struct GemmGroupedSoftmaxMainloopFusion {
 public:
 
   using Mma = Mma_;
   using Epilogue = Epilogue_;
+  using EpilogueOutputOp = typename Epilogue::OutputOp;
   using ThreadblockSwizzle = ThreadblockSwizzle_;
-
   static GroupScheduleMode const kGroupScheduleMode = GroupScheduleMode_;
-
-  using EpilogueVisitor = typename Epilogue::Visitor;
-  using EpilogueOutputOp = typename EpilogueVisitor::ElementwiseFunctor;
-  static bool const kTransposed = Transposed_;
+  static bool const kTransposed = Transposed;
 
   // Optional transpose
   using MapArguments = kernel::detail::MapArguments<
     typename Mma::IteratorA::Element,
     typename Mma::IteratorA::Layout,
     Mma::kTransformA,
     Mma::IteratorA::AccessType::kElements,
@@ -92,19 +88,18 @@
 
   // Public-facing type definitions related to operand element type, layout, and complex conjugate
   // operation. Must interact with the 'kTransposed' notion.
   using ElementA = typename MapArguments::ElementA;
   using LayoutA = typename MapArguments::LayoutA;
   using ElementB = typename MapArguments::ElementB;
   using LayoutB = typename MapArguments::LayoutB;
-  using ElementC = typename EpilogueVisitor::ElementOutput;
+  using ElementC = typename Epilogue::OutputTileIterator::Element;
   using LayoutC = typename MapArguments::LayoutC;
 
-  using ElementNorm = typename EpilogueVisitor::ElementNorm;
-  using ElementSum = typename EpilogueVisitor::ElementSum;
+  using ElementScaleBias = typename Mma::IteratorNormSum::Element;
 
   static ComplexTransform const kTransformA = MapArguments::kTransformA;
   static ComplexTransform const kTransformB = MapArguments::kTransformB;
 
   // Type definitions about the mainloop.
   using Operator = typename Mma::Operator;
   using OperatorClass = typename Mma::Operator::OperatorClass;
@@ -112,15 +107,15 @@
   using WarpShape = typename Mma::Operator::Shape;
   using InstructionShape = typename Mma::Policy::Operator::InstructionShape;
   using ArchTag = typename Mma::ArchTag;
 
   static int const kStages = Mma::kStages;
   static int const kAlignmentA = MapArguments::kAlignmentA;
   static int const kAlignmentB = MapArguments::kAlignmentB;
-  static int const kAlignmentC = EpilogueVisitor::kElementsPerAccess;
+  static int const kAlignmentC = Epilogue::OutputTileIterator::kElementsPerAccess;
 
   /// Warp count (concept: GemmShape)
   using WarpCount = typename Mma::WarpCount;
   static int const kThreadCount = 32 * WarpCount::kCount;
 
   using ProblemVisitor = GemmGroupedProblemVisitor<
                             ThreadblockShape,
@@ -137,259 +132,242 @@
   struct Arguments {
 
     //
     // Data members
     //
 
     GemmCoord *problem_sizes;
-    // when using mask, real problem sizes may not be aligned
-    // then we need to mask out unpadded elements in softmax
-    GemmCoord *problem_sizes_real;
     int problem_count;
     int threadblock_count;
 
+    typename EpilogueOutputOp::Params output_op;
+
     ElementA ** ptr_A;
     ElementB ** ptr_B;
     ElementC ** ptr_C;
     ElementC ** ptr_D;
-
-    ElementNorm **ptr_Max;
-    ElementSum **ptr_Sum;
+    void ** ptr_norm;
+    void ** ptr_sum;
 
     typename LayoutA::Stride::LongIndex *lda;
     typename LayoutB::Stride::LongIndex *ldb;
     typename LayoutC::Stride::LongIndex *ldc;
     typename LayoutC::Stride::LongIndex *ldd;
 
-    typename EpilogueVisitor::Arguments epilogue_visitor;
-
     // Only used by device-level operator
     GemmCoord *host_problem_sizes;
 
     //
     // Methods
     //
 
     /// Default ctor
     CUTLASS_HOST_DEVICE
-    Arguments(): 
-      problem_count(0), 
-      threadblock_count(0), 
+    Arguments():
+      problem_count(0),
+      threadblock_count(0),
       ptr_A(nullptr),
       ptr_B(nullptr),
       ptr_C(nullptr),
       ptr_D(nullptr),
-      ptr_Max(nullptr),
-      ptr_Sum(nullptr),
+      ptr_norm(nullptr),
+      ptr_sum(nullptr),
       lda(nullptr),
       ldb(nullptr),
       ldc(nullptr),
       ldd(nullptr),
       host_problem_sizes(nullptr)
     {
 
     }
 
     /// Ctor
     CUTLASS_HOST_DEVICE
-    Arguments(    
+    Arguments(
       GemmCoord *problem_sizes,
       int problem_count,
       int threadblock_count,
+      typename EpilogueOutputOp::Params output_op,
       ElementA ** ptr_A,
       ElementB ** ptr_B,
       ElementC ** ptr_C,
       ElementC ** ptr_D,
-      ElementNorm **ptr_Max,
-      ElementSum **ptr_Sum,
+      void ** ptr_norm,
+      void ** ptr_sum,
       typename LayoutA::Stride::LongIndex *lda,
       typename LayoutB::Stride::LongIndex *ldb,
       typename LayoutC::Stride::LongIndex *ldc,
       typename LayoutC::Stride::LongIndex *ldd,
-      typename EpilogueVisitor::Arguments epilogue_visitor_,
-      GemmCoord *host_problem_sizes=nullptr,
-      GemmCoord *problem_sizes_real=nullptr
-    ): 
+      GemmCoord *host_problem_sizes=nullptr
+    ):
       problem_sizes(problem_sizes),
       problem_count(problem_count),
       threadblock_count(threadblock_count),
+      output_op(output_op),
       ptr_A(ptr_A),
       ptr_B(ptr_B),
       ptr_C(ptr_C),
       ptr_D(ptr_D),
-      ptr_Max(ptr_Max),
-      ptr_Sum(ptr_Sum),
+      ptr_norm(ptr_norm),
+      ptr_sum(ptr_sum),
       lda(lda),
       ldb(ldb),
       ldc(ldc),
       ldd(ldd),
-      epilogue_visitor(epilogue_visitor_),
-      host_problem_sizes(host_problem_sizes),
-      problem_sizes_real(problem_sizes_real)
+      host_problem_sizes(host_problem_sizes)
     {
 
     }
   };
 
   //
   // Structure for precomputing values in host memory and passing to kernels
   //
 
   /// Parameters structure
   struct Params {
 
     typename ProblemVisitor::Params problem_visitor;
-    GemmCoord *problem_sizes_real;
     int threadblock_count;
 
+    typename EpilogueOutputOp::Params output_op;
+
     ElementA ** ptr_A;
     ElementB ** ptr_B;
     ElementC ** ptr_C;
     ElementC ** ptr_D;
 
-    ElementNorm **ptr_Max;
-    ElementSum **ptr_Sum;
+    void ** ptr_norm;
+    void ** ptr_sum;
 
     typename LayoutA::Stride::LongIndex *lda;
     typename LayoutB::Stride::LongIndex *ldb;
     typename LayoutC::Stride::LongIndex *ldc;
     typename LayoutC::Stride::LongIndex *ldd;
 
-    typename EpilogueVisitor::Params epilogue_visitor;
-
     //
     // Methods
     //
 
     CUTLASS_HOST_DEVICE
     Params():
       ptr_A(nullptr),
       ptr_B(nullptr),
       ptr_C(nullptr),
       ptr_D(nullptr),
-      ptr_Max(nullptr),
-      ptr_Sum(nullptr),
+      ptr_norm(nullptr),
+      ptr_sum(nullptr),
       lda(nullptr),
       ldb(nullptr),
       ldc(nullptr),
-      ldd(nullptr),
-      problem_sizes_real(problem_sizes_real)
+      ldd(nullptr)
     { }
 
     CUTLASS_HOST_DEVICE
-    Params(Arguments const &args, void *workspace = nullptr, int32_t tile_count = 0):
+    Params(Arguments const &args,
+          void *workspace = nullptr,
+          int tile_count = 0):
       problem_visitor(args.problem_sizes, args.problem_count, workspace, tile_count),
       threadblock_count(args.threadblock_count),
+      output_op(args.output_op),
       ptr_A(args.ptr_A),
       ptr_B(args.ptr_B),
       ptr_C(args.ptr_C),
       ptr_D(args.ptr_D),
-      ptr_Max(args.ptr_Max),
-      ptr_Sum(args.ptr_Sum),
+      ptr_norm(args.ptr_norm),
+      ptr_sum(args.ptr_sum),
       lda(args.lda),
       ldb(args.ldb),
       ldc(args.ldc),
-      ldd(args.ldd),
-      epilogue_visitor(args.epilogue_visitor),
-      problem_sizes_real(args.problem_sizes_real)
-    { 
+      ldd(args.ldd)
+    {
 
     }
 
     CUTLASS_HOST_DEVICE
     void update(
       Arguments const &args,
       void *workspace = nullptr,
-      int32_t tile_count = -1) {
+      int tile_count = 0) {
 
-      problem_visitor = typename ProblemVisitor::Params(args.problem_sizes, args.problem_count, workspace, tile_count);
+      problem_visitor = typename ProblemVisitor::Params(args.problem_sizes, args.problem_count,
+                                                        workspace, tile_count);
       threadblock_count = args.threadblock_count;
+      output_op = args.output_op;
       ptr_A = args.ptr_A;
       ptr_B = args.ptr_B;
       ptr_C = args.ptr_C;
       ptr_D = args.ptr_D;
-      ptr_Max = args.ptr_Max;
-      ptr_Sum = args.ptr_Sum;
+      ptr_norm = args.ptr_norm;
+      ptr_sum = args.ptr_sum;
       lda = args.lda;
       ldb = args.ldb;
       ldc = args.ldc;
       ldd = args.ldd;
-      problem_sizes_real = args.problem_sizes_real;
     }
   };
 
   /// Shared memory storage structure
   struct SharedStorage {
     union {
       typename Mma::SharedStorage main_loop;
-      struct {
-        typename Epilogue::SharedStorage epilogue;
-        typename EpilogueVisitor::SharedStorage visitor;
-      } epilogue;
+      typename Epilogue::SharedStorage epilogue;
     } kernel;
 
     // ProblemVisitor shared storage can't be overlapped with others
     typename ProblemVisitor::SharedStorage problem_visitor;
   };
 
-
 public:
 
   //
   // Methods
   //
 
   CUTLASS_DEVICE
-  GemmGroupedWithEpilogueVistor() { } 
+  GemmGroupedSoftmaxMainloopFusion() { }
 
   /// Determines whether kernel satisfies alignment
   static Status can_implement(cutlass::gemm::GemmCoord const & problem_size) {
     return Status::kSuccess;
   }
 
   static Status can_implement(Arguments const &args) {
     return Status::kSuccess;
   }
 
-  static size_t get_extra_workspace_size(
-    Arguments const &args,
-    cutlass::gemm::GemmCoord const &grid_tiled_shape) {
-
-    return 0;
-  }
- 
   /// Executes one GEMM
   CUTLASS_DEVICE
   void operator()(Params const &params, SharedStorage &shared_storage) {
 
     //
     // These types shadow the type-level definitions and support the ability to implement
     // a 'transposed' GEMM that computes the transposed problems.
     //
     using ElementA = typename Mma::IteratorA::Element;
     using LayoutA = typename Mma::IteratorA::Layout;
     using ElementB = typename Mma::IteratorB::Element;
     using LayoutB = typename Mma::IteratorB::Layout;
-    using ElementC = typename EpilogueVisitor::ElementOutput;
-    using LayoutC = typename Mma::LayoutC;
+    using ElementC = typename Epilogue::OutputTileIterator::Element;
+    using LayoutC = typename Epilogue::OutputTileIterator::Layout;
 
     //
     // Problem visitor.
     //
     ProblemVisitor problem_visitor(
       params.problem_visitor,
       shared_storage.problem_visitor,
       blockIdx.x);
 
     // Outer 'persistent' loop to iterate over tiles
     while (problem_visitor.next_tile()) {
 
-      GemmCoord problem_size = problem_visitor.problem_size();
-      int32_t problem_idx    = problem_visitor.problem_index();
-      int32_t threadblock_idx        = int32_t(problem_visitor.threadblock_idx());
+      GemmCoord problem_size  = problem_visitor.problem_size();
+      int32_t problem_idx     = problem_visitor.problem_index();
+      int32_t threadblock_idx = int32_t(problem_visitor.threadblock_idx());
 
       GemmCoord grid_shape = problem_visitor.grid_shape(problem_size);
 
       cutlass::gemm::GemmCoord threadblock_offset(
         int(threadblock_idx / grid_shape.n()) * Mma::Shape::kM,
         int(threadblock_idx % grid_shape.n()) * Mma::Shape::kN,
         0);
@@ -426,18 +404,27 @@
       typename Mma::IteratorB iterator_B(
         LayoutB(ldm_B),
         ptr_B,
         {problem_size.k(), problem_size.n()},
         thread_idx,
         tb_offset_B);
 
+      // Construct iterator to the softmax norm/sum vector
+      typename Mma::IteratorNormSum iterator_norm_sum(
+        problem_size.m(),
+        static_cast<ElementScaleBias const *>(params.ptr_norm[problem_idx]),
+        static_cast<ElementScaleBias const *>(params.ptr_sum[problem_idx]),
+        thread_idx,
+        MatrixCoord(0, threadblock_offset.m())
+      );
+
       typename Mma::FragmentC accumulators;
 
       accumulators.clear();
-      
+
       // Broadcast the warp_id computed by lane 0 to ensure dependent code
       // is compiled as warp-uniform.
       int warp_idx = __shfl_sync(0xffffffff, threadIdx.x / 32, 0);
 
       int lane_idx = threadIdx.x % 32;
 
       //
@@ -451,65 +438,66 @@
       int gemm_k_iterations = (problem_size.k() + Mma::Shape::kK - 1) / Mma::Shape::kK;
 
       // Wait for all threads to finish their epilogue phases from the previous tile.
       __syncthreads();
 
       // Compute threadblock-scoped matrix multiply-add
       mma(
-        gemm_k_iterations, 
-        accumulators, 
-        iterator_A, 
-        iterator_B, 
+        gemm_k_iterations,
+        accumulators,
+        iterator_A,
+        iterator_B,
+        iterator_norm_sum,
         accumulators);
 
+      //
+      // Epilogue
+      //
+
+      EpilogueOutputOp output_op(params.output_op);
+
       ElementC *ptr_C = params.ptr_C[problem_idx];
       ElementC *ptr_D = params.ptr_D[problem_idx];
 
-      ElementNorm *ptr_Max = params.ptr_Max[problem_idx];
-      ElementSum *ptr_Sum = params.ptr_Sum[problem_idx];
-
       LayoutC layout_C(params.ldc[problem_idx]);
       LayoutC layout_D(params.ldd[problem_idx]);
 
-      int column_offset = (threadblock_offset.n() / ThreadblockShape::kN) * problem_size.m();
+      typename Epilogue::OutputTileIterator::Params params_C(layout_C);
+      typename Epilogue::OutputTileIterator::Params params_D(layout_D);
 
-      typename EpilogueVisitor::OutputTileIterator::Params params_C(layout_C);
-      typename EpilogueVisitor::OutputTileIterator::Params params_D(layout_D);
-
-      //
-      // Construct the epilogue visitor
-      //
-
-      EpilogueVisitor epilogue_visitor(
-        params.epilogue_visitor,
-        shared_storage.kernel.epilogue.visitor,
+      // Tile iterator loading from source tensor.
+      typename Epilogue::OutputTileIterator iterator_C(
+        params_C,
+        ptr_C,
         problem_size.mn(),
         thread_idx,
-        warp_idx,
-        lane_idx,
-        params_C,
+        threadblock_offset.mn()
+      );
+
+      // Tile iterator writing to destination tensor.
+      typename Epilogue::OutputTileIterator iterator_D(
         params_D,
-        ptr_C,
         ptr_D,
-        ptr_Max,
-        ptr_Sum,
-        threadblock_offset.mn(),
-        column_offset,
-        params.problem_sizes_real[problem_idx].mn()
+        problem_size.mn(),
+        thread_idx,
+        threadblock_offset.mn()
       );
 
-      // Construct the epilogue
       Epilogue epilogue(
-        shared_storage.kernel.epilogue.epilogue, 
-        thread_idx, 
-        warp_idx, 
+        shared_storage.kernel.epilogue,
+        thread_idx,
+        warp_idx,
         lane_idx);
 
-      // Execute the epilogue operator to update the destination tensor
-      epilogue(epilogue_visitor, accumulators);
+      // Execute the epilogue operator to update the destination tensor.
+      epilogue(
+        output_op,
+        iterator_D,
+        accumulators,
+        iterator_C);
 
       // Next tile
       problem_visitor.advance(gridDim.x);
     }
   }
 };
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/42_ampere_tensorop_group_conv/ampere_tensorop_group_conv.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/42_ampere_tensorop_group_conv/ampere_tensorop_group_conv.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/43_ell_block_sparse_gemm/ell_block_sparse_gemm.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/43_ell_block_sparse_gemm/ell_block_sparse_gemm.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/default_bias_act_epilogue_tensor_op.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/default_bias_act_epilogue_tensor_op.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/default_thread_map_tensor_op_for_fused_bias.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/default_thread_map_tensor_op_for_fused_bias.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/fused_bias_act_epilogue.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/fused_bias_act_epilogue.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/output_tile_thread_map_for_fused_bias.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/output_tile_thread_map_for_fused_bias.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/warp/fused_bias_act_fragment_iterator_tensor_op.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/warp/fused_bias_act_fragment_iterator_tensor_op.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/gemm/warp/mma_tensor_op_fragment_iterator_without_output_op.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/gemm/warp/mma_tensor_op_fragment_iterator_without_output_op.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/leaky_bias.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/leaky_bias.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/utils.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/utils.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/45_dual_gemm/device/dual_gemm.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/45_dual_gemm/device/dual_gemm.h`

 * *Files 6% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -48,14 +48,15 @@
 
 #include "cutlass/gemm/device/default_gemm_configuration.h"
 #include "cutlass/gemm/threadblock/default_mma.h"
 #include "cutlass/epilogue/thread/linear_combination_relu.h"
 #include "cutlass/epilogue/threadblock/default_epilogue_tensor_op.h"
 
 #include "../kernel/dual_gemm.h"
+#include "../dual_gemm_common.h"
 
 ////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace gemm {
 namespace device {
 
@@ -64,16 +65,18 @@
 template <
     /// Element type for A matrix operand
     typename ElementA_,
     /// Layout type for A matrix operand
     typename LayoutA_,
     /// Element type for B matrix operand
     typename ElementB_,
-    /// Layout type for B matrix operand
-    typename LayoutB_,
+    /// Layout type for B0 matrix operand
+    typename LayoutB0_,
+    /// Layout type for B1 matrix operand
+    typename LayoutB1_,
     /// Element type for C and D matrix operands
     typename ElementC_,
     /// Layout type for C and D matrix operands
     typename LayoutC_,
     /// Element type for internal accumulation
     typename ElementAccumulator_,
     /// Operator class tag
@@ -115,16 +118,18 @@
 class DualGemm {
  public:
 
   using ElementA = ElementA_;
   using LayoutA = LayoutA_;
   using TensorRefA = TensorRef<ElementA const, LayoutA>;
   using ElementB = ElementB_;
-  using LayoutB = LayoutB_;
-  using TensorRefB = TensorRef<ElementB const, LayoutB>;
+  using LayoutB0 = LayoutB0_;
+  using LayoutB1 = LayoutB1_;
+  using TensorRefB0 = TensorRef<ElementB const, LayoutB0>;
+  using TensorRefB1 = TensorRef<ElementB const, LayoutB1>;
   using ElementC = ElementC_;
   using LayoutC = LayoutC_;
   using TensorRefC = TensorRef<ElementC const, LayoutC>;
   using TensorRefD = TensorRef<ElementC, LayoutC>;
   using ElementAccumulator = ElementAccumulator_;
   using OperatorClass = OperatorClass_;
   using ArchTag = ArchTag_;
@@ -147,44 +152,52 @@
   static ComplexTransform const kTransformB = ComplexTransform::kNone;
 
   using LayoutScaleBias = layout::RowMajor;
   /// Define the kernel
   /// Define the threadblock-scoped matrix multiply-accumulate
   static_assert(ArchTag::kMinComputeCapability >= 80, "Only multistage is implemented");
   static_assert(kStages >= 3, "Only multistage is implemented");
-  using Mma = typename cutlass::gemm::threadblock::DefaultMma<
-      ElementA, LayoutA, kAlignmentA, ElementB, LayoutB, kAlignmentB,
+  using Mma0 = typename cutlass::gemm::threadblock::DefaultMma<
+      ElementA, LayoutA, kAlignmentA, ElementB, LayoutB0, kAlignmentB,
+      ElementAccumulator, layout::RowMajor, arch::OpClassTensorOp, ArchTag,
+      ThreadblockShape, WarpShape, 
+      InstructionShape, Stages, Operator>::ThreadblockMma;
+  using Mma1 = typename cutlass::gemm::threadblock::DefaultMma<
+      ElementA, LayoutA, kAlignmentA, ElementB, LayoutB1, kAlignmentB,
       ElementAccumulator, layout::RowMajor, arch::OpClassTensorOp, ArchTag,
       ThreadblockShape, WarpShape, 
       InstructionShape, Stages, Operator>::ThreadblockMma;
   using DualMma = threadblock::DualMmaMultistage<
-    typename Mma::Shape,
-    typename Mma::IteratorA,
-    typename Mma::SmemIteratorA,
-    Mma::kCacheOpA,
-    typename Mma::IteratorB,
-    typename Mma::SmemIteratorB,
-    Mma::kCacheOpB,
-    typename Mma::ElementC,
-    typename Mma::LayoutC,
-    typename Mma::Policy,
-    Mma::kStages,
+    typename Mma0::Shape,
+    typename Mma0::IteratorA,
+    typename Mma0::SmemIteratorA,
+    Mma0::kCacheOpA,
+    typename Mma0::IteratorB,
+    typename Mma0::SmemIteratorB,
+    Mma0::kCacheOpB,
+    typename Mma1::IteratorB,
+    typename Mma1::SmemIteratorB,
+    typename Mma0::ElementC,
+    typename Mma0::LayoutC,
+    typename Mma0::Policy,
+    typename Mma1::Policy,
+    Mma0::kStages,
     SharedMemoryClearOption::kNone
   >;
 
   static const int kPartitionsK = ThreadblockShape::kK / WarpShape::kK;
 
   /// Define the epilogue
   using Epilogue0 =
       typename cutlass::epilogue::threadblock::DefaultEpilogueTensorOp<
-          ThreadblockShape, typename DualMma::Operator, kPartitionsK, EpilogueOutputOp0,
+          ThreadblockShape, typename DualMma::Operator0, kPartitionsK, EpilogueOutputOp0,
           EpilogueOutputOp0::kCount>::Epilogue;
   using Epilogue1 =
       typename cutlass::epilogue::threadblock::DefaultEpilogueTensorOp<
-          ThreadblockShape, typename DualMma::Operator, kPartitionsK, EpilogueOutputOp1,
+          ThreadblockShape, typename DualMma::Operator1, kPartitionsK, EpilogueOutputOp1,
           EpilogueOutputOp1::kCount>::Epilogue;
 
   /// Define the kernel-level GEMM operator.
   using DualGemmKernel = kernel::DualGemm<
     DualMma,
     Epilogue0, Epilogue1, EpilogueOutputOp2,
     ThreadblockSwizzle, kSplitKSerial,
@@ -193,71 +206,93 @@
   /// Argument structure
   struct Arguments {
 
     //
     // Data members
     //
 
+    DualGemmMode mode;
     GemmCoord problem_size;
     TensorRef<ElementA const, LayoutA> ref_A0;
-    TensorRef<ElementB const, LayoutB> ref_B0;
+    TensorRef<ElementB const, LayoutB0> ref_B0;
     TensorRef<ElementC const, LayoutC> ref_C0;
     TensorRef<ElementC, LayoutC> ref_D0;
-    TensorRef<ElementB const, LayoutB> ref_B1;
+    TensorRef<ElementB const, LayoutB1> ref_B1;
     TensorRef<ElementC const, LayoutC> ref_C1;
     TensorRef<ElementC, LayoutC> ref_D1;
     TensorRef<ElementC, LayoutC> ref_D2;
     typename EpilogueOutputOp0::Params epilogue0;
     typename EpilogueOutputOp1::Params epilogue1;
     typename EpilogueOutputOp2::Params epilogue2;
     int split_k_slices;
 
+    int batch_count;
+    int64_t batch_stride_A;
+    int64_t batch_stride_B0;
+    int64_t batch_stride_B1;
+    int64_t batch_stride_C;
+    int64_t batch_stride_D;
+
     //
     // Methods
     //
 
     /// Default ctor
     CUTLASS_HOST_DEVICE
     Arguments(): problem_size(0, 0, 0), split_k_slices(1) {
 
     }
 
     /// Constructs an Arguments structure 
     CUTLASS_HOST_DEVICE
     Arguments(
+      DualGemmMode mode,
       GemmCoord problem_size_,
       TensorRef<ElementA const, LayoutA> ref_A0_,
-      TensorRef<ElementB const, LayoutB> ref_B0_,
+      TensorRef<ElementB const, LayoutB0> ref_B0_,
       TensorRef<ElementC const, LayoutC> ref_C0_,
       TensorRef<ElementC, LayoutC> ref_D0_,
-      TensorRef<ElementB const, LayoutB> ref_B1_,
+      TensorRef<ElementB const, LayoutB1> ref_B1_,
       TensorRef<ElementC const, LayoutC> ref_C1_,
       TensorRef<ElementC, LayoutC> ref_D1_,
       TensorRef<ElementC, LayoutC> ref_D2_,
       typename EpilogueOutputOp0::Params epilogue0_ =
         typename EpilogueOutputOp0::Params(),
       typename EpilogueOutputOp1::Params epilogue1_ =
         typename EpilogueOutputOp1::Params(),
       typename EpilogueOutputOp2::Params epilogue2_ =
         typename EpilogueOutputOp2::Params(),
-      int split_k_slices_ = 1
+      int split_k_slices_ = 1,
+      int batch_count = 1,
+      int64_t batch_stride_A = 0,
+      int64_t batch_stride_B0 = 0,
+      int64_t batch_stride_B1 = 0,
+      int64_t batch_stride_C = 0,
+      int64_t batch_stride_D = 0
     ):
+      mode(mode),
       problem_size(problem_size_),
       ref_A0(ref_A0_),
       ref_B0(ref_B0_),
       ref_C0(ref_C0_),
       ref_D0(ref_D0_),
       ref_B1(ref_B1_),
       ref_C1(ref_C1_),
       ref_D1(ref_D1_),
       ref_D2(ref_D2_),
       epilogue0(epilogue0_),
       epilogue1(epilogue1_),
       epilogue2(epilogue2_),
-      split_k_slices(split_k_slices_) {
+      split_k_slices(split_k_slices_),
+      batch_count(batch_count),
+      batch_stride_A(batch_stride_A),
+      batch_stride_B0(batch_stride_B0),
+      batch_stride_B1(batch_stride_B1),
+      batch_stride_C(batch_stride_C),
+      batch_stride_D(batch_stride_D) {
 
     }
   };
 
 private:
 
   /// Kernel parameters object
@@ -267,14 +302,17 @@
 
   /// Constructs the GEMM.
   DualGemm() = default;
 
   /// Determines whether the GEMM can execute the given problem.
   static Status can_implement(Arguments const &args) {
 
+    if (args.mode == DualGemmMode::kBatched && kSplitKSerial) {
+      return Status::kErrorInvalidProblem;
+    }
     if (!kSplitKSerial && args.split_k_slices > 1) {
       return Status::kErrorInvalidProblem;
     }
     if (kStoreD0 != (args.ref_D0.data() != nullptr)) {
       return Status::kErrorInternal;
     }
     if (kStoreD1 != (args.ref_D1.data() != nullptr)) {
@@ -300,25 +338,23 @@
     return Status::kSuccess;
   }
 
   /// Gets the workspace size
   static size_t get_workspace_size(Arguments const &args) {
 
     size_t bytes = 0;
-      
-    // Determine grid shape
-    ThreadblockSwizzle threadblock_swizzle;
-
-    cutlass::gemm::GemmCoord tiled_shape = threadblock_swizzle.get_tiled_shape(
-      args.problem_size, 
-      {ThreadblockShape::kM, ThreadblockShape::kN, ThreadblockShape::kK},
-      args.split_k_slices);
 
     if (kSplitKSerial && args.split_k_slices > 1) {
+      // Determine grid shape
+      ThreadblockSwizzle threadblock_swizzle;
 
+      cutlass::gemm::GemmCoord tiled_shape = threadblock_swizzle.get_tiled_shape(
+        args.problem_size, 
+        {ThreadblockShape::kM, ThreadblockShape::kN, ThreadblockShape::kK},
+        args.split_k_slices);
 
       bytes += sizeof(int) * size_t(tiled_shape.m()) * size_t(tiled_shape.n());
     }
 
     return bytes;
   }
 
@@ -327,15 +363,15 @@
 
     // Determine grid shape
     ThreadblockSwizzle threadblock_swizzle;
 
     cutlass::gemm::GemmCoord grid_shape = threadblock_swizzle.get_tiled_shape(
       args.problem_size, 
       {ThreadblockShape::kM, ThreadblockShape::kN, ThreadblockShape::kK},
-      args.split_k_slices);
+      args.mode == DualGemmMode::kBatched ? args.batch_count : args.split_k_slices);
 
     if (kSplitKSerial) {
       if (args.split_k_slices > 1) {
         if (!workspace) {
           return Status::kErrorWorkspaceNull;
         }
 
@@ -353,28 +389,34 @@
       if (args.split_k_slices > 1) {
         return Status::kErrorInvalidProblem;
       }
     }
 
     // Initialize the Params structure
     params_ = typename DualGemmKernel::Params{
+      args.mode,
       args.problem_size,
       grid_shape,
       args.ref_A0.non_const_ref(),
       args.ref_B0.non_const_ref(),
       args.ref_C0.non_const_ref(),
       args.ref_D0,
       args.ref_B1.non_const_ref(),
       args.ref_C1.non_const_ref(),
       args.ref_D1,
       args.ref_D2,
       args.epilogue0,
       args.epilogue1,
       args.epilogue2,
       reinterpret_cast<int *>(workspace),
+      args.batch_stride_A,
+      args.batch_stride_B0,
+      args.batch_stride_B1,
+      args.batch_stride_C,
+      args.batch_stride_D,
     };
 
     return Status::kSuccess;
   }
 
   /// Lightweight update given a subset of arguments
   Status update(Arguments const &args, void *workspace = nullptr) {
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/45_dual_gemm/dual_gemm.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_volta_tensor_op_f16_sm70.cu`

 * *Files 22% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -24,239 +24,244 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
-
 /*! \file
-    \brief CUTLASS Dual-GEMM Example.
-
-    Fused kernel that outputs `D0` and `D1`.
-    We assume that B0/B1 have the same shape/layout
-
-```
-D0 = epilogue0(X @ B0, C0)
-D1 = epilogue1(X @ B1, C1)
-D2 = element_wise(D0, D1)
-```
-    D0 and D1 will be optionally stored in gmem (`kStoreD0` / `kStoreD1`)
+    \brief Tests for device-wide GEMM interface
 */
 
-// #define IS_PROFILING
-
 #include <iostream>
 
 #include "cutlass/cutlass.h"
 #include "cutlass/gemm/device/gemm.h"
 
-#include "cutlass/util/host_tensor.h"
-#include "cutlass/util/tensor_view_io.h"
-#include "cutlass/util/reference/host/tensor_fill.h"
-#include "cutlass/util/reference/host/tensor_copy.h"
-#include "cutlass/util/reference/host/tensor_compare.h"
-#include "cutlass/util/reference/host/gemm.h"
-
-#include "device/dual_gemm.h"
-#include "thread/left_silu_and_mul.h"
-#include "dual_gemm_run.h"
-#include "test_run.h"
-
-
-////////////////////////////////////////////////////////////////////////////////
-
-cutlass::gemm::GemmCoord problem_size(4096, 4096, 8192);
-
-constexpr int kStages = 3;
-constexpr bool kSplitKSerial = false;
-constexpr bool kUseBias = true;
-
-
-#if 0
-using ElementOperandA = cutlass::bfloat16_t;
-using ElementOperandB = cutlass::bfloat16_t;
-using ElementOutput = cutlass::bfloat16_t;
-using ElementAccumulator = float;
-using ElementCompute = float;
-#else
-using ElementOperandA = cutlass::half_t;
-using ElementOperandB = cutlass::half_t;
-using ElementOutput = cutlass::half_t;
-using ElementAccumulator = cutlass::half_t;
-using ElementCompute = cutlass::half_t;
-#endif
+#include "../../common/cutlass_unit_test.h"
 
-constexpr auto kScaleType = kUseBias ? cutlass::epilogue::thread::ScaleType::NoBetaScaling : (
-  // No bias
-  kSplitKSerial ? cutlass::epilogue::thread::ScaleType::Default : cutlass::epilogue::thread::ScaleType::Nothing
-);
-using EpilogueOutputOp0 = cutlass::epilogue::thread::LinearCombination<
-  ElementOutput,
-  128 / cutlass::sizeof_bits<ElementOutput>::value,
-  ElementAccumulator,
-  ElementCompute,
-  kScaleType
->;
-using EpilogueOutputOp1 = cutlass::epilogue::thread::LinearCombination<
-  ElementOutput,
-  128 / cutlass::sizeof_bits<ElementOutput>::value,
-  ElementAccumulator,
-  ElementCompute,
-  kScaleType
->;
-using EpilogueOutputOp2 = cutlass::epilogue::thread::LeftSiLUAndMul<
-  ElementOutput,
-  128 / cutlass::sizeof_bits<ElementOutput>::value,
-  ElementOutput,
-  ElementCompute
->;
-
-const ElementCompute alpha0 = ElementCompute(1);
-const ElementCompute beta0 = ElementCompute(kUseBias ? 1 : 0);
-const ElementCompute alpha1 = ElementCompute(1);
-const ElementCompute beta1 = ElementCompute(kUseBias ? 1 : 0);
-
-bool run_nonfused_gemm_f16_sm80() {
-  using ThreadblockShape = cutlass::gemm::GemmShape<128, 128, 32>;
-  using WarpShape = cutlass::gemm::GemmShape<64, 64, 32>;
-  using InstructionShape = cutlass::gemm::GemmShape<16, 8, 16>;
+#include "testbed.h"
 
-  using Gemm0 = cutlass::gemm::device::Gemm<
-    ElementOperandA,
-    cutlass::layout::RowMajor,
-    ElementOperandB,
+#if defined(CUTLASS_ARCH_MMA_SM70_SUPPORTED)
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM70_Device_Gemm_f16n_f16t_f16t_volta_tensor_op_f16, 128x256x32_64x64x32) {
+
+  using ElementOutput = cutlass::half_t;
+  using ElementAccumulator = cutlass::half_t;
+
+  using Gemm = cutlass::gemm::device::Gemm<
+    cutlass::half_t,
     cutlass::layout::ColumnMajor,
+    cutlass::half_t,
+    cutlass::layout::RowMajor,
     ElementOutput,
     cutlass::layout::RowMajor,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm80,
-    ThreadblockShape,
-    WarpShape,
-    InstructionShape,
-    EpilogueOutputOp0,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<1>,
-    kStages,
-    8,
-    8,
-    kSplitKSerial
+    cutlass::arch::Sm70,
+    cutlass::gemm::GemmShape<128, 256, 32>,
+    cutlass::gemm::GemmShape<64, 64, 32>,
+    cutlass::gemm::GemmShape<8, 8, 4>,
+    cutlass::epilogue::thread::LinearCombination<
+      ElementOutput,
+      128 / cutlass::sizeof_bits<ElementOutput>::value,
+      ElementAccumulator,
+      ElementAccumulator
+    >,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
+    2
   >;
-  using Gemm1 = cutlass::gemm::device::Gemm<
-    ElementOperandA,
-    cutlass::layout::RowMajor,
-    ElementOperandB,
+  
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
+}
+
+TEST(SM70_Device_Gemm_f16n_f16t_f16t_volta_tensor_op_f16, 256x128x32_64x64x32) {
+
+  using ElementOutput = cutlass::half_t;
+  using ElementAccumulator = cutlass::half_t;
+
+  using Gemm = cutlass::gemm::device::Gemm<
+    cutlass::half_t,
     cutlass::layout::ColumnMajor,
+    cutlass::half_t,
+    cutlass::layout::RowMajor,
     ElementOutput,
     cutlass::layout::RowMajor,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm80,
-    ThreadblockShape,
-    WarpShape,
-    InstructionShape,
-    EpilogueOutputOp1,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<1>,
-    kStages,
-    8,
-    8,
-    kSplitKSerial
+    cutlass::arch::Sm70,
+    cutlass::gemm::GemmShape<256, 128, 32>,
+    cutlass::gemm::GemmShape<64, 64, 32>,
+    cutlass::gemm::GemmShape<8, 8, 4>,
+    cutlass::epilogue::thread::LinearCombination<
+      ElementOutput,
+      128 / cutlass::sizeof_bits<ElementOutput>::value,
+      ElementAccumulator,
+      ElementAccumulator
+    >,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
+    2
   >;
 
-  NonFusedDualGemmRun<Gemm0, Gemm1> nonFusedGemm;
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
+}
+
+TEST(SM70_Device_Gemm_f16n_f16t_f16t_volta_tensor_op_f16, 128x128x32_64x64x32) {
 
-  std::cout << "Running Non-fused GEMMs FP16 TN GEMMs...\n";
-  bool pass = nonFusedGemm.run(problem_size, alpha0, beta0, alpha1, beta1);
-  if(pass)
-    std::cout << "Pass\n";
-  else
-    std::cout << "Fail\n";
+  using ElementOutput = cutlass::half_t;
+  using ElementAccumulator = cutlass::half_t;
 
-  return pass;
+  using Gemm = cutlass::gemm::device::Gemm<
+    cutlass::half_t,
+    cutlass::layout::ColumnMajor,
+    cutlass::half_t,
+    cutlass::layout::RowMajor,
+    ElementOutput,
+    cutlass::layout::RowMajor,
+    ElementAccumulator,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm70,
+    cutlass::gemm::GemmShape<128, 128, 32>,
+    cutlass::gemm::GemmShape<64, 64, 32>,
+    cutlass::gemm::GemmShape<8, 8, 4>,
+    cutlass::epilogue::thread::LinearCombination<
+      ElementOutput,
+      128 / cutlass::sizeof_bits<ElementOutput>::value,
+      ElementAccumulator,
+      ElementAccumulator
+    >,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
+    2
+  >;
+
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-template <typename T>
-struct LeftSiLUAndMul {
-  struct Params{};
-  CUTLASS_HOST_DEVICE LeftSiLUAndMul(Params p) {}
-
-  CUTLASS_HOST_DEVICE void set_k_partition(int, int) {}
-
-  CUTLASS_HOST_DEVICE T operator() (
-    T const &lhs, 
-    T const &rhs) const {
-    cutlass::epilogue::thread::SiLu<T> silu;
-    cutlass::multiplies<T> mul;
-    auto silu_lhs = silu(lhs);
-    return mul(silu_lhs, rhs);
-  }
-
-  template <int kCount>
-  CUTLASS_HOST_DEVICE cutlass::Array<T, kCount> operator() (
-    cutlass::Array<T, kCount> const &lhs, 
-    cutlass::Array<T, kCount> const &rhs) const {
-    cutlass::epilogue::thread::SiLu<T> silu;
-    cutlass::multiplies<T> mul;
-    auto silu_lhs = silu(lhs);
-    return mul(silu_lhs, rhs);
-  }
-};
-
-bool run_fused_gemm_f16_sm80_shmem() {
-  using ThreadblockShape = cutlass::gemm::GemmShape<128, 64, 32>;
-  using WarpShape = cutlass::gemm::GemmShape<64, 32, 32>;
-  using InstructionShape = cutlass::gemm::GemmShape<16, 8, 16>;
-
-  // Optionally, we might not need intermediate GEMM outputs
-  constexpr bool kStoreD0 = true;
-  constexpr bool kStoreD1 = true;
+TEST(SM70_Device_Gemm_f16n_f16t_f16t_volta_tensor_op_f16, 128x64x32_64x32x32) {
 
-  using DualGemm = cutlass::gemm::device::DualGemm<
-    ElementOperandA,
-    cutlass::layout::RowMajor,
-    ElementOperandB,
+  using ElementOutput = cutlass::half_t;
+  using ElementAccumulator = cutlass::half_t;
+
+  using Gemm = cutlass::gemm::device::Gemm<
+    cutlass::half_t,
     cutlass::layout::ColumnMajor,
+    cutlass::half_t,
+    cutlass::layout::RowMajor,
     ElementOutput,
     cutlass::layout::RowMajor,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm80,
-    ThreadblockShape,
-    WarpShape,
-    InstructionShape,
-    EpilogueOutputOp0,
-    EpilogueOutputOp1,
-    EpilogueOutputOp2,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<1>,
-    kStages,
-    kStoreD0,
-    kStoreD1,
-    kSplitKSerial
+    cutlass::arch::Sm70,
+    cutlass::gemm::GemmShape<128, 64, 32>,
+    cutlass::gemm::GemmShape<64, 32, 32>,
+    cutlass::gemm::GemmShape<8, 8, 4>,
+    cutlass::epilogue::thread::LinearCombination<
+      ElementOutput,
+      128 / cutlass::sizeof_bits<ElementOutput>::value,
+      ElementAccumulator,
+      ElementAccumulator
+    >,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
+    2
   >;
 
-  DualFusedGemmRun<DualGemm> fusedGemm;
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
+}
 
-  std::cout << "Running Fused FP16 TN GEMMs + Epilogue2...\n";
-  bool passed = fusedGemm.run(problem_size, alpha0, beta0, alpha1, beta1);
-  if(passed)
-    std::cout << "Pass\n";
-  else
-    std::cout << "Fail\n";
+TEST(SM70_Device_Gemm_f16n_f16t_f16t_volta_tensor_op_f16, 64x128x32_32x64x32) {
 
-  return passed;
+  using ElementOutput = cutlass::half_t;
+  using ElementAccumulator = cutlass::half_t;
 
+  using Gemm = cutlass::gemm::device::Gemm<
+    cutlass::half_t,
+    cutlass::layout::ColumnMajor,
+    cutlass::half_t,
+    cutlass::layout::RowMajor,
+    ElementOutput,
+    cutlass::layout::RowMajor,
+    ElementAccumulator,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm70,
+    cutlass::gemm::GemmShape<64, 128, 32>,
+    cutlass::gemm::GemmShape<32, 64, 32>,
+    cutlass::gemm::GemmShape<8, 8, 4>,
+    cutlass::epilogue::thread::LinearCombination<
+      ElementOutput,
+      128 / cutlass::sizeof_bits<ElementOutput>::value,
+      ElementAccumulator,
+      ElementAccumulator
+    >,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
+    2
+  >;
+
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-int main() {
+TEST(SM70_Device_Gemm_f16n_f16t_f16t_volta_tensor_op_f16, 64x64x32_64x64x32) {
 
-  std::vector<bool (*)()>funcs = {
-    &run_nonfused_gemm_f16_sm80,
-    &run_fused_gemm_f16_sm80_shmem
-  };
+  using ElementOutput = cutlass::half_t;
+  using ElementAccumulator = cutlass::half_t;
 
-  std::string test_name = "dual-gemm f16 bias=" + std::to_string(kUseBias) + " split_k_serial=" + std::to_string(kSplitKSerial);
-  return testRun(80, funcs, test_name);
+  using Gemm = cutlass::gemm::device::Gemm<
+    cutlass::half_t,
+    cutlass::layout::ColumnMajor,
+    cutlass::half_t,
+    cutlass::layout::RowMajor,
+    ElementOutput,
+    cutlass::layout::RowMajor,
+    ElementAccumulator,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm70,
+    cutlass::gemm::GemmShape<64, 64, 32>,
+    cutlass::gemm::GemmShape<64, 64, 32>,
+    cutlass::gemm::GemmShape<8, 8, 4>,
+    cutlass::epilogue::thread::LinearCombination<
+      ElementOutput,
+      128 / cutlass::sizeof_bits<ElementOutput>::value,
+      ElementAccumulator,
+      ElementAccumulator
+    >,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
+    2
+  >;
+
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
+TEST(SM70_Device_Gemm_f16n_f16t_f16t_volta_tensor_op_f16, 64x64x32_32x32x32) {
+
+  using ElementOutput = cutlass::half_t;
+  using ElementAccumulator = cutlass::half_t;
+
+  using Gemm = cutlass::gemm::device::Gemm<
+    cutlass::half_t,
+    cutlass::layout::ColumnMajor,
+    cutlass::half_t,
+    cutlass::layout::RowMajor,
+    ElementOutput,
+    cutlass::layout::RowMajor,
+    ElementAccumulator,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm70,
+    cutlass::gemm::GemmShape<64, 64, 32>,
+    cutlass::gemm::GemmShape<32, 32, 32>,
+    cutlass::gemm::GemmShape<8, 8, 4>,
+    cutlass::epilogue::thread::LinearCombination<
+      ElementOutput,
+      128 / cutlass::sizeof_bits<ElementOutput>::value,
+      ElementAccumulator,
+      ElementAccumulator
+    >,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
+    2
+  >;
+
+  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
+}
 
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
-////////////////////////////////////////////////////////////////////////////////
+#endif
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/45_dual_gemm/dual_gemm_run.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/45_dual_gemm/dual_gemm_run.h`

 * *Files 19% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -29,25 +29,30 @@
  *
  **************************************************************************************************/
 #pragma once
 
 #include <iostream>
 #include <fstream>
 #include <sstream>
+#include <type_traits>
 
 #include "cutlass/util/host_tensor.h"
 #include "cutlass/util/tensor_view_io.h"
 #include "cutlass/util/distribution.h"
 #include "cutlass/util/reference/host/tensor_fill.h"
 #include "cutlass/util/reference/host/tensor_copy.h"
 #include "cutlass/util/reference/host/tensor_compare.h"
 #include "cutlass/util/reference/host/tensor_norm.h"
 #include "cutlass/util/reference/device/gemm.h"
 #include "cutlass/util/reference/device/tensor_relu.h"
 
+#include "cutlass/gemm/gemm.h"
+#include "cutlass/gemm/device/gemm_universal.h"
+
+#include "dual_gemm_common.h"
 #include "helper.h"
 
 #define CHECK_GT(val1, val2) \
     if((val1) <= (val2)) \
         std::cerr << __FILE__ << " " << __LINE__ << ": CHECK_GT failed\n";
 #define CHECK_TRUE(val) \
     if(!(val)) \
@@ -201,14 +206,15 @@
   /// Executes one test
   bool run(
     cutlass::gemm::GemmCoord problem_size,
     ElementCompute alpha0 = ElementCompute(1),
     ElementCompute beta0 = ElementCompute(0),
     ElementCompute alpha1 = ElementCompute(1),
     ElementCompute beta1 = ElementCompute(0),
+    bool is_profiling = true,
     bool relu = false,
     int warm_ups = 1,
     int runs = 100) {
     
     //
     // Allocate the GEMM workspace
     //
@@ -331,49 +337,50 @@
 
     for(int i = 0; i < warm_ups; i++) {
         status = gemm_op_0();
         CUTLASS_CHECK(status);
         status = gemm_op_1();
         CUTLASS_CHECK(status);
     }
-#ifdef IS_PROFILING
-    return true;
-#endif
-    //
-    // Run the GEMM
-    //
-    cudaEvent_t start, stop1, stop2;
-    cudaEventCreate(&start);
-    cudaEventCreate(&stop1);
-    cudaEventCreate(&stop2);
 
-    cudaEventRecord(start);
-
-    for(int i = 0; i < runs; i++) {
-        status = gemm_op_0();
-    
-        CUTLASS_CHECK(status);
-    }
-    cudaEventRecord(stop1);
-    for(int i = 0; i < runs; i++) {
-        status = gemm_op_1();
-    
-        CUTLASS_CHECK(status);
+    if (is_profiling) {
+      //
+      // Profile the GEMM
+      //
+
+      cudaEvent_t start, stop1, stop2;
+      cudaEventCreate(&start);
+      cudaEventCreate(&stop1);
+      cudaEventCreate(&stop2);
+
+      cudaEventRecord(start);
+
+      for(int i = 0; i < runs; i++) {
+          status = gemm_op_0();
+      
+          CUTLASS_CHECK(status);
+      }
+      cudaEventRecord(stop1);
+      for(int i = 0; i < runs; i++) {
+          status = gemm_op_1();
+      
+          CUTLASS_CHECK(status);
+      }
+
+      cudaEventRecord(stop2);
+      cudaDeviceSynchronize();
+      float gemm0Time, gemm1Time, totalTime;
+      cudaEventElapsedTime(&gemm0Time, start, stop1);
+      cudaEventElapsedTime(&gemm1Time, stop1, stop2);
+      cudaEventElapsedTime(&totalTime, start, stop2);
+      std::cout << "gemm 0 time " << gemm0Time / (float)runs << " ms\n";
+      std::cout << "gemm 1 time " << gemm1Time / (float)runs << " ms\n";
+      std::cout << "Non-fusion GEMM only time " << totalTime / (float)runs << " ms\n";
     }
 
-    cudaEventRecord(stop2);
-    cudaDeviceSynchronize();
-    float gemm0Time, gemm1Time, totalTime;
-    cudaEventElapsedTime(&gemm0Time, start, stop1);
-    cudaEventElapsedTime(&gemm1Time, stop1, stop2);
-    cudaEventElapsedTime(&totalTime, start, stop2);
-    std::cout << "gemm 0 time " << gemm0Time / (float)runs << " ms\n";
-    std::cout << "gemm 1 time " << gemm1Time / (float)runs << " ms\n";
-    std::cout << "Non-fusion GEMM only time " << totalTime / (float)runs << " ms\n";
-
     tensor_D0.sync_host();
     tensor_D1.sync_host();
 
     //
     // Verify
     //
     cutlass::reference::device::Gemm<
@@ -539,73 +546,112 @@
   /// Executes one test
   bool run(
     cutlass::gemm::GemmCoord problem_size,
     ElementCompute alpha0 = ElementCompute(1),
     ElementCompute beta0 = ElementCompute(1),
     ElementCompute alpha1 = ElementCompute(1),
     ElementCompute beta1 = ElementCompute(1),
+    int batch_count = 1,
+    bool broadcast_b1 = false,
+    bool is_profiling = true,
     bool relu = false,
     int warm_ups = 1,
     int runs = 100) {
     
     //
     // Allocate the GEMM workspace
     //
 
     cutlass::HostTensor<
       typename DualGemm::ElementA,
-      typename DualGemm::LayoutA> tensor_A0(problem_size.mk());
+      typename DualGemm::LayoutA> tensor_A0(
+        std::is_same<typename DualGemm::LayoutA, cutlass::layout::RowMajor>::value ? 
+          cutlass::MatrixCoord(batch_count * problem_size.m(), problem_size.k()) : 
+          cutlass::MatrixCoord(problem_size.m(), batch_count * problem_size.k()));
 
     cutlass::HostTensor<
       typename DualGemm::ElementB,
-      typename DualGemm::LayoutB> tensor_B0(problem_size.kn());
+      typename DualGemm::LayoutB0> tensor_B0(
+        std::is_same<typename DualGemm::LayoutB0, cutlass::layout::RowMajor>::value ? 
+          cutlass::MatrixCoord(batch_count * problem_size.k(), problem_size.n()) : 
+          cutlass::MatrixCoord(problem_size.k(), batch_count * problem_size.n()));
 
     cutlass::HostTensor<
       typename DualGemm::ElementC,
-      typename DualGemm::LayoutC> tensor_C0(problem_size.mn());
+      typename DualGemm::LayoutC> tensor_C0(
+        std::is_same<typename DualGemm::LayoutC, cutlass::layout::RowMajor>::value ? 
+          cutlass::MatrixCoord(batch_count * problem_size.m(), problem_size.n()) : 
+          cutlass::MatrixCoord(problem_size.m(), batch_count * problem_size.n()));
 
     cutlass::HostTensor<
       typename DualGemm::ElementC,
-      typename DualGemm::LayoutScaleBias> tensor_Bias0({1, problem_size.n()});
+      typename DualGemm::LayoutScaleBias> tensor_Bias0({batch_count, problem_size.n()});
 
     cutlass::HostTensor<
       typename DualGemm::ElementC,
-      typename DualGemm::LayoutC> tensor_D0(problem_size.mn());
+      typename DualGemm::LayoutC> tensor_D0(
+        std::is_same<typename DualGemm::LayoutC, cutlass::layout::RowMajor>::value ? 
+          cutlass::MatrixCoord(batch_count * problem_size.m(), problem_size.n()) : 
+          cutlass::MatrixCoord(problem_size.m(), batch_count * problem_size.n()));
 
     cutlass::HostTensor<
       typename DualGemm::ElementC,
-      typename DualGemm::LayoutC> reference_D0(problem_size.mn());
+      typename DualGemm::LayoutC> reference_D0(
+        std::is_same<typename DualGemm::LayoutC, cutlass::layout::RowMajor>::value ? 
+          cutlass::MatrixCoord(batch_count * problem_size.m(), problem_size.n()) : 
+          cutlass::MatrixCoord(problem_size.m(), batch_count * problem_size.n()));
 
     cutlass::HostTensor<
       typename DualGemm::ElementB,
-      typename DualGemm::LayoutB> tensor_B1(problem_size.kn());
+      typename DualGemm::LayoutB1> tensor_B1(
+        std::is_same<typename DualGemm::LayoutB1, cutlass::layout::RowMajor>::value ? 
+          cutlass::MatrixCoord(batch_count * problem_size.k(), problem_size.n()) : 
+          cutlass::MatrixCoord(problem_size.k(), batch_count * problem_size.n()));
+    if (broadcast_b1) {
+      tensor_B1.resize({problem_size.k(), batch_count});
+    }
 
     cutlass::HostTensor<
       typename DualGemm::ElementC,
-      typename DualGemm::LayoutC> tensor_C1(problem_size.mn());
+      typename DualGemm::LayoutC> tensor_C1(
+        std::is_same<typename DualGemm::LayoutC, cutlass::layout::RowMajor>::value ? 
+          cutlass::MatrixCoord(batch_count * problem_size.m(), problem_size.n()) : 
+          cutlass::MatrixCoord(problem_size.m(), batch_count * problem_size.n()));
 
     cutlass::HostTensor<
       typename DualGemm::ElementC,
-      typename DualGemm::LayoutScaleBias> tensor_Bias1({1, problem_size.n()});
+      typename DualGemm::LayoutScaleBias> tensor_Bias1({batch_count, problem_size.n()});
 
     cutlass::HostTensor<
       typename DualGemm::ElementC,
-      typename DualGemm::LayoutC> tensor_D1(problem_size.mn());
+      typename DualGemm::LayoutC> tensor_D1(
+        std::is_same<typename DualGemm::LayoutC, cutlass::layout::RowMajor>::value ? 
+          cutlass::MatrixCoord(batch_count * problem_size.m(), problem_size.n()) : 
+          cutlass::MatrixCoord(problem_size.m(), batch_count * problem_size.n()));
 
     cutlass::HostTensor<
       typename DualGemm::ElementC,
-      typename DualGemm::LayoutC> tensor_D2(problem_size.mn());
+      typename DualGemm::LayoutC> tensor_D2(
+        std::is_same<typename DualGemm::LayoutC, cutlass::layout::RowMajor>::value ? 
+          cutlass::MatrixCoord(batch_count * problem_size.m(), problem_size.n()) : 
+          cutlass::MatrixCoord(problem_size.m(), batch_count * problem_size.n()));
 
     cutlass::HostTensor<
       typename DualGemm::ElementC,
-      typename DualGemm::LayoutC> reference_D1(problem_size.mn());
+      typename DualGemm::LayoutC> reference_D1(
+        std::is_same<typename DualGemm::LayoutC, cutlass::layout::RowMajor>::value ? 
+          cutlass::MatrixCoord(batch_count * problem_size.m(), problem_size.n()) : 
+          cutlass::MatrixCoord(problem_size.m(), batch_count * problem_size.n()));
 
     cutlass::HostTensor<
       typename DualGemm::ElementC,
-      typename DualGemm::LayoutC> reference_D2(problem_size.mn());
+      typename DualGemm::LayoutC> reference_D2(
+        std::is_same<typename DualGemm::LayoutC, cutlass::layout::RowMajor>::value ? 
+          cutlass::MatrixCoord(batch_count * problem_size.m(), problem_size.n()) : 
+          cutlass::MatrixCoord(problem_size.m(), batch_count * problem_size.n()));
 
     CHECK_TRUE(initialize_tensor(tensor_A0.host_view(), init_A, seed + 2019));
     CHECK_TRUE(initialize_tensor(tensor_B0.host_view(), init_B, seed + 2118));
     CHECK_TRUE(initialize_tensor(tensor_C0.host_view(), init_C, seed + 2017));
     CHECK_TRUE(initialize_tensor(tensor_Bias0.host_view(), init_Bias, seed + 2011));
     CHECK_TRUE(initialize_tensor(tensor_B1.host_view(), init_B, seed + 2113));
     CHECK_TRUE(initialize_tensor(tensor_C1.host_view(), init_C, seed + 2015));
@@ -635,42 +681,71 @@
     tensor_D1.sync_device();
     tensor_D2.sync_device();
     reference_D0.sync_device();
     reference_D1.sync_device();
     reference_D2.sync_device();
 
     //
+    // Batch strides (irrelevant when batch_count == 1)
+    //
+
+    int64_t batch_stride_A = problem_size.m() * problem_size.k();
+    int64_t batch_stride_B0 = problem_size.k() * problem_size.n();
+    int64_t batch_stride_B1 = problem_size.k() * problem_size.n();
+    if (broadcast_b1) {
+      // B1 is a (column) vector
+      batch_stride_B1 = problem_size.k();
+    }
+    int64_t batch_stride_Bias = problem_size.n();
+    int64_t batch_stride_D = problem_size.m() * problem_size.n();
+
+    //
     // Initialize the GEMM operator
     //
 
     int split_k_slices = DualGemm::kSplitKSerial ? 2 : 1;
     typename cutlass::TensorRef<typename DualGemm::ElementC, typename DualGemm::LayoutC> nullptr_ref{};
     decltype(nullptr_ref) ref_B0, ref_B1;
     if (beta0 != ElementCompute(0)) {
       ref_B0 = {tensor_Bias0.device_data(), typename DualGemm::LayoutC::Stride(0)};
     }
     if (beta1 != ElementCompute(0)) {
       ref_B1 = {tensor_Bias1.device_data(), typename DualGemm::LayoutC::Stride(0)};
     }
     typename DualGemm::Arguments arguments{
+      (batch_count > 1 ? 
+        cutlass::gemm::DualGemmMode::kBatched : 
+        cutlass::gemm::DualGemmMode::kGemm),
       problem_size,
       tensor_A0.device_ref(),
       tensor_B0.device_ref(),
       ref_B0,
       DualGemm::kStoreD0 ? tensor_D0.device_ref() : nullptr_ref,
-      tensor_B1.device_ref(),
+      (broadcast_b1 ? 
+        typename DualGemm::TensorRefB1(tensor_B1.device_data(), 0) : 
+        tensor_B1.device_ref()),
       ref_B1,
       DualGemm::kStoreD1 ? tensor_D1.device_ref() : nullptr_ref,
       tensor_D2.device_ref(),
       {alpha0, beta0},
       {alpha1, beta1},
       {},
-      split_k_slices
+      split_k_slices,
+      batch_count,
+      batch_stride_A,
+      batch_stride_B0,
+      batch_stride_B1,
+      batch_stride_Bias,
+      batch_stride_D,
     };
 
+    //
+    // Run the GEMM
+    //
+
     DualGemm b2b_gemm_op;
 
     cutlass::device_memory::allocation<uint8_t> workspace(b2b_gemm_op.get_workspace_size(arguments));
   
     cutlass::Status status = b2b_gemm_op.can_implement(arguments);
 
     CUTLASS_CHECK(status);
@@ -680,86 +755,120 @@
     CUTLASS_CHECK(status);
 
     for(int i = 0; i < warm_ups; i++) {
         status = b2b_gemm_op();
         CUTLASS_CHECK(status);
     }
 
-#ifdef IS_PROFILING
-    return true;
-#endif
-    //
-    // Run the GEMM
-    //
-
-    cudaEvent_t start, stop;
-    cudaEventCreate(&start);
-    cudaEventCreate(&stop);
-
-    cudaEventRecord(start);
-
-    for(int i = 0; i < runs; i++) {
-        status = b2b_gemm_op();
-
-        CUTLASS_CHECK(status);
+    if (is_profiling) {
+      //
+      // Profile the GEMM
+      //
+
+      cudaEvent_t start, stop;
+      cudaEventCreate(&start);
+      cudaEventCreate(&stop);
+
+      cudaEventRecord(start);
+
+      for(int i = 0; i < runs; i++) {
+          status = b2b_gemm_op();
+          CUTLASS_CHECK(status);
+      }
+
+      cudaEventRecord(stop);
+      cudaDeviceSynchronize();
+      float gemmTime;
+      cudaEventElapsedTime(&gemmTime, start, stop);
+      std::cout << "Fusion time " << gemmTime / (float)runs << " ms\n";
     }
 
-    cudaEventRecord(stop);
-    cudaDeviceSynchronize();
-    float gemmTime;
-    cudaEventElapsedTime(&gemmTime, start, stop);
-    std::cout << "Fusion time " << gemmTime / (float)runs << " ms\n";
-
     tensor_D0.sync_host();
     tensor_D1.sync_host();
     tensor_D2.sync_host();
 
     //
     // Verify
     //
 
-    cutlass::reference::device::Gemm<
-        typename DualGemm::ElementA, typename DualGemm::LayoutA,
-        typename DualGemm::ElementB, typename DualGemm::LayoutB,
-        typename DualGemm::ElementC, typename DualGemm::LayoutC, 
-        ElementAccumulator, ElementAccumulator>
-        reference_gemm_0;
+    using GemmUniversal0 = cutlass::gemm::device::GemmUniversal<
+      typename DualGemm::ElementA, typename DualGemm::LayoutA,
+      typename DualGemm::ElementB, typename DualGemm::LayoutB0,
+      typename DualGemm::ElementC, typename DualGemm::LayoutC, 
+      ElementAccumulator
+    >;
+
+    GemmUniversal0 reference_gemm0;
+
+    typename GemmUniversal0::Arguments args0 {
+      (batch_count > 1 ? 
+        cutlass::gemm::GemmUniversalMode::kBatched : 
+        cutlass::gemm::GemmUniversalMode::kGemm),
+      problem_size,
+      batch_count,
+      {alpha0, beta0},
+      tensor_A0.device_data(),
+      tensor_B0.device_data(),
+      tensor_Bias0.device_data(),
+      reference_D0.device_data(),
+      batch_stride_A,
+      batch_stride_B0,
+      batch_stride_Bias,
+      batch_stride_D,
+      tensor_A0.stride(0),
+      tensor_B0.stride(0),
+      0,  // zero stride for the bias vector
+      reference_D0.stride(0),
+    };
 
-    cutlass::reference::device::Gemm<
-        typename DualGemm::ElementA, typename DualGemm::LayoutA,
-        typename DualGemm::ElementB, typename DualGemm::LayoutB,
-        typename DualGemm::ElementC, typename DualGemm::LayoutC, ElementCompute,
-        ElementAccumulator, typename DualGemm::Operator>
-        reference_gemm_1;
+    status = reference_gemm0.can_implement(args0);
+    CUTLASS_CHECK(status);
+    status = reference_gemm0(args0);
+    CUTLASS_CHECK(status);
 
-    reference_gemm_0(
+    using GemmUniversal1 = cutlass::gemm::device::GemmUniversal<
+      typename DualGemm::ElementA, typename DualGemm::LayoutA,
+      typename DualGemm::ElementB, typename DualGemm::LayoutB1,
+      typename DualGemm::ElementC, typename DualGemm::LayoutC, 
+      ElementAccumulator
+    >;
+
+    GemmUniversal1 reference_gemm1;
+
+    typename GemmUniversal1::Arguments args1 {
+      (batch_count > 1 ? 
+        cutlass::gemm::GemmUniversalMode::kBatched : 
+        cutlass::gemm::GemmUniversalMode::kGemm),
       problem_size,
-      alpha0,
-      tensor_A0.device_ref(), 
-      tensor_B0.device_ref(), 
-      beta0,
-      {tensor_Bias0.device_data(), typename DualGemm::LayoutC::Stride(0)},
-      reference_D0.device_ref()
-    );
-    if(relu) {
-       cutlass::reference::device::TensorReLu(reference_D0.device_view()); 
-    }
+      batch_count,
+      {alpha1, beta1},
+      tensor_A0.device_data(),
+      tensor_B1.device_data(),
+      tensor_Bias1.device_data(),
+      reference_D1.device_data(),
+      batch_stride_A,
+      batch_stride_B1,
+      batch_stride_Bias,
+      batch_stride_D,
+      tensor_A0.stride(0),
+      (broadcast_b1 ? 0 : tensor_B1.stride(0)),
+      0,  // zero stride for the bias vector
+      reference_D1.stride(0),
+    };
+
+    status = reference_gemm1.can_implement(args1);
+    CUTLASS_CHECK(status);
+    status = reference_gemm1(args1);
+    CUTLASS_CHECK(status);
 
-    reference_gemm_1(
-      problem_size,
-      alpha1, 
-      tensor_A0.device_ref(), 
-      tensor_B1.device_ref(), 
-      beta1,
-      {tensor_Bias1.device_data(), typename DualGemm::LayoutC::Stride(0)},
-      reference_D1.device_ref()
-    );
     if(relu) {
+       cutlass::reference::device::TensorReLu(reference_D0.device_view()); 
        cutlass::reference::device::TensorReLu(reference_D1.device_view()); 
     }
+
     TensorEpilogueForEach<EpilogueOutputOp2>(reference_D0.device_view(), reference_D1.device_view(), reference_D2.device_view());
     cudaDeviceSynchronize();
     reference_D0.sync_host();
     reference_D1.sync_host();
     reference_D2.sync_host();
 
     CHECK_GT(cutlass::reference::host::TensorNorm(reference_D0.host_view()), 0);
@@ -789,15 +898,14 @@
       reference_D2.host_view(), 
       tensor_D2.host_view());
     CHECK_TRUE(passed_out2);
 
     bool passed = passed_out0 && passed_out1 && passed_out2;
     if (!passed)
     {
-
       std::stringstream fname;
 
       fname << "error_DualGemm_device_fused.txt";
       std::cerr << "Dumping results in " << fname.str() << "\n";
 
       std::ofstream file(fname.str());
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/45_dual_gemm/kernel/dual_gemm.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/45_dual_gemm/kernel/dual_gemm.h`

 * *Files 6% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -38,14 +38,15 @@
 
 #include "cutlass/gemm/gemm.h"
 #include "cutlass/matrix_coord.h"
 #include "cutlass/semaphore.h"
 
 #include "../threadblock/dual_mma_multistage.h"
 #include "../threadblock/dual_epilogue.h"
+#include "../dual_gemm_common.h"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace gemm {
 namespace kernel {
 
@@ -88,82 +89,100 @@
       typename Epilogue0::Padding,
       kStoreD0,
       kStoreD1,
       Epilogue0::kFragmentsPerIteration,
       true // IterationsUnroll
   >;
 
+  using ElementA = typename DualMma::IteratorA::Element;
+  using ElementB = typename DualMma::IteratorB0::Element;
+  using ElementC = typename DualEpilogue::OutputTileIterator::Element;
+
   static bool const kSplitKSerial = SplitKSerial;
   static_assert(!kSplitKSerial || (kStoreD0 && kStoreD1),
     "Split-K serial requires buffers for D0/D1 for reduction");
 
   /// Warp count (concept: GemmShape)
   using WarpCount0 = typename DualMma::WarpCount;
   static int const kThreadCount = 32 * WarpCount0::kCount;
 
   /// Parameters structure
   struct Params {
+    DualGemmMode mode;
     cutlass::gemm::GemmCoord problem_size;
     cutlass::gemm::GemmCoord grid_tiled_shape;
     int swizzle_log_tile;
 
     // Mma0
     typename DualMma::IteratorA::Params params_A0;
     typename DualMma::IteratorA::TensorRef ref_A0;
-    typename DualMma::IteratorB::Params params_B0;
-    typename DualMma::IteratorB::TensorRef ref_B0;
+    typename DualMma::IteratorB0::Params params_B0;
+    typename DualMma::IteratorB0::TensorRef ref_B0;
     typename Epilogue0::OutputTileIterator::Params params_C0;
     typename Epilogue0::OutputTileIterator::TensorRef ref_C0;
     typename Epilogue0::OutputTileIterator::Params params_D0;
     typename Epilogue0::OutputTileIterator::TensorRef ref_D0;
     typename OutputOp0::Params output_op_0;
 
     // Mma1
-    typename DualMma::IteratorB::Params params_B1;
-    typename DualMma::IteratorB::TensorRef ref_B1;
+    typename DualMma::IteratorB1::Params params_B1;
+    typename DualMma::IteratorB1::TensorRef ref_B1;
     typename Epilogue1::OutputTileIterator::Params params_C1;
     typename Epilogue1::OutputTileIterator::TensorRef ref_C1;
     typename Epilogue1::OutputTileIterator::Params params_D1;
     typename Epilogue1::OutputTileIterator::TensorRef ref_D1;
     typename OutputOp1::Params output_op_1;
 
     typename Epilogue1::OutputTileIterator::Params params_D2;
     typename Epilogue1::OutputTileIterator::TensorRef ref_D2;
     typename OutputOp2::Params output_op_2;
 
     int *semaphore;
     int gemm_k_size;
 
+    int64_t batch_stride_A;
+    int64_t batch_stride_B0;
+    int64_t batch_stride_B1;
+    int64_t batch_stride_C;
+    int64_t batch_stride_D;
+
     //
     // Methods
     //
 
     CUTLASS_HOST_DEVICE
     Params(): swizzle_log_tile(0), semaphore(0), gemm_k_size(0) { }
 
     CUTLASS_HOST_DEVICE
     Params(
+      DualGemmMode mode,
       cutlass::gemm::GemmCoord const & problem_size,
       cutlass::gemm::GemmCoord const & grid_tiled_shape,
       // Mma0: D0 = A @ B0 + C0
       typename DualMma::IteratorA::TensorRef ref_A0,
-      typename DualMma::IteratorB::TensorRef ref_B0,
+      typename DualMma::IteratorB0::TensorRef ref_B0,
       typename Epilogue0::OutputTileIterator::TensorRef ref_C0,
       typename Epilogue0::OutputTileIterator::TensorRef ref_D0,
       // Mma1: D1 = A @ B1 + C1
-      typename DualMma::IteratorB::TensorRef ref_B1,
+      typename DualMma::IteratorB1::TensorRef ref_B1,
       typename Epilogue1::OutputTileIterator::TensorRef ref_C1,
       typename Epilogue1::OutputTileIterator::TensorRef ref_D1,
 
       typename Epilogue1::OutputTileIterator::TensorRef ref_D2,
       typename OutputOp0::Params output_op_0 = typename OutputOp0::Params(),
       typename OutputOp1::Params output_op_1 = typename OutputOp1::Params(),
       typename OutputOp2::Params output_op_2 = typename OutputOp2::Params(),
-      int *workspace = nullptr
+      int *workspace = nullptr,
+      int64_t batch_stride_A = 1,
+      int64_t batch_stride_B0 = 1,
+      int64_t batch_stride_B1 = 1,
+      int64_t batch_stride_C = 1,
+      int64_t batch_stride_D = 1
     ):
+      mode(mode),
       problem_size(problem_size),
       grid_tiled_shape(grid_tiled_shape),
       swizzle_log_tile(ThreadblockSwizzle().get_log_tile(grid_tiled_shape)),
       // Mma0
       params_A0(ref_A0.layout()),
       ref_A0(ref_A0),
       params_B0(ref_B0.layout()),
@@ -179,21 +198,26 @@
       ref_C1(ref_C1),
       params_D1(ref_D1.layout()),
       ref_D1(ref_D1),
       params_D2(ref_D2.layout()),
       ref_D2(ref_D2),
       output_op_0(output_op_0),
       output_op_1(output_op_1),
-      output_op_2(output_op_2) {
+      output_op_2(output_op_2),
+      batch_stride_A(batch_stride_A),
+      batch_stride_B0(batch_stride_B0),
+      batch_stride_B1(batch_stride_B1),
+      batch_stride_C(batch_stride_C),
+      batch_stride_D(batch_stride_D) {
 
       int total_gemm_k_iterations = (problem_size.k() + DualMma::Shape::kK - 1) / DualMma::Shape::kK;
       int gemm_k_iterations = (total_gemm_k_iterations + grid_tiled_shape.k() - 1) / grid_tiled_shape.k();
       gemm_k_size = gemm_k_iterations * DualMma::Shape::kK;
 
-    semaphore = workspace;
+      semaphore = workspace;
     }
   };
 
   /// Shared memory storage structure
   union SharedStorage {
     typename DualMma::SharedStorage main_loop;
     typename DualEpilogue::SharedStorage epilogue;
@@ -206,24 +230,24 @@
   CUTLASS_HOST_DEVICE
   DualGemm() { }
 
   /// Determines whether kernel satisfies alignment
     static Status can_implement(
       cutlass::gemm::GemmCoord const & problem_size,
       typename DualMma::IteratorA::TensorRef ref_A0,
-      typename DualMma::IteratorB::TensorRef ref_B0,
+      typename DualMma::IteratorB0::TensorRef ref_B0,
       typename Epilogue0::OutputTileIterator::TensorRef ref_C0,
       typename Epilogue0::OutputTileIterator::TensorRef ref_D0,
-      typename DualMma::IteratorB::TensorRef ref_B1,
+      typename DualMma::IteratorB1::TensorRef ref_B1,
       typename Epilogue1::OutputTileIterator::TensorRef ref_C1,
       typename Epilogue1::OutputTileIterator::TensorRef ref_D1,
       typename Epilogue1::OutputTileIterator::TensorRef ref_D2) {
 
     static int const kAlignmentA = DualMma::IteratorA::AccessType::kElements;
-    static int const kAlignmentB = DualMma::IteratorB::AccessType::kElements;
+    static int const kAlignmentB = DualMma::IteratorB0::AccessType::kElements;
     static int const kAlignmentC = Epilogue0::OutputTileIterator::kElementsPerAccess;
 
     if (!TensorRef_aligned(ref_A0, kAlignmentA)) {
       return Status::kErrorMisalignedOperand;
     }
 
     if (!TensorRef_aligned(ref_B0, kAlignmentB)) {
@@ -269,60 +293,74 @@
     // Early exit if CTA is out of range
     if (params.grid_tiled_shape.m() <= threadblock_tile_offset.m() ||
       params.grid_tiled_shape.n() <= threadblock_tile_offset.n()) {
 
       return;
     }
 
+    int offset_k = 0;
+    int problem_size_k = params.problem_size.k();
+
+    ElementA *ptr_A0 = static_cast<ElementA *>(params.ref_A0.data()); 
+    ElementB *ptr_B0 = static_cast<ElementB *>(params.ref_B0.data());
+    ElementB *ptr_B1 = static_cast<ElementB *>(params.ref_B1.data());
+
+    //
+    // Fetch pointers based on mode.
+    //
+    if (params.mode == DualGemmMode::kGemm) {
+      if (threadblock_tile_offset.k() + 1 < params.grid_tiled_shape.k()) {
+        problem_size_k = (threadblock_tile_offset.k() + 1) * params.gemm_k_size; 
+      }
+
+      offset_k = threadblock_tile_offset.k() * params.gemm_k_size;
+    }
+    else if (params.mode == DualGemmMode::kBatched) {
+      ptr_A0 += threadblock_tile_offset.k() * params.batch_stride_A;
+      ptr_B0 += threadblock_tile_offset.k() * params.batch_stride_B0;
+      ptr_B1 += threadblock_tile_offset.k() * params.batch_stride_B1;
+    }
+
     // Compute initial location in logical coordinates
     cutlass::MatrixCoord tb_offset_A0{
       threadblock_tile_offset.m() * DualMma::Shape::kM,
-      threadblock_tile_offset.k() * params.gemm_k_size,
+      offset_k,
     };
 
     cutlass::MatrixCoord tb_offset_B0{
-      threadblock_tile_offset.k() * params.gemm_k_size,
+      offset_k,
       threadblock_tile_offset.n() * DualMma::Shape::kN
     };
 
     cutlass::MatrixCoord tb_offset_B1{
-      threadblock_tile_offset.k() * params.gemm_k_size,
+      offset_k,
       threadblock_tile_offset.n() * DualMma::Shape::kN
     };
 
-    // Problem size is a function of threadblock index in the K dimension
-    int problem_size_k =
-      (params.problem_size.k() < (threadblock_tile_offset.k() + 1) * params.gemm_k_size) ?
-       params.problem_size.k() :
-       (threadblock_tile_offset.k() + 1) * params.gemm_k_size;
-
-    // Compute threadblock-scoped matrix multiply-add
-    int gemm_k_iterations = (problem_size_k - tb_offset_A0.column() + DualMma::Shape::kK - 1) / DualMma::Shape::kK;
-
     // Compute position within threadblock
     int thread_idx = threadIdx.x;
 
     // Construct iterators to A and B operands
     typename DualMma::IteratorA iterator_A0(
       params.params_A0,
-      params.ref_A0.data(),
+      ptr_A0,
       {params.problem_size.m(), problem_size_k},
       thread_idx,
       tb_offset_A0);
 
-    typename DualMma::IteratorB iterator_B0(
+    typename DualMma::IteratorB0 iterator_B0(
       params.params_B0,
-      params.ref_B0.data(),
+      ptr_B0,
       {problem_size_k, params.problem_size.n()},
       thread_idx,
       tb_offset_B0);
 
-    typename DualMma::IteratorB iterator_B1(
+    typename DualMma::IteratorB1 iterator_B1(
       params.params_B1,
-      params.ref_B1.data(),
+      ptr_B1,
       {problem_size_k, params.problem_size.n()},
       thread_idx,
       tb_offset_B1);
 
 
     // Broadcast the warp_id computed by lane 0 to ensure dependent code
     // is compiled as warp-uniform.
@@ -336,14 +374,17 @@
 
     // Construct thread-scoped matrix multiply
     typename DualMma::FragmentC accum0;
     typename DualMma::FragmentC accum1;
     accum0.clear();
     accum1.clear();
 
+    // Compute threadblock-scoped matrix multiply-add
+    int gemm_k_iterations = (problem_size_k - offset_k + DualMma::Shape::kK - 1) / DualMma::Shape::kK;
+
     DualMma mma(shared_storage.main_loop, thread_idx, warp_idx, lane_idx);
     if (!kSplitKSerial || gemm_k_iterations > 0) {
       // Compute threadblock-scoped matrix multiply-add
       mma(gemm_k_iterations,
         accum0, accum1,
         iterator_A0, iterator_B0, iterator_B1,
         accum0, accum1);
@@ -368,62 +409,77 @@
     MatrixCoord threadblock_offset(
       threadblock_tile_offset.m() * DualMma::Shape::kM,
       threadblock_tile_offset.n() * DualMma::Shape::kN
     );
 
     int block_idx = threadblock_tile_offset.m() + threadblock_tile_offset.n() * params.grid_tiled_shape.m();
 
+    ElementC *ptr_C0 = static_cast<ElementC *>(params.ref_C0.data()); 
+    ElementC *ptr_C1 = static_cast<ElementC *>(params.ref_C1.data()); 
+    ElementC *ptr_D0 = static_cast<ElementC *>(params.ref_D0.data()); 
+    ElementC *ptr_D1 = static_cast<ElementC *>(params.ref_D1.data()); 
+    ElementC *ptr_D2 = static_cast<ElementC *>(params.ref_D2.data()); 
+
     // Construct the semaphore.
     Semaphore semaphore(params.semaphore + block_idx, thread_idx);
 
-    // If performing a reduction via split-K, fetch the initial synchronization
-    if (kSplitKSerial && params.grid_tiled_shape.k() > 1) {
-      
-      // Fetch the synchronization lock initially but do not block.
-      semaphore.fetch();
-
-      // Indicate which position in a serial reduction the output operator is currently updating
-      output_op_0.set_k_partition(threadblock_tile_offset.k(), params.grid_tiled_shape.k());
-      output_op_1.set_k_partition(threadblock_tile_offset.k(), params.grid_tiled_shape.k());
+    if (params.mode == DualGemmMode::kGemm) {
+      // If performing a reduction via split-K, fetch the initial synchronization
+      if (kSplitKSerial && params.grid_tiled_shape.k() > 1) {
+        
+        // Fetch the synchronization lock initially but do not block.
+        semaphore.fetch();
+
+        // Indicate which position in a serial reduction the output operator is currently updating
+        output_op_0.set_k_partition(threadblock_tile_offset.k(), params.grid_tiled_shape.k());
+        output_op_1.set_k_partition(threadblock_tile_offset.k(), params.grid_tiled_shape.k());
+      }
+    }
+    else if (params.mode == DualGemmMode::kBatched) {
+      ptr_C0 += threadblock_tile_offset.k() * params.batch_stride_C;
+      ptr_C1 += threadblock_tile_offset.k() * params.batch_stride_C;
+      ptr_D0 += threadblock_tile_offset.k() * params.batch_stride_D;
+      ptr_D1 += threadblock_tile_offset.k() * params.batch_stride_D;
+      ptr_D2 += threadblock_tile_offset.k() * params.batch_stride_D;
     }
 
     // Tile iterator loading from source tensor.
     typename Epilogue0::OutputTileIterator iterator_C0(
       params.params_C0,
-      params.ref_C0.data(),
+      ptr_C0,
       params.problem_size.mn(),
       thread_idx,
       threadblock_offset
     );
     typename Epilogue1::OutputTileIterator iterator_C1(
       params.params_C1,
-      params.ref_C1.data(),
+      ptr_C1,
       params.problem_size.mn(),
       thread_idx,
       threadblock_offset
     );
 
     // Tile iterator writing to destination tensor.
     typename Epilogue0::OutputTileIterator iterator_D0(
       params.params_D0,
-      params.ref_D0.data(),
+      ptr_D0,
       params.problem_size.mn(),
       thread_idx,
       threadblock_offset
     );
     typename Epilogue1::OutputTileIterator iterator_D1(
       params.params_D1,
-      params.ref_D1.data(),
+      ptr_D1,
       params.problem_size.mn(),
       thread_idx,
       threadblock_offset
     );
     typename Epilogue1::OutputTileIterator iterator_D2(
       params.params_D2,
-      params.ref_D2.data(),
+      ptr_D2,
       params.problem_size.mn(),
       thread_idx,
       threadblock_offset
     );
 
     DualEpilogue epilogue(
       shared_storage.epilogue,
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/45_dual_gemm/test_run.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/45_dual_gemm/test_run.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/45_dual_gemm/thread/left_silu_and_mul.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/45_dual_gemm/thread/left_silu_and_mul.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/45_dual_gemm/threadblock/dual_epilogue.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/45_dual_gemm/threadblock/dual_epilogue.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/45_dual_gemm/threadblock/dual_mma_base.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_planar_complex_base.h`

 * *Files 11% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -38,16 +38,14 @@
 #include "cutlass/arch/memory.h"
 #include "cutlass/array.h"
 #include "cutlass/cutlass.h"
 #include "cutlass/gemm/gemm.h"
 #include "cutlass/matrix_shape.h"
 #include "cutlass/numeric_types.h"
 
-#include "cutlass/gemm/threadblock/mma_base.h"
-
 ////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace gemm {
 namespace threadblock {
 
 ////////////////////////////////////////////////////////////////////////////////
@@ -59,15 +57,15 @@
     typename Shape_,
     /// Policy describing tuning details (concept: MmaPolicy)
     typename Policy_,
     /// Number of stages,
     int Stages,
     /// Used for partial specialization
     typename Enable = bool>
-class DualMmaBase {
+class MmaPlanarComplexBase {
  public:
   ///< Size of the Gemm problem - concept: gemm::GemmShape<>
   using Shape = Shape_;
 
   ///< Policy describing tuning details
   using Policy = Policy_;
 
@@ -96,21 +94,14 @@
 
   /// Tensor reference to the A operand
   using TensorRefA = TensorRef<typename Operator::ElementA, typename Operator::LayoutA>;
 
   /// Tensor reference to the B operand
   using TensorRefB = TensorRef<typename Operator::ElementB, typename Operator::LayoutB>;
 
-  static_assert(kWarpGemmIterations > 1,
-                "The pipelined structure requires at least two warp-level "
-                "GEMM operations.");
-
-  static_assert((kWarpGemmIterations % 2) == 0,
-                "Inner loop iteration must be an even number.");
-
   //
   // Nested structs
   //
 
   /// Shared storage object needed by threadblock-scoped GEMM
   class SharedStorage {
    public:
@@ -119,30 +110,35 @@
     //
 
     /// Shape of the A matrix operand in shared memory
     using ShapeA = MatrixShape<Shape::kM + Policy::SmemPaddingA::kRow,
                                Shape::kK * kStages +
                                    Policy::SmemPaddingA::kColumn>;
 
+    /// Stride to the imaginary part of the A operand
+    static int const kImaginaryStrideA = ShapeA::kCount;
+
     /// Shape of the B matrix operand in shared memory
     using ShapeB =
         MatrixShape<Shape::kK * kStages + Policy::SmemPaddingB::kRow,
                     Shape::kN + Policy::SmemPaddingB::kColumn>;
 
+    /// Stride to the imaginary part of the A operand
+    static int const kImaginaryStrideB = ShapeB::kCount;
+
    public:
     //
     // Data members
     //
 
     /// Buffer for A operand
-    AlignedBuffer<typename Operator::ElementA, ShapeA::kCount> operand_A;
+    AlignedBuffer<typename Operator::ElementA, ShapeA::kCount + kImaginaryStrideA> operand_A;
 
     /// Buffer for B operand
-    AlignedBuffer<typename Operator::ElementB, ShapeB::kCount> operand_B0;
-    AlignedBuffer<typename Operator::ElementB, ShapeB::kCount> operand_B1;
+    AlignedBuffer<typename Operator::ElementB, ShapeB::kCount + kImaginaryStrideB> operand_B;
 
    public:
 
     //
     // Methods
     //
 
@@ -162,53 +158,47 @@
     CUTLASS_HOST_DEVICE
     TensorRefA operand_A_ref() {
       return TensorRefA{operand_A.data(), LayoutA()};
     }
 
     /// Returns a TensorRef to the B operand
     CUTLASS_HOST_DEVICE
-    TensorRefB operand_B0_ref() {
-      return TensorRefB{operand_B0.data(), LayoutB()};
-    }
-    CUTLASS_HOST_DEVICE
-    TensorRefB operand_B1_ref() {
-      return TensorRefB{operand_B1.data(), LayoutB()};
+    TensorRefB operand_B_ref() {
+      return TensorRefB{operand_B.data(), LayoutB()};
     }
   };
 
  protected:
 
   //
   // Data members
   //
 
   /// Iterator to load a warp-scoped tile of A operand from shared memory
   typename Operator::IteratorA warp_tile_iterator_A_;
 
   /// Iterator to load a warp-scoped tile of B operand from shared memory
-  typename Operator::IteratorB warp_tile_iterator_B0_;
-  typename Operator::IteratorB warp_tile_iterator_B1_;
+  typename Operator::IteratorB warp_tile_iterator_B_;
 
 public:
 
   /// Construct from tensor references
   CUTLASS_DEVICE
-  DualMmaBase(
+  MmaPlanarComplexBase(
       ///< Shared storage needed for internal use by threadblock-scoped GEMM
       SharedStorage &shared_storage,
       ///< ID within the threadblock
       int thread_idx,
       ///< ID of warp
       int warp_idx,
       ///< ID of each thread within a warp
       int lane_idx
     ):
       warp_tile_iterator_A_(shared_storage.operand_A_ref(), lane_idx),
-      warp_tile_iterator_B0_(shared_storage.operand_B0_ref(), lane_idx),
-      warp_tile_iterator_B1_(shared_storage.operand_B1_ref(), lane_idx) {
+      warp_tile_iterator_B_(shared_storage.operand_B_ref(), lane_idx) {
 
   }
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 }  // namespace threadblock
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/45_dual_gemm/threadblock/dual_mma_multistage.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/45_dual_gemm/threadblock/dual_mma_multistage.h`

 * *Files 3% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -63,88 +63,103 @@
     //  MaskedTileIterator)
     typename IteratorA_,
     /// Iterates over tiles of A operand in shared memory
     /// (concept: WriteableTileIterator | RandomAccessTileIterator)
     typename SmemIteratorA_,
     /// Cache operation for operand A
     cutlass::arch::CacheOperation::Kind CacheOpA,
-    /// Iterates over tiles of B operand in global memory
+    /// Iterates over tiles of B0 operand in global memory
     //  (concept: ReadableTileIterator | ForwardTileIterator |
     //  MaskedTileIterator)
-    typename IteratorB_,
-    /// Iterates over tiles of B operand in shared memory
+    typename IteratorB0_,
+    /// Iterates over tiles of B0 operand in shared memory
     /// (concept: WriteableTileIterator | RandomAccessTileIterator)
-    typename SmemIteratorB_,
+    typename SmemIteratorB0_,
     /// Cache operation for operand B
     cutlass::arch::CacheOperation::Kind CacheOpB,
+    /// Iterates over tiles of B1 operand in global memory
+    //  (concept: ReadableTileIterator | ForwardTileIterator |
+    //  MaskedTileIterator)
+    typename IteratorB1_,
+    /// Iterates over tiles of B1 operand in shared memory
+    /// (concept: WriteableTileIterator | RandomAccessTileIterator)
+    typename SmemIteratorB1_,
     /// Data type of accumulator matrix
     typename ElementC_,
     /// Data type of accumulator matrix
     typename LayoutC_,
     /// Policy describing tuning details (concept: MmaPolicy)
-    typename Policy_,
+    typename Policy0_,
+    /// B1-specific version of the policy (concept: MmaPolicy)
+    typename Policy1_,
     /// Number of stages,
     int Stages,
     /// Use zfill or predicate for out-of-bound cp.async
     SharedMemoryClearOption SharedMemoryClear = SharedMemoryClearOption::kNone,
     /// Used for partial specialization
     typename Enable = bool>
 class DualMmaMultistage : 
-  public DualMmaBase<Shape_, Policy_, Stages> {
+  public DualMmaBase<Shape_, Policy0_, Policy1_, Stages> {
 public:
   ///< Base class
-  using Base = DualMmaBase<Shape_, Policy_, Stages>;
+  using Base = DualMmaBase<Shape_, Policy0_, Policy1_, Stages>;
   ///< Size of the Gemm problem - concept: gemm::GemmShape<>
   using Shape = Shape_;
   ///< Iterates over tiles of A operand in global memory
   using IteratorA = IteratorA_;
-  ///< Iterates over tiles of B operand in global memory
-  using IteratorB = IteratorB_;
+  ///< Iterates over tiles of B0 operand in global memory
+  using IteratorB0 = IteratorB0_;
+  ///< Iterates over tiles of B1 operand in global memory
+  using IteratorB1 = IteratorB1_;
   ///< Data type of accumulator matrix
   using ElementC = ElementC_;
   ///< Layout of accumulator matrix
   using LayoutC = LayoutC_;
   ///< Policy describing tuning details
-  using Policy = Policy_;
+  using Policy0 = Policy0_;
+  using Policy1 = Policy1_;
 
   using SmemIteratorA = SmemIteratorA_;
-  using SmemIteratorB = SmemIteratorB_;
+  using SmemIteratorB0 = SmemIteratorB0_;
+  using SmemIteratorB1 = SmemIteratorB1_;
 
   static cutlass::arch::CacheOperation::Kind const kCacheOpA = CacheOpA;
   static cutlass::arch::CacheOperation::Kind const kCacheOpB = CacheOpB;
 
   //
   // Dependent types
   //
 
   /// Fragment of accumulator tile
-  using FragmentC = typename Policy::Operator::FragmentC;
+  using FragmentC = typename Policy0::Operator::FragmentC;
 
   /// Warp-level Mma
-  using Operator = typename Policy::Operator;
+  using Operator0 = typename Policy0::Operator;
+  using Operator1 = typename Policy1::Operator;
 
   /// Minimum architecture is Sm80 to support cp.async
   using ArchTag = arch::Sm80;
   
   /// Complex transform on A operand
-  static ComplexTransform const kTransformA = Operator::kTransformA;
+  static ComplexTransform const kTransformA = Operator0::kTransformA;
 
   /// Complex transform on B operand
-  static ComplexTransform const kTransformB = Operator::kTransformB;
+  static ComplexTransform const kTransformB0 = Operator0::kTransformB;
+  static ComplexTransform const kTransformB1 = Operator1::kTransformB;
 
   /// Internal structure exposed for introspection.
   struct Detail {
 
     /// Number of cp.async instructions to load one stage of operand A
     static int const AsyncCopyIterationsPerStageA =
         IteratorA::ThreadMap::Iterations::kCount;
 
     /// Number of cp.async instructions to load one stage of operand B
     static int const AsyncCopyIterationsPerStageB =
-        IteratorB::ThreadMap::Iterations::kCount;
+        IteratorB0::ThreadMap::Iterations::kCount;
 
     /// Number of stages
     static int const kStages = Stages;
 
     /// Number of cp.async instructions to load on group of operand A
     static int const kAccessesPerGroupA =
         (AsyncCopyIterationsPerStageA + Base::kWarpGemmIterations - 1) / Base::kWarpGemmIterations;
@@ -152,31 +167,33 @@
     /// Number of cp.async instructions to load on group of operand B
     static int const kAccessesPerGroupB =
         (AsyncCopyIterationsPerStageB + Base::kWarpGemmIterations - 1) / Base::kWarpGemmIterations;
   };
 
  private:
 
-  using WarpLoadedFragmentA = typename Operator::FragmentA;
-  using WarpLoadedFragmentB = typename Operator::FragmentB;
-  using WarpTransformedFragmentA = typename Operator::TransformedFragmentA;
-  using WarpTransformedFragmentB = typename Operator::TransformedFragmentB;
+  using WarpLoadedFragmentA = typename Operator0::FragmentA;
+  using WarpLoadedFragmentB0 = typename Operator0::FragmentB;
+  using WarpLoadedFragmentB1 = typename Operator1::FragmentB;
+  using WarpTransformedFragmentA = typename Operator0::TransformedFragmentA;
+  using WarpTransformedFragmentB0 = typename Operator0::TransformedFragmentB;
+  using WarpTransformedFragmentB1 = typename Operator1::TransformedFragmentB;
 
  private:
 
   //
   // Data members
   //
 
   /// Iterator to write threadblock-scoped tile of A operand to shared memory
   SmemIteratorA smem_iterator_A_;
 
   /// Iterator to write threadblock-scoped tile of B operand to shared memory
-  SmemIteratorB smem_iterator_B0_;
-  SmemIteratorB smem_iterator_B1_;
+  SmemIteratorB0 smem_iterator_B0_;
+  SmemIteratorB1 smem_iterator_B1_;
 
 public:
 
   /// Construct from tensor references
   CUTLASS_DEVICE
   DualMmaMultistage(
       ///< Shared storage needed for internal use by threadblock-scoped GEMM
@@ -211,15 +228,15 @@
     this->warp_tile_iterator_B0_.add_tile_offset(
         {Base::kWarpGemmIterations * warp_idx_k, warp_idx_n});
     this->warp_tile_iterator_B1_.add_tile_offset(
         {Base::kWarpGemmIterations * warp_idx_k, warp_idx_n});
   }
 
   CUTLASS_DEVICE
-  void copy_tiles_and_advance(IteratorA &iterator_A, IteratorB &iterator_B0, IteratorB &iterator_B1,
+  void copy_tiles_and_advance(IteratorA &iterator_A, IteratorB0 &iterator_B0, IteratorB1 &iterator_B1,
                               int group_start_A = 0, int group_start_B = 0) {
     iterator_A.set_iteration_index(group_start_A *
                                    IteratorA::kAccessesPerVector);
     this->smem_iterator_A_.set_iteration_index(group_start_A);
 
     // Async Copy for operand A
     CUTLASS_PRAGMA_UNROLL
@@ -249,34 +266,34 @@
         }
 
         ++this->smem_iterator_A_;
       }
     }
 
     iterator_B0.set_iteration_index(group_start_B *
-                                   IteratorB::kAccessesPerVector);
+                                   IteratorB0::kAccessesPerVector);
     iterator_B1.set_iteration_index(group_start_B *
-                                   IteratorB::kAccessesPerVector);
+                                   IteratorB1::kAccessesPerVector);
     this->smem_iterator_B0_.set_iteration_index(group_start_B);
     this->smem_iterator_B1_.set_iteration_index(group_start_B);
 
     // Async Copy for operand B0
     CUTLASS_PRAGMA_UNROLL
     for (int j = 0; j < Detail::kAccessesPerGroupB; ++j) {
       if (group_start_B + j < Detail::AsyncCopyIterationsPerStageB) {
-        typename IteratorB::AccessType *dst_ptr =
-            reinterpret_cast<typename IteratorB::AccessType *>(
+        typename IteratorB0::AccessType *dst_ptr =
+            reinterpret_cast<typename IteratorB0::AccessType *>(
                 this->smem_iterator_B0_.get());
 
-        int const kSrcBytes = sizeof_bits<typename IteratorB::Element>::value *
-                              IteratorB::ThreadMap::kElementsPerAccess /
-                              IteratorB::kAccessesPerVector / 8;
+        int const kSrcBytes = sizeof_bits<typename IteratorB0::Element>::value *
+                              IteratorB0::ThreadMap::kElementsPerAccess /
+                              IteratorB0::kAccessesPerVector / 8;
 
         CUTLASS_PRAGMA_UNROLL
-        for (int v = 0; v < IteratorB::kAccessesPerVector; ++v) {
+        for (int v = 0; v < IteratorB0::kAccessesPerVector; ++v) {
           auto gmem_ptr = iterator_B0.get();
 
           if (SharedMemoryClear == SharedMemoryClearOption::kZfill) {
             cutlass::arch::cp_async_zfill<kSrcBytes, kCacheOpB>(
                 dst_ptr + v, gmem_ptr, iterator_B0.valid());
           } else {
             cutlass::arch::cp_async<kSrcBytes, kCacheOpB>(
@@ -288,24 +305,24 @@
         ++this->smem_iterator_B0_;
       }
     }
     // Async Copy for operand B1
     CUTLASS_PRAGMA_UNROLL
     for (int j = 0; j < Detail::kAccessesPerGroupB; ++j) {
       if (group_start_B + j < Detail::AsyncCopyIterationsPerStageB) {
-        typename IteratorB::AccessType *dst_ptr =
-            reinterpret_cast<typename IteratorB::AccessType *>(
+        typename IteratorB1::AccessType *dst_ptr =
+            reinterpret_cast<typename IteratorB1::AccessType *>(
                 this->smem_iterator_B1_.get());
 
-        int const kSrcBytes = sizeof_bits<typename IteratorB::Element>::value *
-                              IteratorB::ThreadMap::kElementsPerAccess /
-                              IteratorB::kAccessesPerVector / 8;
+        int const kSrcBytes = sizeof_bits<typename IteratorB1::Element>::value *
+                              IteratorB1::ThreadMap::kElementsPerAccess /
+                              IteratorB1::kAccessesPerVector / 8;
 
         CUTLASS_PRAGMA_UNROLL
-        for (int v = 0; v < IteratorB::kAccessesPerVector; ++v) {
+        for (int v = 0; v < IteratorB1::kAccessesPerVector; ++v) {
           auto gmem_ptr = iterator_B1.get();
 
           if (SharedMemoryClear == SharedMemoryClearOption::kZfill) {
             cutlass::arch::cp_async_zfill<kSrcBytes, kCacheOpB>(
                 dst_ptr + v, gmem_ptr, iterator_B1.valid());
           } else {
             cutlass::arch::cp_async<kSrcBytes, kCacheOpB>(
@@ -326,16 +343,16 @@
       int gemm_k_iterations,
       ///< destination accumulator tile
       FragmentC &accum0,
       FragmentC &accum1,
       ///< iterator over A operand in global memory
       IteratorA iterator_A,
       ///< iterator over B operand in global memory
-      IteratorB iterator_B0,
-      IteratorB iterator_B1,
+      IteratorB0 iterator_B0,
+      IteratorB1 iterator_B1,
       ///< initial value of accumulator
       FragmentC const &src_accum0,
       FragmentC const &src_accum1
     ) {
 
     //
     // Prologue
@@ -382,46 +399,46 @@
       iterator_B1.set_iteration_index(0);
       this->smem_iterator_B0_.set_iteration_index(0);
       this->smem_iterator_B1_.set_iteration_index(0);
 
       // Async Copy for operand B0
       CUTLASS_PRAGMA_UNROLL
       for (int j = 0; j < Detail::AsyncCopyIterationsPerStageB; ++j) {
-        typename IteratorB::AccessType *dst_ptr =
-            reinterpret_cast<typename IteratorB::AccessType *>(
+        typename IteratorB0::AccessType *dst_ptr =
+            reinterpret_cast<typename IteratorB0::AccessType *>(
                 this->smem_iterator_B0_.get());
 
         CUTLASS_PRAGMA_UNROLL
-        for (int v = 0; v < IteratorB::kAccessesPerVector; ++v) {
+        for (int v = 0; v < IteratorB0::kAccessesPerVector; ++v) {
           int const kSrcBytes =
-              sizeof_bits<typename IteratorB::Element>::value *
-              IteratorB::ThreadMap::kElementsPerAccess /
-              IteratorB::kAccessesPerVector / 8;
+              sizeof_bits<typename IteratorB0::Element>::value *
+              IteratorB0::ThreadMap::kElementsPerAccess /
+              IteratorB0::kAccessesPerVector / 8;
 
           cutlass::arch::cp_async_zfill<kSrcBytes, kCacheOpB>(
               dst_ptr + v, iterator_B0.get(), iterator_B0.valid());
 
           ++iterator_B0;
         }
 
         ++this->smem_iterator_B0_;
       }
       // Async Copy for operand B1
       CUTLASS_PRAGMA_UNROLL
       for (int j = 0; j < Detail::AsyncCopyIterationsPerStageB; ++j) {
-        typename IteratorB::AccessType *dst_ptr =
-            reinterpret_cast<typename IteratorB::AccessType *>(
+        typename IteratorB1::AccessType *dst_ptr =
+            reinterpret_cast<typename IteratorB1::AccessType *>(
                 this->smem_iterator_B1_.get());
 
         CUTLASS_PRAGMA_UNROLL
-        for (int v = 0; v < IteratorB::kAccessesPerVector; ++v) {
+        for (int v = 0; v < IteratorB1::kAccessesPerVector; ++v) {
           int const kSrcBytes =
-              sizeof_bits<typename IteratorB::Element>::value *
-              IteratorB::ThreadMap::kElementsPerAccess /
-              IteratorB::kAccessesPerVector / 8;
+              sizeof_bits<typename IteratorB1::Element>::value *
+              IteratorB1::ThreadMap::kElementsPerAccess /
+              IteratorB1::kAccessesPerVector / 8;
 
           cutlass::arch::cp_async_zfill<kSrcBytes, kCacheOpB>(
               dst_ptr + v, iterator_B1.get(), iterator_B1.valid());
 
           ++iterator_B1;
         }
 
@@ -469,43 +486,43 @@
                 last_smem_iterator_A.get());
 
         *dst_ptr = zero_A;
 
         ++last_smem_iterator_A;
       }
 
-      typename IteratorB::AccessType zero_B;
+      typename IteratorB0::AccessType zero_B;
       zero_B.clear();
 
       /// Iterator to write threadblock-scoped tile of B0 operand to shared memory
-      SmemIteratorB last_smem_iterator_B0(this->smem_iterator_B0_);
+      SmemIteratorB0 last_smem_iterator_B0(this->smem_iterator_B0_);
       last_smem_iterator_B0.set_iteration_index(0);
 
-      // Async Copy for operand B
+      // Async Copy for operand B0
       CUTLASS_PRAGMA_UNROLL
       for (int j = 0; j < Detail::AsyncCopyIterationsPerStageB; ++j) {
-
-        typename IteratorB::AccessType *dst_ptr =
-            reinterpret_cast<typename IteratorB::AccessType *>(
+        typename IteratorB0::AccessType *dst_ptr =
+            reinterpret_cast<typename IteratorB0::AccessType *>(
                 last_smem_iterator_B0.get());
 
         *dst_ptr = zero_B;
 
         ++last_smem_iterator_B0;
       }
+
       /// Iterator to write threadblock-scoped tile of B1 operand to shared memory
-      SmemIteratorB last_smem_iterator_B1(this->smem_iterator_B1_);
+      SmemIteratorB1 last_smem_iterator_B1(this->smem_iterator_B1_);
       last_smem_iterator_B1.set_iteration_index(0);
 
-      // Async Copy for operand B
+      // Async Copy for operand B1
       CUTLASS_PRAGMA_UNROLL
       for (int j = 0; j < Detail::AsyncCopyIterationsPerStageB; ++j) {
 
-        typename IteratorB::AccessType *dst_ptr =
-            reinterpret_cast<typename IteratorB::AccessType *>(
+        typename IteratorB1::AccessType *dst_ptr =
+            reinterpret_cast<typename IteratorB1::AccessType *>(
                 last_smem_iterator_B1.get());
 
         *dst_ptr = zero_B;
 
         ++last_smem_iterator_B1;
       }
     }
@@ -513,21 +530,22 @@
     // Waits until stages up to the previous (kStages-2)th stage have committed.
     cutlass::arch::cp_async_wait<Base::kStages - 2>();
     __syncthreads();
 
     // Pair of fragments used to overlap shared memory loads and math
     // instructions
     WarpLoadedFragmentA warp_loaded_frag_A[2];
-    WarpLoadedFragmentB warp_loaded_frag_B0[2];
-    WarpLoadedFragmentB warp_loaded_frag_B1[2];
+    WarpLoadedFragmentB0 warp_loaded_frag_B0[2];
+    WarpLoadedFragmentB1 warp_loaded_frag_B1[2];
     WarpTransformedFragmentA warp_transformed_frag_A[2];
-    WarpTransformedFragmentB warp_transformed_frag_B0[2];
-    WarpTransformedFragmentB warp_transformed_frag_B1[2];
+    WarpTransformedFragmentB0 warp_transformed_frag_B0[2];
+    WarpTransformedFragmentB1 warp_transformed_frag_B1[2];
 
-    Operator warp_mma;
+    Operator0 warp_mma0;
+    Operator1 warp_mma1;
 
     this->warp_tile_iterator_A_.set_kgroup_index(0);
     this->warp_tile_iterator_B0_.set_kgroup_index(0);
     this->warp_tile_iterator_B1_.set_kgroup_index(0);
 
     this->warp_tile_iterator_A_.load(warp_loaded_frag_A[0]);
     this->warp_tile_iterator_B0_.load(warp_loaded_frag_B0[0]);
@@ -540,29 +558,29 @@
     iterator_A.clear_mask(gemm_k_iterations == 0);
     iterator_B0.clear_mask(gemm_k_iterations == 0);
     iterator_B1.clear_mask(gemm_k_iterations == 0);
 
     int smem_write_stage_idx = Base::kStages - 1;
     int smem_read_stage_idx = 0;
 
-    warp_mma.transform(warp_transformed_frag_A[0], warp_transformed_frag_B0[0],
-                       warp_loaded_frag_A[0], warp_loaded_frag_B0[0]);
-    warp_mma.transform(warp_transformed_frag_A[0], warp_transformed_frag_B1[0],
-                       warp_loaded_frag_A[0], warp_loaded_frag_B1[0]);
+    warp_mma0.transform(warp_transformed_frag_A[0], warp_transformed_frag_B0[0],
+                        warp_loaded_frag_A[0], warp_loaded_frag_B0[0]);
+    warp_mma1.transform(warp_transformed_frag_A[0], warp_transformed_frag_B1[0],
+                        warp_loaded_frag_A[0], warp_loaded_frag_B1[0]);
 
     // tf32x3 kernels use staging accumulation. warp_mma uses a temporary
     // accumulator and this temporary accumulator is added to the final
     // accumulator once in every mainloop iteration.
     plus<FragmentC> plus_accum;
 
     FragmentC tmp_accum0, tmp_accum1;
 
-    if (platform::is_same<typename Operator::MathOperator,
+    if (platform::is_same<typename Operator0::MathOperator,
                           arch::OpMultiplyAddFastF32>::value
-      || platform::is_same<typename Operator::MathOperator,
+      || platform::is_same<typename Operator0::MathOperator,
                            arch::OpMultiplyAddComplexFastF32>::value) {
 
       tmp_accum0.clear();
       tmp_accum1.clear();
     }
 
     //
@@ -593,56 +611,56 @@
         this->warp_tile_iterator_B1_.load(warp_loaded_frag_B1[(warp_mma_k + 1) % 2]);
 
         ++this->warp_tile_iterator_A_;
         ++this->warp_tile_iterator_B0_;
         ++this->warp_tile_iterator_B1_;
 
         if (warp_mma_k > 0) {
-          warp_mma.transform(warp_transformed_frag_A[warp_mma_k % 2],
-                             warp_transformed_frag_B0[warp_mma_k % 2],
-                             warp_loaded_frag_A[warp_mma_k % 2],
-                             warp_loaded_frag_B0[warp_mma_k % 2]);
-          warp_mma.transform(warp_transformed_frag_A[warp_mma_k % 2],
-                             warp_transformed_frag_B1[warp_mma_k % 2],
-                             warp_loaded_frag_A[warp_mma_k % 2],
-                             warp_loaded_frag_B1[warp_mma_k % 2]);
+          warp_mma0.transform(warp_transformed_frag_A[warp_mma_k % 2],
+                              warp_transformed_frag_B0[warp_mma_k % 2],
+                              warp_loaded_frag_A[warp_mma_k % 2],
+                              warp_loaded_frag_B0[warp_mma_k % 2]);
+          warp_mma1.transform(warp_transformed_frag_A[warp_mma_k % 2],
+                              warp_transformed_frag_B1[warp_mma_k % 2],
+                              warp_loaded_frag_A[warp_mma_k % 2],
+                              warp_loaded_frag_B1[warp_mma_k % 2]);
         }
 
-        if (platform::is_same<typename Operator::MathOperator,
+        if (platform::is_same<typename Operator0::MathOperator,
                               arch::OpMultiplyAddFastF32>::value
-          || platform::is_same<typename Operator::MathOperator,
+          || platform::is_same<typename Operator0::MathOperator,
                                arch::OpMultiplyAddComplexFastF32>::value) {
 
-          warp_mma(
+          warp_mma0(
             tmp_accum0,
             warp_transformed_frag_A[warp_mma_k % 2],
             warp_transformed_frag_B0[warp_mma_k % 2], 
             tmp_accum0
           );
-          warp_mma(
+          warp_mma1(
             tmp_accum1,
             warp_transformed_frag_A[warp_mma_k % 2],
             warp_transformed_frag_B1[warp_mma_k % 2], 
             tmp_accum1
           );
 
           if (warp_mma_k == 0) {
             accum0 = plus_accum(accum0, tmp_accum0);
             accum1 = plus_accum(accum1, tmp_accum1);
             tmp_accum0.clear();
             tmp_accum1.clear();
           }
         } else {
-          warp_mma(
+          warp_mma0(
             accum0,
             warp_transformed_frag_A[warp_mma_k % 2],
             warp_transformed_frag_B0[warp_mma_k % 2],
             accum0
           );
-          warp_mma(
+          warp_mma1(
             accum1,
             warp_transformed_frag_A[warp_mma_k % 2],
             warp_transformed_frag_B1[warp_mma_k % 2],
             accum1
           );
         }
 
@@ -692,22 +710,22 @@
             smem_write_stage_idx = 0;
           } else {
             ++smem_write_stage_idx;
           }
 
           if (smem_read_stage_idx == (Base::kStages - 1)) {
             this->warp_tile_iterator_A_.add_tile_offset(
-                {0, -Base::kStages * Policy::kPartitionsK *
+                {0, -Base::kStages * Policy0::kPartitionsK *
                         Base::kWarpGemmIterations});
             this->warp_tile_iterator_B0_.add_tile_offset(
-                {-Base::kStages * Policy::kPartitionsK *
+                {-Base::kStages * Policy0::kPartitionsK *
                      Base::kWarpGemmIterations,
                  0});
             this->warp_tile_iterator_B1_.add_tile_offset(
-                {-Base::kStages * Policy::kPartitionsK *
+                {-Base::kStages * Policy1::kPartitionsK *
                      Base::kWarpGemmIterations,
                  0});
             smem_read_stage_idx = 0;
           } else {
             ++smem_read_stage_idx;
           }
 
@@ -716,37 +734,37 @@
           iterator_B0.clear_mask(gemm_k_iterations == 0);
           iterator_B1.clear_mask(gemm_k_iterations == 0);
         }
 
         // Do any conversions feeding the first stage at the end of the loop so
         // we can start right away on mma instructions
         if (warp_mma_k + 1 == Base::kWarpGemmIterations) {
-          warp_mma.transform(warp_transformed_frag_A[(warp_mma_k + 1) % 2],
-                             warp_transformed_frag_B0[(warp_mma_k + 1) % 2],
-                             warp_loaded_frag_A[(warp_mma_k + 1) % 2],
-                             warp_loaded_frag_B0[(warp_mma_k + 1) % 2]);
-          warp_mma.transform(warp_transformed_frag_A[(warp_mma_k + 1) % 2],
-                             warp_transformed_frag_B1[(warp_mma_k + 1) % 2],
-                             warp_loaded_frag_A[(warp_mma_k + 1) % 2],
-                             warp_loaded_frag_B1[(warp_mma_k + 1) % 2]);
+          warp_mma0.transform(warp_transformed_frag_A[(warp_mma_k + 1) % 2],
+                              warp_transformed_frag_B0[(warp_mma_k + 1) % 2],
+                              warp_loaded_frag_A[(warp_mma_k + 1) % 2],
+                              warp_loaded_frag_B0[(warp_mma_k + 1) % 2]);
+          warp_mma1.transform(warp_transformed_frag_A[(warp_mma_k + 1) % 2],
+                              warp_transformed_frag_B1[(warp_mma_k + 1) % 2],
+                              warp_loaded_frag_A[(warp_mma_k + 1) % 2],
+                              warp_loaded_frag_B1[(warp_mma_k + 1) % 2]);
         }
       }
 
     }
 
-    if (platform::is_same<typename Operator::MathOperator,
+    if (platform::is_same<typename Operator0::MathOperator,
                           arch::OpMultiplyAddFastF32>::value
-      || platform::is_same<typename Operator::MathOperator,
+      || platform::is_same<typename Operator0::MathOperator,
                            arch::OpMultiplyAddComplexFastF32>::value) {
       accum0 = plus_accum(accum0, tmp_accum0); 
       accum1 = plus_accum(accum1, tmp_accum1); 
     }
  
     if (SharedMemoryClear == SharedMemoryClearOption::kZfill) {
-      // commit and drain all pending and predicated LDGSTS pnz from the GEMM mainloop
+      // commit and drain all pending and predicated cp.async pnz from the GEMM mainloop
       cutlass::arch::cp_async_fence();
       cutlass::arch::cp_async_wait<0>();
       __syncthreads();
     }
 
   }
 };
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/examples/46_depthwise_simt_conv2dfprop/depthwise_simt_conv2dfprop.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/46_depthwise_simt_conv2dfprop/depthwise_simt_conv2dfprop.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/aligned_buffer.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/aligned_buffer.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/arch.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/arch.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/cache_operation.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/cache_operation.h`

 * *Files 9% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/memory.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/memory.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/memory_sm80.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/memory_sm80.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -50,51 +50,51 @@
 namespace cutlass {
 namespace arch {
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Initiates an asynchronous copy from global memory to shared memory.
 ///
-/// LDGSTS
+/// cp.async
 ///
 template <
     /// Size of the access in bytes
     int SizeInBytes,
     /// Cache operation
     CacheOperation::Kind cache_op = CacheOperation::Always>
 struct cp_async;
 
 /// Initiates an asynchronous copy from global memory to shared memory. Rather than predicate
 /// the entire transfer, zeros are written to SMEM if the guard predicate is false.
 ///
-/// LDGSTS
+/// cp.async
 ///
 template <
     /// Size of the access in bytes
     int SizeInBytes,
     /// Cache operation
     CacheOperation::Kind cache_op = CacheOperation::Always>
 struct cp_async_zfill;
 
 /// Initiates an asynchronous copy from global memory to shared memory. Rather than predicate
 /// the entire transfer, nans (0x7eff) are written to SMEM if the guard predicate is false.
 ///
-/// LDGSTS
+/// cp.async
 ///
 template <
     /// Size of the access in bytes
     int SizeInBytes,
     /// Cache operation
     CacheOperation::Kind cache_op = CacheOperation::Always>
 struct cp_async_nan;
 
 /// Either 0 or 1 are written to SMEM based on input element type
 /// Used for diagonal elements of triangular matrix of BLAS3 functions
 ///
-/// STS
+/// st.shared
 ///
 template <
    /// Type of Element
    typename Element,
    /// If the data is for a Hermitian matrix diagonal
    bool IsHermitianData = false>
 struct cp_async_diag;
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/mma.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/mma.h`

 * *Files 3% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -45,69 +45,69 @@
 
 namespace cutlass {
 namespace arch {
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Tag indicating the operation implied by MMA.
-struct OpMultiplyAdd;
+struct OpMultiplyAdd {};
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Tag indicating the result is saturated to MAX_FLOAT|MIN_FLOAT or MAX_INT|MIN_INT
-struct OpMultiplyAddSaturate;
+struct OpMultiplyAddSaturate {};
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Tag indicating the input is converted to a narrower type (BF16)
-struct OpMultiplyAddFastBF16;
+struct OpMultiplyAddFastBF16 {};
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Tag indicating the input is converted to a narrower type (F16)
-struct OpMultiplyAddFastF16;
+struct OpMultiplyAddFastF16 {};
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Tag indicating the input is converted to 2 (big and small) TF32 components
 //  Perform 3xTF32 or 4xTF32 for every F32 output element
-struct OpMultiplyAddFastF32;
+struct OpMultiplyAddFastF32 {};
 
 /// Tag indicating the input is converted to 2 (big and small) TF32 components
 //  Perform 3xTF32 or 4xTF32 for every complex<F32> output element
-struct OpMultiplyAddComplexFastF32;
+struct OpMultiplyAddComplexFastF32 {};
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Tag indicating the complex multiply-add operation
-struct OpMultiplyAddComplex;
+struct OpMultiplyAddComplex {};
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Tag indicating the gaussian complex multiply-add operation
-struct OpMultiplyAddGaussianComplex;
+struct OpMultiplyAddGaussianComplex {};
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Tag indicating the inner product is defined by (XOR, POPC)
-struct OpXorPopc;
+struct OpXorPopc {};
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Tag classifying math operators as thread-level operations.
-struct OpClassSimt;
+struct OpClassSimt {};
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-/// Tag classifing operators as Tensor Core operations.
-struct OpClassTensorOp;
+/// Tag classifying operators as Tensor Core operations.
+struct OpClassTensorOp {};
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
-/// Tag classifing operators as WMMA Tensor Core operations
-struct OpClassWmmaTensorOp;
+/// Tag classifying operators as WMMA Tensor Core operations
+struct OpClassWmmaTensorOp {};
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Matrix multiply-add operation
 template <
   /// Size of the matrix product (concept: GemmShape)
   typename Shape_,
@@ -220,9 +220,8 @@
 #include "cutlass/arch/mma_sm60.h"
 #include "cutlass/arch/mma_sm61.h"
 #include "cutlass/arch/mma_sm70.h"
 #include "cutlass/arch/mma_sm75.h"
 #include "cutlass/arch/mma_sm80.h"
 #include "cutlass/arch/mma_sparse_sm80.h"
 #include "cutlass/arch/mma_sm90.h"
-
 /////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/mma_sm50.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/mma_sm50.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/mma_sm60.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/mma_sm60.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/mma_sm61.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/mma_sm61.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/mma_sm70.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/mma_sm70.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/mma_sm75.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/mma_sm75.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -1061,15 +1061,15 @@
 
   unsigned const & A = reinterpret_cast<unsigned const &>(a);
   unsigned const & B = reinterpret_cast<unsigned const &>(b);
 
   int const *C = reinterpret_cast<int const *>(&c);
   int *D = reinterpret_cast<int *>(&d);
 
-  asm volatile("_mma.m8n8k32.row.col.u4.s4.sat {%0,%1}, %2, %3, {%4,%5};\n"
+  asm volatile("mma.sync.aligned.m8n8k32.row.col.satfinite.s32.u4.s4.s32 {%0,%1}, {%2}, {%3}, {%4,%5};\n"
       : "=r"(D[0]), "=r"(D[1])
       : "r"(A), "r"(B), "r"(C[0]), "r"(C[1]));
 
 #else
     CUTLASS_UNUSED(a);
     CUTLASS_UNUSED(b);
     CUTLASS_UNUSED(c);
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/mma_sm80.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/mma_sm80.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -2168,15 +2168,15 @@
 #else
     
     CUTLASS_UNUSED(a);
     CUTLASS_UNUSED(b);
     CUTLASS_UNUSED(c);
     CUTLASS_UNUSED(d);
     assert(0);
-    
+
 #endif // defined(CUTLASS_ARCH_MMA_SM80_ENABLED)
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////
 
 } // namespace arch
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/mma_sm90.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/layout/matrix.h`

 * *Files 25% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -24,108 +24,64 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
-/*! \file
-    \brief Matrix multiply
+/* \file
+   \brief Bind Matrix layouts to python
 */
-
 #pragma once
+#include <pybind11/pybind11.h>
+#include <pybind11/stl_bind.h>
 
-#if defined(__CUDACC_RTC__)
-#include <cuda/std/cassert>
-#else
-#include <assert.h>
-#endif
-
-#include "mma.h"
 #include "cutlass/layout/matrix.h"
-#include "cutlass/numeric_types.h"
-
-////////////////////////////////////////////////////////////////////////////////
-
-#if ((__CUDACC_VER_MAJOR__ > 11) || (__CUDACC_VER_MAJOR__ == 11 && __CUDACC_VER_MINOR__ >= 8))
-#define CUTLASS_ARCH_MMA_SM90_SUPPORTED 1
-#if (defined(__CUDA_ARCH__) && (__CUDA_ARCH__ >= 900))
-#define CUTLASS_ARCH_MMA_SM90_ENABLED
-#endif
-#endif
-
-////////////////////////////////////////////////////////////////////////////////
-
-namespace cutlass {
-namespace arch {
-
-////////////////////////////////////////////////////////////////////////////////
-/// Matrix Multiply-Add 16x8x4 fp64
-////////////////////////////////////////////////////////////////////////////////
-
-/// Matrix multiply-add operation: F64 = F64 * F64 + F64
-template <>
-struct Mma<
-  gemm::GemmShape<16,8,4>,
-  32,
-  double,
-  layout::RowMajor,
-  double,
-  layout::ColumnMajor,
-  double,
-  layout::RowMajor,
-  OpMultiplyAdd> {
-
-  using Shape = gemm::GemmShape<16,8,4>;
-
-  using ElementA = double;
-  using LayoutA = layout::RowMajor;
-  using FragmentA = Array<double, 2>;
-
-  using ElementB = double;
-  using LayoutB = layout::ColumnMajor;
-  using FragmentB = Array<double, 1>;
-
-  using ElementC = double;
-  using LayoutC = layout::RowMajor;
-  using FragmentC = Array<double, 4>;
-
-  using Operator = OpMultiplyAdd;
-
-  using ArchTag = arch::Sm90;
-
-  CUTLASS_HOST_DEVICE
-  void operator()(FragmentC &d, FragmentA const &a, FragmentB const &b,
-                  FragmentC const &c) const {
-
-#if defined(CUTLASS_ARCH_MMA_SM90_ENABLED)
-
-  double const *A = reinterpret_cast<double const *>(&a);
-  double const *B = reinterpret_cast<double const *>(&b);
-
-  double const *C = reinterpret_cast<double const *>(&c);
-  double *D = reinterpret_cast<double *>(&d);
-
-  asm volatile("mma.sync.aligned.m16n8k4.row.col.f64.f64.f64.f64 {%0, %1, %2, %3}, {%4, %5}, {%6}, {%7, %8, %9, %10};\n"
-      : "=d"(D[0]), "=d"(D[1]), "=d"(D[2]), "=d"(D[3])
-      : "d"(A[0]), "d"(A[1]), 
-        "d"(B[0]), 
-        "d"(C[0]), "d"(C[1]), "d"(C[2]), "d"(C[3]));
-
-#else
-
-    CUTLASS_UNUSED(d);
-    CUTLASS_UNUSED(a);
-    CUTLASS_UNUSED(b);
-    CUTLASS_UNUSED(c);
-    CUTLASS_NOT_IMPLEMENTED();
-    
-#endif
-  }
-};
-
-/////////////////////////////////////////////////////////////////////////////////////////////////
 
-} // namespace arch
-} // namespace cutlass
+namespace py = pybind11;
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+void bind_matrix_layout(py::module &m) {
+    //
+    // Matrix layouts
+    // cutlass/layout/matrix.h
+    //
+
+    py::class_<cutlass::layout::RowMajor>(m, "RowMajor", R"pbdoc(
+        Mapping function for row-major matrices.
+    )pbdoc")
+        .def_static("packed", &cutlass::layout::RowMajor::packed, 
+            py::arg("extent"), 
+            R"pbdoc(Helper returns a layout to a tightly packed tensor)pbdoc")
+        .def("stride", [](const cutlass::layout::RowMajor & layout){
+            return layout.stride().at(0);
+        }, R"pbdoc(Returns the stride of the layout)pbdoc");
+
+    py::class_<cutlass::layout::ColumnMajor>(m, "ColumnMajor", R"pbdoc(
+        Mapping function for column-major matrices.
+    )pbdoc")
+        .def_static("packed", &cutlass::layout::ColumnMajor::packed, 
+            py::arg("extent"),
+            R"pbdoc(Helper returns a layout to a tightly packed tensor)pbdoc" )
+        .def("stride", [](const cutlass::layout::ColumnMajor & layout){
+            return layout.stride().at(0);
+        }, R"pbdoc(Returns the stride of the layout)pbdoc");
+
+    py::class_<cutlass::layout::RowMajorInterleaved<32>>(m, "RowMajorInterleaved32",
+        R"pbdoc(Mapping function for interleaved matrices. Matrix is structured 
+        as row-major arrangement of fixed-size columns 32)pbdoc")
+        .def_static("packed", &cutlass::layout::RowMajorInterleaved<32>::packed,
+            py::arg("extent"), 
+            R"pbdoc(Helper returns a layout to a tightly packed tensor)pbdoc")
+        .def("stride", [](const cutlass::layout::RowMajorInterleaved<32> & layout){
+            return layout.stride().at(0);
+        }, R"pbdoc(Returns the stride of the layout)pbdoc");
+
+    py::class_<cutlass::layout::ColumnMajorInterleaved<32>>(m, "ColumnMajorInterleaved32",
+        R"pbdoc(Mapping function for interleaved matrices. Matrix is structured 
+        as column-major arrangement of fixed-size rows 32)pbdoc")
+        .def_static("packed", &cutlass::layout::ColumnMajorInterleaved<32>::packed,
+            py::arg("extent"), 
+            R"pbdoc(Helper returns a layout to a tightly packed tensor)pbdoc")
+        .def("stride", [](const cutlass::layout::ColumnMajorInterleaved<32> & layout){
+            return layout.stride().at(0);
+        }, R"pbdoc(Returns the stride of the layout)pbdoc");
+}
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/mma_sparse_sm80.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/mma_sparse_sm80.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/simd.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/simd.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/simd_sm60.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/simd_sm60.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/simd_sm61.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/simd_sm61.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/wmma.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/wmma.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/wmma_sm70.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/wmma_sm70.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/wmma_sm72.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/wmma_sm72.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/arch/wmma_sm75.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/arch/wmma_sm75.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/array.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/array.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -451,44 +451,64 @@
 
   CUTLASS_HOST_DEVICE
   iterator begin() {
     return iterator(storage);
   }
 
   CUTLASS_HOST_DEVICE
+  const_iterator begin() const {
+    return cbegin();
+  }
+
+  CUTLASS_HOST_DEVICE
   const_iterator cbegin() const {
     return const_iterator(storage);
   }
 
   CUTLASS_HOST_DEVICE
   iterator end() {
     return iterator(reinterpret_cast<pointer>(storage + kStorageElements));
   }
 
   CUTLASS_HOST_DEVICE
+  const_iterator end() const {
+    return cend();
+  }
+
+  CUTLASS_HOST_DEVICE
   const_iterator cend() const {
     return const_iterator(reinterpret_cast<const_pointer>(storage + kStorageElements));
   }
 
   CUTLASS_HOST_DEVICE
   reverse_iterator rbegin() {
     return reverse_iterator(reinterpret_cast<pointer>(storage + kStorageElements));
   }
 
   CUTLASS_HOST_DEVICE
+  const_reverse_iterator rbegin() const {
+    return crbegin();
+  }
+
+  CUTLASS_HOST_DEVICE
   const_reverse_iterator crbegin() const {
     return const_reverse_iterator(reinterpret_cast<const_pointer>(storage + kStorageElements));
   }
 
   CUTLASS_HOST_DEVICE
   reverse_iterator rend() {
     return reverse_iterator(reinterpret_cast<pointer>(storage));
   }
 
   CUTLASS_HOST_DEVICE
+  const_reverse_iterator rend() const {
+    return crend();
+  }
+
+  CUTLASS_HOST_DEVICE
   const_reverse_iterator crend() const {
     return const_reverse_iterator(reinterpret_cast<const_pointer>(storage));
   }
 
   //
   // Comparison operators
   //
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/array_planar_complex.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/array_planar_complex.h`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/array_subbyte.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/array_subbyte.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -366,16 +366,14 @@
   public:
 
     CUTLASS_HOST_DEVICE
     reverse_iterator(): ptr_(nullptr), idx_(0) { }
 
     CUTLASS_HOST_DEVICE
     reverse_iterator(Storage *ptr, int idx = 0): ptr_(ptr), idx_(idx) { }
-
-    // TODO
   };
 
   /// Bidirectional constant iterator over elements
   class const_reverse_iterator {
 
     /// Pointer to storage element
     Storage const *ptr_;
@@ -386,16 +384,14 @@
   public:
 
     CUTLASS_HOST_DEVICE
     const_reverse_iterator(): ptr_(nullptr), idx_(0) { }
 
     CUTLASS_HOST_DEVICE
     const_reverse_iterator(Storage const *ptr, int idx = 0): ptr_(ptr), idx_(idx) { }
-
-    // TODO
   };
 
 private:
 
   /// Internal storage
   Storage storage[kStorageElements];
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/barrier.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/barrier.h`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -53,54 +53,50 @@
 
   /// Initial flag value
   static const T INIT = 0;
 
 
 protected:
 
-  /// Load flag, as a strong operation (int specialization)
+  /// Load flag, as a strong acquire operation (int specialization)
   CUTLASS_DEVICE
-  static int ld_strong(int *ptr)
+  static int ld_acquire(int *ptr)
   {
     int state = 0;
 
 #if (__CUDA_ARCH__ >= 700)
-      /// SM70 and newer use memory consistency qualifiers
-      asm volatile ("ld.global.relaxed.gpu.b32 %0, [%1];\n" : "=r"(state) : "l"(ptr));
-#else
-      asm volatile ("ld.cg.global.b32 %0, [%1];\n" : "=r"(state) : "l"(ptr));
-#endif // (__CUDA_ARCH__ >= 700)
+    /// SM70 and newer use memory consistency qualifiers
 
-    return state;
-  }
+    // Acquire pattern using acquire modifier
+    asm volatile ("ld.global.acquire.gpu.b32 %0, [%1];\n" : "=r"(state) : "l"(ptr));
 
-  /// Store flag, as a strong operation (int specialization)
-  CUTLASS_DEVICE
-  static void st_strong(int *ptr, int val)
-  {
-#if (__CUDA_ARCH__ >= 700)
-      /// SM70 and newer use memory consistency qualifiers
-      asm volatile ("st.global.relaxed.gpu.b32 [%0], %1;\n" : : "l"(ptr), "r"(val));
 #else
-      asm volatile ("st.cg.global.b32 [%0], %1;\n" : : "l"(ptr), "r"(val));
+    asm volatile ("ld.cg.global.b32 %0, [%1];\n" : "=r"(state) : "l"(ptr));
 #endif // (__CUDA_ARCH__ >= 700)
+
+    return state;
   }
 
 
   /// Reduce into flag, with release pattern (int specialization)
   CUTLASS_DEVICE
   static void red_release(int *ptr, int val)
   {
 #if defined(__NVCC__) || (defined(__clang__) && defined(__CUDA__)) || defined(__CUDACC_RTC__)
 #if (__CUDA_ARCH__ >= 700)
-      /// SM70 and newer use memory consistency qualifiers
-      asm volatile ("red.release.gpu.global.add.s32 [%0], %1;\n" : : "l"(ptr), "r"(val));
+    /// SM70 and newer use memory consistency qualifiers
+
+    // Release pattern using acq_rel fence + relaxed modifier.  (The fence also releases data
+    // that was weakly-written by other threads prior to the last syncthreads)
+    asm volatile ("fence.acq_rel.gpu;\n");
+    asm volatile ("red.relaxed.gpu.global.add.s32 [%0], %1;\n" : : "l"(ptr), "r"(val));
+
 #else
-      __threadfence();
-      atomicAdd(ptr, val);
+    __threadfence();
+    atomicAdd(ptr, val);
 #endif // (__CUDA_ARCH__ >= 700)
 #endif
   }
 
 
 public:
 
@@ -111,15 +107,15 @@
 #if defined(__NVCC__) || (defined(__clang__) && defined(__CUDA__)) || defined(__CUDACC_RTC__)
     T *flag_ptr = reinterpret_cast<T*>(lock_ptr) + flag_idx;
 
     if (thread_idx == 0)
     {
         // Spin-loop
         #pragma unroll 1
-        while(ld_strong(flag_ptr) < count) {}
+        while(ld_acquire(flag_ptr) < count) {}
     }
 
     __syncthreads();
 #endif
   }
 
   /// Uses thread[0] to wait for at least the specified count of signals on the given flag counter
@@ -129,17 +125,16 @@
 #if defined(__NVCC__) || (defined(__clang__) && defined(__CUDA__)) || defined(__CUDACC_RTC__)
     T *flag_ptr = reinterpret_cast<T*>(lock_ptr) + flag_idx;
 
     if (thread_idx == 0)
     {
         // Spin-loop
         #pragma unroll 1
-        while(ld_strong(flag_ptr) != val) {}
+        while(ld_acquire(flag_ptr) != val) {}
     }
-
     __syncthreads();
 #endif
   }
 
   /// Uses thread[0] to wait for the specified count of signals on the given flag counter
   CUTLASS_DEVICE
   static void wait_eq_reset(void *lock_ptr, int thread_idx, int flag_idx, T val = 1) {
@@ -162,15 +157,16 @@
   static void arrive_inc(void *lock_ptr, int thread_idx, int flag_idx)
   {
 #if defined(__NVCC__) || (defined(__clang__) && defined(__CUDA__)) || defined(__CUDACC_RTC__)
     T* flag_ptr = reinterpret_cast<T*>(lock_ptr) + flag_idx;
 
     __syncthreads();
 
-    if (thread_idx == 0) {
+    if (thread_idx == 0)
+    {
       red_release(flag_ptr, 1);
     }
 #endif
   }
 
 
   /// Increment the arrival counts for a range of flags
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/bfloat16.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/bfloat16.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/blas3.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/blas3.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/block_striped.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/block_striped.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/complex.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/complex.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/constants.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/constants.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/conv2d_problem_size.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/conv2d_problem_size.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/conv3d_problem_size.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/conv3d_problem_size.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/convolution.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/convolution.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/device/direct_convolution.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/device/direct_convolution.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/device/implicit_gemm_convolution.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/device/implicit_gemm_convolution.h`

 * *Files 3% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -158,23 +158,14 @@
         return Status::kErrorMisalignedOperand;
     }
 
     // check for unsupported problem sizes for strided dgrad implementation
     if (kConvolutionalOperator == conv::Operator::kDgrad && 
       kStrideSupport == conv::StrideSupport::kStrided) {
 
-      // Unity stride (1x1) is supported by strided dgrad but disabled for performance 
-      // reasons. For unity stride, use strided dgrad optimized unity stride specialization.
-      // Note that unit tests strided dgrad for unity stride to make sure that strided 
-      // dgrad implemetnation is functionaly sound. 
-      // Strided dgrad implementation also support mixed strides, i.e., (1x2) and (2x1)
-      if(args.problem_size.stride_h == 1 && args.problem_size.stride_w == 1) {
-        return Status::kErrorNotSupported;
-      }
-
       // split-k (serial or parallel) is not supported for strided dgrad
       if(args.problem_size.split_k_slices > 1) {
         return Status::kErrorNotSupported;
       }
       
       // dilation > {1x1} is not supported for strided dgrad
       if(args.problem_size.dilation_h > 1 || args.problem_size.dilation_w > 1) {
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/device/implicit_gemm_convolution_fusion.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/device/implicit_gemm_convolution_fusion.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv2d.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv2d.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv2d_dgrad.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv2d_dgrad.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_fusion.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_fusion.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_with_broadcast.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_with_broadcast.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -103,15 +103,15 @@
   using Epilogue = typename cutlass::conv::kernel::detail::DefaultConvEpilogueWithBroadcastTensorOp<
     ArchTag,
     typename ImplicitGemmBase::Epilogue::Shape,
     typename ImplicitGemmBase::Epilogue::WarpMmaOperator,
     ImplicitGemmBase::Epilogue::kPartitionsK,
     ElementC,
     typename EpilogueOutputOp::ElementT,
-    ElementC,
+    typename EpilogueOutputOp::ElementVector,
     EpilogueOutputOp,
     ImplicitGemmBase::Epilogue::kElementsPerAccess
   >::Epilogue;
 
   // Define the kernel
   using Kernel = cutlass::conv::kernel::ImplicitGemmConvolutionWithFusedEpilogue<
     typename ImplicitGemmBase::Mma,
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_with_reduction.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv2d_fprop_with_reduction.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv2d_group_fprop.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv2d_group_fprop.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv2d_wgrad.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv2d_wgrad.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv2d_wgrad_fusion.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv2d_wgrad_fusion.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv3d_dgrad.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv3d_dgrad.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv3d_fprop.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv3d_fprop.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv3d_fprop_fusion.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv3d_fprop_fusion.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv3d_wgrad.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_conv3d_wgrad.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_depthwise_fprop.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/default_depthwise_fprop.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/direct_convolution.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/direct_convolution.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -328,15 +328,15 @@
         threadblock_tile_idx.k() * Mma::Shape::kK,
         threadblock_tile_idx.n() * Mma::Shape::kN
       )
     );
 
     // Broadcast the warp_id computed by lane 0 to ensure dependent code
     // is compiled as warp-uniform.
-    int warp_idx = __shfl_sync(0xffffffff, threadIdx.x / 32, 0);
+    int warp_idx = canonical_warp_idx();
     int lane_idx = threadIdx.x % 32;
 
     //
     // Main loop
     //
 
     // Construct thread-scoped matrix multiply
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution_fusion.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution_fusion.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -335,15 +335,15 @@
                   // Wgrad
                   (threadblock_tile_idx.n() * Mma::Shape::kN)
       )
     );
 
     // Broadcast the warp_id computed by lane 0 to ensure dependent code
     // is compiled as warp-uniform.
-    int warp_idx = __shfl_sync(0xffffffff, threadIdx.x / 32, 0);
+    int warp_idx = canonical_warp_idx();
     int lane_idx = threadIdx.x % 32;
 
     //
     // Main loop
     //
 
     // Construct thread-scoped matrix multiply
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution_strided_dgrad.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution_strided_dgrad.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -331,15 +331,15 @@
 
     typename Mma::FragmentC accumulators;
 
     accumulators.clear();
 
     // Broadcast the warp_id computed by lane 0 to ensure dependent code
     // is compiled as warp-uniform.
-    int warp_idx = __shfl_sync(0xffffffff, threadIdx.x / 32, 0);
+    int warp_idx = canonical_warp_idx();
     int lane_idx = threadIdx.x % 32;
 
     // Check if CTA contributes valid MMA (Dy * w) and accumulator will be non-zero after MMA
     if (start_r < params.problem_size.R && start_s < params.problem_size.S) {
       // Scale gemm_k_iterations for strided dgrad
       int gemm_k_iterations = (params.gemm_k_iterations / (params.problem_size.R * params.problem_size.S)
                               ) * params.problem_size.num_gemm_k_filter_positions(start_r, start_s);
@@ -385,24 +385,23 @@
     // Epilogue
     //
 
     EpilogueOutputOp output_op(params.output_op);
 
     // Construct the semaphore.
     int block_idx = threadblock_tile_idx.m() + threadblock_tile_idx.n() * params.grid_tiled_shape.m();
-
     Semaphore semaphore(params.semaphore + block_idx, thread_idx);
-    
+
     // Compute logical position within grid
     threadblock_tile_idx =
         threadblock_swizzle.get_tile_offset(params.grid_tiled_shape);
 
     // If performing a reduction via split-K, fetch the initial synchronization
     if (params.split_k_mode == SplitKMode::kSerial && params.grid_tiled_shape.k() > 1) {
-        
+
       // Fetch the synchronization lock initially but do not block.
       semaphore.fetch();
 
       // Indicate which position in a serial reduction the output operator is currently updating
       output_op.set_k_partition(threadblock_tile_idx.k(), params.grid_tiled_shape.k());
     }
 
@@ -417,74 +416,75 @@
       params.ptr_D,
       ConvOutputIteratorParameter::extent(params.problem_size),
       thread_idx,
       params.stride_h_divmod, params.stride_w_divmod,
       start_r, start_s,
       threadblock_offset
     );
-    
-    // Tile iterator reading from source accumulator tensor
-    typename Epilogue::OutputTileIterator iterator_C(
-      params.iterator_C,
-      params.ptr_C,
-      ConvOutputIteratorParameter::extent(params.problem_size),
-      thread_idx,
-      params.stride_h_divmod, params.stride_w_divmod,
-      start_r, start_s,
-      threadblock_offset
-    );
-
 
     // Construct the epilogue
     Epilogue epilogue(
-      shared_storage.epilogue, 
-      thread_idx, 
-      warp_idx, 
+      shared_storage.epilogue,
+      thread_idx,
+      warp_idx,
       lane_idx);
 
-    // Wait on the semaphore - this latency may have been covered by iterator construction
-    if (params.split_k_mode == SplitKMode::kSerial && params.grid_tiled_shape.k() > 1) {
-        
-      // For subsequent threadblocks, the source matrix is held in the 'D' tensor.
-      if (threadblock_tile_idx.k()) {
-        iterator_C = iterator_D;
-      }
+    if (output_op.is_source_needed())
+    {
+      // Tile iterator reading from source accumulator tensor
+      typename Epilogue::OutputTileIterator iterator_C(
+        params.iterator_C,
+        params.ptr_C,
+        ConvOutputIteratorParameter::extent(params.problem_size),
+        thread_idx,
+        params.stride_h_divmod, params.stride_w_divmod,
+        start_r, start_s,
+        threadblock_offset);
+
+      // Wait on the semaphore - this latency may have been covered by iterator construction
+      if (params.split_k_mode == SplitKMode::kSerial && params.grid_tiled_shape.k() > 1) {
+
+        // For subsequent threadblocks, the source matrix is held in the 'D' tensor.
+        if (threadblock_tile_idx.k()) {
+          iterator_C = iterator_D;
+        }
 
-      semaphore.wait(threadblock_tile_idx.k());
+        semaphore.wait(threadblock_tile_idx.k());
+      }
 
+      // Run epilogue with addend source iterator
+      epilogue(output_op, iterator_D, accumulators, iterator_C);
     }
-    // Each split-k-slice writes to a unique tensor location
-    else if (params.split_k_mode == SplitKMode::kParallel) {
-      iterator_D.add_pointer_offset(threadblock_tile_idx.k() * 
-        cutlass::conv::implicit_gemm_tensor_c_size(ConvOperator, params.problem_size));
+    else
+    {
+      // Run epilogue without addend source iterator
+      epilogue(output_op, iterator_D, accumulators);
     }
 
-    // Run efficient epilogue
-    epilogue(output_op, iterator_D, accumulators, iterator_C);
-  
     //
     // Release the semaphore
     //
 
-    if (params.split_k_mode == SplitKMode::kSerial && params.grid_tiled_shape.k() > 1) { 
+    if (params.split_k_mode == SplitKMode::kSerial && params.grid_tiled_shape.k() > 1) {
 
       int lock = 0;
       if (params.grid_tiled_shape.k() == threadblock_tile_idx.k() + 1) {
 
         // The final threadblock resets the semaphore for subsequent grids.
         lock = 0;
       }
       else {
         // Otherwise, the semaphore is incremented
         lock = threadblock_tile_idx.k() + 1;
       }
-      
+
       semaphore.release(lock);
     }
-  } 
+
+  }
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 } // namespace kernel
 } // namespace conv
 } // namespace cutlass
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution_with_fused_epilogue.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/kernel/implicit_gemm_convolution_with_fused_epilogue.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -337,15 +337,15 @@
         threadblock_tile_idx.k() * Mma::Shape::kK,
         threadblock_tile_idx.n() * Mma::Shape::kN
       )
     );
 
     // Broadcast the warp_id computed by lane 0 to ensure dependent code
     // is compiled as warp-uniform.
-    int warp_idx = __shfl_sync(0xffffffff, threadIdx.x / 32, 0);
+    int warp_idx = canonical_warp_idx();
     int lane_idx = threadIdx.x % 32;
 
     //
     // Main loop
     //
 
     // Construct thread-scoped matrix multiply
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/thread/depthwise_mma.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/thread/depthwise_mma.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_filter_tile_access_iterator_analytic.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_filter_tile_access_iterator_analytic.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_filter_tile_access_iterator_optimized.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_filter_tile_access_iterator_optimized.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_output_gradient_tile_access_iterator_analytic.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_output_gradient_tile_access_iterator_analytic.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_output_gradient_tile_access_iterator_optimized.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_dgrad_output_gradient_tile_access_iterator_optimized.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -226,15 +226,15 @@
       
       // Access (p, q) coordinates for Dy tensor for filter position in gemm_k=0
       // note that (h + pad_h - filter_r) and (w + pad_w - filter_s) are ensured to be 
       // divisible by stride_h and stride_w
       offset_p[s] = (mapped_h + problem_size_.pad_h - filter_r) / problem_size_.stride_h;
       offset_q[s] = (mapped_w + problem_size_.pad_w - filter_s) / problem_size_.stride_w;
 
-      // Intialize pointers for gemm_k=0
+      // Initialize pointers for gemm_k=0
       TensorCoord coord{offset_n[s], offset_p[s], offset_q[s], filter_k_};
 
       pointer_[s] += params_.layout(coord) * sizeof_bits<Element>::value / 8;
     }
 
     //
     // Precompute mask predicates
@@ -337,25 +337,25 @@
       // Move filter_r by stride_h
       filter_r_ += problem_size_.stride_h;
 #if 0
       if (filter_r_ < problem_size_.R) {
 
         next_idx = 1;
 
-        // Restore bytes in q coordinate (Mma in filter s dimenstion)
+        // Restore bytes in q coordinate (Mma in filter s dimension)
         reset_bytes = reset_bytes_s_;
 
       } else {
 
         // Restore filter_r
         filter_r_ = start_r_;
 
         next_idx = 2;
 
-        // Restore bytes in p and q coordinate (Mma in filter s and r dimenstion)
+        // Restore bytes in p and q coordinate (Mma in filter s and r dimension)
         reset_bytes = reset_bytes_r_;
       }
 #else
       asm volatile(
           "{\n\t"
           " .reg .pred %%p;\n\t"
           " setp.lt.s32 %%p, %3, %4;\n\t"
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_analytic.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_analytic.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_few_channels.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_few_channels.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_fixed_channels.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_fixed_channels.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_optimized.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_activation_tile_access_iterator_optimized.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_analytic.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_analytic.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_few_channels.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_few_channels.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_fixed_channels.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_fixed_channels.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_optimized.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_fprop_filter_tile_access_iterator_optimized.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_params.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_params.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_tile_iterator.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_tile_iterator.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_activation_tile_access_iterator_analytic.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_activation_tile_access_iterator_analytic.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -191,15 +191,15 @@
     if (kAccessesPerVector == 1) {
       /// One 128b aligned access fetching more than one element
       c = filter_c_[iteration_contiguous_];
       r = filter_r_[iteration_contiguous_];
       s = filter_s_[iteration_contiguous_];
     }  
     else {
-      /// Multiple access to support non-128b alignment in contiguous dimenstion
+      /// Multiple access to support non-128b alignment in contiguous dimension
       c = (filter_c_[iteration_contiguous_] + iteration_vector_ * AccessType::kElements) % problem_size_.C;
       int wrap_c = (filter_c_[iteration_contiguous_] + iteration_vector_ * AccessType::kElements) / problem_size_.C;
       s = (filter_s_[iteration_contiguous_] + wrap_c) % problem_size_.S;
       int wrap_s = (filter_s_[iteration_contiguous_] + wrap_c) / problem_size_.S;
       r = filter_r_[iteration_contiguous_] + wrap_s;
     }
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_activation_tile_access_iterator_optimized.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_activation_tile_access_iterator_optimized.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -208,15 +208,15 @@
   TensorCoord at() const {
     int r = precomputed_filter_r_[iteration_contiguous_];
     int s = precomputed_filter_s_[iteration_contiguous_];
     int c = filter_c_[iteration_contiguous_];
 
     if (kAccessesPerVector > 1) {
       // This code section is only to support non-128b alignment
-      // Multiple access to support non-128b alignment in contiguous dimenstion
+      // Multiple access to support non-128b alignment in contiguous dimension
       int wrap_c;
       params_.c_divmod(wrap_c, c, c + iteration_vector_ * AccessType::kElements);
 
       if (problem_size_.mode == Mode::kConvolution) {
         s -= (problem_size_.dilation_w * wrap_c);
         
         int wrap_s;
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_output_gradient_tile_access_iterator_analytic.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_output_gradient_tile_access_iterator_analytic.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_output_gradient_tile_access_iterator_optimized.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv2d_wgrad_output_gradient_tile_access_iterator_optimized.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_filter_tile_access_iterator_analytic.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_filter_tile_access_iterator_analytic.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_filter_tile_access_iterator_optimized.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_filter_tile_access_iterator_optimized.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_output_gradient_tile_access_iterator_analytic.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_output_gradient_tile_access_iterator_analytic.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_output_gradient_tile_access_iterator_optimized.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_dgrad_output_gradient_tile_access_iterator_optimized.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_activation_tile_access_iterator_analytic.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_activation_tile_access_iterator_analytic.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_activation_tile_access_iterator_optimized.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_activation_tile_access_iterator_optimized.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_filter_tile_access_iterator_analytic.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_filter_tile_access_iterator_analytic.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_filter_tile_access_iterator_optimized.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_fprop_filter_tile_access_iterator_optimized.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_params.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_params.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_activation_tile_access_iterator_analytic.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_activation_tile_access_iterator_analytic.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_activation_tile_access_iterator_optimized.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_activation_tile_access_iterator_optimized.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_output_gradient_tile_access_iterator_analytic.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_output_gradient_tile_access_iterator_analytic.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_output_gradient_tile_access_iterator_optimized.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/conv3d_wgrad_output_gradient_tile_access_iterator_optimized.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/depthwise_direct_conv_params.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/depthwise_direct_conv_params.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_activation_tile_access_iterator_direct_conv_fixed_stride_dilation.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_activation_tile_access_iterator_direct_conv_fixed_stride_dilation.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_activation_tile_access_iterator_direct_conv_optimized.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_activation_tile_access_iterator_direct_conv_optimized.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_direct_conv_multistage.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_direct_conv_multistage.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_filter_tile_access_iterator_direct_conv_optimized.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_filter_tile_access_iterator_direct_conv_optimized.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_pipelined.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/depthwise_fprop_pipelined.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -237,15 +237,15 @@
 
     int smem_write_stage_idx = 1;
     // Depthwise specific
     int channel_start_index = 0;
     int rs_plane_idx = 0;
 
     // Issue loads during the first warp-level matrix multiply-add *AFTER* issuing 
-    // shared memory loads (which have the tighest latency requirement).
+    // shared memory loads (which have the tightest latency requirement).
 
     //
     // Mainloop
     //
 
     // Note: The main loop does not support Base::kWarpGemmIterations == 2.
     CUTLASS_GEMM_LOOP
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/depthwise_mma_base.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/depthwise_mma_base.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/depthwise_mma_core_with_lane_access_size.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/depthwise_mma_core_with_lane_access_size.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/implicit_gemm_fprop_fusion_multistage.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/implicit_gemm_fprop_fusion_multistage.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/implicit_gemm_multistage.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/implicit_gemm_multistage.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/implicit_gemm_pipelined.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/implicit_gemm_pipelined.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -234,15 +234,15 @@
     ++this->warp_tile_iterator_B_;
 
     Operator warp_mma;
 
     int smem_write_stage_idx = 1;
 
     // Issue loads during the first warp-level matrix multiply-add *AFTER* issuing 
-    // shared memory loads (which have the tighest latency requirement).
+    // shared memory loads (which have the tightest latency requirement).
 
     //
     // Mainloop
     //
 
     // Note: The main loop does not support Base::kWarpGemmIterations == 2.
     CUTLASS_GEMM_LOOP
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/implicit_gemm_wgrad_fusion_multistage.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/implicit_gemm_wgrad_fusion_multistage.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/predicated_scale_bias_vector_access_iterator.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/predicated_scale_bias_vector_access_iterator.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/predicated_scale_bias_vector_iterator.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/predicated_scale_bias_vector_iterator.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/threadblock_swizzle.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/threadblock/threadblock_swizzle.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -63,15 +63,15 @@
   // and point-wise fusion
   int tile_m = tile_m_per_filter * int(problem_size.stride().product());
 
   // There is a possible performance optimization here that leads up to 2x speeds than the current 
   // CUTLASS strided dgrad performance for stride > filter, i.e., stride={2x2} and filter={1x1})
   //
   // * Optimization * 
-  // Only launch CTAs in M dimenstion which contribute to a row in Dx output
+  // Only launch CTAs in M dimension which contribute to a row in Dx output
   // 
   // 
   // * Constraints *
   // (A) stride <= filter, for example, stride={2x2} and filter={3x3}: 
   //       - (A.1): There are no constraints for this case and the optimization does 
   //                affect this case functionality or performance. 
   // (B) stride > filter, for example, stride={2x2} and filter={1x1}: 
@@ -103,15 +103,15 @@
 
     gemm::GemmCoord implicit_gemm_problem_size = 
     cutlass::conv::implicit_gemm_problem_size(conv_operator, problem_size);
 
     // compute number of tiles in m dimension
     int tile_m = get_strided_dgrad_tile_m(problem_size, tile_size.m());
 
-    // compute number of tiles in n dimenstion 
+    // compute number of tiles in n dimension
     int tile_n = (implicit_gemm_problem_size.n() + tile_size.n() - 1) / tile_size.n();
 
     return gemm::GemmCoord(
       tile_m,
       tile_n,
       split_k_slices);
   }
@@ -144,15 +144,15 @@
 
     gemm::GemmCoord implicit_gemm_problem_size = 
     cutlass::conv::implicit_gemm_problem_size(conv_operator, problem_size);
 
     // compute number of tiles in m dimension
     int tile_m = get_strided_dgrad_tile_m(problem_size, tile_size.m());
 
-    // compute number of tiles in n dimenstion 
+    // compute number of tiles in n dimension
     int tile_n = (implicit_gemm_problem_size.n() + tile_size.n() - 1) / tile_size.n();
 
     return gemm::GemmCoord(
       tile_m,
       tile_n,
       split_k_slices);
   }
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/warp/mma_depthwise_simt.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/warp/mma_depthwise_simt.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/warp/mma_depthwise_simt_tile_iterator.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/warp/mma_depthwise_simt_tile_iterator.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/conv/warp/scale_bias_relu_transform.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/conv/warp/scale_bias_relu_transform.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/coord.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/coord.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/core_io.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/core_io.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/cutlass.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/cutlass.h`

 * *Files 9% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -34,58 +34,68 @@
 */
 
 #pragma once
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 #ifdef CUTLASS_NAMESPACE
-#define cutlass CUTLASS_NAMESPACE
+#define concat_tok(a, b) a ## b
+#define mkcutlassnamespace(pre, ns) concat_tok(pre, ns)
+#define cutlass mkcutlassnamespace(cutlass_, CUTLASS_NAMESPACE)
 #endif
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
-#define CUTLASS_UNUSED(expr) do { ; } while (&expr != &expr)
+#if defined(__NVCC__) || (defined(__clang__) && defined(__CUDA__))
+#define CUTLASS_HOST_DEVICE __forceinline__ __device__ __host__
+#define CUTLASS_DEVICE __forceinline__ __device__
+#elif defined(__CUDACC_RTC__)
+#define CUTLASS_HOST_DEVICE __forceinline__ __device__
+#define CUTLASS_DEVICE __forceinline__ __device__
+#else
+#define CUTLASS_HOST_DEVICE inline
+#define CUTLASS_DEVICE inline
+#endif
 
-#if !defined(__CUDACC_RTC__)
+////////////////////////////////////////////////////////////////////////////////////////////////////
 
-#include <assert.h>
+template<typename T>
+CUTLASS_HOST_DEVICE void __CUTLASS_UNUSED(T const &) 
+{ }
 
-#if defined(_MSC_VER)
-  #define CUTLASS_NOT_IMPLEMENTED() assert(0 && __FUNCSIG__)
+#if defined(__GNUC__)
+  #define CUTLASS_UNUSED(expr) __CUTLASS_UNUSED(expr)
 #else
-  #define CUTLASS_NOT_IMPLEMENTED() assert(0 && __PRETTY_FUNCTION__)
+  #define CUTLASS_UNUSED(expr) do { ; } while (&expr != &expr)
 #endif
 
-#else
+#if !defined(__CUDACC_RTC__)
 
-#if defined(_MSC_VER)
-  #define CUTLASS_NOT_IMPLEMENTED() assert(0 && __FUNCSIG__)
-#else
-  #define CUTLASS_NOT_IMPLEMENTED() assert(0 && __PRETTY_FUNCTION__)
-#endif
+#include <assert.h>
 
+  #if defined(__CUDA_ARCH__)
+    #if defined(_MSC_VER)
+      #define CUTLASS_NOT_IMPLEMENTED() { printf("%s not implemented\n", __FUNCSIG__); asm volatile ("brkpt;\n"); }
+    #else
+      #define CUTLASS_NOT_IMPLEMENTED() { printf("%s not implemented\n", __PRETTY_FUNCTION__); asm volatile ("brkpt;\n"); }
+    #endif
+
+  #else
+    #if defined(_MSC_VER)
+      #define CUTLASS_NOT_IMPLEMENTED() assert(0 && __FUNCSIG__)
+    #else
+      #define CUTLASS_NOT_IMPLEMENTED() assert(0 && __PRETTY_FUNCTION__)
+    #endif
+  #endif
 #endif
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 
-////////////////////////////////////////////////////////////////////////////////////////////////////
-
-#if defined(__NVCC__) || (defined(__clang__) && defined(__CUDA__))
-#define CUTLASS_HOST_DEVICE __forceinline__ __device__ __host__
-#define CUTLASS_DEVICE __forceinline__ __device__
-#elif defined(__CUDACC_RTC__)
-#define CUTLASS_HOST_DEVICE __forceinline__ __device__
-#define CUTLASS_DEVICE __forceinline__ __device__
-#else
-#define CUTLASS_HOST_DEVICE inline
-#define CUTLASS_DEVICE inline
-#endif
-
 /// Status code returned by CUTLASS operations
 enum class Status {
   kSuccess,                    ///< Operation was successful.
   kErrorMisalignedOperand,     ///< operands fail alignment requirements.
   kErrorInvalidDataType,       ///< DataType fails requirement.
   kErrorInvalidLayout,         ///< Layout fails alignment requirement.
   kErrorInvalidProblem,        ///< Specified problem size is not supported by operator.
@@ -167,28 +177,51 @@
     #define CUTLASS_PRAGMA_NO_UNROLL
     #define CUTLASS_GEMM_LOOP
 
 #endif
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
-static const int NUM_THREADS_PER_WARP = 32;
-static const int NUM_THREADS_PER_HALF_WARP = NUM_THREADS_PER_WARP / 2;
-static const int NUM_THREADS_PER_QUAD = 4;
-static const int NUM_THREADS_PER_QUAD_PAIR = NUM_THREADS_PER_QUAD * 2;
+static const int NumThreadsPerWarp = 32;
+static const int NumThreadsPerWarpGroup = 128;
+static const int NumThreadsPerHalfWarp = NumThreadsPerWarp / 2;
+static const int NumThreadsPerQuad = 4;
+static const int NumThreadsPerQuadPair = NumThreadsPerQuad * 2;
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Helper function to return true when called by thread 0 of threadblock 0.
 CUTLASS_HOST_DEVICE bool thread0() {
   #if defined(__CUDA_ARCH__)
     return (!threadIdx.x && !threadIdx.y && !threadIdx.z) && (!blockIdx.x && !blockIdx.y && !blockIdx.z);
   #else
     return false;
   #endif
 }
 
+/// Returns a warp-uniform value indicating the canonical warp index of the calling threads.
+/// Threads within the warp must be converged.
+CUTLASS_DEVICE
+int canonical_warp_idx() { 
+  #if defined(__CUDA_ARCH__)
+    return __shfl_sync(0xffffffff, threadIdx.x / NumThreadsPerWarp, 0);
+  #else
+    return 0;
+  #endif
+}
+
+/// Returns a warp-uniform value indicating the canonical warp group index of the calling threads.
+/// Threads within the warp must be converged.
+CUTLASS_DEVICE
+int canonical_warp_group_idx() {
+  #if defined(__CUDA_ARCH__)
+    return __shfl_sync(0xffffffff, threadIdx.x / NumThreadsPerWarpGroup, 0);
+  #else
+    return 0;
+  #endif
+}
+
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 }  // namespace cutlass
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/device_kernel.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_grouped.h`

 * *Files 21% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -24,56 +24,38 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
-/*! \file
-    \brief Template for generic CUTLASS kernel.
+/*!
+  \file
+  \brief Device-level grouped GEMM.
 */
 
 #pragma once
 
-#include "cutlass/cutlass.h"
-////////////////////////////////////////////////////////////////////////////////
-
-namespace cutlass {
+#include "cutlass/gemm/device/base_grouped.h"
 
 ////////////////////////////////////////////////////////////////////////////////
 
-/// Generic CUTLASS kernel template.
-template <typename Operator>
-__global__
-void Kernel(typename Operator::Params params) {
-  // Dynamic shared memory base pointer
-  extern __shared__ int SharedStorageBase[];
-
-  // Declare pointer to dynamic shared memory.
-  typename Operator::SharedStorage *shared_storage =
-      reinterpret_cast<typename Operator::SharedStorage *>(SharedStorageBase);
-
-  Operator op;
-
-  op(params, *shared_storage);
-}
-
-
-/// Generic CUTLASS kernel template.
-template <typename Operator>
-__global__
-void Kernel2(typename Operator::Params params) {
-  // Dynamic shared memory base pointer
-  extern __shared__ int SharedStorageBase[];
-
-  // Declare pointer to dynamic shared memory.
-  typename Operator::SharedStorage *shared_storage =
-      reinterpret_cast<typename Operator::SharedStorage *>(SharedStorageBase);
+namespace cutlass {
+namespace gemm {
+namespace device {
 
-  Operator::invoke(params, *shared_storage);
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
-}
+/// GEMM Grouped
+template <typename GemmKernel_>
+class GemmGrouped : public BaseGrouped<GemmKernel_> {
+public:
+  using GemmKernel = GemmKernel_;
+};
 
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
-////////////////////////////////////////////////////////////////////////////////
-} /// namespace cutlass
+} // namespace device
+} // namespace gemm
+} // namespace cutlass
 
+/////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/activation.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/activation.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/conversion_op.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/conversion_op.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_with_elementwise.h`

 * *Files 14% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -25,224 +25,207 @@
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /*! \file
-  \brief Functor performing linear combination operations used by epilogues.
+  
+  \brief Functor performing linear combination with elementwise
 */
 
 #pragma once
 
+#include <cutlass/half.h>
 #include "cutlass/cutlass.h"
 #include "cutlass/numeric_types.h"
 #include "cutlass/array.h"
+#include "cutlass/constants.h"
+#include "cutlass/fast_math.h"
 #include "cutlass/functional.h"
 #include "cutlass/numeric_conversion.h"
-#include "cutlass/epilogue/thread/scale_type.h"
-#include "cutlass/epilogue/thread/linear_combination_params.h"
+#include "cutlass/epilogue/thread/activation.h"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace epilogue {
 namespace thread {
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Applies a linear combination operator to an array of elements.
 ///
 /// D = alpha * accumulator + beta * source + uniform
 ///
 template <
-  typename ElementOutput_,                             ///< Data type used to load and store tensors
-  int Count,                                           ///< Number of elements computed per operation.
+  typename ElementCompute_,                            ///< Data type returned by this functor
+  typename ElementAccumulator_,                        ///< Data type of accumulators
+  typename ElementSource_,                             ///< Data type of source tensor
+  typename ElementTensor_,                             ///< Data type of additional tensor
+  int Count,                                           ///< Number of elements computed per operation
                                                        ///< Usually it is 128/sizeof_bits<ElementOutput_>,
                                                        ///< but we use 64 or 32 sometimes when there are not enough data to store
-  typename ElementAccumulator_ = ElementOutput_,       ///< Accumulator data type
-  typename ElementCompute_ = ElementOutput_,           ///< Data type used to compute linear combination
-  ScaleType::Kind Scale = ScaleType::Default,          ///< Control Alpha and Beta scaling
   FloatRoundStyle Round = FloatRoundStyle::round_to_nearest
 >
-class LinearCombination {
+class LinearCombinationWithElementwise {
 public:
 
-  using ElementOutput = ElementOutput_;
-  using ElementAccumulator = ElementAccumulator_;
+  using ElementOutput = ElementSource_;
   using ElementCompute = ElementCompute_;
+  using ElementAccumulator = ElementAccumulator_;
+  using ElementSource = ElementSource_;
+  using ElementTensor = ElementTensor_;
+
+  static bool const kIsHeavy = true;
 
   static int const kCount = Count;
-  static const ScaleType::Kind kScale = Scale;
-  using FragmentOutput = Array<ElementOutput, kCount>;
+
+  using FragmentCompute = Array<ElementCompute, kCount>;
   using FragmentAccumulator = Array<ElementAccumulator, kCount>;
-  using ComputeFragment = Array<ElementCompute, kCount>;
+  using FragmentSource = Array<ElementSource, kCount>;
+  using FragmentTensor = Array<ElementTensor, kCount>;
 
-  using ParamsBase = LinearCombinationParams;
-  
   static FloatRoundStyle const kRound = Round;
 
   /// Host-constructable parameters structure
-  struct Params : ParamsBase{
+  struct Params {
+
     ElementCompute alpha;                  ///< scales accumulators
     ElementCompute beta;                   ///< scales source tensor
+    ElementCompute threshold;              ///< minimum value that is output 
     ElementCompute const *alpha_ptr;       ///< pointer to accumulator scalar - if not null, loads it from memory
     ElementCompute const *beta_ptr;        ///< pointer to source scalar - if not null, loads it from memory
+    //
+    // Methods
+    //
 
     CUTLASS_HOST_DEVICE
     Params(): 
-      ParamsBase(
-        ElementCompute(1), 
-        ElementCompute(0)
-      ),
       alpha(ElementCompute(1)), 
-      beta(ElementCompute(0)), 
+      beta(ElementCompute(0)),
+      threshold(ElementCompute(0)), 
       alpha_ptr(nullptr), 
       beta_ptr(nullptr) { }
 
     CUTLASS_HOST_DEVICE
     Params(
       ElementCompute alpha,
-      ElementCompute beta
-    ): 
-      ParamsBase(alpha, beta),
-      alpha(alpha), beta(beta), alpha_ptr(nullptr), beta_ptr(nullptr) { } 
+      ElementCompute beta,
+      ElementCompute threshold = ElementCompute(0)
+    ): alpha(alpha), beta(beta), threshold(threshold), alpha_ptr(nullptr), beta_ptr(nullptr) {
 
-    CUTLASS_HOST_DEVICE
-    Params(
-      ElementCompute alpha
-    ): 
-      ParamsBase(alpha, ElementCompute(0)),
-      alpha(alpha), beta(0), alpha_ptr(nullptr), beta_ptr(nullptr) { }
+    }
 
     CUTLASS_HOST_DEVICE
     Params(
       ElementCompute const *alpha_ptr,
-      ElementCompute const *beta_ptr
-    ): 
-      ParamsBase(*alpha_ptr, *beta_ptr),
-      alpha(0), beta(0), alpha_ptr(alpha_ptr), beta_ptr(beta_ptr) { }
-
-    CUTLASS_HOST_DEVICE
-    Params(
-      ElementCompute const *alpha_ptr
-    ):
-      ParamsBase(*alpha_ptr, ElementCompute(0)),
-      alpha(0), beta(0), alpha_ptr(alpha_ptr), beta_ptr(nullptr) { }
+      ElementCompute const *beta_ptr,
+      ElementCompute threshold = ElementCompute(0)
+    ): alpha(0), beta(0), threshold(threshold), alpha_ptr(alpha_ptr), beta_ptr(beta_ptr) {
 
-    CUTLASS_HOST_DEVICE
-    Params(
-      ParamsBase const& base
-    ): ParamsBase(base), alpha_ptr(nullptr), beta_ptr(nullptr) { 
-      #if defined(__CUDA_ARCH__)
-      alpha = reinterpret_cast<ElementCompute const&>(base.alpha_data);
-      beta = reinterpret_cast<ElementCompute const&>(base.beta_data);
-      #else
-      memcpy( alpha, base.alpha_data, sizeof(ElementCompute) ); 
-      memcpy( beta, base.alpha_data, sizeof(ElementCompute) ); 
-      #endif
     }
   };
 
 private:
 
   //
   // Data members
   //
 
   ElementCompute alpha_;
   ElementCompute beta_;
+  ElementCompute threshold_;
+  bool participates_in_reduction_;
 
 public:
 
   /// Constructs the function object, possibly loading from pointers in host memory
   CUTLASS_HOST_DEVICE
-  LinearCombination(Params const &params) {
+  LinearCombinationWithElementwise(Params const &params) {
+
     alpha_ = (params.alpha_ptr ? *params.alpha_ptr : params.alpha);
     beta_ = (params.beta_ptr ? *params.beta_ptr : params.beta);
+    threshold_ = params.threshold;
+    participates_in_reduction_ = true;
   }
 
   /// Returns true if source is needed
   CUTLASS_HOST_DEVICE
   bool is_source_needed() const {
-    if (Scale == ScaleType::NoBetaScaling) return true;
-
-    if (Scale == ScaleType::OnlyAlphaScaling) return false;
-
-    if (Scale == ScaleType::Nothing) return false;
-
     return beta_ != ElementCompute(0);
   }
 
+  /// Returns true if the threadblock computes the reduction
+  CUTLASS_HOST_DEVICE
+  bool participates_in_reduction() const {
+    return participates_in_reduction_;
+  }
+
   /// Functionally required for serial reduction in the epilogue
   CUTLASS_HOST_DEVICE
   void set_k_partition(int k_partition, int k_partition_count) {
     if (k_partition) {
       beta_ = ElementCompute(1);
     }
-  }
 
+    if (k_partition != k_partition_count - 1) {
+      // set to NaN to make ReLU no-op for all except last k partitions
+      int64_t allones = -1;
+      threshold_ = reinterpret_cast<ElementCompute const &>(allones);
+      // Avoid computing the reduction if this isn't the final Split-K slice
+      participates_in_reduction_ = false;
+    }
+  }
+  
   /// Computes linear scaling: D = alpha * accumulator + beta * source
   CUTLASS_HOST_DEVICE
-  FragmentOutput operator()(
+  FragmentCompute operator()(
     FragmentAccumulator const &accumulator, 
-    FragmentOutput const &source) const {
+    FragmentSource const &source,
+    FragmentTensor const &tensor) const {
 
     // Convert source to interal compute numeric type
-    NumericArrayConverter<ElementCompute, ElementOutput, kCount, Round> source_converter;
+    NumericArrayConverter<ElementCompute, ElementSource, kCount, Round> source_converter;
     NumericArrayConverter<ElementCompute, ElementAccumulator, kCount, Round> accumulator_converter;
 
-    // Convert to destination numeric type
-    NumericArrayConverter<ElementOutput, ElementCompute, kCount, Round> destination_converter;
-
-    ComputeFragment converted_source = source_converter(source);
-    ComputeFragment converted_accumulator = accumulator_converter(accumulator);
-
-    if (Scale == ScaleType::Nothing)
-      return destination_converter(converted_accumulator);
+    FragmentCompute converted_source = source_converter(source);
+    FragmentCompute converted_accumulator = accumulator_converter(accumulator);
 
     // Perform binary operations
-    ComputeFragment intermediate;
+    FragmentCompute intermediate;
 
-    multiplies<ComputeFragment> mul_add_source;
-    multiply_add<ComputeFragment> mul_add_accumulator;
-
-    if (Scale == ScaleType::NoBetaScaling)
-      intermediate = converted_source;
-    else
-      intermediate = mul_add_source(beta_, converted_source);                             // X =  beta * C + uniform
+    multiplies<FragmentCompute> mul_add_source;
+    multiply_add<FragmentCompute> mul_add_accumulator;
 
+    intermediate = mul_add_source(beta_, converted_source);                             // X =  beta * C + uniform
     intermediate = mul_add_accumulator(alpha_, converted_accumulator, intermediate);    // D = alpha * Accum + X
 
-    return destination_converter(intermediate);
+    return intermediate;
   }
 
   /// Computes linear scaling: D = alpha * accumulator
   CUTLASS_HOST_DEVICE
-  FragmentOutput operator()(
-    FragmentAccumulator const &accumulator) const {
+  FragmentCompute operator()(
+    FragmentAccumulator const &accumulator,
+    FragmentTensor const &tensor) const {
 
     // Convert source to interal compute numeric type
     NumericArrayConverter<ElementCompute, ElementAccumulator, kCount, Round> accumulator_converter;
 
-    // Convert to destination numeric type
-    NumericArrayConverter<ElementOutput, ElementCompute, kCount, Round> destination_converter;
-
-    ComputeFragment converted_accumulator = accumulator_converter(accumulator);
-
-    if (Scale == ScaleType::Nothing)
-      return destination_converter(converted_accumulator);
+    FragmentCompute converted_accumulator = accumulator_converter(accumulator);
 
     // Perform binary operations
-    ComputeFragment intermediate;
-    multiplies<ComputeFragment> mul_accumulator;
+    FragmentCompute intermediate;
+
+    multiplies<FragmentCompute> mul_accumulator;
 
-    intermediate = mul_accumulator(alpha_, converted_accumulator);    // D = alpha * Accum 
+    intermediate = mul_accumulator(alpha_, converted_accumulator);    // D = alpha * Accum
 
-    return destination_converter(intermediate);
+    return intermediate;
   }
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 } // namespace thread
 } // namespace epilogue
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_bias_elementwise.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_bias_elementwise.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -57,25 +57,28 @@
   typename ElementC_,
   typename ElementAccumulator_,
   typename ElementCompute_,
   typename ElementZ_,
   typename ElementT_,
   int ElementsPerAccess,
   typename ElementwiseOp_ = Identity<ElementCompute_>,
-  typename BinaryOp_ = plus<ElementCompute_>
+  typename BinaryOp_ = plus<ElementCompute_>,
+  bool StoreT_ = true,
+  typename ElementVector_ = ElementC_
 >
 class LinearCombinationBiasElementwise {
 public:
 
   using ElementOutput = ElementC_;
   using ElementC = ElementC_;
   using ElementAccumulator = ElementAccumulator_;
   using ElementCompute = ElementCompute_;
   using ElementZ = ElementZ_;
   using ElementT = ElementT_;
+  using ElementVector = ElementVector_;
   static int const kElementsPerAccess = ElementsPerAccess;
   static int const kCount = kElementsPerAccess;
 
   using ElementwiseOp = ElementwiseOp_;
   using BinaryOp = BinaryOp_;
 
   // Indicates that this epilogue applies only one binary operation
@@ -91,15 +94,15 @@
 
   static bool const kIsHeavy = ElementwiseOp::kIsHeavy;
 
   /// If true, the 'Z' tensor is stored
   static bool const kStoreZ = true;
 
   /// If true, the 'T' tensor is stored
-  static bool const kStoreT = true;
+  static bool const kStoreT = StoreT_;
 
   /// Host-constructable parameters structure
   struct Params {
 
     ElementCompute alpha;                  ///< scales accumulators
     ElementCompute beta;                   ///< scales source tensor
     ElementCompute const *alpha_ptr;       ///< pointer to accumulator scalar - if not null, loads it from memory
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_bias_relu.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_bias_relu.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -200,24 +200,26 @@
 /// EpilogueWithBroadcast::OutputOp
 template <
   typename ElementC_,
   typename ElementAccumulator_,
   typename ElementCompute_,
   typename ElementZ_,
   int ElementsPerAccess,
-  bool StoreT = true
+  bool StoreT_ = true,
+  typename ElementVector_ = ElementC_
 >
 class LinearCombinationBiasRelu {
 public:
 
   using ElementOutput = ElementC_;
   using ElementC = ElementC_;
   using ElementAccumulator = ElementAccumulator_;
   using ElementCompute = ElementCompute_;
   using ElementZ = ElementZ_;
+  using ElementVector = ElementVector_;
 
   using ElementT = uint1b_t;
 
   static int const kElementsPerAccess = ElementsPerAccess;
   static int const kCount = kElementsPerAccess;
 
   using ElementwiseOp = ReLu<ElementCompute>;
@@ -232,15 +234,15 @@
   using FragmentZ = Array<ElementZ, kElementsPerAccess>;
   using FragmentT = Array<ElementT, kElementsPerAccess>;
 
   /// If true, the 'Z' tensor is stored
   static bool const kStoreZ = true;
 
   /// If true, the 'T' tensor is stored
-  static bool const kStoreT = StoreT;
+  static bool const kStoreT = StoreT_;
 
   /// Host-constructable parameters structure
   struct Params {
 
     ElementCompute alpha;                  ///< scales accumulators
     ElementCompute beta;                   ///< scales source tensor
     ElementCompute const *alpha_ptr;       ///< pointer to accumulator scalar - if not null, loads it from memory
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_clamp.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_clamp.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_dgelu.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_dgelu.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_drelu.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_drelu.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_gelu.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_gelu.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_generic.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_generic.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_hardswish.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_hardswish.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /*************************************************************************************************** 
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_leaky_relu.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_leaky_relu.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_params.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_params.h`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_planar_complex.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_planar_complex.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_relu.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_relu.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_relu0.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_relu0.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_residual_block.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_residual_block.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -55,23 +55,26 @@
 
 /// Models a residual block of the form: UnaryOp(BinaryOp(BinaryOp(ActivationOp(TensorOp(X) + bias), residual1), residual2))
 template <typename ElementOutput_, typename ElementAccumulator_,
           typename ElementCompute_, typename ElementC_, int ElementsPerAccess,
           template <typename T> class ActivationOp_,
           template <typename T> class BinaryOp1_,
           template <typename T> class UnaryOp_,
-          template <typename T> class BinaryOp2_ = detail::NoOp>
+          template <typename T> class BinaryOp2_ = detail::NoOp,
+          bool StoreT_ = false,
+          typename ElementVector_ = ElementC_>
 class LinearCombinationResidualBlock {
 public:
   static bool const kIsSingleSource = false;
 
   using ElementOutput = ElementC_;
   using ElementC = ElementC_;
   using ElementAccumulator = ElementAccumulator_;
   using ElementCompute = ElementCompute_;
+  using ElementVector = ElementVector_;
   static int const kElementsPerAccess = ElementsPerAccess;
   static int const kCount = kElementsPerAccess;
 
   using UnaryOp = UnaryOp_<Array<ElementCompute, kCount>>;
   using BinaryOp1 = BinaryOp1_<Array<ElementCompute, kCount>>;
   using BinaryOp2 = BinaryOp2_<Array<ElementCompute, kCount>>;
   using ActivationOp = ActivationOp_<Array<ElementCompute, kCount>>;
@@ -84,15 +87,15 @@
   using ElementZ = ElementOutput_;
   using ElementT = ElementZ;
   using FragmentZ = Array<ElementZ, kElementsPerAccess>;
   using FragmentT = Array<ElementT, kElementsPerAccess>;
 
   static bool const kIsHeavy = true;
   static bool const kStoreZ = true;
-  static bool const kStoreT = false;
+  static bool const kStoreT = StoreT_;
 
   /// Host-constructable parameters structure
   struct Params {
 
     ElementCompute alpha;                  ///< scales accumulators
     ElementCompute beta;                   ///< scales residual input
     ElementCompute const *alpha_ptr{nullptr};       ///< pointer to accumulator scalar - if not null, loads it from memory
@@ -175,26 +178,29 @@
 };
 
 /// Models a residual block of the form: UnaryOp(BinaryOp(ActivationOp(TensorOp(X) + bias), residual))
 template <typename ElementOutput_, typename ElementAccumulator_,
           typename ElementCompute_, typename ElementC_, int ElementsPerAccess,
           template <typename T> class ActivationOp_,
           template <typename T> class BinaryOp1_,
-          template <typename T> class UnaryOp_>
+          template <typename T> class UnaryOp_,
+          bool StoreT_,
+          typename ElementVector_>
 class LinearCombinationResidualBlock<ElementOutput_, ElementAccumulator_,
           ElementCompute_, ElementC_, ElementsPerAccess,
           ActivationOp_, BinaryOp1_, UnaryOp_,
-          detail::NoOp> {
+          detail::NoOp, StoreT_, ElementVector_> {
 public:
   static bool const kIsSingleSource = true;
 
   using ElementOutput = ElementC_;
   using ElementC = ElementC_;
   using ElementAccumulator = ElementAccumulator_;
   using ElementCompute = ElementCompute_;
+  using ElementVector = ElementVector_;
   static int const kElementsPerAccess = ElementsPerAccess;
   static int const kCount = kElementsPerAccess;
 
   using UnaryOp = UnaryOp_<Array<ElementCompute, kCount>>;
   using BinaryOp = BinaryOp1_<Array<ElementCompute, kCount>>;
   using ActivationOp = ActivationOp_<Array<ElementCompute, kCount>>;
 
@@ -206,15 +212,15 @@
   using ElementZ = ElementOutput_;
   using ElementT = ElementZ;
   using FragmentZ = Array<ElementZ, kElementsPerAccess>;
   using FragmentT = Array<ElementT, kElementsPerAccess>;
 
   static bool const kIsHeavy = true;
   static bool const kStoreZ = true;
-  static bool const kStoreT = false;
+  static bool const kStoreT = StoreT_;
 
   /// Host-constructable parameters structure
   struct Params {
 
     ElementCompute alpha;                  ///< scales accumulators
     ElementCompute beta;                   ///< scales residual input
     ElementCompute const *alpha_ptr{nullptr};       ///< pointer to accumulator scalar - if not null, loads it from memory
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_sigmoid.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_sigmoid.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_silu.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_silu.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination_with_elementwise.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/linear_combination.h`

 * *Files 22% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -25,207 +25,279 @@
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /*! \file
-  
-  \brief Functor performing linear combination with elementwise
+  \brief Functor performing linear combination operations used by epilogues.
 */
 
 #pragma once
 
-#include <cutlass/half.h>
 #include "cutlass/cutlass.h"
 #include "cutlass/numeric_types.h"
 #include "cutlass/array.h"
-#include "cutlass/constants.h"
-#include "cutlass/fast_math.h"
 #include "cutlass/functional.h"
 #include "cutlass/numeric_conversion.h"
-#include "cutlass/epilogue/thread/activation.h"
+#include "cutlass/epilogue/thread/scale_type.h"
+#include "cutlass/epilogue/thread/linear_combination_params.h"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace epilogue {
 namespace thread {
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Applies a linear combination operator to an array of elements.
 ///
 /// D = alpha * accumulator + beta * source + uniform
 ///
 template <
-  typename ElementCompute_,                            ///< Data type returned by this functor
-  typename ElementAccumulator_,                        ///< Data type of accumulators
-  typename ElementSource_,                             ///< Data type of source tensor
-  typename ElementTensor_,                             ///< Data type of additional tensor
-  int Count,                                           ///< Number of elements computed per operation
+  typename ElementOutput_,                             ///< Data type used to load and store tensors
+  int Count,                                           ///< Number of elements computed per operation.
                                                        ///< Usually it is 128/sizeof_bits<ElementOutput_>,
                                                        ///< but we use 64 or 32 sometimes when there are not enough data to store
-  FloatRoundStyle Round = FloatRoundStyle::round_to_nearest
+  typename ElementAccumulator_ = ElementOutput_,       ///< Accumulator data type
+  typename ElementCompute_ = ElementOutput_,           ///< Data type used to compute linear combination
+  ScaleType::Kind Scale = ScaleType::Default,          ///< Control Alpha and Beta scaling
+  FloatRoundStyle Round = FloatRoundStyle::round_to_nearest,
+  typename ElementSource_ = ElementOutput_
 >
-class LinearCombinationWithElementwise {
+class LinearCombination {
 public:
 
-  using ElementOutput = ElementSource_;
-  using ElementCompute = ElementCompute_;
+  using ElementOutput = ElementOutput_;
   using ElementAccumulator = ElementAccumulator_;
-  using ElementSource = ElementSource_;
-  using ElementTensor = ElementTensor_;
-
-  static bool const kIsHeavy = true;
+  using ElementCompute = ElementCompute_;
+  using ElementC = ElementSource_;
+  using ElementD = ElementOutput_;
 
   static int const kCount = Count;
-
-  using FragmentCompute = Array<ElementCompute, kCount>;
+  static const ScaleType::Kind kScale = Scale;
+  using FragmentOutput = Array<ElementOutput, kCount>;
   using FragmentAccumulator = Array<ElementAccumulator, kCount>;
-  using FragmentSource = Array<ElementSource, kCount>;
-  using FragmentTensor = Array<ElementTensor, kCount>;
+  using ComputeFragment = Array<ElementCompute, kCount>;
 
+  using ParamsBase = LinearCombinationParams;
   static FloatRoundStyle const kRound = Round;
 
   /// Host-constructable parameters structure
-  struct Params {
-
+  struct Params : ParamsBase{
     ElementCompute alpha;                  ///< scales accumulators
     ElementCompute beta;                   ///< scales source tensor
-    ElementCompute threshold;              ///< minimum value that is output 
     ElementCompute const *alpha_ptr;       ///< pointer to accumulator scalar - if not null, loads it from memory
     ElementCompute const *beta_ptr;        ///< pointer to source scalar - if not null, loads it from memory
-    //
-    // Methods
-    //
 
     CUTLASS_HOST_DEVICE
-    Params(): 
-      alpha(ElementCompute(1)), 
+    Params():
+      ParamsBase(
+        ElementCompute(1),
+        ElementCompute(0)
+      ),
+      alpha(ElementCompute(1)),
       beta(ElementCompute(0)),
-      threshold(ElementCompute(0)), 
-      alpha_ptr(nullptr), 
+      alpha_ptr(nullptr),
       beta_ptr(nullptr) { }
 
     CUTLASS_HOST_DEVICE
     Params(
       ElementCompute alpha,
-      ElementCompute beta,
-      ElementCompute threshold = ElementCompute(0)
-    ): alpha(alpha), beta(beta), threshold(threshold), alpha_ptr(nullptr), beta_ptr(nullptr) {
+      ElementCompute beta
+    ):
+      ParamsBase(alpha, beta),
+      alpha(alpha), beta(beta), alpha_ptr(nullptr), beta_ptr(nullptr) { }
 
-    }
+    CUTLASS_HOST_DEVICE
+    Params(
+      ElementCompute alpha
+    ):
+      ParamsBase(alpha, ElementCompute(0)),
+      alpha(alpha), beta(0), alpha_ptr(nullptr), beta_ptr(nullptr) { }
 
     CUTLASS_HOST_DEVICE
     Params(
       ElementCompute const *alpha_ptr,
-      ElementCompute const *beta_ptr,
-      ElementCompute threshold = ElementCompute(0)
-    ): alpha(0), beta(0), threshold(threshold), alpha_ptr(alpha_ptr), beta_ptr(beta_ptr) {
+      ElementCompute const *beta_ptr
+    ):
+      ParamsBase(*alpha_ptr, *beta_ptr),
+      alpha(0), beta(0), alpha_ptr(alpha_ptr), beta_ptr(beta_ptr) { }
+
+    CUTLASS_HOST_DEVICE
+    Params(
+      ElementCompute const *alpha_ptr
+    ):
+      ParamsBase(*alpha_ptr, ElementCompute(0)),
+      alpha(0), beta(0), alpha_ptr(alpha_ptr), beta_ptr(nullptr) { }
 
+    CUTLASS_HOST_DEVICE
+    Params(
+      ParamsBase const& base
+    ): ParamsBase(base), alpha_ptr(nullptr), beta_ptr(nullptr) {
+      #if defined(__CUDA_ARCH__)
+      alpha = reinterpret_cast<ElementCompute const&>(base.alpha_data);
+      beta = reinterpret_cast<ElementCompute const&>(base.beta_data);
+      #else
+      memcpy( alpha, base.alpha_data, sizeof(ElementCompute) );
+      memcpy( beta, base.alpha_data, sizeof(ElementCompute) );
+      #endif
     }
   };
 
 private:
 
   //
   // Data members
   //
 
   ElementCompute alpha_;
   ElementCompute beta_;
-  ElementCompute threshold_;
-  bool participates_in_reduction_;
 
 public:
 
   /// Constructs the function object, possibly loading from pointers in host memory
   CUTLASS_HOST_DEVICE
-  LinearCombinationWithElementwise(Params const &params) {
-
+  LinearCombination(Params const &params) {
     alpha_ = (params.alpha_ptr ? *params.alpha_ptr : params.alpha);
     beta_ = (params.beta_ptr ? *params.beta_ptr : params.beta);
-    threshold_ = params.threshold;
-    participates_in_reduction_ = true;
   }
 
   /// Returns true if source is needed
   CUTLASS_HOST_DEVICE
   bool is_source_needed() const {
-    return beta_ != ElementCompute(0);
-  }
+    if (Scale == ScaleType::NoBetaScaling) return true;
 
-  /// Returns true if the threadblock computes the reduction
-  CUTLASS_HOST_DEVICE
-  bool participates_in_reduction() const {
-    return participates_in_reduction_;
+    if (Scale == ScaleType::OnlyAlphaScaling) return false;
+
+    if (Scale == ScaleType::Nothing) return false;
+
+    return beta_ != ElementCompute(0);
   }
 
   /// Functionally required for serial reduction in the epilogue
   CUTLASS_HOST_DEVICE
   void set_k_partition(int k_partition, int k_partition_count) {
     if (k_partition) {
       beta_ = ElementCompute(1);
     }
-
-    if (k_partition != k_partition_count - 1) {
-      // set to NaN to make ReLU no-op for all except last k partitions
-      int64_t allones = -1;
-      threshold_ = reinterpret_cast<ElementCompute const &>(allones);
-      // Avoid computing the reduction if this isn't the final Split-K slice
-      participates_in_reduction_ = false;
-    }
   }
-  
+
   /// Computes linear scaling: D = alpha * accumulator + beta * source
   CUTLASS_HOST_DEVICE
-  FragmentCompute operator()(
-    FragmentAccumulator const &accumulator, 
-    FragmentSource const &source,
-    FragmentTensor const &tensor) const {
+  FragmentOutput operator()(
+    FragmentAccumulator const &accumulator,
+    FragmentOutput const &source) const {
 
     // Convert source to interal compute numeric type
-    NumericArrayConverter<ElementCompute, ElementSource, kCount, Round> source_converter;
+    NumericArrayConverter<ElementCompute, ElementOutput, kCount, Round> source_converter;
     NumericArrayConverter<ElementCompute, ElementAccumulator, kCount, Round> accumulator_converter;
 
-    FragmentCompute converted_source = source_converter(source);
-    FragmentCompute converted_accumulator = accumulator_converter(accumulator);
+    // Convert to destination numeric type
+    NumericArrayConverter<ElementOutput, ElementCompute, kCount, Round> destination_converter;
+
+    ComputeFragment converted_source = source_converter(source);
+    ComputeFragment converted_accumulator = accumulator_converter(accumulator);
+
+    if (Scale == ScaleType::Nothing)
+      return destination_converter(converted_accumulator);
 
     // Perform binary operations
-    FragmentCompute intermediate;
+    ComputeFragment intermediate;
+
+    multiplies<ComputeFragment> mul_add_source;
+    multiply_add<ComputeFragment> mul_add_accumulator;
 
-    multiplies<FragmentCompute> mul_add_source;
-    multiply_add<FragmentCompute> mul_add_accumulator;
+    if (Scale == ScaleType::NoBetaScaling)
+      intermediate = converted_source;
+    else
+      intermediate = mul_add_source(beta_, converted_source);                             // X =  beta * C + uniform
 
-    intermediate = mul_add_source(beta_, converted_source);                             // X =  beta * C + uniform
     intermediate = mul_add_accumulator(alpha_, converted_accumulator, intermediate);    // D = alpha * Accum + X
 
-    return intermediate;
+    return destination_converter(intermediate);
   }
 
   /// Computes linear scaling: D = alpha * accumulator
   CUTLASS_HOST_DEVICE
-  FragmentCompute operator()(
-    FragmentAccumulator const &accumulator,
-    FragmentTensor const &tensor) const {
+  FragmentOutput operator()(
+    FragmentAccumulator const &accumulator) const {
 
     // Convert source to interal compute numeric type
     NumericArrayConverter<ElementCompute, ElementAccumulator, kCount, Round> accumulator_converter;
 
-    FragmentCompute converted_accumulator = accumulator_converter(accumulator);
+    // Convert to destination numeric type
+    NumericArrayConverter<ElementOutput, ElementCompute, kCount, Round> destination_converter;
 
-    // Perform binary operations
-    FragmentCompute intermediate;
+    ComputeFragment converted_accumulator = accumulator_converter(accumulator);
 
-    multiplies<FragmentCompute> mul_accumulator;
+    if (Scale == ScaleType::Nothing)
+      return destination_converter(converted_accumulator);
+
+    // Perform binary operations
+    ComputeFragment intermediate;
+    multiplies<ComputeFragment> mul_accumulator;
 
     intermediate = mul_accumulator(alpha_, converted_accumulator);    // D = alpha * Accum
 
-    return intermediate;
+    return destination_converter(intermediate);
+  }
+
+  //
+  // Specializations for scalar (for use with cute::collective::DefaultEpilogue)
+  //
+  CUTLASS_HOST_DEVICE
+  ElementD operator()(ElementAccumulator const accumulator, ElementC const source) const {
+    // Convert everything to Compute type, do compute, and then store to output type
+    NumericConverter<ElementCompute, ElementAccumulator, Round> accumulator_converter;
+    [[maybe_unused]] NumericConverter<ElementCompute, ElementC, Round> source_converter;
+    NumericConverter<ElementD, ElementCompute, Round> destination_converter;
+
+    // Convert to destination numeric type
+
+    ElementCompute converted_accumulator = accumulator_converter(accumulator);
+    if constexpr (Scale == ScaleType::Nothing) {
+      return destination_converter(converted_accumulator);
+    }
+
+    // Perform binary operations
+    ElementCompute intermediate;
+    multiplies<ElementCompute> multiply;
+    multiply_add<ElementCompute> madd;
+
+    if constexpr (Scale == ScaleType::NoBetaScaling) {
+      intermediate = source_converter(source);
+    }
+    else {
+      intermediate = multiply(beta_, source);                            // X =  beta * C + uniform
+    }
+
+    intermediate = madd(alpha_, converted_accumulator, intermediate);    // D = alpha * Accum + X
+    return destination_converter(intermediate);
+  }
+
+  CUTLASS_HOST_DEVICE
+  ElementD operator()(ElementAccumulator const accumulator) const {
+    // Convert everything to Compute type, do compute, and then store to output type
+    NumericConverter<ElementCompute, ElementAccumulator, Round> accumulator_converter;
+    NumericConverter<ElementD, ElementCompute, Round> destination_converter;
+    ElementCompute converted_accumulator = accumulator_converter(accumulator);
+
+    // Convert to destination numeric type
+    if constexpr (Scale == ScaleType::Nothing) {
+      return destination_converter(converted_accumulator);
+    }
+
+    // Perform binary operations
+    ElementCompute intermediate;
+    multiplies<ElementCompute> multiply;
+
+    intermediate = multiply(alpha_, accumulator);    // D = alpha * Accum
+    return destination_converter(intermediate);
   }
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 } // namespace thread
 } // namespace epilogue
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/reduction_op.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/reduction_op.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/scale_type.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/thread/scale_type.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_complex_tensor_op.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_complex_tensor_op.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -73,15 +73,15 @@
 /////////////////////////////////////////////////////////////////////////////////////////////////
 /// Specialization and defines sensible defaults for epilogues for complex*complex case
 //  4 real-valued mma operations (Complex)
 //  A = (ar + j ai), B (br +j bi), D = AB
 //  D = dr + j di = (ar*br - ai*bi) + j (ar*bi + ai*br) 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 template <
-  /// Epilouge Shape
+  /// Epilogue Shape
   typename Shape_,
   /// Warp-level mma operator
   typename WarpMmaTensorOp_,
   /// Number of k partitions
   int PartitionsK,
   /// Epilogue output operator
   typename OutputOp_,
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_complex_tensor_op_blas3.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_complex_tensor_op_blas3.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -74,15 +74,15 @@
 /////////////////////////////////////////////////////////////////////////////////////////////////
 /// Specialization and defines sensible defaults for epilogues for complex*complex case
 //  4 real-valued mma operations (Complex)
 //  A = (ar + j ai), B (br +j bi), D = AB
 //  D = dr + j di = (ar*br - ai*bi) + j (ar*bi + ai*br) 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 template <
-  /// Epilouge Shape
+  /// Epilogue Shape
   typename Shape_,
   /// Warp-level mma operator
   typename WarpMmaTensorOp_,
   /// Number of k partitions
   int PartitionsK,
   /// Epilogue output operator
   typename OutputOp_,
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_direct_store.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_direct_store.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_planar_complex.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_planar_complex.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_simt.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_simt.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -38,15 +38,18 @@
 
 #pragma once
 
 #include "cutlass/cutlass.h"
 #include "cutlass/numeric_types.h"
 #include "cutlass/array.h"
 
+#include "cutlass/arch/mma.h"
+
 #include "cutlass/gemm/gemm.h"
+#include "cutlass/gemm/warp/mma.h"
 
 #include "cutlass/epilogue/thread/linear_combination.h"
 #include "cutlass/epilogue/thread/linear_combination_clamp.h"
 #include "cutlass/epilogue/thread/linear_combination_relu.h"
 #include "cutlass/epilogue/thread/linear_combination_gelu.h"
 #include "cutlass/epilogue/thread/linear_combination_sigmoid.h"
 #include "cutlass/epilogue/thread/linear_combination_planar_complex.h"
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_tensor_op.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_tensor_op.h`

 * *Files 3% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -132,22 +132,23 @@
     ThreadMap,
     float
   >;
 
   static int const kFragmentsPerIteration = 2;
 };
 
-/// Partial specialization for int32_t <= int32_t x 4
+/// Partial specialization for int32_t <= int32_t
 template <
+  int ElementsPerAccess,
   typename ThreadblockShape,
   typename WarpShape,
   typename InstructionShape,
   typename ThreadMap
 >
-struct DefaultIteratorsTensorOp<int32_t, int32_t, 4, ThreadblockShape, WarpShape, InstructionShape, ThreadMap> {
+struct DefaultIteratorsTensorOp<int32_t, int32_t, ElementsPerAccess, ThreadblockShape, WarpShape, InstructionShape, ThreadMap> {
   
   using WarpTileIterator = cutlass::epilogue::warp::TileIteratorTensorOp<
     WarpShape,
     InstructionShape,
     int32_t,
     layout::RowMajor
   >;
@@ -156,22 +157,23 @@
     ThreadMap,
     int32_t
   >;
 
   static int const kFragmentsPerIteration = 1;
 };
 
-/// Partial specialization for float <= int32_t x 4
+/// Partial specialization for float <= int32_t
 template <
+  int ElementsPerAccess,
   typename ThreadblockShape,
   typename WarpShape,
   typename InstructionShape,
   typename ThreadMap
 >
-struct DefaultIteratorsTensorOp<float, int32_t, 4, ThreadblockShape, WarpShape, InstructionShape, ThreadMap> {
+struct DefaultIteratorsTensorOp<float, int32_t, ElementsPerAccess, ThreadblockShape, WarpShape, InstructionShape, ThreadMap> {
 
   using WarpTileIterator = cutlass::epilogue::warp::TileIteratorTensorOp<
     WarpShape,
     InstructionShape,
     int32_t,
     layout::RowMajor
   >;
@@ -218,14 +220,52 @@
     8,
     8
   >;
 
   static int const kFragmentsPerIteration = 2;
 };
 
+/// Partial specialization for half <= int32_t x 8 epilogues avoids shared memory bank conflicts.
+template <
+  typename ThreadblockShape,
+  typename WarpShape,
+  typename InstructionShape,
+  typename ThreadMap
+>
+struct DefaultIteratorsTensorOp<
+  half_t, 
+  int32_t, 
+  8, 
+  ThreadblockShape, 
+  WarpShape, 
+  InstructionShape, 
+  ThreadMap> {
+  
+  using WarpTileIterator = cutlass::epilogue::warp::TileIteratorTensorOpMixed<
+    WarpShape,
+    InstructionShape,
+    int32_t,
+    32,
+    16,
+    8,
+    8
+  >;
+
+  using SharedLoadIterator = cutlass::epilogue::threadblock::SharedLoadIteratorMixed<
+    ThreadMap,
+    int32_t,
+    32,
+    16,
+    8,
+    8
+  >;
+
+  static int const kFragmentsPerIteration = 2;
+};
+
 /// Partial specialization for int8/int4b_t <= int32 x 16/8 epilogues avoids shared memory bank conflicts.
 /// Threadblock::kN = 256 still has bank conflicts.
 template <
   typename ElementOutput,
   int ElementsPerAccess,
   typename ThreadblockShape,
   typename WarpShape,
@@ -264,15 +304,15 @@
     WarpShape,
     InstructionShape,
     int32_t,
     layout::RowMajor
   >;
 
   using WarpTileIterator = typename platform::conditional<
-                             (ThreadblockShape::kN == 256),
+                             (ThreadblockShape::kN == 256) || (ThreadblockShape::kN == 128 && ElementsPerAccess == 8),
                              WarpTileIteratorNotMixed,
                              WarpTileIteratorMixed>::type;
 
   using SharedLoadIteratorMixed = cutlass::epilogue::threadblock::SharedLoadIteratorMixed<
     ThreadMap,
     int32_t,
     32,
@@ -283,15 +323,15 @@
 
   using SharedLoadIteratorNotMixed = cutlass::epilogue::threadblock::SharedLoadIterator<
     ThreadMap,
     int32_t
   >;
 
   using SharedLoadIterator = typename platform::conditional<
-                             (ThreadblockShape::kN == 256),
+                             (ThreadblockShape::kN == 256) || (ThreadblockShape::kN == 128 && ElementsPerAccess == 8),
                              SharedLoadIteratorNotMixed,
                              SharedLoadIteratorMixed>::type;
 
   static int const kFragmentsPerIteration = 1;
 };
 
 /// Partial specialization for float_e4m3_t <= float x 16/8 epilogues avoids shared memory bank conflicts.
@@ -331,15 +371,15 @@
     WarpShape,
     InstructionShape,
     float,
     layout::RowMajor
   >;
 
   using WarpTileIterator = typename platform::conditional<
-                             (ThreadblockShape::kN == 256),
+                             (ThreadblockShape::kN == 256) || (ThreadblockShape::kN == 128 && ElementsPerAccess == 8),
                              WarpTileIteratorNotMixed,
                              WarpTileIteratorMixed>::type;
 
   using SharedLoadIteratorMixed = cutlass::epilogue::threadblock::SharedLoadIteratorMixed<
     ThreadMap,
     float,
     32,
@@ -350,15 +390,15 @@
 
   using SharedLoadIteratorNotMixed = cutlass::epilogue::threadblock::SharedLoadIterator<
     ThreadMap,
     float
   >;
 
   using SharedLoadIterator = typename platform::conditional<
-                             (ThreadblockShape::kN == 256),
+                             (ThreadblockShape::kN == 256) || (ThreadblockShape::kN == 128 && ElementsPerAccess == 8),
                              SharedLoadIteratorNotMixed,
                              SharedLoadIteratorMixed>::type;
 
   static int const kFragmentsPerIteration = 1;
 };
 
 /// Partial specialization for float_e5m2_t <= float x 16/8 epilogues avoids shared memory bank conflicts.
@@ -398,15 +438,15 @@
     WarpShape,
     InstructionShape,
     float,
     layout::RowMajor
   >;
 
   using WarpTileIterator = typename platform::conditional<
-                             (ThreadblockShape::kN == 256),
+                             (ThreadblockShape::kN == 256) || (ThreadblockShape::kN == 128 && ElementsPerAccess == 8),
                              WarpTileIteratorNotMixed,
                              WarpTileIteratorMixed>::type;
 
   using SharedLoadIteratorMixed = cutlass::epilogue::threadblock::SharedLoadIteratorMixed<
     ThreadMap,
     float,
     32,
@@ -417,15 +457,15 @@
 
   using SharedLoadIteratorNotMixed = cutlass::epilogue::threadblock::SharedLoadIterator<
     ThreadMap,
     float
   >;
 
   using SharedLoadIterator = typename platform::conditional<
-                             (ThreadblockShape::kN == 256),
+                             (ThreadblockShape::kN == 256) || (ThreadblockShape::kN == 128 && ElementsPerAccess == 8),
                              SharedLoadIteratorNotMixed,
                              SharedLoadIteratorMixed>::type;
 
   static int const kFragmentsPerIteration = 1;
 };
 
 } // namespace detail
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_tensor_op_blas3.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_tensor_op_blas3.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_volta_tensor_op.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_volta_tensor_op.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_with_broadcast.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_with_broadcast.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_with_reduction.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_with_reduction.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_wmma_tensor_op.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_epilogue_wmma_tensor_op.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_simt.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_simt.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_tensor_op.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_tensor_op.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_volta_tensor_op.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_volta_tensor_op.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_wmma_tensor_op.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/default_thread_map_wmma_tensor_op.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/direct_store_epilogue_iterator.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/direct_store_epilogue_iterator.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/interleaved_epilogue.h`

 * *Files 13% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -30,192 +30,237 @@
  **************************************************************************************************/
 /*! \file
   \brief Epilogue for threadblock scoped GEMMs using Tensor Ops.
 
   The epilogue rearranges the result of a matrix product through shared memory to match canonical
   tensor layouts in global memory. Epilogues support conversion and reduction operations.
 
-  The shared memory resource is time-sliced across warps.
 */
 
 #pragma once
 
-#if defined(__CUDACC_RTC__)
-#include <cuda/std/cassert>
-#else
-#include <assert.h>
-#endif
-
 #include "cutlass/cutlass.h"
 #include "cutlass/numeric_types.h"
 #include "cutlass/array.h"
 #include "cutlass/layout/vector.h"
 #include "cutlass/layout/tensor.h"
 #include "cutlass/tensor_coord.h"
 #include "cutlass/aligned_buffer.h"
-#include "cutlass/functional.h"
 
 #include "cutlass/gemm/gemm.h"
 
 #include "cutlass/transform/pitch_linear_thread_map.h"
 #include "cutlass/transform/threadblock/regular_tile_iterator.h"
 
-#include "cutlass/epilogue/threadblock/epilogue_base.h"
 #include "cutlass/epilogue/threadblock/epilogue_base_streamk.h"
 #include "cutlass/epilogue/threadblock/predicated_tile_iterator.h"
 
 ////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace epilogue {
 namespace threadblock {
 
-
 ////////////////////////////////////////////////////////////////////////////////
 
-/// Epilogue operator
+/// Epilogue operator without splitk
 template <
-  typename Shape_,                          ///< Shape of threadblock tile (concept: GemmShape)
-  typename WarpMmaOperator_,                ///< Warp-level MMA operator (concept: gemm::warp::MmaTensorOp)
-  int PartitionsK,                          ///< Number of partitions of the K dimension
-  typename OutputTileIterator_,             ///< Tile iterator reading and writing output tensors
-  typename AccumulatorFragmentIterator_,    ///< Fragment iterator selecting accumulators
-  typename WarpTileIterator_,               ///< Warp-scoped tile iterator writing accumulators to SMEM
-  typename SharedLoadIterator_,             ///< Threadblock-scoped tile iterator loading from SMEM
-  typename OutputOp_,                       ///< Output operator
-  typename Padding_,                        ///< Padding added to SMEM allocation to avoid bank conflicts (concept: MatrixShape)
-  int FragmentsPerPartition = 1,            ///< Used to coarsten the epilogue granularity
-  int IterationsUnroll =                    ///< Used to reduce binary size when epilogue op is large
-    (!IsEpilogueFunctorHeavy<OutputOp_>::value)
->
-class Epilogue :
-  public EpilogueBase<
-    Shape_,
-    typename WarpMmaOperator_::Shape,
-    PartitionsK,
-    AccumulatorFragmentIterator_,
-    WarpTileIterator_,
-    Padding_,
-    FragmentsPerPartition>,
+    /// Shape of threadblock tile (concept: GemmShape)
+    typename Shape_,
+    /// Warp-level MMA operator (concept: gemm::warp::MmaTensorOp)
+    typename WarpMmaOperator_,
+    /// Number of partitions of the K dimension
+    int PartitionsK,
+    /// Tile iterator reading and writing output tensors
+    typename OutputTileIterator_,
+    /// Fragment iterator selecting accumulators
+    typename AccumulatorFragmentIterator_,
+    /// Output operator
+    typename OutputOp_,
+    /// Number of interleaved k
+    int InterleavedK>
+class InterleavedEpilogue :
   public EpilogueBaseStreamK<
     Shape_,
     PartitionsK,
     WarpMmaOperator_,
     AccumulatorFragmentIterator_>
 {
-
 public:
 
-  using Base = EpilogueBase<
-    Shape_,
-    typename WarpMmaOperator_::Shape,
-    PartitionsK,
-    AccumulatorFragmentIterator_,
-    WarpTileIterator_,
-    Padding_,
-    FragmentsPerPartition>;
-
   using BaseStreamK = EpilogueBaseStreamK<
     Shape_,
     PartitionsK,
     WarpMmaOperator_,
     AccumulatorFragmentIterator_>;
 
   using Shape = Shape_;
   using WarpMmaOperator = WarpMmaOperator_;
   static int const kPartitionsK = PartitionsK;
-  using OutputTileIterator = OutputTileIterator_;
   using AccumulatorFragmentIterator = AccumulatorFragmentIterator_;
-  using WarpTileIterator = WarpTileIterator_;
-  using SharedLoadIterator = SharedLoadIterator_;
+  using OutputTileIterator = OutputTileIterator_;
   using OutputOp = OutputOp_;
-  using Padding = Padding_;
-  using Layout = layout::RowMajor;
-  using LongIndex = typename Layout::LongIndex;
-
-  /// Number of warps per block
-  using WarpCount = typename Base::WarpCount;
-
-  /// Number of threads per block
-  static int const kBlockThreads = 32 * WarpCount::kCount;
 
-  /// Per-thread accumulator tile type
-  using AccumulatorTile = typename Base::AccumulatorTile;
-
-  /// Numerical accumulation element type
-  using ElementAccumulator = typename WarpMmaOperator::ElementC;
+  /// The complete warp-level accumulator tile
+  using AccumulatorTile = typename AccumulatorFragmentIterator::AccumulatorTile;
 
   /// Fragment type used by the accumulator tile's fragment iterator
   using AccumulatorFragment = typename AccumulatorFragmentIterator::Fragment;
 
+  /// Accumulator element
+  using ElementAccumulator = typename AccumulatorTile::Element;
+
   /// Output element
   using ElementOutput = typename OutputTileIterator::Element;
 
   /// Output access size
   static int const kElementsPerAccess = OutputTileIterator::kElementsPerAccess;
 
   /// Tensor reference to destination tensor
   using TensorRef = typename OutputTileIterator::TensorRef;
 
   /// Tensor reference to sync tensor
-  using SyncTensorRef = typename cutlass::TensorRef<int, cutlass::layout::PackedVectorLayout>;
+  using SyncTensorRef =
+      typename cutlass::TensorRef<int, cutlass::layout::PackedVectorLayout>;
 
   /// Const tensor reference to source tensor
   using ConstTensorRef = typename OutputTileIterator::ConstTensorRef;
 
-  /// Vector type used by the global output iterator
-  using OutputAccessType = Array<
-    typename OutputTileIterator::Element, OutputTileIterator::kElementsPerAccess>;
+  /// Array type used to output
+  using OutputAccessType = Array<typename OutputTileIterator::Element,
+                                 OutputTileIterator::kElementsPerAccess>;
+
+  /// Array type used by output functor
+  using AccumulatorAccessType =
+      Array<ElementAccumulator, OutputTileIterator::kElementsPerAccess>;
+
+  /// Number of warps
+  using WarpCount =
+      gemm::GemmShape<Shape::kM / WarpMmaOperator::Shape::kM,
+                      Shape::kN / WarpMmaOperator::Shape::kN, kPartitionsK>;
 
-  /// Vector type used by the shared output iterator
-  using AccumulatorAccessType = Array<typename WarpTileIterator::Element, OutputTileIterator::kElementsPerAccess>;
+public:
 
-  static int constexpr kSmemTiles = Base::kFragmentsPerIteration > 1 ? Base::kFragmentsPerIteration : kPartitionsK;
+  static_assert(OutputTileIterator::kElementsPerAccess,
+                "This must not be zero.");
 
-  static int constexpr kSmemPointerOffset = Base::SharedStorage::StorageShape::kCount / kSmemTiles;
+  static_assert(!(OutputTileIterator::Fragment::kElements %
+                  OutputTileIterator::kElementsPerAccess),
+                "Divisibility");
 
 public:
 
+  /// Aspect for when epilogue source is not needed
+  struct SourceAspectNotNeeded
+  {
+    /// Constructor
+    CUTLASS_DEVICE
+    SourceAspectNotNeeded()
+    {}
+
+    /// Invoke the output functor over each vector of output
+    CUTLASS_DEVICE
+    void apply_output_operator(
+      typename OutputTileIterator::Fragment &output_fragment,
+      OutputOp const &output_op,
+      typename AccumulatorFragmentIterator::Fragment const &aligned_accum_fragment)
+    {
+      OutputAccessType *output_frag_ptr =
+        reinterpret_cast<OutputAccessType *>(&output_fragment);
+
+      AccumulatorAccessType const *compute_frag_ptr =
+        reinterpret_cast<AccumulatorAccessType const *>(&aligned_accum_fragment);
+
+      int const kOutputOpIterations =
+        OutputTileIterator::Fragment::kElements / OutputTileIterator::kElementsPerAccess;
+
+      CUTLASS_PRAGMA_UNROLL
+      for (int i = 0; i < kOutputOpIterations; ++i)
+      {
+        // Call the output operator
+        output_frag_ptr[i] = output_op(compute_frag_ptr[i]);
+      }
+    }
+  };
+
+
+  /// Aspect for when epilogue source is needed
+  struct SourceAspectNeeded
+  {
+    OutputTileIterator source_iterator;
+
+    typename OutputTileIterator::Fragment source_fragment;
+
+    /// Invoke the output functor over each vector of output
+    CUTLASS_DEVICE
+    static void apply_output_operator(
+      typename OutputTileIterator::Fragment &output_fragment,
+      OutputOp const &output_op,
+      typename AccumulatorFragmentIterator::Fragment const &aligned_accum_fragment,
+      typename OutputTileIterator::Fragment const &source_fragment)
+    {
+      OutputAccessType *output_frag_ptr =
+        reinterpret_cast<OutputAccessType *>(&output_fragment);
+
+      AccumulatorAccessType const *compute_frag_ptr =
+        reinterpret_cast<AccumulatorAccessType const *>(&aligned_accum_fragment);
+
+      OutputAccessType const *source_frag_ptr =
+        reinterpret_cast<OutputAccessType const *>(&source_fragment);
 
-  static_assert(SharedLoadIterator::Fragment::kElements == OutputTileIterator::Fragment::kElements,
-    "Mismatch between shared load iterator and output tile iterator.");
+      int const kOutputOpIterations =
+        OutputTileIterator::Fragment::kElements / OutputTileIterator::kElementsPerAccess;
 
-  static_assert(OutputTileIterator::kElementsPerAccess, "OutputTileIterator::kElementsPerAccess must not be zero.");
+      CUTLASS_PRAGMA_UNROLL
+      for (int i = 0; i < kOutputOpIterations; ++i)
+      {
+        // Call the output operator
+        output_frag_ptr[i] = output_op(compute_frag_ptr[i], source_frag_ptr[i]);
+      }
+    }
 
-  static_assert(!(OutputTileIterator::Fragment::kElements % OutputTileIterator::kElementsPerAccess), 
-    "Divisibility");
+    /// Constructor
+    CUTLASS_DEVICE
+    SourceAspectNeeded(OutputTileIterator source_iterator) :
+      source_iterator(source_iterator)
+    {
+      source_fragment.clear();
+    }
 
-  static_assert(kPartitionsK == 1 || Base::kFragmentsPerIteration == 1, "One of these must be exactly 1.");
+    /// Invoke the output functor over each vector of output
+    CUTLASS_DEVICE
+    void apply_output_operator(
+      typename OutputTileIterator::Fragment &output_fragment,
+      OutputOp const &output_op,
+      typename AccumulatorFragmentIterator::Fragment const &aligned_accum_fragment)
+    {
+      // Load addend source fragment from global memory
+      source_iterator.load(source_fragment);
+      ++source_iterator;
 
-private:
+      apply_output_operator(output_fragment, output_op, aligned_accum_fragment, source_fragment);
+    }
+  };
 
-  /// Loads fragment from shared memory aligned with output tensor
-  SharedLoadIterator shared_load_iterator_;
 
-  /// Thread index in the threadblock
-  int thread_idx;
+  /// Shared storage allocation needed by the epilogue
+  struct SharedStorage {};
 
-  /// Warp index in the threadblock
-  int warp_idx;
 
 public:
 
   /// Constructor
   CUTLASS_DEVICE
-  Epilogue(
-      typename Base::SharedStorage &shared_storage,   ///< Shared storage object
-      int thread_idx,                                 ///< ID of a thread within the threadblock
-      int warp_idx,                                   ///< ID of warp within threadblock
-      int lane_idx)                                   ///< Id of thread within warp
+  InterleavedEpilogue(
+      SharedStorage &shared_storage,  ///< Shared storage object
+      int thread_idx,                 ///< ID of a thread within the threadblock
+      int warp_idx,                   ///< ID of warp within threadblock
+      int lane_idx)                   ///< Id of thread within warp
   :
-      Base(shared_storage, thread_idx, warp_idx, lane_idx),
-      BaseStreamK(thread_idx),
-      shared_load_iterator_(shared_storage.reference(), thread_idx),
-      thread_idx(thread_idx),
-      warp_idx(warp_idx)
+      BaseStreamK(thread_idx)
   {}
 
 
   /// Aggregates the accumulator sets shared by peer blocks in the global workspace,
   /// performing epilogue computations, writing to output
   CUTLASS_DEVICE
   void reduce(
@@ -227,202 +272,134 @@
       OutputTileIterator destination_iterator,        ///< Tile iterator for destination
       OutputTileIterator source_iterator)             ///< Threadblock tile coordinate in GEMM (in units of threadblock tiles)
   {
     // Redcuce peer accumulator fragments into one fragment
     AccumulatorFragment accum_fragment;
     BaseStreamK::reduce(accum_fragment, peer_idx_begin, peer_idx_end, reduce_fragment_idx, element_workspace);
 
-    // Store fragment to shared memory
-    this->warp_tile_iterator_.store(accum_fragment);
-
-    __syncthreads();
-
-    // Initialize/load source-fragment data
+    // Source-fragment data (zero-initialized for scenarios where the
+    // output operator allows us to skip loading it from global input)
     typename OutputTileIterator::Fragment source_fragment;
     source_fragment.clear();
 
     if (output_op.is_source_needed())
     {
       source_iterator += reduce_fragment_idx;
       source_iterator.load(source_fragment);
     }
 
-    // Load fragment from shared memory
-    typename SharedLoadIterator::Fragment aligned_accum_fragment;
-    shared_load_iterator_.load(aligned_accum_fragment);
-
-    // Add fragments shared by other k partitions
-    if (kPartitionsK > 1)
-    {
-      plus <typename SharedLoadIterator::Fragment> add_fragments;
-
-      CUTLASS_PRAGMA_UNROLL
-      for ( int i = 1; i < kPartitionsK; ++i) {
-        typename SharedLoadIterator::Fragment aligned_addend_fragment;
-        shared_load_iterator_.add_pointer_offset(kSmemPointerOffset);
-        shared_load_iterator_.load(aligned_addend_fragment);
-        aligned_accum_fragment = add_fragments(aligned_accum_fragment, aligned_addend_fragment);
-      }
-    }
-
     // Compute the output result
     typename OutputTileIterator::Fragment output_fragment;
 
     // Apply the output operator
-    apply_output_operator(output_fragment, output_op, aligned_accum_fragment, source_fragment);
+    SourceAspectNeeded::apply_output_operator(output_fragment, output_op, accum_fragment, source_fragment);
 
     // Store the final result
     destination_iterator += reduce_fragment_idx;
     destination_iterator.store(output_fragment);
   }
 
 
-  /// Streams the result to global memory
+  /// Perform the epilogue computations and stream the result to global memory.
+  CUTLASS_DEVICE
+  void operator()(
+    OutputOp const &output_op,                      ///< Output operator
+    OutputTileIterator destination_iterator,        ///< Tile iterator for destination
+    AccumulatorTile const &accumulators)            ///< Complete warp-level accumulator tile
+  {
+    operator()(output_op, destination_iterator, accumulators, SourceAspectNotNeeded());
+  }
+
+
+  /// Perform the epilogue computations and stream the result to global memory.  Implements
+  /// two alternative codepaths, depending on whether the output op requires addend data to be loaded.
   CUTLASS_DEVICE
   void operator()(
     OutputOp const &output_op,                      ///< Output operator
     OutputTileIterator destination_iterator,        ///< Tile iterator for destination
     AccumulatorTile const &accumulators,            ///< Complete warp-level accumulator tile
-    OutputTileIterator source_iterator )            ///< Threadblock tile coordinate in GEMM (in units of threadblock tiles)
+    OutputTileIterator source_iterator )            ///< Tile iterator for addend source
+  {
+    if (output_op.is_source_needed())
+    {
+      operator()(output_op, destination_iterator, accumulators, SourceAspectNeeded(source_iterator));
+    }
+    else
+    {
+      operator()(output_op, destination_iterator, accumulators, SourceAspectNotNeeded());
+    }
+  }
+
+
+  /// Perform the epilogue computations and stream the result to global memory.  Implements a
+  /// single codepath, regardless of whether the output op requires addend data to be loaded
+  CUTLASS_DEVICE
+  void unified(
+    OutputOp const &output_op,                      ///< Output operator
+    OutputTileIterator destination_iterator,        ///< Tile iterator for destination
+    AccumulatorTile const &accumulators,            ///< Complete warp-level accumulator tile
+    OutputTileIterator source_iterator )            ///< Tile iterator for addend source
   {
     if (!output_op.is_source_needed())
     {
       source_iterator.clear_mask();
       __syncthreads();  // Dummy (CUDA 11.0)
     }
 
-    // Source-fragment data (zero-initialized for scenarios where the
-    // output operator allows us to skip loading it from global input)
-    typename OutputTileIterator::Fragment source_fragment;
-    source_fragment.clear();
+    operator()(output_op, destination_iterator, accumulators, SourceAspectNeeded(source_iterator));
+  }
 
+
+  /// Streams the result to global memory
+  template <typename SourceAspect>
+  CUTLASS_DEVICE
+  void operator()(
+    OutputOp const &output_op,                      ///< Output operator
+    OutputTileIterator destination_iterator,        ///< Tile iterator for destination
+    AccumulatorTile const &accumulators,            ///< Complete warp-level accumulator tile
+    SourceAspect source)
+  {
+    //
     // Iterator over warp-level accumulator fragment
+    //
+
     AccumulatorFragmentIterator accum_fragment_iterator(accumulators);
 
     //
     // Iterate over accumulator tile
     //
 
-    #pragma unroll(IterationsUnroll ? OutputTileIterator::kIterations / Base::kFragmentsPerIteration : 1)
-    for (int iter = 0; iter < OutputTileIterator::kIterations; iter += Base::kFragmentsPerIteration)
-    {
+    CUTLASS_PRAGMA_UNROLL
+    for (int iter = 0; iter < OutputTileIterator::kIterations; ++iter) {
 
       //
-      // Convert and store fragment
+      // Convert fragment
       //
 
-      __syncthreads();
-
-      CUTLASS_PRAGMA_UNROLL
-      for (int p = 0; p < Base::kFragmentsPerIteration; ++p)
-      {
-        typename AccumulatorFragmentIterator::Fragment accum_fragment;
-
-        accum_fragment_iterator.load(accum_fragment);
-        ++accum_fragment_iterator;
-
-        this->warp_tile_iterator_.store(accum_fragment);
-
-        if (p < Base::kFragmentsPerIteration - 1) {
-          this->warp_tile_iterator_.add_pointer_offset(kSmemPointerOffset);
-        }
-      }
-
-      if (Base::kFragmentsPerIteration > 1) {
-        this->warp_tile_iterator_.add_pointer_offset(kSmemPointerOffset * (1 - Base::kFragmentsPerIteration));
-      }
+      typename AccumulatorFragmentIterator::Fragment accum_fragment;
 
+      accum_fragment_iterator.load(accum_fragment);
+      ++accum_fragment_iterator;
 
       //
-      // Load fragments from shared memory
+      // Compute the output result
       //
 
-      __syncthreads();
-
-      CUTLASS_PRAGMA_UNROLL
-      for (int p = 0; p < Base::kFragmentsPerIteration; ++p)
-      {
-        // Load addend source fragment from global memory
-        source_iterator.load(source_fragment);
-        ++source_iterator;
-
-        typename SharedLoadIterator::Fragment aligned_accum_fragment[kPartitionsK];
-
-        shared_load_iterator_.load(aligned_accum_fragment[0]);
-
-        if (p < Base::kFragmentsPerIteration - 1)
-        {
-          shared_load_iterator_.add_pointer_offset(kSmemPointerOffset);
-        }
-        else if (kPartitionsK > 1)
-        {
-          plus <typename SharedLoadIterator::Fragment> add_fragments;
-
-          CUTLASS_PRAGMA_UNROLL
-          for ( int i = 1; i < kPartitionsK; ++i) {
-            shared_load_iterator_.add_pointer_offset(kSmemPointerOffset);
-            shared_load_iterator_.load(aligned_accum_fragment[i]);
-            aligned_accum_fragment[0] = add_fragments(aligned_accum_fragment[0], aligned_accum_fragment[i]);
-          }
-
-          shared_load_iterator_.add_pointer_offset((1 - kPartitionsK) * kSmemPointerOffset);
-        }
-
-        //
-        // Compute the output result
-        //
-
-        typename OutputTileIterator::Fragment output_fragment;
-        apply_output_operator(output_fragment, output_op, aligned_accum_fragment[0], source_fragment);
-
-        //
-        // Store the final result
-        //
-
-        destination_iterator.store(output_fragment);
-        ++destination_iterator;
-      }
-
-      if (Base::kFragmentsPerIteration > 1) {
-        shared_load_iterator_.add_pointer_offset(kSmemPointerOffset * (1 - Base::kFragmentsPerIteration));
-      }
-    }
-  }
-
-private:
-
-  /// Helper to invoke the output functor over each vector of output
-  CUTLASS_DEVICE
-  void apply_output_operator(
-    typename OutputTileIterator::Fragment &output_fragment,
-    OutputOp const &output_op,                    ///< Output operator
-    typename SharedLoadIterator::Fragment const &aligned_accum_fragment,
-    typename OutputTileIterator::Fragment const &source_fragment)
-  {
-
-    OutputAccessType *output_frag_ptr =
-      reinterpret_cast<OutputAccessType *>(&output_fragment);
+      typename OutputTileIterator::Fragment output_fragment;
+      source.apply_output_operator(output_fragment, output_op, accum_fragment);
 
-    AccumulatorAccessType const *compute_frag_ptr =
-      reinterpret_cast<AccumulatorAccessType const *>(&aligned_accum_fragment);
-
-    OutputAccessType const *source_frag_ptr =
-      reinterpret_cast<OutputAccessType const *>(&source_fragment);
-
-    int const kOutputOpIterations =
-      OutputTileIterator::Fragment::kElements / OutputTileIterator::kElementsPerAccess;
+      //
+      // Store the final result
+      //
 
-    CUTLASS_PRAGMA_UNROLL
-    for (int i = 0; i < kOutputOpIterations; ++i)
-    {
-      // Call the output operator
-      output_frag_ptr[i] = output_op(compute_frag_ptr[i], source_frag_ptr[i]);
+      destination_iterator.set_iteration_index(iter);
+      destination_iterator.store(output_fragment);
+      ++destination_iterator;
     }
   }
-
 };
 
 ////////////////////////////////////////////////////////////////////////////////
 
 } // namespace threadblock
 } // namespace epilogue
 } // namespace cutlass
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_base.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_base.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_base_streamk.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_base_streamk.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_depthwise.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_depthwise.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_direct_store.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_direct_store.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_gemm_k_reduction.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_gemm_k_reduction.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_planar_complex.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_planar_complex.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_smem_accumulator.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_smem_accumulator.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_visitor_with_softmax.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_visitor_with_softmax.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_broadcast.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_broadcast.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_reduction.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_reduction.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_visitor.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_with_visitor.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_workspace.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue_workspace.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/interleaved_epilogue.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/epilogue.h`

 * *Files 25% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -30,142 +30,288 @@
  **************************************************************************************************/
 /*! \file
   \brief Epilogue for threadblock scoped GEMMs using Tensor Ops.
 
   The epilogue rearranges the result of a matrix product through shared memory to match canonical
   tensor layouts in global memory. Epilogues support conversion and reduction operations.
 
+  The shared memory resource is time-sliced across warps.
 */
 
 #pragma once
 
+#if defined(__CUDACC_RTC__)
+#include <cuda/std/cassert>
+#else
+#include <assert.h>
+#endif
+
 #include "cutlass/cutlass.h"
 #include "cutlass/numeric_types.h"
 #include "cutlass/array.h"
 #include "cutlass/layout/vector.h"
 #include "cutlass/layout/tensor.h"
 #include "cutlass/tensor_coord.h"
 #include "cutlass/aligned_buffer.h"
+#include "cutlass/functional.h"
 
 #include "cutlass/gemm/gemm.h"
 
 #include "cutlass/transform/pitch_linear_thread_map.h"
 #include "cutlass/transform/threadblock/regular_tile_iterator.h"
 
+#include "cutlass/epilogue/threadblock/epilogue_base.h"
 #include "cutlass/epilogue/threadblock/epilogue_base_streamk.h"
 #include "cutlass/epilogue/threadblock/predicated_tile_iterator.h"
 
 ////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace epilogue {
 namespace threadblock {
 
+
 ////////////////////////////////////////////////////////////////////////////////
 
-/// Epilogue operator without splitk
+/// Epilogue operator
 template <
-    /// Shape of threadblock tile (concept: GemmShape)
-    typename Shape_,
-    /// Warp-level MMA operator (concept: gemm::warp::MmaTensorOp)
-    typename WarpMmaOperator_,
-    /// Number of partitions of the K dimension
-    int PartitionsK,
-    /// Tile iterator reading and writing output tensors
-    typename OutputTileIterator_,
-    /// Fragment iterator selecting accumulators
-    typename AccumulatorFragmentIterator_,
-    /// Output operator
-    typename OutputOp_,
-    /// Number of interleaved k
-    int InterleavedK>
-class InterleavedEpilogue :
+  typename Shape_,                          ///< Shape of threadblock tile (concept: GemmShape)
+  typename WarpMmaOperator_,                ///< Warp-level MMA operator (concept: gemm::warp::MmaTensorOp)
+  int PartitionsK,                          ///< Number of partitions of the K dimension
+  typename OutputTileIterator_,             ///< Tile iterator reading and writing output tensors
+  typename AccumulatorFragmentIterator_,    ///< Fragment iterator selecting accumulators
+  typename WarpTileIterator_,               ///< Warp-scoped tile iterator writing accumulators to SMEM
+  typename SharedLoadIterator_,             ///< Threadblock-scoped tile iterator loading from SMEM
+  typename OutputOp_,                       ///< Output operator
+  typename Padding_,                        ///< Padding added to SMEM allocation to avoid bank conflicts (concept: MatrixShape)
+  int FragmentsPerPartition = 1,            ///< Used to coarsten the epilogue granularity
+  int IterationsUnroll =                    ///< Used to reduce binary size when epilogue op is large
+    (!IsEpilogueFunctorHeavy<OutputOp_>::value)
+>
+class Epilogue :
+  public EpilogueBase<
+    Shape_,
+    typename WarpMmaOperator_::Shape,
+    PartitionsK,
+    AccumulatorFragmentIterator_,
+    WarpTileIterator_,
+    Padding_,
+    FragmentsPerPartition>,
   public EpilogueBaseStreamK<
     Shape_,
     PartitionsK,
     WarpMmaOperator_,
     AccumulatorFragmentIterator_>
 {
+
 public:
 
+  using Base = EpilogueBase<
+    Shape_,
+    typename WarpMmaOperator_::Shape,
+    PartitionsK,
+    AccumulatorFragmentIterator_,
+    WarpTileIterator_,
+    Padding_,
+    FragmentsPerPartition>;
+
   using BaseStreamK = EpilogueBaseStreamK<
     Shape_,
     PartitionsK,
     WarpMmaOperator_,
     AccumulatorFragmentIterator_>;
 
   using Shape = Shape_;
   using WarpMmaOperator = WarpMmaOperator_;
   static int const kPartitionsK = PartitionsK;
-  using AccumulatorFragmentIterator = AccumulatorFragmentIterator_;
   using OutputTileIterator = OutputTileIterator_;
+  using AccumulatorFragmentIterator = AccumulatorFragmentIterator_;
+  using WarpTileIterator = WarpTileIterator_;
+  using SharedLoadIterator = SharedLoadIterator_;
   using OutputOp = OutputOp_;
+  using Padding = Padding_;
+  using Layout = layout::RowMajor;
+  using LongIndex = typename Layout::LongIndex;
+
+  /// Number of warps per block
+  using WarpCount = typename Base::WarpCount;
+
+  /// Number of threads per block
+  static int const kBlockThreads = 32 * WarpCount::kCount;
+
+  /// Per-thread accumulator tile type
+  using AccumulatorTile = typename Base::AccumulatorTile;
 
-  /// The complete warp-level accumulator tile
-  using AccumulatorTile = typename AccumulatorFragmentIterator::AccumulatorTile;
+  /// Numerical accumulation element type
+  using ElementAccumulator = typename WarpMmaOperator::ElementC;
 
   /// Fragment type used by the accumulator tile's fragment iterator
   using AccumulatorFragment = typename AccumulatorFragmentIterator::Fragment;
 
-  /// Accumulator element
-  using ElementAccumulator = typename AccumulatorTile::Element;
-
   /// Output element
   using ElementOutput = typename OutputTileIterator::Element;
 
   /// Output access size
   static int const kElementsPerAccess = OutputTileIterator::kElementsPerAccess;
 
   /// Tensor reference to destination tensor
   using TensorRef = typename OutputTileIterator::TensorRef;
 
   /// Tensor reference to sync tensor
-  using SyncTensorRef =
-      typename cutlass::TensorRef<int, cutlass::layout::PackedVectorLayout>;
+  using SyncTensorRef = typename cutlass::TensorRef<int, cutlass::layout::PackedVectorLayout>;
 
   /// Const tensor reference to source tensor
   using ConstTensorRef = typename OutputTileIterator::ConstTensorRef;
 
-  /// Array type used to output
-  using OutputAccessType = Array<typename OutputTileIterator::Element,
-                                 OutputTileIterator::kElementsPerAccess>;
-
-  /// Array type used by output functor
-  using AccumulatorAccessType =
-      Array<ElementAccumulator, OutputTileIterator::kElementsPerAccess>;
-
-  /// Number of warps
-  using WarpCount =
-      gemm::GemmShape<Shape::kM / WarpMmaOperator::Shape::kM,
-                      Shape::kN / WarpMmaOperator::Shape::kN, kPartitionsK>;
+  /// Vector type used by the global output iterator
+  using OutputAccessType = Array<
+    typename OutputTileIterator::Element, OutputTileIterator::kElementsPerAccess>;
+
+  /// Vector type used by the shared output iterator
+  using AccumulatorAccessType = Array<typename WarpTileIterator::Element, OutputTileIterator::kElementsPerAccess>;
+
+  static int constexpr kSmemTiles = Base::kFragmentsPerIteration > 1 ? Base::kFragmentsPerIteration : kPartitionsK;
+
+  static int constexpr kSmemPointerOffset = Base::SharedStorage::StorageShape::kCount / kSmemTiles;
+
 
 public:
 
-  static_assert(OutputTileIterator::kElementsPerAccess,
-                "This must not be zero.");
+  static_assert(SharedLoadIterator::Fragment::kElements == OutputTileIterator::Fragment::kElements,
+    "Mismatch between shared load iterator and output tile iterator.");
+
+  static_assert(OutputTileIterator::kElementsPerAccess, "OutputTileIterator::kElementsPerAccess must not be zero.");
+
+  static_assert(!(OutputTileIterator::Fragment::kElements % OutputTileIterator::kElementsPerAccess), 
+    "Divisibility");
+
+  static_assert(kPartitionsK == 1 || Base::kFragmentsPerIteration == 1, "One of these must be exactly 1.");
+
+
+public:
+
+  /// Aspect for when epilogue source is not needed
+  struct SourceAspectNotNeeded
+  {
+    /// Constructor
+    CUTLASS_DEVICE
+    SourceAspectNotNeeded()
+    {}
+
+    /// Invoke the output functor over each vector of output
+    CUTLASS_DEVICE
+    void apply_output_operator(
+      typename OutputTileIterator::Fragment &output_fragment,
+      OutputOp const &output_op,
+      typename SharedLoadIterator::Fragment const &aligned_accum_fragment)
+    {
+      OutputAccessType *output_frag_ptr =
+        reinterpret_cast<OutputAccessType *>(&output_fragment);
+
+      AccumulatorAccessType const *compute_frag_ptr =
+        reinterpret_cast<AccumulatorAccessType const *>(&aligned_accum_fragment);
+
+      int const kOutputOpIterations =
+        OutputTileIterator::Fragment::kElements / OutputTileIterator::kElementsPerAccess;
+
+      CUTLASS_PRAGMA_UNROLL
+      for (int i = 0; i < kOutputOpIterations; ++i)
+      {
+        // Call the output operator
+        output_frag_ptr[i] = output_op(compute_frag_ptr[i]);
+      }
+    }
+  };
+
+
+  /// Aspect for when epilogue source is needed
+  struct SourceAspectNeeded
+  {
+    OutputTileIterator source_iterator;
+
+    typename OutputTileIterator::Fragment source_fragment;
+
+    /// Invoke the output functor over each vector of output
+    CUTLASS_DEVICE
+    static void apply_output_operator(
+      typename OutputTileIterator::Fragment &output_fragment,
+      OutputOp const &output_op,
+      typename SharedLoadIterator::Fragment const &aligned_accum_fragment,
+      typename OutputTileIterator::Fragment const &source_fragment)
+    {
+      OutputAccessType *output_frag_ptr =
+        reinterpret_cast<OutputAccessType *>(&output_fragment);
+
+      AccumulatorAccessType const *compute_frag_ptr =
+        reinterpret_cast<AccumulatorAccessType const *>(&aligned_accum_fragment);
+
+      OutputAccessType const *source_frag_ptr =
+        reinterpret_cast<OutputAccessType const *>(&source_fragment);
+
+      int const kOutputOpIterations =
+        OutputTileIterator::Fragment::kElements / OutputTileIterator::kElementsPerAccess;
+
+      CUTLASS_PRAGMA_UNROLL
+      for (int i = 0; i < kOutputOpIterations; ++i)
+      {
+        // Call the output operator
+        output_frag_ptr[i] = output_op(compute_frag_ptr[i], source_frag_ptr[i]);
+      }
+    }
+
+    /// Constructor
+    CUTLASS_DEVICE
+    SourceAspectNeeded(OutputTileIterator source_iterator) :
+      source_iterator(source_iterator)
+    {
+      source_fragment.clear();
+    }
+
+    /// Invoke the output functor over each vector of output
+    CUTLASS_DEVICE
+    void apply_output_operator(
+      typename OutputTileIterator::Fragment &output_fragment,
+      OutputOp const &output_op,
+      typename SharedLoadIterator::Fragment const &aligned_accum_fragment)
+    {
+      // Load addend source fragment from global memory
+      source_iterator.load(source_fragment);
+      ++source_iterator;
+
+      apply_output_operator(output_fragment, output_op, aligned_accum_fragment, source_fragment);
+    }
+  };
+
 
-  static_assert(!(OutputTileIterator::Fragment::kElements %
-                  OutputTileIterator::kElementsPerAccess),
-                "Divisibility");
+private:
 
-  /// Shared storage allocation needed by the epilogue
-  struct SharedStorage {};
+  /// Loads fragment from shared memory aligned with output tensor
+  SharedLoadIterator shared_load_iterator_;
 
+  /// Thread index in the threadblock
+  int thread_idx;
+
+  /// Warp index in the threadblock
+  int warp_idx;
 
 public:
 
   /// Constructor
   CUTLASS_DEVICE
-  InterleavedEpilogue(
-      SharedStorage &shared_storage,  ///< Shared storage object
-      int thread_idx,                 ///< ID of a thread within the threadblock
-      int warp_idx,                   ///< ID of warp within threadblock
-      int lane_idx)                   ///< Id of thread within warp
+  Epilogue(
+      typename Base::SharedStorage &shared_storage,   ///< Shared storage object
+      int thread_idx,                                 ///< ID of a thread within the threadblock
+      int warp_idx,                                   ///< ID of warp within threadblock
+      int lane_idx)                                   ///< Id of thread within warp
   :
-      BaseStreamK(thread_idx)
+      Base(shared_storage, thread_idx, warp_idx, lane_idx),
+      BaseStreamK(thread_idx),
+      shared_load_iterator_(shared_storage.reference(), thread_idx),
+      thread_idx(thread_idx),
+      warp_idx(warp_idx)
   {}
 
 
   /// Aggregates the accumulator sets shared by peer blocks in the global workspace,
   /// performing epilogue computations, writing to output
   CUTLASS_DEVICE
   void reduce(
@@ -177,215 +323,235 @@
       OutputTileIterator destination_iterator,        ///< Tile iterator for destination
       OutputTileIterator source_iterator)             ///< Threadblock tile coordinate in GEMM (in units of threadblock tiles)
   {
     // Redcuce peer accumulator fragments into one fragment
     AccumulatorFragment accum_fragment;
     BaseStreamK::reduce(accum_fragment, peer_idx_begin, peer_idx_end, reduce_fragment_idx, element_workspace);
 
-    // Source-fragment data (zero-initialized for scenarios where the
-    // output operator allows us to skip loading it from global input)
+    // Store fragment to shared memory
+    this->warp_tile_iterator_.store(accum_fragment);
+
+    __syncthreads();
+
+    // Initialize/load source-fragment data
     typename OutputTileIterator::Fragment source_fragment;
     source_fragment.clear();
 
     if (output_op.is_source_needed())
     {
       source_iterator += reduce_fragment_idx;
       source_iterator.load(source_fragment);
     }
 
+    // Load fragment from shared memory
+    typename SharedLoadIterator::Fragment aligned_accum_fragment;
+    shared_load_iterator_.load(aligned_accum_fragment);
+
+    // Add fragments shared by other k partitions
+    if (kPartitionsK > 1)
+    {
+      plus <typename SharedLoadIterator::Fragment> add_fragments;
+
+      CUTLASS_PRAGMA_UNROLL
+      for ( int i = 1; i < kPartitionsK; ++i) {
+        typename SharedLoadIterator::Fragment aligned_addend_fragment;
+        shared_load_iterator_.add_pointer_offset(kSmemPointerOffset);
+        shared_load_iterator_.load(aligned_addend_fragment);
+        aligned_accum_fragment = add_fragments(aligned_accum_fragment, aligned_addend_fragment);
+      }
+    }
+
     // Compute the output result
     typename OutputTileIterator::Fragment output_fragment;
 
     // Apply the output operator
-    apply_output_operator(output_fragment, output_op, accum_fragment, source_fragment);
+    SourceAspectNeeded::apply_output_operator(
+        output_fragment,
+        output_op,
+        aligned_accum_fragment,
+        source_fragment);
 
     // Store the final result
     destination_iterator += reduce_fragment_idx;
     destination_iterator.store(output_fragment);
   }
 
 
-  /// Streams the result to global memory
+  /// Perform the epilogue computations and stream the result to global memory.
   CUTLASS_DEVICE
   void operator()(
-    OutputOp const &output_op,                    ///< Output operator
-    OutputTileIterator destination_iterator,      ///< Tile iterator for destination
-    AccumulatorTile const &accumulators,          ///< Complete warp-level accumulator tile
-    OutputTileIterator source_iterator) {         ///< Threadblock tile coordinate in GEMM (in units of threadblock tiles)
-    if (!output_op.is_source_needed()) {
-      compute_source_not_needed_(output_op, destination_iterator, accumulators);  
-    }
-    else {
-      compute_source_needed_(output_op, destination_iterator, accumulators, source_iterator);
-    }
+    OutputOp const &output_op,                      ///< Output operator
+    OutputTileIterator destination_iterator,        ///< Tile iterator for destination
+    AccumulatorTile const &accumulators)            ///< Complete warp-level accumulator tile
+  {
+    operator()(output_op, destination_iterator, accumulators, SourceAspectNotNeeded());
   }
-   
-  /// Streams the result to global memory
-  CUTLASS_DEVICE
-  void compute_source_not_needed_(
-    OutputOp const &output_op,                    ///< Output operator
-    OutputTileIterator destination_iterator,      ///< Tile iterator for destination
-    AccumulatorTile const &accumulators           ///< Complete warp-level accumulator tile
-    ) { 
 
-    //
-    // Iterator over warp-level accumulator fragment
-    //
 
-    AccumulatorFragmentIterator accum_fragment_iterator(accumulators);
-
-    //
-    // Iterate over accumulator tile
-    //
-
-    CUTLASS_PRAGMA_UNROLL
-    for (int iter = 0; iter < OutputTileIterator::kIterations; ++iter) {
-
-      //
-      // Convert fragment
-      //
+  /// Perform the epilogue computations and stream the result to global memory.  Implements
+  /// two alternative codepaths, depending on whether the output op requires addend data to be loaded.
+  CUTLASS_DEVICE
+  void operator()(
+    OutputOp const &output_op,                      ///< Output operator
+    OutputTileIterator destination_iterator,        ///< Tile iterator for destination
+    AccumulatorTile const &accumulators,            ///< Complete warp-level accumulator tile
+    OutputTileIterator source_iterator )            ///< Tile iterator for addend source
+  {
+    if (output_op.is_source_needed())
+    {
+      operator()(output_op, destination_iterator, accumulators, SourceAspectNeeded(source_iterator));
+    }
+    else
+    {
+      operator()(output_op, destination_iterator, accumulators, SourceAspectNotNeeded());
+    }
+  }
 
-      typename AccumulatorFragmentIterator::Fragment accum_fragment;
 
-      accum_fragment_iterator.load(accum_fragment);
-      ++accum_fragment_iterator;
+  /// Perform the epilogue computations and stream the result to global memory.  Implements a
+  /// single codepath, regardless of whether the output op requires addend data to be loaded
+  CUTLASS_DEVICE
+  void unified(
+    OutputOp const &output_op,                      ///< Output operator
+    OutputTileIterator destination_iterator,        ///< Tile iterator for destination
+    AccumulatorTile const &accumulators,            ///< Complete warp-level accumulator tile
+    OutputTileIterator source_iterator )            ///< Tile iterator for addend source
+  {
+    if (!output_op.is_source_needed())
+    {
+      source_iterator.clear_mask();
+      __syncthreads();  // Dummy (CUDA 11.0)
+    }
 
-      //
-      // Compute the output result
-      //
+    operator()(output_op, destination_iterator, accumulators, SourceAspectNeeded(source_iterator));
+  }
 
-      typename OutputTileIterator::Fragment output_fragment;
-      apply_output_operator_source_not_needed(output_fragment, output_op, accum_fragment);
+  template<class Seq>
+  struct acc2smem;
 
-      //
-      // Store the final result
-      //
+  template <size_t... Seq>
+  struct acc2smem<cutlass::index_sequence<Seq...>> {
+    template<int Advance>
+    CUTLASS_DEVICE
+    static void helper(AccumulatorFragmentIterator accum_fragment_iterator,
+                      WarpTileIterator &warp_tile_iterator) {
+      CUTLASS_PRAGMA_UNROLL
+      for (int i = 0; i < Advance; i++) {
+        ++accum_fragment_iterator;
+      }
+
+      CUTLASS_PRAGMA_UNROLL
+      for (int p = 0; p < Base::kFragmentsPerIteration; ++p) {
+        typename AccumulatorFragmentIterator::Fragment accum_fragment;
+
+        accum_fragment_iterator.load(accum_fragment);
+        ++accum_fragment_iterator;
+
+        warp_tile_iterator.store(accum_fragment);
+        if (p < Base::kFragmentsPerIteration - 1) {
+          warp_tile_iterator.add_pointer_offset(kSmemPointerOffset);
+        }
+      }
+
+      if (Base::kFragmentsPerIteration > 1) {
+        warp_tile_iterator.add_pointer_offset(kSmemPointerOffset *
+                                              (1 - Base::kFragmentsPerIteration));
+      }
+    }
 
-      destination_iterator.set_iteration_index(iter);
-      destination_iterator.store(output_fragment);
-      ++destination_iterator;
+    CUTLASS_DEVICE
+    static void push(size_t pos,
+                    AccumulatorFragmentIterator const &iterator_begin,
+                    WarpTileIterator &warp_tile_iterator) {
+      int dummy[] = {(pos == Seq) && (helper<Seq>(iterator_begin, warp_tile_iterator), 0)...};
     }
-  } 
+  };
+
 
   /// Streams the result to global memory
+  template <typename SourceAspect>
   CUTLASS_DEVICE
-  void compute_source_needed_(
-    OutputOp const &output_op,                    ///< Output operator
-    OutputTileIterator destination_iterator,      ///< Tile iterator for destination
-    AccumulatorTile const &accumulators,          ///< Complete warp-level accumulator tile
-    OutputTileIterator source_iterator           ///< Threadblock tile coordinate in GEMM (in units of threadblock tiles)
-    ) { 
- 
-    //
-    // Predicated tile iterators constructed from members
-    //
-
-    typename OutputTileIterator::Fragment source_fragment;
-
-    source_fragment.clear();
-
-    //
+  void operator()(
+    OutputOp const &output_op,                      ///< Output operator
+    OutputTileIterator destination_iterator,        ///< Tile iterator for destination
+    AccumulatorTile const &accumulators,            ///< Complete warp-level accumulator tile
+    SourceAspect source)
+  {
     // Iterator over warp-level accumulator fragment
-    //
-
     AccumulatorFragmentIterator accum_fragment_iterator(accumulators);
 
     //
     // Iterate over accumulator tile
     //
 
-    CUTLASS_PRAGMA_UNROLL
-    for (int iter = 0; iter < OutputTileIterator::kIterations; ++iter) {
-      //
-      // Load the source
-      //
-
-      source_iterator.set_iteration_index(iter);
-      source_iterator.load(source_fragment);
-      ++source_iterator;
+    #pragma unroll(IterationsUnroll ? OutputTileIterator::kIterations / Base::kFragmentsPerIteration : 1)
+    for (int iter = 0; iter < OutputTileIterator::kIterations; iter += Base::kFragmentsPerIteration)
+    {
 
       //
-      // Convert fragment
+      // Convert and store fragment
       //
 
-      typename AccumulatorFragmentIterator::Fragment accum_fragment;
+      __syncthreads();
 
-      accum_fragment_iterator.load(accum_fragment);
-      ++accum_fragment_iterator;
+      acc2smem<cutlass::make_index_sequence<OutputTileIterator::kIterations>>::push(
+        iter, accum_fragment_iterator, this->warp_tile_iterator_);
 
       //
-      // Compute the output result
+      // Load fragments from shared memory
       //
 
-      typename OutputTileIterator::Fragment output_fragment;
-      apply_output_operator(output_fragment, output_op, accum_fragment, source_fragment);
-
-      //
-      // Store the final result
-      //
+      __syncthreads();
 
-      destination_iterator.set_iteration_index(iter);
-      destination_iterator.store(output_fragment);
-      ++destination_iterator;
-    }
-  }
+      CUTLASS_PRAGMA_UNROLL
+      for (int p = 0; p < Base::kFragmentsPerIteration; ++p)
+      {
+        typename SharedLoadIterator::Fragment aligned_accum_fragment;
+        shared_load_iterator_.load(aligned_accum_fragment);
 
-protected:
+        if (p < Base::kFragmentsPerIteration - 1)
+        {
+          shared_load_iterator_.add_pointer_offset(kSmemPointerOffset);
+        }
+        else if (kPartitionsK > 1)
+        {
+          plus <typename SharedLoadIterator::Fragment> add_fragments;
 
-  /// Helper to invoke the output functor over each vector of output
-  CUTLASS_DEVICE
-  void apply_output_operator(
-    typename OutputTileIterator::Fragment &output_fragment,
-    OutputOp const &output_op,
-    typename AccumulatorFragmentIterator::Fragment const &aligned_accum_fragment,
-    typename OutputTileIterator::Fragment const &source_fragment)
-  {
-    OutputAccessType *output_frag_ptr =
-        reinterpret_cast<OutputAccessType *>(&output_fragment);
+          CUTLASS_PRAGMA_UNROLL
+          for ( int i = 1; i < kPartitionsK; ++i) {
+            typename SharedLoadIterator::Fragment aligned_accum_fragment_addend;
+            shared_load_iterator_.add_pointer_offset(kSmemPointerOffset);
+            shared_load_iterator_.load(aligned_accum_fragment_addend);
+            aligned_accum_fragment = add_fragments(aligned_accum_fragment, aligned_accum_fragment_addend);
+          }
 
-    AccumulatorAccessType const *compute_frag_ptr =
-        reinterpret_cast<AccumulatorAccessType const *>(
-            &aligned_accum_fragment);
+          shared_load_iterator_.add_pointer_offset((1 - kPartitionsK) * kSmemPointerOffset);
+        }
 
-    OutputAccessType const *source_frag_ptr =
-        reinterpret_cast<OutputAccessType const *>(&source_fragment);
+        //
+        // Compute the output result
+        //
 
-    int const kOutputOpIterations = OutputTileIterator::Fragment::kElements /
-                                    OutputTileIterator::kElementsPerAccess;
+        typename OutputTileIterator::Fragment output_fragment;
+        source.apply_output_operator(output_fragment, output_op, aligned_accum_fragment);
 
-    CUTLASS_PRAGMA_UNROLL
-    for (int i = 0; i < kOutputOpIterations; ++i) {
-      // Call the output operator
-      output_frag_ptr[i] = output_op(compute_frag_ptr[i], source_frag_ptr[i]);
-    }
-  }
+        //
+        // Store the final result
+        //
 
-  /// Helper to invoke the output functor over each vector of output
-  CUTLASS_DEVICE
-  void apply_output_operator_source_not_needed(
-    typename OutputTileIterator::Fragment &output_fragment,
-    OutputOp const &output_op,
-    typename AccumulatorFragmentIterator::Fragment const &aligned_accum_fragment)
-  {
-    OutputAccessType *output_frag_ptr =
-        reinterpret_cast<OutputAccessType *>(&output_fragment);
+        destination_iterator.store(output_fragment);
+        ++destination_iterator;
+      }
 
-    AccumulatorAccessType const *compute_frag_ptr =
-        reinterpret_cast<AccumulatorAccessType const *>(
-            &aligned_accum_fragment);
-
-    int const kOutputOpIterations = OutputTileIterator::Fragment::kElements /
-                                    OutputTileIterator::kElementsPerAccess;
-
-    CUTLASS_PRAGMA_UNROLL
-    for (int i = 0; i < kOutputOpIterations; ++i) {
-      // Call the output operator
-      output_frag_ptr[i] = output_op(compute_frag_ptr[i]);
+      if (Base::kFragmentsPerIteration > 1) {
+        shared_load_iterator_.add_pointer_offset(kSmemPointerOffset * (1 - Base::kFragmentsPerIteration));
+      }
     }
   }
+
 };
 
 ////////////////////////////////////////////////////////////////////////////////
 
 } // namespace threadblock
 } // namespace epilogue
 } // namespace cutlass
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/output_iterator_parameter.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/output_iterator_parameter.h`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/output_tile_thread_map.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/output_tile_thread_map.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_affine.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_affine.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_affine_layout_params.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_affine_layout_params.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_blas3.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_blas3.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_direct_conv.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_direct_conv.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -194,15 +194,15 @@
 
   /// A thread's starting row position (assuming steady-state predicates have been computed)
   Index thread_start_row_;
 
   /// A thread's starting column
   Index thread_start_column_;
 
-  /// Initial thread ouput location
+  /// Initial thread output location
   int thread_start_n_, thread_start_p_, thread_start_q_;
 
   /// Current threadblock tile index
   int tile_index_;
 
   //
   // Static asserts about internal strides
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_params.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_params.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_predicates.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_predicates.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_strided_dgrad.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/predicated_tile_iterator_strided_dgrad.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -182,18 +182,18 @@
 
   /// Array of boolean values to contain steady-state predicates
   Mask mask_;
 
   /// Extent of the matrix tile in rows
   Index extent_row_;
 
-  /// Starting Dx h and w dimenstion for strided dgrad mapping
+  /// Starting Dx h and w dimension for strided dgrad mapping
   int start_h_, start_w_;
 
-  /// Effective Dy P and Q dimenstions for strided dgrad mapping
+  /// Effective Dy P and Q dimensions for strided dgrad mapping
   int p_, q_;
 
   /// A thread's starting row position (assuming steady-state predicates have been computed)
   Index thread_start_row_;
 
   /// A thread's starting column position (assuming steady-state predicates have been computed)
   Index thread_start_column_;
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/shared_load_iterator.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/shared_load_iterator.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/shared_load_iterator_mixed.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/shared_load_iterator_mixed.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -66,30 +66,31 @@
 ///
 template <
   typename ThreadMap_,       ///< Thread map (conept: OutputTileThreadMap)
   typename Element_,         ///< Accumulator data type
   int ElementSizeBits_,      ///< Size of accumulator in bits
   int OutputSizeBits_,       ///< Size of output element in bits
   int ElementsPerAccess,     ///< Vector length of output vector
-  int ContiguousLanes        ///< Number of lanes in the warp writing to contiguous elements
+  int ContiguousLanes,       ///< Number of lanes in the warp writing to contiguous elements
                              ///  in the global memory tensor
+  bool EightBitsOutputOrLess = (OutputSizeBits_ <= 8)
 >
 class SharedLoadIteratorMixed;
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Tile iterator used to load output tile from shared memory in epilogue.
 ///
 /// Satisfies: ReadableTileIterator
 ///
 template <
   typename ThreadMap_,       ///< Thread map (conept: OutputTileThreadMap)
   typename Element_          ///< Accumulator data type
 >
-class SharedLoadIteratorMixed<ThreadMap_, Element_, 32, 16, 8, 8> {
+class SharedLoadIteratorMixed<ThreadMap_, Element_, 32, 16, 8, 8, false> {
 public:
   using ThreadMap = ThreadMap_;
   using Shape = typename ThreadMap::Shape;
 
   using Element = Element_;
 
   using Layout = layout::RowMajor;
@@ -249,15 +250,15 @@
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Partial specialization for int32_t x 16 => int8_t/int4b_t x 16 
 template <
   typename ThreadMap_,      ///< Thread map (conept: OutputTileThreadMap)
   int OutputSizeBits_       ///< Size of output element in bits
 >
-class SharedLoadIteratorMixed<ThreadMap_, int32_t, 32, OutputSizeBits_, 16, 8> {
+class SharedLoadIteratorMixed<ThreadMap_, int32_t, 32, OutputSizeBits_, 16, 8, true> {
 public:
   using ThreadMap = ThreadMap_;
   using Shape = typename ThreadMap::Shape;
 
   using Element = int32_t;
 
   using Layout = layout::RowMajor;
@@ -414,15 +415,15 @@
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Partial specialization for int32_t x 8 => int8_t/int4b_t x 8
 template <
   typename ThreadMap_,      ///< Thread map (conept: OutputTileThreadMap)
   int OutputSizeBits_
 >
-class SharedLoadIteratorMixed<ThreadMap_, int32_t, 32, OutputSizeBits_, 8, 8> {
+class SharedLoadIteratorMixed<ThreadMap_, int32_t, 32, OutputSizeBits_, 8, 8, true> {
 public:
   using ThreadMap = ThreadMap_;
   using Shape = typename ThreadMap::Shape;
 
   using Element = int32_t;
 
   using Layout = layout::RowMajor;
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/shared_load_iterator_pitch_liner.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/threadblock/shared_load_iterator_pitch_liner.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/fragment_iterator_complex_tensor_op.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/fragment_iterator_complex_tensor_op.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/fragment_iterator_gaussian_complex_tensor_op.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/fragment_iterator_gaussian_complex_tensor_op.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/fragment_iterator_simt.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/fragment_iterator_simt.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/fragment_iterator_tensor_op.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/fragment_iterator_tensor_op.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/fragment_iterator_volta_tensor_op.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/fragment_iterator_volta_tensor_op.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/fragment_iterator_wmma_tensor_op.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/fragment_iterator_wmma_tensor_op.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/simt_policy.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/simt_policy.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/tensor_op_policy.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/tensor_op_policy.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/tile_iterator_simt.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/tile_iterator_simt.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/tile_iterator_tensor_op.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/tile_iterator_tensor_op.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/tile_iterator_tensor_op_mixed.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/tile_iterator_tensor_op_mixed.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -60,15 +60,16 @@
 template <
   typename WarpShape_,            ///< shape of warp-level GEMM (concept: GemmShape)
   typename OperatorShape_,        ///< matrix multiply operation shape (concept: gemm::GemmShape)
   typename Element_,              ///< data type of accumulator element
   int ElementSizeBits,            ///< Size of accumulator element in bits
   int OutputSizeBits,             ///< Size of output element in bits
   int OutputElementCount,         ///< number of elements in output vector
-  int ContiguousLanes             ///< Number of consecutive lanes writing to contiguous memory
+  int ContiguousLanes,            ///< Number of consecutive lanes writing to contiguous memory
+  bool EightBitsOutputOrLess = (OutputSizeBits <= 8)
 >
 class TileIteratorTensorOpMixed {
 public:
 
   using WarpShape = WarpShape_;
   using OperatorShape = OperatorShape_;
   using Element = Element_;
@@ -315,15 +316,15 @@
 
 /// Partial specialization for int32_t x 16 => int8_t/int4b_t x 16
 template <
   typename WarpShape_,            ///< shape of warp-level GEMM (concept: GemmShape)
   typename OperatorShape_,        ///< matrix multiply operation shape (concept: gemm::GemmShape),
   int OutputSizeBits              ///< Size of output element in bits
 >
-class TileIteratorTensorOpMixed<WarpShape_, OperatorShape_, int32_t, 32, OutputSizeBits, 16, 8> {
+class TileIteratorTensorOpMixed<WarpShape_, OperatorShape_, int32_t, 32, OutputSizeBits, 16, 8, true> {
 public:
 
   using WarpShape = WarpShape_;
   using OperatorShape = OperatorShape_;
   using Element = int32_t;
   using Layout = layout::RowMajor;
   static int const kOutputElementCount = 16;
@@ -522,15 +523,15 @@
 
 /// Partial specialization for int32_t x 8 => int8_t/int4b_t x 8
 template <
   typename WarpShape_,            ///< shape of warp-level GEMM (concept: GemmShape)
   typename OperatorShape_,        ///< matrix multiply operation shape (concept: gemm::GemmShape)
   int OutputSizeBits              ///< Size of output element in bits
 >
-class TileIteratorTensorOpMixed<WarpShape_, OperatorShape_, int32_t, 32, OutputSizeBits, 8, 8> {
+class TileIteratorTensorOpMixed<WarpShape_, OperatorShape_, int32_t, 32, OutputSizeBits, 8, 8, true> {
 public:
 
   using WarpShape = WarpShape_;
   using OperatorShape = OperatorShape_;
   using Element = int32_t;
   using Layout = layout::RowMajor;
   static int const kOutputElementCount = 8;
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/tile_iterator_volta_tensor_op.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/tile_iterator_volta_tensor_op.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/tile_iterator_wmma_tensor_op.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/tile_iterator_wmma_tensor_op.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/volta_tensor_op_policy.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/volta_tensor_op_policy.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/wmma_tensor_op_policy.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/epilogue/warp/wmma_tensor_op_policy.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/fast_math.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/fast_math.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/float8.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/float8.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -51,24 +51,26 @@
 #include <limits>
 #include <cstdint>
 #include <cstring>
 #endif
 
 ///////////////////////////////////////////////////////////////////////////////////////////////////
 
-#if defined(__CUDA_ARCH__) && (__CUDA_ARCH__ >= 900)
 #if (__CUDACC_VER_MAJOR__ >= 12) || ((__CUDACC_VER_MAJOR__ == 11) && (__CUDACC_VER_MINOR__ >= 8))
-
+#if defined(__CUDA_ARCH__) && (__CUDA_ARCH__ >= 900)
 #ifndef CUDA_PTX_FP8_CVT_ENABLED
 #define CUDA_PTX_FP8_CVT_ENABLED 1
 #endif
-
 #endif
 #endif
 
+#ifdef __GNUC__
+// Ignore checks on reinterpret-casts that are being used for bitcasts.
+#pragma GCC diagnostic ignored "-Wstrict-aliasing"
+#endif
 
 namespace cutlass {
 
 ///////////////////////////////////////////////////////////////////////////////////////////////////
 //
 //  FP8 Has 2 encodings possible : E4M3 and E5M2
 //
@@ -393,41 +395,41 @@
     #if defined(CUDA_PTX_FP8_CVT_ENABLED)
         uint16_t tmp = 0;
         uint32_t bits = reinterpret_cast<uint16_t const &>(flt);
         asm volatile("cvt.rn.satfinite.e4m3x2.f16x2 %0, %1;" : "=h"(tmp) : "r"(bits));
 
         return *reinterpret_cast<float_e4m3_t *>(&tmp);
     #else
-        return bitcast(Base::convert_float_to_fp8(float(flt)));
+        return bitcast(Base::convert_float_to_fp8(__half2float(flt)));
     #endif
     }
 
     // E4M3 -> half
     CUTLASS_HOST_DEVICE
     static half to_half(float_e4m3_t const& x) {
     #if defined(CUDA_PTX_FP8_CVT_ENABLED)
         uint16_t bits = x.storage;
         uint32_t packed;
         asm volatile("cvt.rn.f16x2.e4m3x2 %0, %1;\n" : "=r"(packed) : "h"(bits));
 
         return reinterpret_cast<half2 const &>(packed).x;
     #else
-        return half(Base::convert_fp8_to_float(x.storage));
+        return __float2half(Base::convert_fp8_to_float(x.storage));
     #endif
     }
 
     // E4M3 -> Float
     CUTLASS_HOST_DEVICE
     static float to_float(float_e4m3_t const& x) {
     #if defined(CUDA_PTX_FP8_CVT_ENABLED)
         uint16_t bits = x.storage;
         uint32_t packed;
         asm volatile("cvt.rn.f16x2.e4m3x2 %0, %1;\n" : "=r"(packed) : "h"(bits));
 
-        return float(reinterpret_cast<half2 const &>(packed).x);
+        return __half2float(reinterpret_cast<half2 const &>(packed).x);
     #else
         return Base::convert_fp8_to_float(x.storage);
     #endif
     }
 
     //
     // Methods
@@ -603,41 +605,41 @@
     #if defined(CUDA_PTX_FP8_CVT_ENABLED)
         uint16_t tmp = 0;
         uint32_t bits = reinterpret_cast<uint16_t const &>(flt);
         asm volatile("cvt.rn.satfinite.e5m2x2.f16x2 %0, %1;" : "=h"(tmp) : "r"(bits));
 
         return *reinterpret_cast<float_e5m2_t *>(&tmp);
     #else
-        return bitcast(Base::convert_float_to_fp8(float(flt)));
+        return bitcast(Base::convert_float_to_fp8(__half2float(flt)));
     #endif
     }
 
     // E5M2 -> half
     CUTLASS_HOST_DEVICE
     static half to_half(float_e5m2_t const& x) {
     #if defined(CUDA_PTX_FP8_CVT_ENABLED)
         uint16_t bits = x.storage;
         uint32_t packed;
         asm volatile("cvt.rn.f16x2.e5m2x2 %0, %1;\n" : "=r"(packed) : "h"(bits));
 
         return reinterpret_cast<half2 const &>(packed).x;
     #else
-        return half(Base::convert_fp8_to_float(x.storage));
+        return __float2half(Base::convert_fp8_to_float(x.storage));
     #endif
     }
 
     // E5M2 -> Float
     CUTLASS_HOST_DEVICE
     static float to_float(float_e5m2_t const& x) {
     #if defined(CUDA_PTX_FP8_CVT_ENABLED)
         uint16_t bits = x.storage;
         uint32_t packed;
         asm volatile("cvt.rn.f16x2.e5m2x2 %0, %1;\n" : "=r"(packed) : "h"(bits));
 
-        return float(reinterpret_cast<half2 const &>(packed).x);
+        return __half2float(reinterpret_cast<half2 const &>(packed).x);
     #else
         return Base::convert_fp8_to_float(x.storage);
     #endif
     }
 
     //
     // Methods
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/floating_point_nvrtc.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/floating_point_nvrtc.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/functional.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/functional.h`

 * *Files 8% similar despite different names*

```diff
@@ -1,9 +1,9 @@
   /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -52,14 +52,20 @@
 struct absolute_value_op {
   CUTLASS_HOST_DEVICE
   T operator()(T lhs) const {
     return abs(lhs);
   }
 };
 
+template <>
+struct absolute_value_op<float> {
+  CUTLASS_HOST_DEVICE
+  float operator()(float lhs) const { return fabs(lhs); }
+};
+
 template <typename T>
 struct plus {
   CUTLASS_HOST_DEVICE
   T operator()(T lhs, T const &rhs) const {
     lhs += rhs;
     return lhs;
   }
@@ -79,14 +85,91 @@
   CUTLASS_HOST_DEVICE
   T operator()(T lhs, T const &rhs) const {
     lhs *= rhs;
     return lhs;
   }
 };
 
+#if defined(__CUDA_ARCH__)
+/// Partial specializations needed when __CUDA_NO_HALF2_OPERATORS__ is set
+template<>
+struct plus<__half2> {
+  CUTLASS_HOST_DEVICE
+  __half2 operator()(__half2 lhs, __half2 const &rhs) const {
+    return __hadd2(lhs, rhs);
+  }
+};
+
+template<>
+struct minus<__half2> {
+  CUTLASS_HOST_DEVICE
+  __half2 operator()(__half2 lhs, __half2 const &rhs) const {
+    return __hsub2(lhs, rhs);
+  }
+};
+
+template<>
+struct multiplies<__half2> {
+  CUTLASS_HOST_DEVICE
+  __half2 operator()(__half2 lhs, __half2 const &rhs) const {
+    return __hmul2(lhs, rhs);
+  }
+};
+
+/// Partial specializations needed when __CUDA_NO_HALF_OPERATORS__ is set
+template<>
+struct plus<__half> {
+  CUTLASS_HOST_DEVICE
+  __half operator()(__half lhs, __half const &rhs) const {
+    return __hadd(lhs, rhs);
+  }
+};
+
+template<>
+struct minus<__half> {
+  CUTLASS_HOST_DEVICE
+  __half operator()(__half lhs, __half const &rhs) const {
+    return __hsub(lhs, rhs);
+  }
+};
+
+template<>
+struct multiplies<__half> {
+  CUTLASS_HOST_DEVICE
+  __half operator()(__half lhs, __half const &rhs) const {
+    return __hmul(lhs, rhs);
+  }
+};
+#endif // defined(__CUDA_ARCH__)
+
+
+// Maximum with nan propogation
+// To propgate the NANs, the "max" of a two element that contains NaNs should also return a NaN 
+template <typename T>
+struct maximum_with_nan_propogation {
+  CUTLASS_HOST_DEVICE
+  T operator()(T const &lhs, T const &rhs) const {
+    return lhs > rhs or std::isnan(lhs) ? lhs : rhs;
+  }
+};
+
+template <>
+struct maximum_with_nan_propogation<float> {
+  CUTLASS_HOST_DEVICE
+  float operator()(float const lhs, float const rhs) const {
+    float res;
+#if defined(__CUDA_ARCH__) && (__CUDA_ARCH__ >= 800)
+    asm volatile("max.NaN.f32 %0, %1, %2;\n" : "=f"(res) : "f"(lhs), "f"(rhs));
+#else
+    res = lhs > rhs or std::isnan(lhs) ? lhs : rhs;
+#endif
+    return res;
+  }
+};
+
 /// Squares with optional conversion
 template <typename T, typename Output = T>
 struct square {
   CUTLASS_HOST_DEVICE
   Output operator()(T lhs) const {
     multiplies<Output> mul_op;
 
@@ -346,14 +429,16 @@
 template<>
 struct red<double>
 {
   CUTLASS_DEVICE
   void operator()(double *ptr, const double &data)
   {
 #if !defined(__CUDA_ARCH__)
+      CUTLASS_UNUSED(ptr);
+      CUTLASS_UNUSED(data);
 #elif (__CUDA_ARCH__ >= 600)
 
     atomicAdd(ptr, data);
 
 #else
 
     // Use CAS loop
@@ -375,42 +460,23 @@
 /// Reduces value into the data pointed to by ptr (half2 specialization)
 template<>
 struct red<half2>
 {
   CUTLASS_DEVICE
   void operator()(half2 *ptr, const half2 &data)
   {
-#if !defined(__CUDA_ARCH__)
-#elif (__CUDA_ARCH__ >= 600)
+#if !defined(__CUDA_ARCH__) || (defined(__CUDA_ARCH__)  && (__CUDA_ARCH__ < 600))
+      CUTLASS_UNUSED(ptr);
+      CUTLASS_UNUSED(data);
+#else
 
     // Vector-2 atomic reduction requires .target sm_60 or higher
     uint32_t word = reinterpret_cast<const uint32_t&>(data);
     asm volatile ("red.gpu.global.add.noftz.f16x2 [%0], %1;\n" : : "l"(ptr), "r"(word));
 
-#else
-
-    // Use CAS loop
-    uint32_t *ptr_int = reinterpret_cast<uint32_t *>(ptr);
-    uint32_t old_int = *ptr_int;
-    uint32_t assumed_int;
-
-    do
-    {
-      half2 old = reinterpret_cast<half2&>(old_int);
-
-      half hi = __hadd(__high2half(old), __high2half(data));
-      half lo = __hadd(__low2half(old), __low2half(data));
-      half2 update = __halves2half2(hi, lo);
-      uint32_t update_int = reinterpret_cast<const uint32_t&>(update);
-
-      assumed_int = old_int;
-      old_int = atomicCAS(ptr_int, assumed_int, update_int);
-
-    } while (assumed_int != old_int);
-
 #endif // (__CUDA_ARCH__ >= 600)
   }
 };
 
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 //
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/base_grouped.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/base_grouped.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -338,15 +338,15 @@
 
     // Choose between the full wave of threadblocks and the tile count. If there
     // are fewer tiles in the group than threadblocks in the full wave, only
     // some threadblocks will be assigned tiles. Those threadblocks
     // which are not assigned tiles still need to perform the work of iterating through
     // problem sizes to determine that they have no work to do. This competes for cycles
     // with those threadblocks that are assigned tiles to compute.
-    return min(total_tiles, occupancy_based_block_count);
+    return std::min(total_tiles, occupancy_based_block_count);
   }
 
 
   /// Initializes GEMM state from arguments.
   Status initialize(Arguments const &args, void *workspace = nullptr, cudaStream_t stream = nullptr) {
 
     CUTLASS_TRACE_HOST("BaseGrouped::initialize() - workspace "
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/default_gemm_configuration.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/default_gemm_configuration.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/ell_gemm.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/ell_gemm.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -543,15 +543,15 @@
 
     return status;
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////
 
-/// Parital specialization for column-major output exchanges problem size and operand.
+/// Partial specialization for column-major output exchanges problem size and operand.
 template <
     /// Element type for A matrix operand
     typename ElementA_,
     /// Layout type for A matrix operand
     typename LayoutA_,
     /// Element type for B matrix operand
     typename ElementB_,
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -505,27 +505,27 @@
 
   /// Runs the kernel using initialized state.
   Status operator()(
     Arguments const &args, 
     void *workspace = nullptr, 
     cudaStream_t stream = nullptr) {
     
-    Status status = initialize(args, workspace);
+    Status status = initialize(args, workspace, stream);
     
     if (status == Status::kSuccess) {
       status = run(stream);
     }
 
     return status;
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////
 
-/// Parital specialization for column-major output exchanges problem size and operand.
+/// Partial specialization for column-major output exchanges problem size and operand.
 template <
     /// Element type for A matrix operand
     typename ElementA_,
     /// Layout type for A matrix operand
     typename LayoutA_,
     /// Element type for B matrix operand
     typename ElementB_,
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_array.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_array.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -472,15 +472,15 @@
 
     return status;
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////
 
-/// Parital specialization for column-major output exchanges problem size and operand.
+/// Partial specialization for column-major output exchanges problem size and operand.
 template <
   /// Element type for A matrix operand
   typename ElementA_,
   /// Layout type for A matrix operand
   typename LayoutA_,
   /// Element type for B matrix operand
   typename ElementB_,
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_batched.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_batched.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -450,15 +450,15 @@
 
     return status;
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////
 
-/// Parital specialization for column-major output exchanges problem size and operand.
+/// Partial specialization for column-major output exchanges problem size and operand.
 template <
   /// Element type for A matrix operand
   typename ElementA_,
   /// Layout type for A matrix operand
   typename LayoutA_,
   /// Element type for B matrix operand
   typename ElementB_,
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_complex.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_complex.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -471,15 +471,15 @@
 
     return status;
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////
 
-/// Parital specialization for column-major output exchanges problem size and operand.
+/// Partial specialization for column-major output exchanges problem size and operand.
 template <
   /// Element type for A matrix operand
   typename ElementA_,
   /// Layout type for A matrix operand
   typename LayoutA_,
   /// Element type for B matrix operand
   typename ElementB_,
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_grouped.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma.h`

 * *Files 10% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -24,38 +24,37 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
-/*!
-  \file
-  \brief Device-level grouped GEMM.
+/*! \file
+    \brief Templates exposing architecture support for warp-level multiply-add operations
 */
 
 #pragma once
 
-#include "cutlass/gemm/device/base_grouped.h"
+#include "cutlass/cutlass.h"
 
-////////////////////////////////////////////////////////////////////////////////
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace gemm {
-namespace device {
+namespace warp {
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-/// GEMM Grouped
-template <typename GemmKernel_>
-class GemmGrouped : public BaseGrouped<GemmKernel_> {
-public:
-  using GemmKernel = GemmKernel_;
+/// Query the number of threads per warp
+template <typename OperatorClass>
+struct WarpSize {
+  static int const value = 32;
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-} // namespace device
+} // namespace warp
 } // namespace gemm
 } // namespace cutlass
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
+
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_layernorm_mainloop_fusion.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_layernorm_mainloop_fusion.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -190,15 +190,15 @@
 
   using Arguments = typename Base::Arguments;
   using GemmKernel = typename Base::GemmKernel;
 };
 
 ////////////////////////////////////////////////////////////////////////////////
 
-/// Parital specialization for column-major output exchanges problem size and operand.
+/// Partial specialization for column-major output exchanges problem size and operand.
 template <
     /// Element type for A matrix operand
     typename ElementA_,
     /// Layout type for A matrix operand
     typename LayoutA_,
     /// Element type for B matrix operand
     typename ElementB_,
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_sparse.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_sparse.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_splitk_parallel.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/symm.h`

 * *Files 19% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -25,367 +25,325 @@
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /*! \file
-    \brief Template for GEMM performing a reduction over K partitions in parallel.
+    \brief Template for a pipelined SYMM and HEMM kernels. Does not compute batching or support split-K.
+
+  
 */
 
 #pragma once
 
-#include "cutlass/cutlass.h"
-#include "cutlass/numeric_types.h"
+#include "cutlass/blas3.h"
 #include "cutlass/arch/arch.h"
 #include "cutlass/device_kernel.h"
 
 #include "cutlass/gemm/threadblock/threadblock_swizzle.h"
-#include "cutlass/gemm/kernel/gemm.h"
+#include "cutlass/gemm/kernel/symm_universal.h"
 
-#include "cutlass/gemm/kernel/default_gemm_splitk_parallel.h"
+#include "cutlass/gemm/kernel/default_symm_universal.h"
 #include "cutlass/gemm/device/default_gemm_configuration.h"
 
-#include "cutlass/epilogue/thread/conversion_op.h"
-#include "cutlass/reduction/kernel/reduce_split_k.h"
-#include "cutlass/reduction/thread/reduction_operators.h"
-
 ////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace gemm {
 namespace device {
 
-////////////////////////////////////////////////////////////////////////////////
-
-/*! 
-  Gemm device-level operator performing parallel reduction over the K partition.
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
-*/
 template <
     /// Element type for A matrix operand
     typename ElementA_,
     /// Layout type for A matrix operand
     typename LayoutA_,
+    /// Side Mode for A (kLeft or kRight)
+    SideMode SideModeA,
+    /// Fill Mode for A (kLower or kUpper)
+    FillMode FillModeA,
     /// Element type for B matrix operand
     typename ElementB_,
     /// Layout type for B matrix operand
     typename LayoutB_,
     /// Element type for C and D matrix operands
     typename ElementC_,
     /// Layout type for C and D matrix operands
     typename LayoutC_,
     /// Element type for internal accumulation
     typename ElementAccumulator_ = ElementC_,
     /// Operator class tag
-    typename OperatorClass_ = arch::OpClassSimt,
-    /// Tag indicating architecture to tune for.  This is the minimum SM that
-      /// supports the intended feature. The device kernel can be built
-      /// targeting any SM larger than this number.
-    typename ArchTag_ = arch::Sm70,
+    typename OperatorClass_ = arch::OpClassTensorOp,
+    /// Tag indicating architecture to tune for
+    typename ArchTag_ = arch::Sm80,
     /// Threadblock-level tile size (concept: GemmShape)
     typename ThreadblockShape_ = typename DefaultGemmConfiguration<
         OperatorClass_, ArchTag_, ElementA_, ElementB_, ElementC_,
         ElementAccumulator_>::ThreadblockShape,
     /// Warp-level tile size (concept: GemmShape)
     typename WarpShape_ = typename DefaultGemmConfiguration<
         OperatorClass_, ArchTag_, ElementA_, ElementB_, ElementC_,
         ElementAccumulator_>::WarpShape,
     /// Instruction-level tile size (concept: GemmShape)
     typename InstructionShape_ = typename DefaultGemmConfiguration<
         OperatorClass_, ArchTag_, ElementA_, ElementB_, ElementC_,
         ElementAccumulator_>::InstructionShape,
     /// Epilogue output operator
-    typename EpilogueOutputOp_ = typename DefaultGemmConfiguration<
-        OperatorClass_, ArchTag_, ElementA_, ElementB_, ElementC_,
-        ElementAccumulator_>::EpilogueOutputOp,
-    /// Epilogue output operator
-    typename ConvertScaledOp_ = cutlass::epilogue::thread::Convert<
-        ElementAccumulator_,
-        DefaultGemmConfiguration<OperatorClass_, ArchTag_, ElementA_, ElementB_,
-                                 ElementAccumulator_,
-                                 ElementAccumulator_>::EpilogueOutputOp::kCount,
-        ElementAccumulator_>,
-    /// Reduction operator
-    typename ReductionOp_ = cutlass::reduction::thread::ReduceAdd<
-        ElementAccumulator_, typename EpilogueOutputOp_::ElementAccumulator,
-        EpilogueOutputOp_::kCount>,
+    typename EpilogueOutputOp_ = epilogue::thread::LinearCombination<
+      ElementC_,
+      128 / sizeof_bits<ElementC_>::value,
+      ElementAccumulator_,
+      ElementAccumulator_,
+      epilogue::thread::ScaleType::OnlyAlphaScaling
+    >,
     /// Threadblock-level swizzling operator
-    typename ThreadblockSwizzle_ =
-        threadblock::GemmSplitKHorizontalThreadblockSwizzle,
+    typename ThreadblockSwizzle_ = threadblock::GemmIdentityThreadblockSwizzle<>,
     /// Number of stages used in the pipelined mainloop
     int Stages =
         DefaultGemmConfiguration<OperatorClass_, ArchTag_, ElementA_, ElementB_,
                                  ElementC_, ElementAccumulator_>::kStages,
     /// Access granularity of A matrix in units of elements
-    int kAlignmentA =
+    int AlignmentA =
         DefaultGemmConfiguration<OperatorClass_, ArchTag_, ElementA_, ElementB_,
                                  ElementC_, ElementAccumulator_>::kAlignmentA,
     /// Access granularity of B matrix in units of elements
-    int kAlignmentB =
+    int AlignmentB =
         DefaultGemmConfiguration<OperatorClass_, ArchTag_, ElementA_, ElementB_,
                                  ElementC_, ElementAccumulator_>::kAlignmentB,
-    /// Operation performed by GEMM
+    /// If true, kernel supports split-K with serial reduction
+    bool SplitKSerial = false,
+    /// Operation performed by SYMM
     typename Operator_ = typename DefaultGemmConfiguration<
         OperatorClass_, ArchTag_, ElementA_, ElementB_, ElementC_,
-        ElementAccumulator_>::Operator>
-class GemmSplitKParallel {
+        ElementAccumulator_>::Operator,
+    /// Blas3 computation mode (symmetric/hermitian)
+    BlasMode BlasMode_ = BlasMode::kSymmetric>
+class Symm {
  public:
 
   using ElementA = ElementA_;
   using LayoutA = LayoutA_;
+  using ElementAKernel = typename platform::conditional<(SideModeA == SideMode::kRight), ElementB_, ElementA_>::type;
+  using LayoutAKernel = typename platform::conditional<(SideModeA == SideMode::kRight), LayoutB_, LayoutA_>::type;
   using ElementB = ElementB_;
   using LayoutB = LayoutB_;
+  using ElementBKernel = typename platform::conditional<(SideModeA == SideMode::kRight), ElementA_, ElementB_>::type;
+  using LayoutBKernel = typename platform::conditional<(SideModeA == SideMode::kRight), LayoutA_, LayoutB_>::type;
   using ElementC = ElementC_;
   using LayoutC = LayoutC_;
   using ElementAccumulator = ElementAccumulator_;
   using OperatorClass = OperatorClass_;
   using ArchTag = ArchTag_;
   using ThreadblockShape = ThreadblockShape_;
   using WarpShape = WarpShape_;
   using InstructionShape = InstructionShape_;
-  using ConvertScaledOp = ConvertScaledOp_;
   using EpilogueOutputOp = EpilogueOutputOp_;
-  using ReductionOp = ReductionOp_;
   using ThreadblockSwizzle = ThreadblockSwizzle_;
   using Operator = Operator_;
+  static SideMode const kSideModeA = SideModeA;
+  static FillMode const kFillModeA = FillModeA;
   static int const kStages = Stages;
-
-  /// GEMM kernel 
-  using GemmKernel = typename kernel::DefaultGemmSplitKParallel<
-    ElementA,
-    LayoutA,
-    kAlignmentA,
-    ElementB,
-    LayoutB,
-    kAlignmentB,
-    ElementAccumulator,
+  static int const kAlignmentA = AlignmentA;
+  static int const kAlignmentAKernel = (SideModeA == SideMode::kRight) ? AlignmentB : AlignmentA;
+  static int const kAlignmentB = AlignmentB;
+  static int const kAlignmentBKernel = (SideModeA == SideMode::kRight) ? AlignmentA : AlignmentB;
+  static int const kAlignmentC = EpilogueOutputOp::kCount;
+  static bool const kSplitKSerial = SplitKSerial;
+  static BlasMode const kBlasMode = BlasMode_;
+
+  // static asserts for symm update kernel
+  static_assert(platform::is_same<LayoutA, LayoutB>::value,
+    "SYMM update operator support same layouts for operand A and B");
+
+  /// Define the kernel
+  using SymmKernel = typename kernel::DefaultSymmUniversal<
+    ElementAKernel,
+    LayoutAKernel,
+    kSideModeA,
+    kFillModeA,
+    kAlignmentAKernel,
+    ElementBKernel,
+    LayoutBKernel,
+    kAlignmentBKernel,
+    ElementC,
     LayoutC,
     ElementAccumulator,
     OperatorClass,
     ArchTag,
     ThreadblockShape,
     WarpShape,
     InstructionShape,
-    ConvertScaledOp,
+    EpilogueOutputOp,
     ThreadblockSwizzle,
     kStages,
-    Operator
-  >::GemmKernel;
-
-  /// Reduction kernel
-  using ReductionKernel = cutlass::reduction::kernel::ReduceSplitK<
-    cutlass::MatrixShape<4, 32 * EpilogueOutputOp::kCount>,
-    EpilogueOutputOp,
-    ReductionOp
-  >;
-
-  //
-  //
-  //
-
-  /// Argument structure
-  struct Arguments {
-
-    //
-    // Data members
-    //
-
-    GemmCoord problem_size;
-    TensorRef<ElementA const, LayoutA> ref_A;
-    TensorRef<ElementB const, LayoutB> ref_B;
-    TensorRef<ElementC const, LayoutC> ref_C;
-    TensorRef<ElementC, LayoutC> ref_D;
-    typename EpilogueOutputOp::Params epilogue;
-    int split_k_slices;
-    typename ConvertScaledOp::Params convert;
-    typename ReductionOp::Params reduction;
-
-    //
-    // Methods
-    //
-
-    /// Default ctor
-    CUTLASS_HOST_DEVICE
-    Arguments() { }
-
-    /// Constructs an Arguments structure 
-    CUTLASS_HOST_DEVICE
-    Arguments(
-      GemmCoord problem_size_,
-      TensorRef<ElementA const, LayoutA> ref_A_,
-      TensorRef<ElementB const, LayoutB> ref_B_,
-      TensorRef<ElementC const, LayoutC> ref_C_,
-      TensorRef<ElementC, LayoutC> ref_D_,
-      typename EpilogueOutputOp::Params epilogue_ = 
-        typename EpilogueOutputOp::Params(),
-      int split_k_slices = 1,
-      typename ConvertScaledOp::Params convert_ = 
-        typename ConvertScaledOp::Params(),
-      typename ReductionOp::Params reduction_ =
-        typename ReductionOp::Params()
-    ):
-      problem_size(problem_size_),
-      ref_A(ref_A_),
-      ref_B(ref_B_),
-      ref_C(ref_C_),
-      ref_D(ref_D_),
-      epilogue(epilogue_),
-      split_k_slices(split_k_slices),
-      convert(convert_),
-      reduction(reduction_) { }
-  };
+    kSplitKSerial,
+    Operator,
+    kBlasMode
+  >::SymmKernel;
+  
+  using Arguments = typename SymmKernel::Arguments;
 
 private:
 
   /// Kernel parameters object
-  typename GemmKernel::Params gemm_params_;
-
-  /// Reduction kernel parameters object
-  typename ReductionKernel::Params reduction_params_;
-
+  typename SymmKernel::Params params_;
 public:
 
-  /// Constructs the GEMM.
-  GemmSplitKParallel() { }
+  /// Constructs the SYMM.
+  Symm() { }
 
-  /// Determines whether the GEMM can execute the given problem.
+  /// Determines whether the SYMM can execute the given problem.
   static Status can_implement(Arguments const &args) {
 
-    // TODO
+    if (!kSplitKSerial && args.batch_count > 1) {
+      return Status::kErrorInvalidProblem;
+    }
+
+    Status status = SymmKernel::can_implement(args);
+
+    if (SideModeA == SideMode::kInvalid) {
+      return Status::kErrorInvalidProblem;
+    }
+   
+    if (FillModeA != FillMode::kLower && FillModeA != FillMode::kUpper) {
+      return Status::kErrorInvalidProblem;
+    }
+
+    if (status != Status::kSuccess) {
+      return status;
+    }
 
     return Status::kSuccess;
   }
 
   /// Gets the workspace size
   static size_t get_workspace_size(Arguments const &args) {
     
+    size_t bytes = 0;
+
     // Determine grid shape
     ThreadblockSwizzle threadblock_swizzle;
 
-    cutlass::gemm::GemmCoord grid_shape = threadblock_swizzle.get_tiled_shape(
+    cutlass::gemm::GemmCoord tiled_shape = threadblock_swizzle.get_tiled_shape(
       args.problem_size, 
       {ThreadblockShape::kM, ThreadblockShape::kN, ThreadblockShape::kK},
-      args.split_k_slices);
+      args.batch_count);
+    
+    if (kSplitKSerial && args.batch_count > 1) {
 
-    return sizeof(ElementAccumulator_) * size_t(args.problem_size.m()) * size_t(args.problem_size.n()) * grid_shape.k();
-  }
+      bytes += sizeof(int) * size_t(tiled_shape.m()) * size_t(tiled_shape.n());
+    }
 
-  /// Initializes GEMM state from arguments.
-  Status initialize(Arguments const &args, void *workspace) {
+    return bytes;
+  }
 
+  /// Initializes SYMM state from arguments.
+  Status initialize(Arguments const &args, void *workspace = nullptr, cudaStream_t stream = nullptr) {
+    
     // Determine grid shape
     ThreadblockSwizzle threadblock_swizzle;
 
-    cutlass::gemm::GemmCoord grid_shape = threadblock_swizzle.get_tiled_shape(
+    cutlass::gemm::GemmCoord grid_tiled_shape = threadblock_swizzle.get_tiled_shape(
       args.problem_size, 
       {ThreadblockShape::kM, ThreadblockShape::kN, ThreadblockShape::kK},
-      args.split_k_slices);
+      args.batch_count);
 
-    // Define a reference to the workspace - this is an aligned region in device memory.
-    if (!workspace) {
-      return Status::kErrorWorkspaceNull;
+    if (kSplitKSerial) {
+      if (args.batch_count > 1) {
+        if (!workspace) {
+          return Status::kErrorWorkspaceNull;
+        }
+
+        size_t bytes = get_workspace_size(args);
+      
+        cudaError_t result = cudaMemsetAsync(workspace, 0, bytes, stream);
+
+        if (result != cudaSuccess) {
+          return Status::kErrorInternal;
+        }
+      }
+    }
+    else {
+
+      if (args.batch_count > 1) {
+        return Status::kErrorInvalidProblem;
+      }
     }
     
-    TensorRef<ElementAccumulator_, layout::RowMajor> ref_workspace(
-      static_cast<ElementAccumulator_ *>(workspace), 
-      args.problem_size.n());
+    int gemm_k_size = args.problem_size.k();
 
-    int64_t partition_stride = int64_t(args.problem_size.m()) * int64_t(args.problem_size.n());
+   // Swapping argument for A and B, if A was on the right side (problem size doesn't need to change here).
+    if (kSideModeA == SideMode::kRight) {
+      // Initialize the Params structure
+      params_ = typename SymmKernel::Params{
+        args.swapped_matrices(),
+        grid_tiled_shape,
+        gemm_k_size,
+        static_cast<int *>(workspace)
+      };
+
+      return Status::kSuccess;
+    }
 
     // Initialize the Params structure
-    gemm_params_ = typename GemmKernel::Params{
-      args.problem_size,
-      grid_shape,
-      args.ref_A.non_const_ref(),
-      args.ref_B.non_const_ref(),
-      ref_workspace,
-      args.convert,
-      partition_stride
+    params_ = typename SymmKernel::Params{
+      args,
+      grid_tiled_shape,
+      gemm_k_size,
+      static_cast<int *>(workspace)
     };
-
-    reduction_params_ = typename ReductionKernel::Params(
-      args.problem_size.mn(),
-      grid_shape.k(),
-      partition_stride,
-      ref_workspace,
-      args.ref_D,
-      args.ref_C.non_const_ref(),
-      args.epilogue
-    );
-
+    
     return Status::kSuccess;
   }
 
   /// Lightweight update given a subset of arguments
   Status update(Arguments const &args, void *workspace = nullptr) {
+    
+    if (kSplitKSerial && args.batch_count > 1) {  
+      if (!workspace) {
+        return Status::kErrorWorkspaceNull;
+      }
+    }
+
+    size_t workspace_bytes = get_workspace_size(args);
 
-    if (!workspace) {
+    if (workspace_bytes && !workspace) {
       return Status::kErrorWorkspaceNull;
     }
 
-    gemm_params_.ref_A.reset(args.ref_A.data());
-    gemm_params_.ref_B.reset(args.ref_B.data());
-    gemm_params_.ref_D.reset(workspace);     
-
-    reduction_params_.ref_D.reset(args.ref_D.data());
-    reduction_params_.ref_C.reset(args.ref_C.data());
+    params_.update(args, workspace);
 
     return Status::kSuccess;
   }
 
   /// Runs the kernel using initialized state.
   Status run(cudaStream_t stream = nullptr) {
 
-    //
-    // Launch GEMM kernel
-    //
-
     ThreadblockSwizzle threadblock_swizzle;
 
-    dim3 grid = threadblock_swizzle.get_grid_shape(gemm_params_.grid_tiled_shape);
-    dim3 block(GemmKernel::kThreadCount, 1, 1);
+    dim3 grid = threadblock_swizzle.get_grid_shape(params_.grid_tiled_shape);
+    dim3 block(SymmKernel::kThreadCount, 1, 1);
 
-    cudaError_t result;
+    int smem_size = int(sizeof(typename SymmKernel::SharedStorage));
 
-    int smem_size = int(sizeof(typename GemmKernel::SharedStorage));
     if (smem_size >= (48 << 10)) {
-
-      result = cudaFuncSetAttribute(
-        Kernel<GemmKernel>,
-        cudaFuncAttributeMaxDynamicSharedMemorySize,
-        smem_size);
+      cudaError_t result = cudaFuncSetAttribute(Kernel<SymmKernel>,
+                                    cudaFuncAttributeMaxDynamicSharedMemorySize,
+                                    smem_size);
 
       if (result != cudaSuccess) {
         return Status::kErrorInternal;
       }
     }
 
-    Kernel<GemmKernel><<<grid, block, smem_size, stream>>>(gemm_params_);
-
-    result = cudaGetLastError();
-
-    if (result != cudaSuccess) {
-      return Status::kErrorInternal;
-    }
-
-    //
-    // Launch reduction kernel
-    //
-
-    block = ReductionKernel::block_shape();
-    grid = ReductionKernel::grid_shape(gemm_params_.problem_size.mn());
+    cutlass::Kernel<SymmKernel><<<grid, block, smem_size, stream>>>(params_);
 
-    Kernel<ReductionKernel><<< grid, block, 0, stream >>>(reduction_params_);
-
-    result = cudaGetLastError();
-
-    if (result != cudaSuccess) {
-      return Status::kErrorInternal;
-    }
+    cudaError_t result = cudaGetLastError();
 
     return result == cudaSuccess ? Status::kSuccess : Status::kErrorInternal;
   }
 
   /// Runs the kernel using initialized state.
   Status operator()(cudaStream_t stream = nullptr) {
     return run(stream);
@@ -402,202 +360,208 @@
     if (status == Status::kSuccess) {
       status = run(stream);
     }
 
     return status;
   }
 };
-
 ////////////////////////////////////////////////////////////////////////////////
 
-/// Partial specialization for column-major output
+/********************************************************************************************************
+  SYMM/HEMM has 4 combinations based on Layouts {RowMajor, ColumnMajor} x Side mode {LeftSide, RightSide}
+  In templates and arguments to cutlass kernel, `matrix A` is always symmetric/hermitian, and `matrix B` is rectangular. 
+  (adhering to the cuBLAS convention)
+
+  Although, cuBLAS SYMM/HEMM only supports ColumnMajor layouts for all matrices (A, B, C/D).
+
+  For the mainloop and symm kernel, `A` and `B` points to left-side and right-side matrices, respectively.
+  
+  Thus, for LeftSide mode `A` and `B` points to `matrix A` and `matrix B`, respectively. While for 
+  the RightSide mode `A` and `B` points to `matrix B` and `matrix A`, respectively. 
+  
+  Additionally, CUTLASS GEMM epilogue is always RowMajor, and ColumnMajor output is achieved by 
+  transposing the GEMM problem. Thus, ColumnMajor output layout for SYMM/HEMM requires:
+   - Transposing `matrix A` and `matrix B` layouts
+   - Swapping problem size m and n values
+   - Swapping LeftSide and RightSide mode
+  
+  RowMajor output:    D = matrix A x matrix B
+  ColumnMajor output: D = matrix A x matrix B -> Transpose (D) = Transpose(matrix B) x Transpose(matrix A)
+
+  {RowMajor, ColumnMajor} x Side Mode {LeftSide, RightSide} 4 cases:
+    1.  LeftSide mode and RowMajor output (default template)
+    2.  LeftSide mode and ColumnMajor output 
+    3.  RightSide mode and RowMajor output
+    4.  RightSide mode and ColumnMajor output
+  
+  Mapping ColumnMajor output layout cases 2 and 4 to RowMajor efficient epilogue implementation:
+  
+  Case 2 -> Case 3:
+      D_col = matrix A x matrix B (LeftSide mode) 
+   => Transpose(D_col) = Transpose(matrix B) x Transpose(matrix A) (RightSide mode)
+
+  swap pointers for `A` and `B` call GEMM mainloop with RowMajor efficient-epilogue
+
+  Case 4 -> Case 1:
+      D_col = matrix B x matrix A (RightSide mode) 
+   => Transpose(D_col) = Transpose(matrix A) x Transpose(matrix B) (LeftSide mode)
+
+   call GEMM mainloop for with RowMajor efficient-epilogue
+********************************************************************************************************/
+
+/// Partial specialization for column-major output exchanges problem size and operand.
 template <
     /// Element type for A matrix operand
     typename ElementA_,
     /// Layout type for A matrix operand
     typename LayoutA_,
+    /// Side Mode for A (kLeft or kRight)
+    SideMode SideModeA,
+    /// Fill Mode for A (kLower or kUpper)
+    FillMode FillModeA,
     /// Element type for B matrix operand
     typename ElementB_,
     /// Layout type for B matrix operand
     typename LayoutB_,
     /// Element type for C and D matrix operands
     typename ElementC_,
     /// Element type for internal accumulation
     typename ElementAccumulator_,
     /// Operator class tag
     typename OperatorClass_,
     /// Tag indicating architecture to tune for.  This is the minimum SM that
-      /// supports the intended feature. The device kernel can be built
-      /// targeting any SM larger than this number.
+    /// supports the intended feature. The device kernel can be built
+    /// targeting any SM larger than this number.
     typename ArchTag_,
     /// Threadblock-level tile size (concept: GemmShape)
     typename ThreadblockShape_,
     /// Warp-level tile size (concept: GemmShape)
     typename WarpShape_,
     /// Instruction-level tile size (concept: GemmShape)
     typename InstructionShape_,
     /// Epilogue output operator
     typename EpilogueOutputOp_,
-    /// Epilogue output operator
-    typename ConvertScaledOp_,
-    /// Reduction operator
-    typename ReductionOp_,
     /// Threadblock-level swizzling operator
     typename ThreadblockSwizzle_,
     /// Number of stages used in the pipelined mainloop
-    int Stages, int kAlignmentA, int kAlignmentB,
-    /// Operation performed by GEMM
-    typename Operator_>
-class GemmSplitKParallel<ElementA_, LayoutA_, ElementB_, LayoutB_, ElementC_,
-                         layout::ColumnMajor, ElementAccumulator_,
-                         OperatorClass_, ArchTag_, ThreadblockShape_,
-                         WarpShape_, InstructionShape_, EpilogueOutputOp_,
-                         ConvertScaledOp_, ReductionOp_, ThreadblockSwizzle_,
-                         Stages, kAlignmentA, kAlignmentB, Operator_> {
+    int Stages,
+    /// Access granularity of A matrix in units of elements
+    int AlignmentA,
+    /// Access granularity of B matrix in units of elements
+    int AlignmentB,
+    /// If true, kernel supports split-K with serial reduction
+    bool SplitKSerial,
+    /// Operation performed by Symm update kernel
+    typename Operator_,
+    /// Blas3 computation mode (symmetric/hermitian)
+    BlasMode BlasMode_
+    >
+class Symm<ElementA_, LayoutA_, SideModeA, FillModeA, ElementB_, LayoutB_, ElementC_,
+           layout::ColumnMajor,  // partially specialized on LayoutC
+           ElementAccumulator_, OperatorClass_, ArchTag_, ThreadblockShape_,
+           WarpShape_, InstructionShape_, EpilogueOutputOp_,
+           ThreadblockSwizzle_, Stages, AlignmentA, AlignmentB,
+           SplitKSerial, Operator_, BlasMode_> {
  public:
 
   using ElementA = ElementA_;
   using LayoutA = LayoutA_;
   using ElementB = ElementB_;
   using LayoutB = LayoutB_;
   using ElementC = ElementC_;
   using LayoutC = layout::ColumnMajor;
   using ElementAccumulator = ElementAccumulator_;
   using OperatorClass = OperatorClass_;
   using ArchTag = ArchTag_;
   using ThreadblockShape = ThreadblockShape_;
   using WarpShape = WarpShape_;
   using InstructionShape = InstructionShape_;
-  using ConvertScaledOp = ConvertScaledOp_;
   using EpilogueOutputOp = EpilogueOutputOp_;
-  using ReductionOp = ReductionOp_;
   using ThreadblockSwizzle = ThreadblockSwizzle_;
   using Operator = Operator_;
+  static SideMode const kSideModeA = SideModeA;
+  static FillMode const kFillModeA = FillModeA;
   static int const kStages = Stages;
-
-  using UnderlyingOperator = GemmSplitKParallel< 
-    ElementB,
-    typename layout::LayoutTranspose<LayoutB>::type,
+  static int const kAlignmentA = AlignmentA;
+  static int const kAlignmentB = AlignmentB;
+  static int const kAlignmentC = EpilogueOutputOp::kCount;
+  static bool const kSplitKSerial = SplitKSerial;
+  static BlasMode const kBlasMode = BlasMode_;
+  
+  /// Define the kernel
+  using UnderlyingOperator = typename cutlass::gemm::device::Symm<
     ElementA,
     typename layout::LayoutTranspose<LayoutA>::type,
+    InvertSideMode<kSideModeA>::mode,
+    InvertFillMode<kFillModeA>::mode,
+    ElementB,
+    typename layout::LayoutTranspose<LayoutB>::type, 
     ElementC,
-    layout::RowMajor,    
+    layout::RowMajor,
     ElementAccumulator,
     OperatorClass,
     ArchTag,
     ThreadblockShape,
     WarpShape,
     InstructionShape,
     EpilogueOutputOp,
-    ConvertScaledOp,
-    ReductionOp,
     ThreadblockSwizzle,
-    Stages,
+    kStages,
     kAlignmentA,
     kAlignmentB,
-    Operator
+    kSplitKSerial,
+    Operator,
+    kBlasMode
   >;
-
-  using UnderlyingArguments = typename UnderlyingOperator::Arguments;
-  using GemmKernel = typename UnderlyingOperator::GemmKernel;
-  using ReductionKernel = typename UnderlyingOperator::ReductionKernel;
+  
 
   /// Argument structure
-  struct Arguments {
-
-    //
-    // Data members
-    //
-
-    GemmCoord problem_size;
-    TensorRef<ElementA const, LayoutA> ref_A;
-    TensorRef<ElementB const, LayoutB> ref_B;
-    TensorRef<ElementC const, LayoutC> ref_C;
-    TensorRef<ElementC, LayoutC> ref_D;
-    typename EpilogueOutputOp::Params epilogue;
-    int split_k_slices;
-    typename ConvertScaledOp::Params convert;
-    typename ReductionOp::Params reduction;
-
-    //
-    // Methods
-    //
-
-    /// Default ctor
-    CUTLASS_HOST_DEVICE
-    Arguments() { }
-
-    /// Constructs an Arguments structure 
-    CUTLASS_HOST_DEVICE
-    Arguments(
-      GemmCoord problem_size_,
-      TensorRef<ElementA const, LayoutA> ref_A_,
-      TensorRef<ElementB const, LayoutB> ref_B_,
-      TensorRef<ElementC const, LayoutC> ref_C_,
-      TensorRef<ElementC, LayoutC> ref_D_,
-      typename EpilogueOutputOp::Params epilogue_ = 
-        typename EpilogueOutputOp::Params(),
-      int split_k_slices = 1,
-      typename ConvertScaledOp::Params convert_ = 
-        typename ConvertScaledOp::Params(),
-      typename ReductionOp::Params reduction_ =
-        typename ReductionOp::Params()
-    ):
-      problem_size(problem_size_),
-      ref_A(ref_A_),
-      ref_B(ref_B_),
-      ref_C(ref_C_),
-      ref_D(ref_D_),
-      epilogue(epilogue_),
-      split_k_slices(split_k_slices),
-      convert(convert_),
-      reduction(reduction_) { }
-  };
+  using Arguments = typename UnderlyingOperator::Arguments;
+  using SymmKernel = typename UnderlyingOperator::SymmKernel;
 
 private:
 
-  /// Kernel parameters object
   UnderlyingOperator underlying_operator_;
 
 public:
 
-  /// Constructs the GEMM.
-  GemmSplitKParallel() { }
+  /// Constructs the Symm.
+  Symm() { }
 
-  /// Helper to construct a transposed equivalent for the underying GEMM operator
-  static UnderlyingArguments to_underlying_arguments(Arguments const &args) {
-    return UnderlyingArguments(
-      {args.problem_size.n(), args.problem_size.m(), args.problem_size.k()},
-      {args.ref_B.data(), args.ref_B.stride(0)},
-      {args.ref_A.data(), args.ref_A.stride(0)},
-      {args.ref_C.data(), args.ref_C.stride(0)},
-      {args.ref_D.data(), args.ref_D.stride(0)},
-      args.epilogue,
-      args.split_k_slices,
-      args.convert,
-      args.reduction
-    );
+  /// Helper to construct a transposed equivalent for the underying SYMM operator
+  static Arguments to_underlying_arguments(Arguments const &args) {
+    return args.transposed_problem_size();
   }
 
-  /// Determines whether the GEMM can execute the given problem.
+  /// Determines whether the Symm can execute the given problem.
   static Status can_implement(Arguments const &args) {
 
     return UnderlyingOperator::can_implement(to_underlying_arguments(args));
   }
 
   /// Gets the workspace size
   static size_t get_workspace_size(Arguments const &args) {
     
     return UnderlyingOperator::get_workspace_size(to_underlying_arguments(args));
   }
 
-  /// Initializes GEMM state from arguments.
-  Status initialize(Arguments const &args, void *workspace) {
+  /// Computes the grid shape
+  static dim3 get_grid_shape(Arguments const &args) { 
+    return UnderlyingOperator::get_grid_shape(to_underlying_arguments(args));
+  }
+
+  /// Computes the maximum number of active blocks per multiprocessor
+  static int maximum_active_blocks(int smem_capacity = -1) {
+    return UnderlyingOperator::maximum_active_blocks(smem_capacity);
+  }
+
+  /// Initializes Symm state from arguments.
+  Status initialize(Arguments const &args, void *workspace = nullptr, cudaStream_t stream = nullptr) {
 
-    return underlying_operator_.initialize(to_underlying_arguments(args), workspace);
+    return underlying_operator_.initialize(to_underlying_arguments(args), workspace, stream);
   }
 
   /// Lightweight update given a subset of arguments
   Status update(Arguments const &args, void *workspace = nullptr) {
 
     return underlying_operator_.update(to_underlying_arguments(args), workspace);
   }
@@ -628,11 +592,11 @@
     return status;
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////
 
 } // namespace device
-} // namespace gemm
+} // namespace Symm
 } // namespace cutlass
 
 ////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_universal.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_universal.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -215,15 +215,15 @@
 
   using Arguments = typename Base::Arguments;
   using GemmKernel = typename Base::GemmKernel;
 };
 
 ////////////////////////////////////////////////////////////////////////////////
 
-/// Parital specialization for column-major output exchanges problem size and operand.
+/// Partial specialization for column-major output exchanges problem size and operand.
 template <
     /// Element type for A matrix operand
     typename ElementA_,
     /// Layout type for A matrix operand
     typename LayoutA_,
     /// Element type for B matrix operand
     typename ElementB_,
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_universal_adapter.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_with_reduction.h`

 * *Files 26% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -24,179 +24,118 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
-/*! 
-  \file
-  \brief The universal GEMM accommodates serial reductions, parallel reductions, batched strided, and 
-    batched array variants.
+/*! \file
+    \brief Template for a pipelined GEMM kernel. Does not compute batching or support split-K.
 */
 
 #pragma once
 
 #include "cutlass/cutlass.h"
-#include "cutlass/gemm/device/gemm_universal_base.h"
-#include "cutlass/gemm/kernel/gemm_transpose_operands.h"
+#include "cutlass/numeric_types.h"
+#include "cutlass/arch/arch.h"
+
+#include "cutlass/layout/matrix.h"
+#include "cutlass/transform/threadblock/predicated_tile_iterator.h"
+#include "cutlass/transform/threadblock/predicated_tile_iterator_2dthreadtile.h"
+#include "cutlass/gemm/threadblock/default_mma_core_with_reduction.h"
 
 ////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace gemm {
-namespace device {
-
-/////////////////////////////////////////////////////////////////////////////////////////////////
+namespace threadblock {
 
-template <typename GemmKernel_>
-class GemmUniversalAdapter {
-public:
-
-  using GemmKernel = GemmKernel_;
-
-  static bool const kInternalTranspose = 
-    platform::is_same<typename GemmKernel::LayoutC, cutlass::layout::RowMajor>::value;
-
-  using ThreadblockShape = typename GemmKernel::Mma::Shape;
-  using WarpShape = typename GemmKernel::WarpShape;
-  using InstructionShape = typename GemmKernel::InstructionShape;
-
-  // warp-level, arch-level (instruction), math operator 
-  using WarpMmaOperator = typename GemmKernel::Mma::Policy::Operator;
-  using ArchMmaOperator = typename WarpMmaOperator::ArchMmaOperator;
-  using MathOperator = typename WarpMmaOperator::MathOperator;
-  
-  // Operator class and arch tag extract bottom-up 
-  // set it for top-level gemm device-level template
-  using OperatorClass = typename WarpMmaOperator::OperatorClass;
-  using ArchTag = typename WarpMmaOperator::ArchTag;
-
-  // Type, layout, and complex transform deliberately exchanged with B
-  using MapArguments = kernel::detail::MapArguments<
-    typename GemmKernel::ElementA,
-    typename GemmKernel::LayoutA,
-    GemmKernel::kTransformA,
-    GemmKernel::kAlignmentA,
-    typename GemmKernel::ElementB,
-    typename GemmKernel::LayoutB,
-    GemmKernel::kTransformB,
-    GemmKernel::kAlignmentB,
-    typename GemmKernel::LayoutC,
-    kInternalTranspose
-  >;
-
-  using ElementA = typename MapArguments::ElementA;
-  using LayoutA = typename MapArguments::LayoutA;
-  static ComplexTransform const kTransformA = MapArguments::kTransformA;
-  static int const kAlignmentA = MapArguments::kAlignmentA;
-
-  using ElementB = typename MapArguments::ElementB;
-  using LayoutB = typename MapArguments::LayoutB;
-  static ComplexTransform const kTransformB = MapArguments::kTransformB;
-  static int const kAlignmentB = MapArguments::kAlignmentB;
-  
-  using ElementC = typename GemmKernel::ElementC;
-  using LayoutC = typename MapArguments::LayoutC;
-  static int const kAlignmentC = GemmKernel::kAlignmentC;
- 
-  using TensorRefA = TensorRef<ElementA const, LayoutA>;
-  using TensorRefB = TensorRef<ElementB const, LayoutB>;
-  using TensorRefC = TensorRef<ElementC const, LayoutC>;
-  using TensorRefD = TensorRef<ElementC, LayoutC>;
-
-  static int const kStages = GemmKernel::Mma::kStages;
-
-  using EpilogueOutputOp = typename GemmKernel::EpilogueOutputOp;
-  using ElementAccumulator = typename EpilogueOutputOp::ElementAccumulator;
-  using ThreadblockSwizzle = typename GemmKernel::ThreadblockSwizzle;
-  using UnderlyingOperator = GemmUniversalBase<GemmKernel>;
-  using Arguments = typename UnderlyingOperator::Arguments;
-
-private:
-
-  UnderlyingOperator underlying_operator_;
-
-public:
-
-  /// Constructs the GEMM.
-  GemmUniversalAdapter() { }
-
-  /// Helper to construct a transposed equivalent for the underying GEMM operator
-  static Arguments to_underlying_arguments(Arguments const &args) {
-    if (kInternalTranspose) {
-      return args.transposed_problem();
-    }
-    else {
-      return args;
-    }
-  }
-
-  /// Determines whether the GEMM can execute the given problem.
-  static Status can_implement(Arguments const &args) {
-
-    return UnderlyingOperator::can_implement(to_underlying_arguments(args));
-  }
-
-  /// Gets the workspace size
-  static size_t get_workspace_size(Arguments const &args) {
-    
-    return UnderlyingOperator::get_workspace_size(to_underlying_arguments(args));
-  }
-
-  /// Computes the grid shape
-  static dim3 get_grid_shape(Arguments const &args) { 
-    return UnderlyingOperator::get_grid_shape(to_underlying_arguments(args));
-  }
-
-  /// Computes the maximum number of active blocks per multiprocessor
-  static int maximum_active_blocks(int smem_capacity = -1) {
-    return UnderlyingOperator::maximum_active_blocks(smem_capacity);
-  }
-
-  /// Initializes GEMM state from arguments.
-  Status initialize(Arguments const &args, void *workspace = nullptr, cudaStream_t stream = nullptr) {
-
-    return underlying_operator_.initialize(to_underlying_arguments(args), workspace, stream);
-  }
-
-  /// Lightweight update given a subset of arguments.  Problem geometry is assumed to
-  /// remain the same.
-  Status update(Arguments const &args) {
-
-    return underlying_operator_.update(to_underlying_arguments(args));
-  }
-
-  /// Runs the kernel using initialized state.
-  Status run(cudaStream_t stream = nullptr) {
-
-    return underlying_operator_.run(stream);
-  }
-
-  /// Runs the kernel using initialized state.
-  Status operator()(cudaStream_t stream = nullptr) {
-    return run(stream);
-  }
-
-  /// Runs the kernel using initialized state.
-  Status operator()(
-    Arguments const &args, 
-    void *workspace = nullptr, 
-    cudaStream_t stream = nullptr) {
-    
-    Status status = initialize(args, workspace, stream);
-    
-    if (status == Status::kSuccess) {
-      status = run(stream);
-    }
+////////////////////////////////////////////////////////////////////////////////
 
-    return status;
-  }
+template <
+    /// Element type for A matrix operand
+    typename ElementA,
+    /// Layout type for A matrix operand
+    typename LayoutA,
+    /// Access granularity of A matrix in units of elements
+    int kAlignmentA,
+    /// Element type for B matrix operand
+    typename ElementB,
+    /// Layout type for B matrix operand
+    typename LayoutB,
+    /// Access granularity of B matrix in units of elements
+    int kAlignmentB,
+    /// Element type for internal accumulation
+    typename ElementAccumulator,
+    /// Layout type for C and D matrix operands
+    typename LayoutC,
+    /// Operator class tag
+    typename OperatorClass,
+    ///                                                                                               
+    bool ReduceKForA_,
+    /// Tag indicating architecture to tune for
+    typename ArchTag,
+    /// Threadblock-level tile size (concept: GemmShape)
+    typename ThreadblockShape,
+    /// Warp-level tile size (concept: GemmShape)
+    typename WarpShape,
+    /// Instruction-level tile size (concept: GemmShape)
+    typename InstructionShape,
+    /// Number of stages used in the pipelined mainloop
+    int Stages,
+    /// Operation perfomed by GEMM
+    typename Operator,
+    /// Store the accumulators in row major or column major.  Row major is used
+    /// when output layout is interleaved.
+    bool AccumulatorsInRowMajor = false,
+    /// Use zfill or predicate for SM80 out-of-bound cp.async 
+    SharedMemoryClearOption SharedMemoryClear = SharedMemoryClearOption::kNone
+    >
+struct DefaultMmaWithReduction {
+
+  static cutlass::arch::CacheOperation::Kind const CacheOpA =
+      ((sizeof_bits<ElementA>::value * kAlignmentA) == 128)
+          ? cutlass::arch::CacheOperation::Global
+          : cutlass::arch::CacheOperation::Always;
+
+  static cutlass::arch::CacheOperation::Kind const CacheOpB =
+      ((sizeof_bits<ElementB>::value * kAlignmentB) == 128)
+          ? cutlass::arch::CacheOperation::Global
+          : cutlass::arch::CacheOperation::Always;
+
+  // Define the MmaCore components
+  using MmaCore = typename cutlass::gemm::threadblock::DefaultMmaWithReductionCore<
+      ThreadblockShape, WarpShape, InstructionShape, ElementA, LayoutA,
+      ElementB, LayoutB, ElementAccumulator, layout::RowMajor, arch::OpClassTensorOp,
+      ReduceKForA_,  Stages, Operator, false, CacheOpA, CacheOpB>;
+
+  // Define iterators over tiles from the A operand
+  using ThreadMapA = typename MmaCore::IteratorThreadMapA;
+  using AccessTypeA = cutlass::Array<ElementA, kAlignmentA>;
+  using IteratorA =
+      cutlass::transform::threadblock::PredicatedTileAccessIterator<
+          cutlass::MatrixShape<ThreadblockShape::kM, ThreadblockShape::kK>,
+          ElementA, LayoutA, 1, ThreadMapA, AccessTypeA>;
+
+  // Define iterators over tiles from the B operand
+  using ThreadMapB = typename MmaCore::IteratorThreadMapB;
+  using AccessTypeB = cutlass::Array<ElementB, kAlignmentB>;
+  using IteratorB =
+      cutlass::transform::threadblock::PredicatedTileAccessIterator<
+          cutlass::MatrixShape<ThreadblockShape::kK, ThreadblockShape::kN>,
+          ElementB, LayoutB, 0, ThreadMapB, AccessTypeB>;
+
+  // Define the threadblock-scoped multistage matrix multiply
+  using ThreadblockMma = cutlass::gemm::threadblock::MmaWithReductionMultistage<
+      typename MmaCore::Shape, IteratorA, typename MmaCore::SmemIteratorA,
+      MmaCore::kCacheOpA, IteratorB, typename MmaCore::SmemIteratorB,
+      MmaCore::kCacheOpB, ElementAccumulator, layout::RowMajor,
+      typename MmaCore::MmaPolicy, Stages, SharedMemoryClear>;
 };
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+////////////////////////////////////////////////////////////////////////////////
 
-} // namespace device
+} // namespace threadblock
 } // namespace gemm
-} // namespace cutlass
+} // namespace cutlass 
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_universal_base.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_universal_base.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -103,14 +103,16 @@
 
   /// Device SM count
   thread_local static int device_sms_;
 
   /// Kernel SM occupancy (in thread blocks)
   thread_local static int sm_occupancy_;
 
+  /// Kernel dynamic shared memory allocation requirement
+  thread_local static int smem_size_;
 
   /// Initialize static thread-local members for the thread's current device,
   /// if necessary.
   static Status init_device_props()
   {
     CUTLASS_TRACE_HOST("GemmUniversalBase::init_device_props()");
 
@@ -134,23 +136,23 @@
     cudart_result = cudaDeviceGetAttribute (&device_sms_, cudaDevAttrMultiProcessorCount, current_ordinal);
     if (cudart_result != cudaSuccess) {
       CUTLASS_TRACE_HOST("  cudaDeviceGetAttribute() returned error " << cudaGetErrorString(cudart_result));
       return Status::kErrorInternal;
     }
 
     // Update the kernel function's shared memory configuration for the current device
-    int smem_size = int(sizeof(typename GemmKernel::SharedStorage));
-    if (smem_size >= (48 << 10))
-    {
-      // Requires more than 48KB: configure for extended, dynamic shared memory
+    smem_size_ = int(sizeof(typename GemmKernel::SharedStorage));
 
+    // If requires more than 48KB: configure for extended, dynamic shared memory
+    if (smem_size_ >= (48 << 10))
+    {
       cudart_result = cudaFuncSetAttribute(
         Kernel2<GemmKernel>,
         cudaFuncAttributeMaxDynamicSharedMemorySize,
-        smem_size);
+        smem_size_);
       if (cudart_result != cudaSuccess) {
         CUTLASS_TRACE_HOST("  cudaFuncSetAttribute() returned error " << cudaGetErrorString(cudart_result));
         return Status::kErrorInternal;
       }
 
       cudart_result = cudaFuncSetAttribute(
           Kernel2<GemmKernel>,
@@ -162,28 +164,30 @@
     }
 
     // Update SM occupancy member
     cudart_result = cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags(
       &sm_occupancy_,
       Kernel2<GemmKernel>,
       GemmKernel::kThreadCount,
-      int(sizeof(typename GemmKernel::SharedStorage)),
+      smem_size_,
       cudaOccupancyDisableCachingOverride);
     if (cudart_result != cudaSuccess) {
       CUTLASS_TRACE_HOST("  cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags() returned error " << cudaGetErrorString(cudart_result));
       return Status::kErrorInternal;
     }
 
     // Update device ordinal member on success
     device_ordinal_ = current_ordinal;
 
     CUTLASS_TRACE_HOST("  "
       "device_ordinal: (" << device_ordinal_ << "), "
       "device_sms: (" << device_sms_ << "), "
-      "sm_occupancy: (" << sm_occupancy_ << ")");
+      "sm_occupancy: (" << sm_occupancy_ << ") "
+      "smem_size: (" << smem_size_ << ") "
+      "GemmKernel::kThreadCount: (" << GemmKernel::kThreadCount << ")");
 
     return Status::kSuccess;
   }
 
 
 protected:
 
@@ -298,15 +302,15 @@
   //---------------------------------------------------------------------------------------------
   // Stateful API
   //---------------------------------------------------------------------------------------------
 
   /// Initializes GEMM state from arguments and workspace memory
   Status initialize(
     Arguments const &args,
-    void *workspace,
+    void *workspace = nullptr,
     cudaStream_t stream = nullptr)
   {
     CUTLASS_TRACE_HOST("GemmUniversalBase::initialize() - workspace "
       << workspace << ", stream: " << (stream ? "non-null" : "null"));
 
     // Initialize parameters from args
     Status result = init_params(args);
@@ -331,25 +335,24 @@
 
   /// Runs the kernel using initialized state.
   Status run(cudaStream_t stream = nullptr)
   {
     CUTLASS_TRACE_HOST("GemmUniversalBase::run()");
 
     // Configure grid and block dimensions
-    int smem_size = int(sizeof(typename GemmKernel::SharedStorage));
     dim3 block(GemmKernel::kThreadCount, 1, 1);
     dim3 grid = params_.get_grid_dims();
 
     // Launch kernel
     CUTLASS_TRACE_HOST("  "
       "grid: (" << grid << "), "
       "block: (" << block << "), "
-      "SMEM: (" << smem_size << ")");
+      "SMEM: (" << smem_size_ << ")");
 
-    Kernel2<GemmKernel><<<grid, block, smem_size, stream>>>(params_);
+    Kernel2<GemmKernel><<<grid, block, smem_size_, stream>>>(params_);
 
     // Query for errors
     cudaError_t result = cudaGetLastError();
     if (result != cudaSuccess) {
       CUTLASS_TRACE_HOST("  grid launch failed with error " << cudaGetErrorString(result));
       return Status::kErrorInternal;
     }
@@ -394,14 +397,19 @@
 template <typename GemmKernel_>
 thread_local int GemmUniversalBase<GemmKernel_>::device_sms_ = -1;
 
 /// Kernel SM occupancy (in thread blocks)
 template <typename GemmKernel_>
 thread_local int GemmUniversalBase<GemmKernel_>::sm_occupancy_ = -1;
 
+/// Kernel dynamic shared memory allocation requirement
+template <typename GemmKernel_>
+thread_local int GemmUniversalBase<GemmKernel_>::smem_size_ = -1;
+
+
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 } // namespace device
 } // namespace gemm
 } // namespace cutlass
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_universal_with_broadcast.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_universal_with_broadcast.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -194,15 +194,15 @@
 
   using Arguments = typename Base::Arguments;
   using GemmKernel = typename Base::GemmKernel;
 };
 
 ////////////////////////////////////////////////////////////////////////////////
 
-/// Parital specialization for column-major output exchanges problem size and operand.
+/// Partial specialization for column-major output exchanges problem size and operand.
 template <
     /// Element type for A matrix operand
     typename ElementA_,
     /// Layout type for A matrix operand
     typename LayoutA_,
     /// Element type for B matrix operand
     typename ElementB_,
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_with_k_reduction.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemm_with_k_reduction.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -207,15 +207,15 @@
 
   using Arguments = typename Base::Arguments;
   using GemmKernel = typename Base::GemmKernel;
 };
 
 ////////////////////////////////////////////////////////////////////////////////
 
-/// Parital specialization for column-major output exchanges problem size and operand.
+/// Partial specialization for column-major output exchanges problem size and operand.
 template <
     /// Element type for A matrix operand
     typename ElementA_,
     /// Layout type for A matrix operand
     typename LayoutA_,
     /// Element type for B matrix operand
     typename ElementB_,
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemv.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/gemv.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/rank_2k.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/rank_2k.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -344,15 +344,15 @@
     }
 
     return status;
   }
 };
 ////////////////////////////////////////////////////////////////////////////////
 
-/// Parital specialization for column-major output exchange operand.
+/// Partial specialization for column-major output exchange operand.
 template <
     /// Element type for A matrix operand
     typename ElementA_,
     /// Layout type for A matrix operand
     typename LayoutA_,
     /// Element type for B matrix operand
     typename ElementB_,
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/rank_2k_grouped.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/rank_2k_grouped.h`

 * *Files 8% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/rank_k.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/rank_k.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -321,15 +321,15 @@
     }
 
     return status;
   }
 };
 ////////////////////////////////////////////////////////////////////////////////
 
-/// Parital specialization for column-major output exchange operand.
+/// Partial specialization for column-major output exchange operand.
 template <
     /// Element type for A matrix operand
     typename ElementA_,
     /// Layout type for A matrix operand
     typename LayoutA_,
     /// Element type for C and D matrix operands
     typename ElementC_,
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/device/symm.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/device/trmm.h`

 * *Files 19% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -25,48 +25,194 @@
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /*! \file
-    \brief Template for a pipelined SYMM and HEMM kernels. Does not compute batching or support split-K.
+    \brief Template for a TRMM kernel. Does not compute batching or support split-K.
 
   
 */
 
 #pragma once
 
 #include "cutlass/blas3.h"
 #include "cutlass/arch/arch.h"
 #include "cutlass/device_kernel.h"
 
 #include "cutlass/gemm/threadblock/threadblock_swizzle.h"
-#include "cutlass/gemm/kernel/symm_universal.h"
+#include "cutlass/gemm/kernel/trmm_universal.h"
 
-#include "cutlass/gemm/kernel/default_symm_universal.h"
+#include "cutlass/gemm/kernel/default_trmm_universal.h"
 #include "cutlass/gemm/device/default_gemm_configuration.h"
 
 ////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace gemm {
 namespace device {
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
+/*! Trmm device-level operator. This is an interface to efficient CUTLASS TRMM kernels that may
+  be invoked from host code.
+
+  The contributions of this class are:
+    
+    1. At compile time, it maps data types and high-level structural parameters onto 
+       specific CUTLASS components.
+
+    2. At runtime, it maps logical arguments to TRMM problems to kernel parameters.
+
+    3. At runtime, it launches kernels on the device.
+
+  The intent is to provide a convenient mechanism for interacting with most plausible TRMM
+  configurations for each supported architecture. Consequently, not all parameters are exposed
+  to the top-level interface. Rather, sensible defaults at each level of the CUTLASS hierarchy
+  are selected to tradeoff simplicity of the interface with flexibility. We expect 
+  most configurations to be specified at this level. Applications with more exotic requirements 
+  may construct their kernels of interest using CUTLASS components at the threadblock, warp, 
+  and thread levels of abstraction.
+
+  CUTLASS exposes computations using the functor design pattern in which objects compose some
+  internal state with an overloaded function call operator. This enables decoupling of
+  initialization from execution, possibly reducing overhead during steady state phases of
+  application execution.
+
+  CUTLASS device-level operators expose an Arguments structure encompassing each logical
+  input to the computation. This is distinct from the kernel-level Params structure pattern
+  which contains application-specific precomputed state needed by the device code.
+
+  Example of a CUTLASS TRMM operator implementing the functionality of cuBLAS's STRMM NN
+  is as follows:
+
+    //
+    // Instantiate the CUTLASS TRMM operator.
+    //
+
+    cutlass::gemm::device::Trmm<
+      float,
+      cutlass::layout::ColumnMajor,
+      cutlass::SideMode::kLeft,
+      cutlass::FillMode::kLower,
+      cutlass::DiagType::kNonUnit,
+      float,
+      cutlass::layout::ColumnMajor,
+      float,
+      cutlass::layout::ColumnMajor,
+    > trmm_op;
+
+    //
+    // Launch the TRMM operation on the device
+    //
+
+    cutlass::Status status = trmm_op({
+      cutlass::gemm::GemmUniversalMode,   // Trmm Problem Mode
+      {m, n, m/n},                        // GemmCoord problem_size (k is based on left- or right-side mode)
+      batch_count,
+      {alpha},                            // EpilogueOutputOp::Params epilogue_op_params
+      void const * ptr_A,
+      void const * ptr_B,
+      void const * ptr_C,
+      int64_t batch_stride_A,
+      int64_t batch_stride_B,
+      int64_t batch_stride_C,
+      int lda,
+      int ldb,
+      int ldc
+    });
+
+  A simplified view of the template is listed below.
+
+    template <
+      /// Element type for A matrix operand
+      typename ElementA,
+      
+      /// Layout type for A matrix operand
+      typename LayoutA,
+      
+      /// Side Mode for A (kLeft or kRight)
+      SideMode SideModeA,
+
+      /// Fill Mode for A (kLower or kUpper)
+      FillMode FillModeA,
+
+      /// DiagType for A (kNonUnit or kUnit)
+      DiagType DiagTypeA,
+
+      /// Element type for B matrix operand
+      typename ElementB,
+      
+      /// Layout type for B matrix operand
+      typename LayoutB,
+      
+      /// Element type for C and D matrix operands
+      typename ElementC,
+      
+      /// Layout type for C and D matrix operands
+      typename LayoutC,
+      
+      /// Element type for internal accumulation
+      typename ElementAccumulator,
+
+      /// Operator class tag
+      typename OperatorClass,
+      
+      /// Tag indicating architecture to tune for.  This is the minimum SM that
+      /// supports the intended feature. The device kernel can be built
+      /// targeting any SM larger than this number.
+      typename ArchTag,
+      
+      /// Threadblock-level tile size (concept: GemmShape)
+      typename ThreadblockShape,
+      
+      /// Warp-level tile size (concept: GemmShape)
+      typename WarpShape,
+      
+      /// Warp-level tile size (concept: GemmShape)
+      typename InstructionShape,
+      
+      /// Epilogue output operator
+      typename EpilogueOutputOp,
+      
+      /// Threadblock-level swizzling operator
+      typename ThreadblockSwizzle,
+      
+      /// Number of stages used in the pipelined mainloop
+      int Stages,
+
+      /// Access granularity of A matrix in units of elements
+      int AlignmentA,
+
+      /// Access granularity of B matrix in units of elements
+      int AlignmentB,
+
+      /// If true, kernel supports split-K with serial reduction
+      bool SplitKSerial,
+
+      /// Operation performed by TRMM
+      typename Operator,
+
+      /// Complex elementwise transformation on A operand
+      ComplexTransform TransformA
+    >
+    class Trmm;
+*/
 template <
     /// Element type for A matrix operand
     typename ElementA_,
     /// Layout type for A matrix operand
     typename LayoutA_,
-    /// Side Mode for A (kLeft or kRight)
+    /// Side Mode for A 
     SideMode SideModeA,
-    /// Fill Mode for A (kLower or kUpper)
+    /// Fill Mode for A
     FillMode FillModeA,
+    /// DiagType for A
+    DiagType DiagTypeA,
     /// Element type for B matrix operand
     typename ElementB_,
     /// Layout type for B matrix operand
     typename LayoutB_,
     /// Element type for C and D matrix operands
     typename ElementC_,
     /// Layout type for C and D matrix operands
@@ -109,108 +255,120 @@
                                  ElementC_, ElementAccumulator_>::kAlignmentA,
     /// Access granularity of B matrix in units of elements
     int AlignmentB =
         DefaultGemmConfiguration<OperatorClass_, ArchTag_, ElementA_, ElementB_,
                                  ElementC_, ElementAccumulator_>::kAlignmentB,
     /// If true, kernel supports split-K with serial reduction
     bool SplitKSerial = false,
-    /// Operation performed by SYMM
+    /// Operation performed by TRMM
     typename Operator_ = typename DefaultGemmConfiguration<
         OperatorClass_, ArchTag_, ElementA_, ElementB_, ElementC_,
         ElementAccumulator_>::Operator,
-    /// Blas3 computation mode (symmetric/hermitian)
-    BlasMode BlasMode_ = BlasMode::kSymmetric>
-class Symm {
+    /// Complex elementwise transformation on A operand
+    ComplexTransform TransformA = ComplexTransform::kNone>
+class Trmm {
  public:
-
   using ElementA = ElementA_;
   using LayoutA = LayoutA_;
+  using TensorRefA = TensorRef<ElementA const, LayoutA>;
   using ElementAKernel = typename platform::conditional<(SideModeA == SideMode::kRight), ElementB_, ElementA_>::type;
   using LayoutAKernel = typename platform::conditional<(SideModeA == SideMode::kRight), LayoutB_, LayoutA_>::type;
   using ElementB = ElementB_;
   using LayoutB = LayoutB_;
+  using TensorRefB = TensorRef<ElementB const, LayoutB>;
   using ElementBKernel = typename platform::conditional<(SideModeA == SideMode::kRight), ElementA_, ElementB_>::type;
   using LayoutBKernel = typename platform::conditional<(SideModeA == SideMode::kRight), LayoutA_, LayoutB_>::type;
   using ElementC = ElementC_;
   using LayoutC = LayoutC_;
+  using TensorRefC = TensorRef<ElementC const, LayoutC>;
+  using TensorRefD = TensorRef<ElementC, LayoutC>;
   using ElementAccumulator = ElementAccumulator_;
   using OperatorClass = OperatorClass_;
   using ArchTag = ArchTag_;
   using ThreadblockShape = ThreadblockShape_;
   using WarpShape = WarpShape_;
   using InstructionShape = InstructionShape_;
   using EpilogueOutputOp = EpilogueOutputOp_;
   using ThreadblockSwizzle = ThreadblockSwizzle_;
   using Operator = Operator_;
-  static SideMode const kSideModeA = SideModeA;
-  static FillMode const kFillModeA = FillModeA;
+  static SideMode const kSideMode = SideModeA;
+  static FillMode const kFillMode = FillModeA;
+  static DiagType const kDiagType = DiagTypeA;
   static int const kStages = Stages;
   static int const kAlignmentA = AlignmentA;
   static int const kAlignmentAKernel = (SideModeA == SideMode::kRight) ? AlignmentB : AlignmentA;
   static int const kAlignmentB = AlignmentB;
   static int const kAlignmentBKernel = (SideModeA == SideMode::kRight) ? AlignmentA : AlignmentB;
   static int const kAlignmentC = EpilogueOutputOp::kCount;
   static bool const kSplitKSerial = SplitKSerial;
-  static BlasMode const kBlasMode = BlasMode_;
-
-  // static asserts for symm update kernel
-  static_assert(platform::is_same<LayoutA, LayoutB>::value,
-    "SYMM update operator support same layouts for operand A and B");
+  // Complex Transform don't appply to B
+  static ComplexTransform const kTransformA = TransformA; 
+  static ComplexTransform const kTransformB = ComplexTransform::kNone; 
+  static ComplexTransform const kTransformAKernel = (SideModeA == SideMode::kRight) ? 
+                                              ComplexTransform::kNone : TransformA;
+  static ComplexTransform const kTransformBKernel = (SideModeA == SideMode::kRight) ? 
+                                              TransformA : ComplexTransform::kNone;
 
   /// Define the kernel
-  using SymmKernel = typename kernel::DefaultSymmUniversal<
+  using TrmmKernel = typename kernel::DefaultTrmmUniversal<
     ElementAKernel,
     LayoutAKernel,
-    kSideModeA,
-    kFillModeA,
+    kTransformAKernel,
     kAlignmentAKernel,
     ElementBKernel,
     LayoutBKernel,
+    kTransformBKernel,
     kAlignmentBKernel,
+    kSideMode,
+    kFillMode,
+    kDiagType,
     ElementC,
     LayoutC,
     ElementAccumulator,
     OperatorClass,
     ArchTag,
     ThreadblockShape,
     WarpShape,
     InstructionShape,
     EpilogueOutputOp,
     ThreadblockSwizzle,
     kStages,
     kSplitKSerial,
-    Operator,
-    kBlasMode
-  >::SymmKernel;
+    Operator
+  >::TrmmKernel;
   
-  using Arguments = typename SymmKernel::Arguments;
+  using Arguments = typename TrmmKernel::Arguments;
 
 private:
 
   /// Kernel parameters object
-  typename SymmKernel::Params params_;
+  typename TrmmKernel::Params params_;
 public:
 
-  /// Constructs the SYMM.
-  Symm() { }
+  /// Constructs the TRMM.
+  Trmm() { }
 
-  /// Determines whether the SYMM can execute the given problem.
+  /// Determines whether the TRMM can execute the given problem.
   static Status can_implement(Arguments const &args) {
 
     if (!kSplitKSerial && args.batch_count > 1) {
       return Status::kErrorInvalidProblem;
     }
 
-    Status status = SymmKernel::can_implement(args);
-
+    Status status = TrmmKernel::can_implement(args);
+   
     if (SideModeA == SideMode::kInvalid) {
       return Status::kErrorInvalidProblem;
     }
-   
-    if (FillModeA != FillMode::kLower && FillModeA != FillMode::kUpper) {
+
+    if (FillModeA == FillMode::kInvalid) {
+      return Status::kErrorInvalidProblem;
+    }
+
+    if (DiagTypeA == DiagType::kInvalid) {
       return Status::kErrorInvalidProblem;
     }
 
     if (status != Status::kSuccess) {
       return status;
     }
 
@@ -234,17 +392,17 @@
 
       bytes += sizeof(int) * size_t(tiled_shape.m()) * size_t(tiled_shape.n());
     }
 
     return bytes;
   }
 
-  /// Initializes SYMM state from arguments.
+  /// Initializes TRMM state from arguments.
   Status initialize(Arguments const &args, void *workspace = nullptr, cudaStream_t stream = nullptr) {
-    
+ 
     // Determine grid shape
     ThreadblockSwizzle threadblock_swizzle;
 
     cutlass::gemm::GemmCoord grid_tiled_shape = threadblock_swizzle.get_tiled_shape(
       args.problem_size, 
       {ThreadblockShape::kM, ThreadblockShape::kN, ThreadblockShape::kK},
       args.batch_count);
@@ -270,28 +428,28 @@
         return Status::kErrorInvalidProblem;
       }
     }
     
     int gemm_k_size = args.problem_size.k();
 
    // Swapping argument for A and B, if A was on the right side (problem size doesn't need to change here).
-    if (kSideModeA == SideMode::kRight) {
+    if (kSideMode == SideMode::kRight) {
       // Initialize the Params structure
-      params_ = typename SymmKernel::Params{
+      params_ = typename TrmmKernel::Params{
         args.swapped_matrices(),
         grid_tiled_shape,
         gemm_k_size,
         static_cast<int *>(workspace)
       };
 
       return Status::kSuccess;
     }
 
     // Initialize the Params structure
-    params_ = typename SymmKernel::Params{
+    params_ = typename TrmmKernel::Params{
       args,
       grid_tiled_shape,
       gemm_k_size,
       static_cast<int *>(workspace)
     };
     
     return Status::kSuccess;
@@ -319,29 +477,29 @@
 
   /// Runs the kernel using initialized state.
   Status run(cudaStream_t stream = nullptr) {
 
     ThreadblockSwizzle threadblock_swizzle;
 
     dim3 grid = threadblock_swizzle.get_grid_shape(params_.grid_tiled_shape);
-    dim3 block(SymmKernel::kThreadCount, 1, 1);
-
-    int smem_size = int(sizeof(typename SymmKernel::SharedStorage));
+    dim3 block(TrmmKernel::kThreadCount, 1, 1);
 
+    int smem_size = int(sizeof(typename TrmmKernel::SharedStorage));
+    
     if (smem_size >= (48 << 10)) {
-      cudaError_t result = cudaFuncSetAttribute(Kernel<SymmKernel>,
+      cudaError_t result = cudaFuncSetAttribute(Kernel<TrmmKernel>,
                                     cudaFuncAttributeMaxDynamicSharedMemorySize,
                                     smem_size);
 
       if (result != cudaSuccess) {
         return Status::kErrorInternal;
       }
     }
 
-    cutlass::Kernel<SymmKernel><<<grid, block, smem_size, stream>>>(params_);
+    cutlass::Kernel<TrmmKernel><<<grid, block, smem_size, stream>>>(params_);
 
     cudaError_t result = cudaGetLastError();
 
     return result == cudaSuccess ? Status::kSuccess : Status::kErrorInternal;
   }
 
   /// Runs the kernel using initialized state.
@@ -360,30 +518,27 @@
     if (status == Status::kSuccess) {
       status = run(stream);
     }
 
     return status;
   }
 };
-////////////////////////////////////////////////////////////////////////////////
 
 /********************************************************************************************************
-  SYMM/HEMM has 4 combinations based on Layouts {RowMajor, ColumnMajor} x Side mode {LeftSide, RightSide}
-  In templates and arguments to cutlass kernel, `matrix A` is always symmetric/hermitian, and `matrix B` is rectangular. 
+  TRMM has 4 combinations based on Layouts {RowMajor, ColumnMajor} x Side mode {LeftSide, RightSide}
+  In templates and arguments to cutlass kernel, `matrix A` is always triangular, and `matrix B` is rectangular. 
   (adhering to the cuBLAS convention)
 
-  Although, cuBLAS SYMM/HEMM only supports ColumnMajor layouts for all matrices (A, B, C/D).
-
-  For the mainloop and symm kernel, `A` and `B` points to left-side and right-side matrices, respectively.
+For the mainloop and trmm kernel, `A` and `B` points to left-side and right-side matrices, respectively.
   
   Thus, for LeftSide mode `A` and `B` points to `matrix A` and `matrix B`, respectively. While for 
   the RightSide mode `A` and `B` points to `matrix B` and `matrix A`, respectively. 
   
   Additionally, CUTLASS GEMM epilogue is always RowMajor, and ColumnMajor output is achieved by 
-  transposing the GEMM problem. Thus, ColumnMajor output layout for SYMM/HEMM requires:
+  transposing the GEMM problem. Thus, ColumnMajor output layout for TRMM requires:
    - Transposing `matrix A` and `matrix B` layouts
    - Swapping problem size m and n values
    - Swapping LeftSide and RightSide mode
   
   RowMajor output:    D = matrix A x matrix B
   ColumnMajor output: D = matrix A x matrix B -> Transpose (D) = Transpose(matrix B) x Transpose(matrix A)
 
@@ -404,37 +559,37 @@
   Case 4 -> Case 1:
       D_col = matrix B x matrix A (RightSide mode) 
    => Transpose(D_col) = Transpose(matrix A) x Transpose(matrix B) (LeftSide mode)
 
    call GEMM mainloop for with RowMajor efficient-epilogue
 ********************************************************************************************************/
 
-/// Parital specialization for column-major output exchanges problem size and operand.
+/// Partial specialization for column-major output exchanges problem size and operand.
 template <
     /// Element type for A matrix operand
     typename ElementA_,
     /// Layout type for A matrix operand
     typename LayoutA_,
-    /// Side Mode for A (kLeft or kRight)
+    /// Side Mode for A 
     SideMode SideModeA,
-    /// Fill Mode for A (kLower or kUpper)
+    /// Fill Mode for A
     FillMode FillModeA,
+    /// DiagType for A
+    DiagType DiagTypeA,
     /// Element type for B matrix operand
     typename ElementB_,
     /// Layout type for B matrix operand
     typename LayoutB_,
     /// Element type for C and D matrix operands
     typename ElementC_,
     /// Element type for internal accumulation
     typename ElementAccumulator_,
     /// Operator class tag
     typename OperatorClass_,
-    /// Tag indicating architecture to tune for.  This is the minimum SM that
-    /// supports the intended feature. The device kernel can be built
-    /// targeting any SM larger than this number.
+    /// Tag indicating architecture to tune for
     typename ArchTag_,
     /// Threadblock-level tile size (concept: GemmShape)
     typename ThreadblockShape_,
     /// Warp-level tile size (concept: GemmShape)
     typename WarpShape_,
     /// Instruction-level tile size (concept: GemmShape)
     typename InstructionShape_,
@@ -444,59 +599,71 @@
     typename ThreadblockSwizzle_,
     /// Number of stages used in the pipelined mainloop
     int Stages,
     /// Access granularity of A matrix in units of elements
     int AlignmentA,
     /// Access granularity of B matrix in units of elements
     int AlignmentB,
-    /// If true, kernel supports split-K with serial reduction
+    /// If true, kernel supports split-K as a serial reduction
     bool SplitKSerial,
-    /// Operation performed by Symm update kernel
+    /// Operation performed by TRMM
     typename Operator_,
-    /// Blas3 computation mode (symmetric/hermitian)
-    BlasMode BlasMode_
-    >
-class Symm<ElementA_, LayoutA_, SideModeA, FillModeA, ElementB_, LayoutB_, ElementC_,
+    /// Complex elementwise transformation on A operand
+    ComplexTransform TransformA>
+class Trmm<ElementA_, LayoutA_, SideModeA, FillModeA, DiagTypeA,
+           ElementB_, LayoutB_, ElementC_,
            layout::ColumnMajor,  // partially specialized on LayoutC
            ElementAccumulator_, OperatorClass_, ArchTag_, ThreadblockShape_,
            WarpShape_, InstructionShape_, EpilogueOutputOp_,
-           ThreadblockSwizzle_, Stages, AlignmentA, AlignmentB,
-           SplitKSerial, Operator_, BlasMode_> {
+           ThreadblockSwizzle_, Stages, AlignmentA, AlignmentB, SplitKSerial,
+           Operator_, TransformA> {
  public:
 
   using ElementA = ElementA_;
-  using LayoutA = LayoutA_;
+  using LayoutA = LayoutA_; 
+  using TensorRefA = TensorRef<ElementA const, LayoutA>;
   using ElementB = ElementB_;
   using LayoutB = LayoutB_;
+  using TensorRefB = TensorRef<ElementB const, LayoutB>;
   using ElementC = ElementC_;
   using LayoutC = layout::ColumnMajor;
+  using TensorRefC = TensorRef<ElementC const, LayoutC>;
+  using TensorRefD = TensorRef<ElementC, LayoutC>;
   using ElementAccumulator = ElementAccumulator_;
   using OperatorClass = OperatorClass_;
   using ArchTag = ArchTag_;
   using ThreadblockShape = ThreadblockShape_;
   using WarpShape = WarpShape_;
   using InstructionShape = InstructionShape_;
   using EpilogueOutputOp = EpilogueOutputOp_;
   using ThreadblockSwizzle = ThreadblockSwizzle_;
   using Operator = Operator_;
-  static SideMode const kSideModeA = SideModeA;
-  static FillMode const kFillModeA = FillModeA;
+  static SideMode const kSideMode = SideModeA;
+  static FillMode const kFillMode = FillModeA;
+  static DiagType const kDiagType = DiagTypeA;
+  // Changing SideMode as we change the layout
+  static SideMode const kSideModeT = (SideModeA == SideMode::kLeft) ?
+                                      SideMode::kRight : SideMode::kLeft;
+  // Changing FillMode as we change the layout
+  static FillMode const kFillModeT = (FillModeA == FillMode::kLower) ? 
+                                      FillMode::kUpper : FillMode::kLower;
   static int const kStages = Stages;
   static int const kAlignmentA = AlignmentA;
   static int const kAlignmentB = AlignmentB;
-  static int const kAlignmentC = EpilogueOutputOp::kCount;
+  static ComplexTransform const kTransformA = TransformA;
+  // Complex Transform don't appply to B
+  static ComplexTransform const kTransformB = ComplexTransform::kNone; 
   static bool const kSplitKSerial = SplitKSerial;
-  static BlasMode const kBlasMode = BlasMode_;
-  
-  /// Define the kernel
-  using UnderlyingOperator = typename cutlass::gemm::device::Symm<
+
+  using UnderlyingOperator = Trmm<
     ElementA,
     typename layout::LayoutTranspose<LayoutA>::type,
-    InvertSideMode<kSideModeA>::mode,
-    InvertFillMode<kFillModeA>::mode,
+    kSideModeT,
+    kFillModeT,
+    kDiagType,
     ElementB,
     typename layout::LayoutTranspose<LayoutB>::type, 
     ElementC,
     layout::RowMajor,
     ElementAccumulator,
     OperatorClass,
     ArchTag,
@@ -506,59 +673,48 @@
     EpilogueOutputOp,
     ThreadblockSwizzle,
     kStages,
     kAlignmentA,
     kAlignmentB,
     kSplitKSerial,
     Operator,
-    kBlasMode
+    TransformA
   >;
-  
 
-  /// Argument structure
   using Arguments = typename UnderlyingOperator::Arguments;
-  using SymmKernel = typename UnderlyingOperator::SymmKernel;
+  using TrmmKernel = typename UnderlyingOperator::TrmmKernel;
+  static int const kAlignmentC = UnderlyingOperator::kAlignmentC;
 
 private:
 
   UnderlyingOperator underlying_operator_;
 
 public:
 
-  /// Constructs the Symm.
-  Symm() { }
+  /// Constructs the TRMM.
+  Trmm() { }
 
-  /// Helper to construct a transposed equivalent for the underying SYMM operator
+  /// Helper to construct a transposed equivalent for the underying TRMM operator which is identical
   static Arguments to_underlying_arguments(Arguments const &args) {
     return args.transposed_problem_size();
   }
 
-  /// Determines whether the Symm can execute the given problem.
+  /// Determines whether the TRMM can execute the given problem.
   static Status can_implement(Arguments const &args) {
 
     return UnderlyingOperator::can_implement(to_underlying_arguments(args));
   }
 
   /// Gets the workspace size
   static size_t get_workspace_size(Arguments const &args) {
     
     return UnderlyingOperator::get_workspace_size(to_underlying_arguments(args));
   }
 
-  /// Computes the grid shape
-  static dim3 get_grid_shape(Arguments const &args) { 
-    return UnderlyingOperator::get_grid_shape(to_underlying_arguments(args));
-  }
-
-  /// Computes the maximum number of active blocks per multiprocessor
-  static int maximum_active_blocks(int smem_capacity = -1) {
-    return UnderlyingOperator::maximum_active_blocks(smem_capacity);
-  }
-
-  /// Initializes Symm state from arguments.
+  /// Initializes TRMM state from arguments.
   Status initialize(Arguments const &args, void *workspace = nullptr, cudaStream_t stream = nullptr) {
 
     return underlying_operator_.initialize(to_underlying_arguments(args), workspace, stream);
   }
 
   /// Lightweight update given a subset of arguments
   Status update(Arguments const &args, void *workspace = nullptr) {
@@ -578,25 +734,25 @@
   }
 
   /// Runs the kernel using initialized state.
   Status operator()(
     Arguments const &args, 
     void *workspace = nullptr, 
     cudaStream_t stream = nullptr) {
-    
+   
     Status status = initialize(args, workspace, stream);
     
     if (status == Status::kSuccess) {
       status = run(stream);
     }
 
     return status;
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////
 
 } // namespace device
-} // namespace Symm
+} // namespace gemm
 } // namespace cutlass
 
 ////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_ell_gemm.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_ell_gemm.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -258,16 +258,16 @@
 >
 struct DefaultGemm<ElementA, LayoutA, kAlignmentA, ElementB, LayoutB, kAlignmentB, ElementC,
                    LayoutC, ElementAccumulator, arch::OpClassTensorOp,
                    arch::Sm80, ThreadblockShape, WarpShape, InstructionShape,
                    EpilogueOutputOp, ThreadblockSwizzle, Stages, SplitKSerial,
                    Operator, SharedMemoryClear, GatherA, GatherB, ScatterD, PermuteDLayout> {
 
-  static_assert(platform::is_same<LayoutC, layout::RowMajor>::value
-             || platform::is_same<LayoutC, layout::AffineRankN<2>>::value,
+  static_assert((platform::is_same<LayoutC, layout::RowMajor>::value
+             || platform::is_same<LayoutC, layout::AffineRankN<2>>::value),
              "Epilogue in the kernel level must be row major");
 
   /// Define the threadblock-scoped matrix multiply-accumulate
   using Mma = typename cutlass::gemm::threadblock::DefaultMma<
       ElementA, LayoutA, kAlignmentA, ElementB, LayoutB, kAlignmentB,
       ElementAccumulator, LayoutC, arch::OpClassTensorOp, arch::Sm80,
       ThreadblockShape, WarpShape, InstructionShape, Stages,
@@ -710,16 +710,16 @@
     SharedMemoryClear,
     GatherA,
     GatherB,
     ScatterD,
     PermuteDLayout,
     typename platform::enable_if< ! platform::is_same<ArchTag, arch::Sm80>::value >::type > {
 
-  static_assert(platform::is_same<LayoutC, layout::RowMajor>::value
-             || platform::is_same<LayoutC, layout::AffineRankN<2>>::value,
+  static_assert((platform::is_same<LayoutC, layout::RowMajor>::value
+             || platform::is_same<LayoutC, layout::AffineRankN<2>>::value),
              "Epilogue in the kernel level must be row major");
 
   /// Define the threadblock-scoped matrix multiply-accumulate
   using Mma = typename cutlass::gemm::threadblock::DefaultMma<
       ElementA,
       LayoutA,
       kAlignmentA,
@@ -837,16 +837,16 @@
                    Operator,
                    SharedMemoryClear,
                    GatherA,
                    GatherB,
                    ScatterD,
                    PermuteDLayout> {
 
-  static_assert(platform::is_same<LayoutC, layout::RowMajor>::value
-             || platform::is_same<LayoutC, layout::AffineRankN<2>>::value,
+  static_assert((platform::is_same<LayoutC, layout::RowMajor>::value
+             || platform::is_same<LayoutC, layout::AffineRankN<2>>::value),
              "Epilogue in the kernel level must be row major");
 
   /// Define the threadblock-scoped matrix multiply-accumulate
   using Mma = typename cutlass::gemm::threadblock::DefaultMma<
       ElementA, LayoutA, kAlignmentA, ElementB, LayoutB, kAlignmentB,
       ElementAccumulator, LayoutC, arch::OpClassSimt, arch::Sm80,
       ThreadblockShape, WarpShape, GemmShape<1, 1, 1>, Stages,
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_complex.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_complex.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_grouped.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_grouped.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_grouped_softmax_mainloop_fusion.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_grouped_softmax_mainloop_fusion.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_layernorm_mainloop_fusion.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_layernorm_mainloop_fusion.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_planar_complex_universal.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_planar_complex_universal.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_sparse.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_sparse.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_splitk_parallel.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_splitk_parallel.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_universal.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_universal.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_with_broadcast.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_with_broadcast.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -117,15 +117,15 @@
   // Replace epilogue
   using Epilogue = typename cutlass::epilogue::threadblock::DefaultEpilogueWithBroadcastTensorOp<
     typename GemmBase::Epilogue::Shape,
     typename GemmBase::Epilogue::WarpMmaOperator,
     GemmBase::Epilogue::kPartitionsK,
     ElementC_,
     typename EpilogueOutputOp::ElementT,
-    ElementC_,
+    typename EpilogueOutputOp::ElementVector,
     EpilogueOutputOp,
     GemmBase::Epilogue::kElementsPerAccess
   >::Epilogue;
 
   // Compose the GEMM kernel
   using GemmKernel = GemmWithFusedEpilogue<
     typename GemmBase::Mma,
@@ -133,15 +133,15 @@
     ThreadblockSwizzle
   >;
 };
 
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-/// Parital specialization: ArchTag = cutlass::arch::Sm70
+/// Partial specialization: ArchTag = cutlass::arch::Sm70
 ///
 ///
 template <
   /// Element type for A matrix operand
   typename ElementA_,
   /// Layout type for A matrix operand
   typename LayoutA_,
@@ -217,15 +217,15 @@
   // Replace epilogue
   using Epilogue = typename cutlass::epilogue::threadblock::DefaultEpilogueWithBroadcastVoltaTensorOp<
     typename GemmBase::Epilogue::Shape,
     typename GemmBase::Epilogue::WarpMmaOperator,
     GemmBase::Epilogue::kPartitionsK,
     ElementC_,
     typename EpilogueOutputOp::ElementT,
-    ElementC_,
+    typename EpilogueOutputOp::ElementVector,
     EpilogueOutputOp,
     GemmBase::Epilogue::kElementsPerAccess
   >::Epilogue;
 
   // Compose the GEMM kernel
   using GemmKernel = GemmWithFusedEpilogue<
     typename GemmBase::Mma,
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_with_k_reduction.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_with_k_reduction.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_with_reduction.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemm_with_reduction.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -134,15 +134,15 @@
     Epilogue,
     ThreadblockSwizzle
   >;
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-/// Parital specialization: ArchTag = cutlass::arch::Sm70
+/// Partial specialization: ArchTag = cutlass::arch::Sm70
 ///
 ///
 template <
   /// Element type for A matrix operand
   typename ElementA_,
   /// Layout type for A matrix operand
   typename LayoutA_,
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemv.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_gemv.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_rank_2k.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_rank_2k.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_rank_2k_complex.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_rank_2k_complex.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_rank_2k_grouped.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_rank_2k_grouped.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_rank_2k_universal.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_rank_2k_universal.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_rank_k.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_rank_k.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_rank_k_complex.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_rank_k_complex.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_rank_k_universal.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_rank_k_universal.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_symm.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_symm.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_symm_complex.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_symm_complex.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_symm_universal.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_symm_universal.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_trmm.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_trmm.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_trmm_complex.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_trmm_complex.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_trmm_universal.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/default_trmm_universal.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/ell_gemm.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/ell_gemm.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -252,15 +252,15 @@
       {problem_size_k, params.problem_size.n()},
       thread_idx,
       tb_offset_B,
       params.gather_B_indices);
 
     // Broadcast the warp_id computed by lane 0 to ensure dependent code
     // is compiled as warp-uniform.
-    int warp_idx = __shfl_sync(0xffffffff, threadIdx.x / 32, 0);
+    int warp_idx = canonical_warp_idx();
     int lane_idx = threadIdx.x % 32;
 
     //
     // Main loop
     //
 
     // Construct thread-scoped matrix multiply
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_array.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_array.h`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -189,15 +189,15 @@
 
       //
       // Main loop
       //
       
       // Broadcast the warp_id computed by lane 0 to ensure dependent code
       // is compiled as warp-uniform.
-      int warp_idx = __shfl_sync(0xffffffff, threadIdx.x / 32, 0);
+      int warp_idx = canonical_warp_idx();
 
       int lane_idx = threadIdx.x % 32;
       
       Mma mma(shared_storage.main_loop, thread_idx, warp_idx, lane_idx);
 
       typename Mma::FragmentC accumulators;
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_batched.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_batched.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -200,15 +200,15 @@
 
       //
       // Main loop
       //
 
       // Broadcast the warp_id computed by lane 0 to ensure dependent code
       // is compiled as warp-uniform.
-      int warp_idx = __shfl_sync(0xffffffff, threadIdx.x / 32, 0);
+      int warp_idx = canonical_warp_idx();
 
       int lane_idx = threadIdx.x % 32;
       
       Mma mma(shared_storage.main_loop, thread_idx, warp_idx, lane_idx);
 
       typename Mma::FragmentC accumulators;
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_grouped.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_grouped.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -391,15 +391,15 @@
 
       typename Mma::FragmentC accumulators;
 
       accumulators.clear();
       
       // Broadcast the warp_id computed by lane 0 to ensure dependent code
       // is compiled as warp-uniform.
-      int warp_idx = __shfl_sync(0xffffffff, threadIdx.x / 32, 0);
+      int warp_idx = canonical_warp_idx();
 
       int lane_idx = threadIdx.x % 32;
 
       //
       // Matrix multiply phase
       //
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_grouped_problem_visitor.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_grouped_problem_visitor.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_grouped_softmax_mainloop_fusion.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/rank_k_universal.h`

 * *Files 21% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -26,481 +26,536 @@
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 
 /*! \file
-    \brief Problem visitor for grouped GEMMs with a softmax fused beforehand
+    \brief 
+
 */
 
 #pragma once
 
-#include "cutlass/cutlass.h"
+#include "cutlass/blas3.h"
 #include "cutlass/fast_math.h"
 #include "cutlass/gemm/gemm.h"
 #include "cutlass/matrix_coord.h"
 #include "cutlass/complex.h"
 #include "cutlass/semaphore.h"
 
-#include "cutlass/layout/matrix.h"
-#include "cutlass/trace.h"
-#include "cutlass/gemm/kernel/gemm_transpose_operands.h"
-#include "cutlass/gemm/kernel/gemm_grouped_problem_visitor.h"
-
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace gemm {
 namespace kernel {
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 template <
-  typename Mma_,                           ///! Threadblock-scoped matrix multiply-accumulate
-  typename Epilogue_,                      ///! Epilogue
-  typename ThreadblockSwizzle_,            ///! Threadblock swizzling function
-  GroupScheduleMode GroupScheduleMode_,    ///! Type of scheduling to perform
-  bool Transposed = false
+  typename Mma_,                  ///! Threadblock-scoped matrix multiply-accumulate 
+  typename Epilogue_,             ///! Epilogue
+  typename ThreadblockSwizzle_,   ///! Threadblock swizzling function
+  FillMode FillModeC_             ///! Fill Mode for C (kLower or kUpper)
 >
-struct GemmGroupedSoftmaxMainloopFusion {
+struct RankKUniversal {
 public:
 
   using Mma = Mma_;
   using Epilogue = Epilogue_;
   using EpilogueOutputOp = typename Epilogue::OutputOp;
   using ThreadblockSwizzle = ThreadblockSwizzle_;
-  static GroupScheduleMode const kGroupScheduleMode = GroupScheduleMode_;
-  static bool const kTransposed = Transposed;
 
-  // Optional transpose
-  using MapArguments = kernel::detail::MapArguments<
-    typename Mma::IteratorA::Element,
-    typename Mma::IteratorA::Layout,
-    Mma::kTransformA,
-    Mma::IteratorA::AccessType::kElements,
-    typename Mma::IteratorB::Element,
-    typename Mma::IteratorB::Layout,
-    Mma::kTransformB,
-    Mma::IteratorB::AccessType::kElements,
-    typename Mma::LayoutC,
-    kTransposed
-  >;
-
-  // Public-facing type definitions related to operand element type, layout, and complex conjugate
-  // operation. Must interact with the 'kTransposed' notion.
-  using ElementA = typename MapArguments::ElementA;
-  using LayoutA = typename MapArguments::LayoutA;
-  using ElementB = typename MapArguments::ElementB;
-  using LayoutB = typename MapArguments::LayoutB;
+  using ElementA = typename Mma::IteratorA::Element;
+  using LayoutA = typename Mma::IteratorA::Layout;
+  using ElementB = typename Mma::IteratorB::Element;
+  using LayoutB = typename Mma::IteratorB::Layout;
   using ElementC = typename Epilogue::OutputTileIterator::Element;
-  using LayoutC = typename MapArguments::LayoutC;
-
-  using ElementScaleBias = typename Mma::IteratorNormSum::Element;
+  using LayoutC = typename Epilogue::OutputTileIterator::Layout;
+  static FillMode const kFillModeC = FillModeC_;
 
-  static ComplexTransform const kTransformA = MapArguments::kTransformA;
-  static ComplexTransform const kTransformB = MapArguments::kTransformB;
-
-  // Type definitions about the mainloop.
+  static ComplexTransform const kTransformA = Mma::kTransformA;
+  static ComplexTransform const kTransformB = Mma::kTransformB;
   using Operator = typename Mma::Operator;
+
   using OperatorClass = typename Mma::Operator::OperatorClass;
   using ThreadblockShape = typename Mma::Shape;
   using WarpShape = typename Mma::Operator::Shape;
   using InstructionShape = typename Mma::Policy::Operator::InstructionShape;
   using ArchTag = typename Mma::ArchTag;
 
   static int const kStages = Mma::kStages;
-  static int const kAlignmentA = MapArguments::kAlignmentA;
-  static int const kAlignmentB = MapArguments::kAlignmentB;
+  static int const kAlignmentA = Mma::IteratorA::AccessType::kElements;
+  static int const kAlignmentB = Mma::IteratorB::AccessType::kElements;
   static int const kAlignmentC = Epilogue::OutputTileIterator::kElementsPerAccess;
 
   /// Warp count (concept: GemmShape)
   using WarpCount = typename Mma::WarpCount;
   static int const kThreadCount = 32 * WarpCount::kCount;
 
-  using ProblemVisitor = GemmGroupedProblemVisitor<
-                            ThreadblockShape,
-                            kGroupScheduleMode,
-                            kThreadCount,
-                            kThreadCount,
-                            kTransposed>;
+  /// Split-K preserves splits that are 128b aligned
+  static int const kSplitKAlignment = 128 / sizeof_bits<ElementA>::value;
 
   //
   // Structures
   //
 
   /// Argument structure
   struct Arguments {
 
     //
     // Data members
     //
 
-    GemmCoord *problem_sizes;
-    int problem_count;
-    int threadblock_count;
-
-    typename EpilogueOutputOp::Params output_op;
-
-    ElementA ** ptr_A;
-    ElementB ** ptr_B;
-    ElementC ** ptr_C;
-    ElementC ** ptr_D;
-    void ** ptr_norm;
-    void ** ptr_sum;
-
-    typename LayoutA::Stride::LongIndex *lda;
-    typename LayoutB::Stride::LongIndex *ldb;
-    typename LayoutC::Stride::LongIndex *ldc;
-    typename LayoutC::Stride::LongIndex *ldd;
-
-    // Only used by device-level operator
-    GemmCoord *host_problem_sizes;
+    GemmUniversalMode mode;
+    GemmCoord problem_size;
+    int batch_count;
+
+    typename EpilogueOutputOp::Params epilogue;
+
+    void const * ptr_A;
+    void const * ptr_C;
+    void * ptr_D;
+
+    int64_t batch_stride_A;
+    int64_t batch_stride_C;
+    int64_t batch_stride_D;
+
+    typename LayoutA::Stride::Index lda;
+    typename LayoutB::Stride::Index ldb;
+    typename LayoutC::Stride::Index ldc;
+    typename LayoutC::Stride::Index ldd;
 
     //
     // Methods
     //
+    
+    Arguments(): 
+      mode(GemmUniversalMode::kGemm), 
+      batch_count(1), 
+      ptr_A(nullptr), ptr_C(nullptr), ptr_D(nullptr) { }
 
-    /// Default ctor
-    CUTLASS_HOST_DEVICE
-    Arguments():
-      problem_count(0),
-      threadblock_count(0),
-      ptr_A(nullptr),
-      ptr_B(nullptr),
-      ptr_C(nullptr),
-      ptr_D(nullptr),
-      ptr_norm(nullptr),
-      ptr_sum(nullptr),
-      lda(nullptr),
-      ldb(nullptr),
-      ldc(nullptr),
-      ldd(nullptr),
-      host_problem_sizes(nullptr)
-    {
-
-    }
-
-    /// Ctor
-    CUTLASS_HOST_DEVICE
+    /// constructs an arguments structure
     Arguments(
-      GemmCoord *problem_sizes,
-      int problem_count,
-      int threadblock_count,
-      typename EpilogueOutputOp::Params output_op,
-      ElementA ** ptr_A,
-      ElementB ** ptr_B,
-      ElementC ** ptr_C,
-      ElementC ** ptr_D,
-      void ** ptr_norm,
-      void ** ptr_sum,
-      typename LayoutA::Stride::LongIndex *lda,
-      typename LayoutB::Stride::LongIndex *ldb,
-      typename LayoutC::Stride::LongIndex *ldc,
-      typename LayoutC::Stride::LongIndex *ldd,
-      GemmCoord *host_problem_sizes=nullptr
+      GemmUniversalMode mode,
+      GemmCoord problem_size,
+      int batch_count,
+      typename EpilogueOutputOp::Params epilogue,
+      void const * ptr_A,
+      void const * ptr_C,
+      void * ptr_D,
+      int64_t batch_stride_A,
+      int64_t batch_stride_C,
+      int64_t batch_stride_D,
+      typename LayoutA::Stride::Index lda,
+      typename LayoutC::Stride::Index ldc,
+      typename LayoutC::Stride::Index ldd
     ):
-      problem_sizes(problem_sizes),
-      problem_count(problem_count),
-      threadblock_count(threadblock_count),
-      output_op(output_op),
-      ptr_A(ptr_A),
-      ptr_B(ptr_B),
-      ptr_C(ptr_C),
-      ptr_D(ptr_D),
-      ptr_norm(ptr_norm),
-      ptr_sum(ptr_sum),
-      lda(lda),
-      ldb(ldb),
-      ldc(ldc),
-      ldd(ldd),
-      host_problem_sizes(host_problem_sizes)
-    {
+      mode(mode), 
+      problem_size(problem_size), 
+      batch_count(batch_count),
+      epilogue(epilogue), 
+      ptr_A(ptr_A), ptr_C(ptr_C), ptr_D(ptr_D), 
+      batch_stride_A(batch_stride_A), batch_stride_C(batch_stride_C), batch_stride_D(batch_stride_D), 
+      lda(lda), ldb(ldb), ldc(ldc), ldd(ldd) {
+
+      }
 
-    }
   };
 
   //
   // Structure for precomputing values in host memory and passing to kernels
   //
 
   /// Parameters structure
   struct Params {
 
-    typename ProblemVisitor::Params problem_visitor;
-    int threadblock_count;
-
+    cutlass::gemm::GemmCoord problem_size;
+    cutlass::gemm::GemmCoord grid_tiled_shape;
+    int swizzle_log_tile;
+   
+    typename Mma::IteratorA::Params params_A;
+    typename Mma::IteratorB::Params params_B;
+    typename Epilogue::OutputTileIterator::Params params_C;
+    typename Epilogue::OutputTileIterator::Params params_D;
+    
     typename EpilogueOutputOp::Params output_op;
 
-    ElementA ** ptr_A;
-    ElementB ** ptr_B;
-    ElementC ** ptr_C;
-    ElementC ** ptr_D;
-
-    void ** ptr_norm;
-    void ** ptr_sum;
-
-    typename LayoutA::Stride::LongIndex *lda;
-    typename LayoutB::Stride::LongIndex *ldb;
-    typename LayoutC::Stride::LongIndex *ldc;
-    typename LayoutC::Stride::LongIndex *ldd;
+    GemmUniversalMode mode;
+    int batch_count;
+    int gemm_k_size;
+
+    void * ptr_A;
+    void * ptr_B;
+    void * ptr_C;
+    void * ptr_D;
+
+    int64_t batch_stride_A;
+    int64_t batch_stride_B;
+    int64_t batch_stride_C;
+    int64_t batch_stride_D;
+
+    int *semaphore;
 
     //
     // Methods
     //
 
     CUTLASS_HOST_DEVICE
     Params():
+      swizzle_log_tile(0),
+      params_A(0),
+      params_B(0),
+      params_C(0),
+      params_D(0),
+      batch_count(0),
+      gemm_k_size(0),
+      mode(cutlass::gemm::GemmUniversalMode::kGemm),
       ptr_A(nullptr),
       ptr_B(nullptr),
       ptr_C(nullptr),
       ptr_D(nullptr),
-      ptr_norm(nullptr),
-      ptr_sum(nullptr),
-      lda(nullptr),
-      ldb(nullptr),
-      ldc(nullptr),
-      ldd(nullptr)
-    { }
+      batch_stride_A(0),
+      batch_stride_B(0),
+      batch_stride_C(0),
+      batch_stride_D(0),
+      semaphore(nullptr) { }
 
     CUTLASS_HOST_DEVICE
-    Params(Arguments const &args,
-          void *workspace = nullptr,
-          int tile_count = 0):
-      problem_visitor(args.problem_sizes, args.problem_count, workspace, tile_count),
-      threadblock_count(args.threadblock_count),
-      output_op(args.output_op),
-      ptr_A(args.ptr_A),
-      ptr_B(args.ptr_B),
-      ptr_C(args.ptr_C),
-      ptr_D(args.ptr_D),
-      ptr_norm(args.ptr_norm),
-      ptr_sum(args.ptr_sum),
-      lda(args.lda),
-      ldb(args.ldb),
-      ldc(args.ldc),
-      ldd(args.ldd)
-    {
-
+    Params(
+      Arguments const &args,
+      cutlass::gemm::GemmCoord const & grid_tiled_shape,
+      int gemm_k_size,
+      void *workspace = nullptr
+    ):
+      problem_size(args.problem_size),
+      grid_tiled_shape(grid_tiled_shape),
+      swizzle_log_tile(ThreadblockSwizzle().get_log_tile(grid_tiled_shape)),
+      params_A(args.lda),
+      params_B(args.lda),
+      params_C(args.ldc),
+      params_D(args.ldd),
+      output_op(args.epilogue),
+      mode(args.mode),
+      batch_count(args.batch_count),
+      gemm_k_size(gemm_k_size),
+      ptr_A(const_cast<void *>(args.ptr_A)),
+      ptr_B(const_cast<void *>(args.ptr_A)),
+      ptr_C(const_cast<void *>(args.ptr_C)),
+      ptr_D(const_cast<void *>(args.ptr_D)),
+      batch_stride_A(args.batch_stride_A),
+      batch_stride_B(args.batch_stride_A),
+      batch_stride_C(args.batch_stride_C),
+      batch_stride_D(args.batch_stride_D),
+      semaphore(static_cast<int *>(workspace)) {
     }
 
     CUTLASS_HOST_DEVICE
     void update(
       Arguments const &args,
-      void *workspace = nullptr,
-      int tile_count = 0) {
+      void *workspace = nullptr) {
 
-      problem_visitor = typename ProblemVisitor::Params(args.problem_sizes, args.problem_count,
-                                                        workspace, tile_count);
-      threadblock_count = args.threadblock_count;
-      output_op = args.output_op;
-      ptr_A = args.ptr_A;
-      ptr_B = args.ptr_B;
-      ptr_C = args.ptr_C;
+      ptr_A = const_cast<void *>(args.ptr_A);
+      ptr_B = const_cast<void *>(args.ptr_A);
+      ptr_C = const_cast<void *>(args.ptr_C);
       ptr_D = args.ptr_D;
-      ptr_norm = args.ptr_norm;
-      ptr_sum = args.ptr_sum;
-      lda = args.lda;
-      ldb = args.ldb;
-      ldc = args.ldc;
-      ldd = args.ldd;
+
+      output_op = args.epilogue;
+
+      semaphore = static_cast<int *>(workspace);
     }
+
   };
 
   /// Shared memory storage structure
-  struct SharedStorage {
-    union {
-      typename Mma::SharedStorage main_loop;
-      typename Epilogue::SharedStorage epilogue;
-    } kernel;
-
-    // ProblemVisitor shared storage can't be overlapped with others
-    typename ProblemVisitor::SharedStorage problem_visitor;
+  union SharedStorage {
+    typename Mma::SharedStorage main_loop;
+    typename Epilogue::SharedStorage epilogue;
   };
 
 public:
 
   //
   // Methods
   //
 
   CUTLASS_DEVICE
-  GemmGroupedSoftmaxMainloopFusion() { }
+  RankKUniversal() { } 
 
   /// Determines whether kernel satisfies alignment
-  static Status can_implement(cutlass::gemm::GemmCoord const & problem_size) {
+  static Status can_implement(
+    cutlass::gemm::GemmCoord const & problem_size) {
+
+    static int const kAlignmentA = Mma::IteratorA::AccessType::kElements;
+    static int const kAlignmentB = Mma::IteratorB::AccessType::kElements;
+    static int const kAlignmentC = Epilogue::OutputTileIterator::kElementsPerAccess;
+
+    if ((problem_size.m() % kAlignmentA) || (problem_size.k() % kAlignmentA) ||
+      (problem_size.n() % kAlignmentB) || (problem_size.k() % kAlignmentB) ||
+      (problem_size.m() % kAlignmentC) || (problem_size.n() % kAlignmentC)) {
+
+      return Status::kErrorMisalignedOperand;
+    }
+
     return Status::kSuccess;
   }
 
   static Status can_implement(Arguments const &args) {
-    return Status::kSuccess;
+    return can_implement(args.problem_size);
   }
 
   /// Executes one GEMM
   CUTLASS_DEVICE
   void operator()(Params const &params, SharedStorage &shared_storage) {
 
+    // Compute threadblock location
+    ThreadblockSwizzle threadblock_swizzle;
+
+    cutlass::gemm::GemmCoord threadblock_tile_offset =
+        threadblock_swizzle.get_tile_offset(params.swizzle_log_tile);
+
+    // Early exit if CTA is out of range
+    if (params.grid_tiled_shape.m() <= threadblock_tile_offset.m() ||
+      params.grid_tiled_shape.n() <= threadblock_tile_offset.n()) {
+      return;
+    }
+   
+    // Early exit if Fill Mode is Lower and
+    // if the entire tile is above the main diagonal (bottom-left corner is at or above the diagonal)
+    if (kFillModeC == cutlass::FillMode::kLower &&
+        (threadblock_tile_offset.m() + 1) * Mma::Shape::kM <= threadblock_tile_offset.n() * Mma::Shape::kN) {
+      return;
+    }    
+    
+    // Early exit if Fill Mode is Upper and
+    // if the entire tile is below the main diagonal (top-right corner is at or below the diagonal)
+    if (kFillModeC == cutlass::FillMode::kUpper &&
+        threadblock_tile_offset.m() * Mma::Shape::kM >= (threadblock_tile_offset.n() + 1) * Mma::Shape::kN) {
+      return;
+    }    
+    
+    bool tile_on_diagonal = false;
+    // Mark tiles that are being crossed by the main diagonal
+    // (top-right and bottom-left corners are on either side of the diagonal)
+    if ((threadblock_tile_offset.m() + 1) * Mma::Shape::kM > threadblock_tile_offset.n() * Mma::Shape::kN
+        && threadblock_tile_offset.m() * Mma::Shape::kM < (threadblock_tile_offset.n() + 1) * Mma::Shape::kN) {
+      tile_on_diagonal = true;
+    }
+
+    int offset_k = 0;
+    int problem_size_k = params.problem_size.k();
+
+    ElementA *ptr_A = static_cast<ElementA *>(params.ptr_A); 
+    ElementB *ptr_B = static_cast<ElementB *>(params.ptr_B);
+
+    //
+    // Fetch pointers based on mode.
+    //
+    if (params.mode == GemmUniversalMode::kGemm || 
+      params.mode == GemmUniversalMode::kGemmSplitKParallel) {
+
+      if (threadblock_tile_offset.k() + 1 < params.grid_tiled_shape.k()) {
+
+        problem_size_k = (threadblock_tile_offset.k() + 1) * params.gemm_k_size; 
+      }
+
+      offset_k = threadblock_tile_offset.k() * params.gemm_k_size;
+    }
+    else if (params.mode == GemmUniversalMode::kBatched) {
+      ptr_A += threadblock_tile_offset.k() * params.batch_stride_A;
+      ptr_B += threadblock_tile_offset.k() * params.batch_stride_B;
+    }
+    else if (params.mode == GemmUniversalMode::kArray) {
+      ptr_A = static_cast<ElementA * const *>(params.ptr_A)[threadblock_tile_offset.k()];
+      ptr_B = static_cast<ElementB * const *>(params.ptr_B)[threadblock_tile_offset.k()];
+    }
+
+    __syncthreads();
+
+    // Compute initial location in logical coordinates
+    cutlass::MatrixCoord tb_offset_A{
+      threadblock_tile_offset.m() * Mma::Shape::kM,
+      offset_k,
+    };
+
+    cutlass::MatrixCoord tb_offset_B{
+      offset_k,
+      threadblock_tile_offset.n() * Mma::Shape::kN
+    };
+
+
+    // Compute position within threadblock
+    int thread_idx = threadIdx.x;
+
+    // Construct iterators to A and B operands
+    typename Mma::IteratorA iterator_A(
+      params.params_A,
+      ptr_A,
+      {params.problem_size.m(), problem_size_k},
+      thread_idx,
+      tb_offset_A);
+
+    typename Mma::IteratorB iterator_B(
+      params.params_B,
+      ptr_B,
+      {problem_size_k, params.problem_size.n()},
+      thread_idx,
+      tb_offset_B);
+
+    // Broadcast the warp_id computed by lane 0 to ensure dependent code
+    // is compiled as warp-uniform.
+    int warp_idx = canonical_warp_idx();
+
+    int lane_idx = threadIdx.x % 32;
+
+    //
+    // Main loop
+    //
+
+    // Construct thread-scoped matrix multiply
+    Mma mma(shared_storage.main_loop, thread_idx, warp_idx, lane_idx);
+
+    typename Mma::FragmentC accumulators;
+
+    accumulators.clear();
+
+    // Compute threadblock-scoped matrix multiply-add
+    int gemm_k_iterations = (problem_size_k - offset_k + Mma::Shape::kK - 1) / Mma::Shape::kK;
+
+    // Compute threadblock-scoped matrix multiply-add
+    mma(
+      gemm_k_iterations, 
+      accumulators, 
+      iterator_A, 
+      iterator_B, 
+      accumulators);
+
+    //
+    // Epilogue
+    //
+
+    EpilogueOutputOp output_op(params.output_op);
+
     //
-    // These types shadow the type-level definitions and support the ability to implement
-    // a 'transposed' GEMM that computes the transposed problems.
+    // Masked tile iterators constructed from members
     //
-    using ElementA = typename Mma::IteratorA::Element;
-    using LayoutA = typename Mma::IteratorA::Layout;
-    using ElementB = typename Mma::IteratorB::Element;
-    using LayoutB = typename Mma::IteratorB::Layout;
-    using ElementC = typename Epilogue::OutputTileIterator::Element;
-    using LayoutC = typename Epilogue::OutputTileIterator::Layout;
-
-    //
-    // Problem visitor.
-    //
-    ProblemVisitor problem_visitor(
-      params.problem_visitor,
-      shared_storage.problem_visitor,
-      blockIdx.x);
-
-    // Outer 'persistent' loop to iterate over tiles
-    while (problem_visitor.next_tile()) {
-
-      GemmCoord problem_size  = problem_visitor.problem_size();
-      int32_t problem_idx     = problem_visitor.problem_index();
-      int32_t threadblock_idx = int32_t(problem_visitor.threadblock_idx());
-
-      GemmCoord grid_shape = problem_visitor.grid_shape(problem_size);
-
-      cutlass::gemm::GemmCoord threadblock_offset(
-        int(threadblock_idx / grid_shape.n()) * Mma::Shape::kM,
-        int(threadblock_idx % grid_shape.n()) * Mma::Shape::kN,
-        0);
-
-      // Load element pointers. Exchange pointers and strides if working on the transpose
-      ElementA *ptr_A = reinterpret_cast<ElementA *>((kTransposed ? params.ptr_B[problem_idx] : params.ptr_A[problem_idx]));
-      typename LayoutA::LongIndex ldm_A = (kTransposed ? params.ldb[problem_idx] : params.lda[problem_idx]);
-
-      ElementB *ptr_B = reinterpret_cast<ElementB *>((kTransposed ? params.ptr_A[problem_idx] : params.ptr_B[problem_idx]));
-      typename LayoutB::LongIndex ldm_B = (kTransposed ? params.lda[problem_idx] : params.ldb[problem_idx]);
-
-      // Compute initial location in logical coordinates
-      cutlass::MatrixCoord tb_offset_A{
-        threadblock_offset.m(),
-        0,
-      };
-
-      cutlass::MatrixCoord tb_offset_B{
-        0,
-        threadblock_offset.n()
-      };
-
-      // Compute position within threadblock
-      int thread_idx = threadIdx.x;
-
-      // Construct iterators to A and B operands
-      typename Mma::IteratorA iterator_A(
-        LayoutA(ldm_A),
-        ptr_A,
-        {problem_size.m(), problem_size.k()},
-        thread_idx,
-        tb_offset_A);
-
-      typename Mma::IteratorB iterator_B(
-        LayoutB(ldm_B),
-        ptr_B,
-        {problem_size.k(), problem_size.n()},
-        thread_idx,
-        tb_offset_B);
-
-      // Construct iterator to the softmax norm/sum vector
-      typename Mma::IteratorNormSum iterator_norm_sum(
-        problem_size.m(),
-        static_cast<ElementScaleBias const *>(params.ptr_norm[problem_idx]),
-        static_cast<ElementScaleBias const *>(params.ptr_sum[problem_idx]),
-        thread_idx,
-        MatrixCoord(0, threadblock_offset.m())
-      );
-
-      typename Mma::FragmentC accumulators;
-
-      accumulators.clear();
-
-      // Broadcast the warp_id computed by lane 0 to ensure dependent code
-      // is compiled as warp-uniform.
-      int warp_idx = __shfl_sync(0xffffffff, threadIdx.x / 32, 0);
-
-      int lane_idx = threadIdx.x % 32;
-
-      //
-      // Matrix multiply phase
-      //
-
-      // Construct thread-scoped matrix multiply
-      Mma mma(shared_storage.kernel.main_loop, thread_idx, warp_idx, lane_idx);
-
-      // Compute threadblock-scoped matrix multiply-add
-      int gemm_k_iterations = (problem_size.k() + Mma::Shape::kK - 1) / Mma::Shape::kK;
-
-      // Wait for all threads to finish their epilogue phases from the previous tile.
-      __syncthreads();
-
-      // Compute threadblock-scoped matrix multiply-add
-      mma(
-        gemm_k_iterations,
-        accumulators,
-        iterator_A,
-        iterator_B,
-        iterator_norm_sum,
-        accumulators);
-
-      //
-      // Epilogue
-      //
-
-      EpilogueOutputOp output_op(params.output_op);
-
-      ElementC *ptr_C = params.ptr_C[problem_idx];
-      ElementC *ptr_D = params.ptr_D[problem_idx];
-
-      LayoutC layout_C(params.ldc[problem_idx]);
-      LayoutC layout_D(params.ldd[problem_idx]);
-
-      typename Epilogue::OutputTileIterator::Params params_C(layout_C);
-      typename Epilogue::OutputTileIterator::Params params_D(layout_D);
-
-      // Tile iterator loading from source tensor.
-      typename Epilogue::OutputTileIterator iterator_C(
-        params_C,
-        ptr_C,
-        problem_size.mn(),
-        thread_idx,
-        threadblock_offset.mn()
-      );
-
-      // Tile iterator writing to destination tensor.
-      typename Epilogue::OutputTileIterator iterator_D(
-        params_D,
-        ptr_D,
-        problem_size.mn(),
-        thread_idx,
-        threadblock_offset.mn()
-      );
-
-      Epilogue epilogue(
-        shared_storage.kernel.epilogue,
-        thread_idx,
-        warp_idx,
-        lane_idx);
-
-      // Execute the epilogue operator to update the destination tensor.
-      epilogue(
-        output_op,
-        iterator_D,
-        accumulators,
-        iterator_C);
 
-      // Next tile
-      problem_visitor.advance(gridDim.x);
+    threadblock_tile_offset =
+        threadblock_swizzle.get_tile_offset(params.swizzle_log_tile);
+
+    //assume identity swizzle
+    MatrixCoord threadblock_offset(
+      threadblock_tile_offset.m() * Mma::Shape::kM,
+      threadblock_tile_offset.n() * Mma::Shape::kN
+    );
+
+    int block_idx = threadblock_tile_offset.m() + threadblock_tile_offset.n() * params.grid_tiled_shape.m();
+
+    ElementC *ptr_C = static_cast<ElementC *>(params.ptr_C); 
+    ElementC *ptr_D = static_cast<ElementC *>(params.ptr_D);
+
+    //
+    // Fetch pointers based on mode.
+    //
+    
+    // Construct the semaphore.
+    Semaphore semaphore(params.semaphore + block_idx, thread_idx);
+
+    if (params.mode == GemmUniversalMode::kGemm) {
+
+      // If performing a reduction via split-K, fetch the initial synchronization
+      if (params.grid_tiled_shape.k() > 1) {
+        
+        // Fetch the synchronization lock initially but do not block.
+        semaphore.fetch();
+
+        // Indicate which position in a serial reduction the output operator is currently updating
+        output_op.set_k_partition(threadblock_tile_offset.k(), params.grid_tiled_shape.k());
+      }
+    }
+    else if (params.mode == GemmUniversalMode::kGemmSplitKParallel) {
+      ptr_D += threadblock_tile_offset.k() * params.batch_stride_D;
+    }
+    else if (params.mode == GemmUniversalMode::kBatched) {
+      ptr_C += threadblock_tile_offset.k() * params.batch_stride_C;
+      ptr_D += threadblock_tile_offset.k() * params.batch_stride_D;
+    }
+    else if (params.mode == GemmUniversalMode::kArray) {
+      ptr_C = static_cast<ElementC * const *>(params.ptr_C)[threadblock_tile_offset.k()];
+      ptr_D = static_cast<ElementC * const *>(params.ptr_D)[threadblock_tile_offset.k()];
+    }
+
+    
+    // If CTA not on diagonal, FillMode doesn't apply. 
+    FillMode kFillModeCTA = tile_on_diagonal ? kFillModeC : FillMode::kNone;
+
+    // Tile iterator loading from source tensor.
+    typename Epilogue::OutputTileIterator iterator_C(
+      params.params_C,
+      ptr_C,
+      params.problem_size.mn(),
+      thread_idx,
+      threadblock_offset,
+      kFillModeCTA
+    );
+
+    // Tile iterator writing to destination tensor.
+    typename Epilogue::OutputTileIterator iterator_D(
+      params.params_D,
+      ptr_D,
+      params.problem_size.mn(),
+      thread_idx,
+      threadblock_offset,
+      kFillModeCTA
+    );
+
+    Epilogue epilogue(
+      shared_storage.epilogue, 
+      thread_idx, 
+      warp_idx, 
+      lane_idx);
+
+    // Wait on the semaphore - this latency may have been covered by iterator construction
+    if (params.mode == GemmUniversalMode::kGemm && params.grid_tiled_shape.k() > 1) {
+        
+      // For subsequent threadblocks, the source matrix is held in the 'D' tensor.
+      if (threadblock_tile_offset.k()) {
+        iterator_C = iterator_D;
+      }
+
+      semaphore.wait(threadblock_tile_offset.k());
+
+      __threadfence();
+    }
+
+    // Execute the epilogue operator to update the destination tensor.
+    epilogue(
+      output_op, 
+      iterator_D, 
+      accumulators, 
+      iterator_C); 
+    
+    //
+    // Release the semaphore
+    //
+
+    if (params.mode == GemmUniversalMode::kGemm && params.grid_tiled_shape.k() > 1) { 
+
+      int lock = 0;
+      if (params.grid_tiled_shape.k() == threadblock_tile_offset.k() + 1) {
+
+        // The final threadblock resets the semaphore for subsequent grids.
+        lock = 0;
+      }
+      else {
+        // Otherwise, the semaphore is incremented
+        lock = threadblock_tile_offset.k() + 1;
+      }
+      
+      semaphore.release(lock);
     }
   }
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 } // namespace kernel
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_layernorm_mainloop_fusion.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_layernorm_mainloop_fusion.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_params.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_params.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_pipelined.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_pipelined.h`

 * *Files 6% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -107,15 +107,15 @@
   typename Mma::IteratorB iterator_B(
     params_B,
     ref_B.data(),
     {problem_size.k(), problem_size.n()},
     tb_thread_id,
     tb_offset_B);
 
-  int warp_id = __shfl_sync(0xffffffff, threadIdx.x / 32, 0);
+  int warp_id = canonical_warp_idx();
   int lane_id = threadIdx.x % 32;
 
   //
   // Main loop
   //
 
   // Construct thread-scoped matrix multiply
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_planar_complex.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_planar_complex.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -521,15 +521,15 @@
       ptr_B_imag,
       {problem_size_k, params.problem_size.n()},
       thread_idx,
       tb_offset_B);
 
     // Broadcast the warp_id computed by lane 0 to ensure dependent code
     // is compiled as warp-uniform.
-    int warp_idx = __shfl_sync(0xffffffff, threadIdx.x / 32, 0);
+    int warp_idx = canonical_warp_idx();
 
     int lane_idx = threadIdx.x % 32;
 
     //
     // Main loop
     //
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_planar_complex_array.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_planar_complex_array.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -463,15 +463,15 @@
         //
         // Compute indices within threadblock and warp.
         //
         int thread_idx = threadIdx.x;
 
         // Broadcast the warp_id computed by lane 0 to ensure dependent code
         // is compiled as warp-uniform.
-        int warp_idx = __shfl_sync(0xffffffff, threadIdx.x / 32, 0);
+        int warp_idx = canonical_warp_idx();
         int lane_idx = threadIdx.x % 32;
     
         //
         // Proceed with regular GEMM logic.
         //
 
         // Compute initial location in logical coordinates
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_splitk_parallel.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_splitk_parallel.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_transpose_operands.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_transpose_operands.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_universal.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_universal.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -32,18 +32,22 @@
 /*! \file
     \brief 
 */
 
 #pragma once
 
 #include "cutlass/cutlass.h"
+
+#include "cutlass/arch/arch.h"
 #include "cutlass/fast_math.h"
 #include "cutlass/matrix_coord.h"
 #include "cutlass/complex.h"
 #include "cutlass/semaphore.h"
+#include "cutlass/gemm/kernel/gemm_universal.hpp"
+
 #include "cutlass/layout/matrix.h"
 #include "cutlass/gemm/gemm.h"
 #include "cutlass/gemm/kernel/params_universal_base.h"
 
 #include "cutlass/trace.h"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
@@ -55,15 +59,23 @@
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 template <
   typename Mma_,                  ///! Threadblock-scoped matrix multiply-accumulate
   typename Epilogue_,             ///! Epilogue
   typename ThreadblockSwizzle_    ///! Threadblock swizzling function
 >
-struct GemmUniversal {
+class GemmUniversal<
+  Mma_,
+  Epilogue_,
+  ThreadblockSwizzle_,
+  void,
+  // 3.x kernels use the first template argument to define the ProblemShape tuple
+  // We use this invariant to SFINAE dispatch against either the 2.x API or the 3.x API
+  std::enable_if_t<not cute::is_tuple<Mma_>::value>
+> {
 public:
 
   using Mma = Mma_;
   using Epilogue = Epilogue_;
   using EpilogueOutputOp = typename Epilogue::OutputOp;
   using ThreadblockSwizzle = ThreadblockSwizzle_;
 
@@ -522,15 +534,15 @@
       {problem_size_k, params.problem_size.n()},
       thread_idx,
       tb_offset_B,
       params.ptr_gather_B_indices);
 
     // Broadcast the warp_id computed by lane 0 to ensure dependent code
     // is compiled as warp-uniform.
-    int warp_idx = __shfl_sync(0xffffffff, threadIdx.x / 32, 0);
+    int warp_idx = canonical_warp_idx();
 
     int lane_idx = threadIdx.x % 32;
 
     //
     // Main loop
     //
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_universal_streamk.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_universal_streamk.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -120,15 +120,15 @@
 
     //
     // Data members
     //
 
     GemmUniversalMode mode;
     GemmCoord problem_size;
-    int batch_count;
+    int batch_count;        // Either (mode == GemmUniversalMode::kBatched) the batch count, or (mode == GemmUniversalMode::kGemm) the tile-splitting factor
 
     typename EpilogueOutputOp::Params epilogue;
 
     void const * ptr_A;
     void const * ptr_B;
     void const * ptr_C;
     void * ptr_D;
@@ -144,87 +144,90 @@
     typename LayoutC::Stride stride_d;
 
     typename LayoutA::Stride::LongIndex lda;
     typename LayoutB::Stride::LongIndex ldb;
     typename LayoutC::Stride::LongIndex ldc;
     typename LayoutC::Stride::LongIndex ldd;
 
-    int sm_limit;    /// Carvout override: when the above are defaulted, the number of SMs that dispatch heuristics will attempt to load-balance
+    int avail_sms;          /// The number of SMs that StreamK dispatch heuristics will attempt to load-balance across (-1 defaults to device width, 1 implies classic data-parallel scheduling)
 
 
     //
     // Methods
     //
 
     /// Default Constructor
     Arguments():
       mode(GemmUniversalMode::kGemm),
       batch_count(1),
-      ptr_A(nullptr), ptr_B(nullptr), ptr_C(nullptr), ptr_D(nullptr),
-      sm_limit(-1)
+      ptr_A(nullptr),
+      ptr_B(nullptr),
+      ptr_C(nullptr),
+      ptr_D(nullptr),
+      avail_sms(-1)
     {}
 
     /// Constructor
     Arguments(
       GemmUniversalMode mode,
       GemmCoord problem_size,
-      int batch_count,
+      int batch_split,                              /// Either (mode == GemmUniversalMode::kBatched) the batch count, or (mode == GemmUniversalMode::kGemm) the tile-splitting factor (1 defaults to StreamK, >1 emulates Split-K)
       typename EpilogueOutputOp::Params epilogue,
       void const * ptr_A,
       void const * ptr_B,
       void const * ptr_C,
       void * ptr_D,
       int64_t batch_stride_A,
       int64_t batch_stride_B,
       int64_t batch_stride_C,
       int64_t batch_stride_D,
       typename LayoutA::Stride stride_a,
       typename LayoutB::Stride stride_b,
       typename LayoutC::Stride stride_c,
       typename LayoutC::Stride stride_d,
-      int sm_limit = -1                    /// Carvout override: when the above are defaulted, the number of SMs that dispatch heuristics will attempt to load-balance
+      int avail_sms = -1                            /// The number of SMs that StreamK dispatch heuristics will attempt to load-balance across (-1 defaults to device width, 1 implies classic data-parallel scheduling)
     ):
       mode(mode),
       problem_size(problem_size),
-      batch_count(batch_count),
+      batch_count(batch_split),
       epilogue(epilogue),
       ptr_A(ptr_A), ptr_B(ptr_B), ptr_C(ptr_C), ptr_D(ptr_D),
       batch_stride_A(batch_stride_A), batch_stride_B(batch_stride_B), batch_stride_C(batch_stride_C), batch_stride_D(batch_stride_D),
-      stride_a(stride_a), stride_b(stride_b), stride_c(stride_c), stride_d(stride_d), sm_limit(sm_limit)
+      stride_a(stride_a), stride_b(stride_b), stride_c(stride_c), stride_d(stride_d), avail_sms(avail_sms)
     {
       CUTLASS_TRACE_HOST("GemmUniversalStreamk::Arguments::Arguments() - problem_size: " << problem_size);
     }
 
     /// Constructor
     Arguments(
       GemmUniversalMode mode,
       GemmCoord problem_size,
-      int batch_count,
+      int batch_split,                              /// Either (mode == GemmUniversalMode::kBatched) the batch count, or (mode == GemmUniversalMode::kGemm) the tile-splitting factor (1 defaults to StreamK, >1 emulates Split-K)
       typename EpilogueOutputOp::Params epilogue,
       void const * ptr_A,
       void const * ptr_B,
       void const * ptr_C,
       void * ptr_D,
       int64_t batch_stride_A,
       int64_t batch_stride_B,
       int64_t batch_stride_C,
       int64_t batch_stride_D,
       typename LayoutA::Stride::LongIndex lda,
       typename LayoutB::Stride::LongIndex ldb,
       typename LayoutC::Stride::LongIndex ldc,
       typename LayoutC::Stride::LongIndex ldd,
-      int sm_limit = -1                    /// Carvout override: when the above are defaulted, the number of SMs that dispatch heuristics will attempt to load-balance
+      int avail_sms = -1                            /// The number of SMs that StreamK dispatch heuristics will attempt to load-balance across (-1 defaults to device width, 1 implies classic data-parallel scheduling)
     ):
       mode(mode),
       problem_size(problem_size),
-      batch_count(batch_count),
+      batch_count(batch_split),
       epilogue(epilogue),
       ptr_A(ptr_A), ptr_B(ptr_B), ptr_C(ptr_C), ptr_D(ptr_D),
       batch_stride_A(batch_stride_A), batch_stride_B(batch_stride_B), batch_stride_C(batch_stride_C), batch_stride_D(batch_stride_D),
-      lda(lda), ldb(ldb), ldc(ldc), ldd(ldd), sm_limit(sm_limit)
+      lda(lda), ldb(ldb), ldc(ldc), ldd(ldd), avail_sms(avail_sms)
     {
       stride_a = make_Coord(lda);
       stride_b = make_Coord(ldb);
       stride_c = make_Coord(ldc);
       stride_d = make_Coord(ldd);
       CUTLASS_TRACE_HOST("GemmUniversalStreamk::Arguments::Arguments() - problem_size: " << problem_size);
     }
@@ -250,36 +253,41 @@
   {
   public:
 
     //
     // Data members
     //
 
-    ThreadblockSwizzle block_mapping;
+    void * ptr_A;
+    void * ptr_B;
 
     typename Mma::IteratorA::Params params_A;
     typename Mma::IteratorB::Params params_B;
-    typename Epilogue::OutputTileIterator::Params params_C;
-    typename Epilogue::OutputTileIterator::Params params_D;
-    typename EpilogueOutputOp::Params output_op;
+
+    int64_t batch_stride_A;
+    int64_t batch_stride_B;
 
     GemmUniversalMode mode;
 
-    void * ptr_A;
-    void * ptr_B;
-    void * ptr_C;
+    ThreadblockSwizzle block_mapping;
+
+    void *barrier_workspace;
+    void *partials_workspace;
+
+    typename EpilogueOutputOp::Params output_op;
+
     void * ptr_D;
+    void * ptr_C;
+
+    typename Epilogue::OutputTileIterator::Params params_D;
+    typename Epilogue::OutputTileIterator::Params params_C;
 
-    int64_t batch_stride_A;
-    int64_t batch_stride_B;
-    int64_t batch_stride_C;
     int64_t batch_stride_D;
+    int64_t batch_stride_C;
 
-    void *barrier_workspace;
-    void *partials_workspace;
 
   protected:
 
     //
     // Host-only dispatch-utilities
     //
 
@@ -291,24 +299,24 @@
     }
 
     /// Get the workspace size needed for barrier
     size_t get_barrier_workspace_size() const
     {
       // For atomic reduction, each SK-block needs a synchronization flag.  For parallel reduction,
       // each reduction block needs its own synchronization flag.
-      int sk_blocks = block_mapping.sk_regions * block_mapping.sk_blocks_per_region;
+      int sk_blocks = block_mapping.sk_regions() * block_mapping.sk_blocks_per_region();
       int num_flags = fast_max(sk_blocks, block_mapping.reduction_blocks);
 
       return cacheline_align_up(sizeof(typename Barrier::T) * num_flags);
     }
 
     /// Get the workspace size needed for intermediate partial sums
     size_t get_partials_workspace_size() const
     {
-      int sk_blocks = block_mapping.sk_regions * block_mapping.sk_blocks_per_region;
+      int sk_blocks = block_mapping.sk_regions() * block_mapping.sk_blocks_per_region();
       return cacheline_align_up(kWorkspaceBytesPerBlock * sk_blocks);
     }
 
 
   public:
 
     //
@@ -339,26 +347,27 @@
       batch_stride_B(args.batch_stride_B),
       batch_stride_C(args.batch_stride_C),
       batch_stride_D(args.batch_stride_D),
       barrier_workspace(nullptr),
       partials_workspace(nullptr)
     {
       // Number of SMs to make available for StreamK decomposition
-      int avail_sms = (args.sm_limit == -1) ?
+      int avail_sms = (args.avail_sms == -1) ?
                         device_sms :
-                        fast_min(args.sm_limit, device_sms);
+                        fast_min(args.avail_sms, device_sms);
 
       // Initialize the block mapping structure
       block_mapping = ThreadblockSwizzle(
         typename ThreadblockSwizzle::template KernelTraits<GemmUniversalStreamk>(),
         args.mode,
         args.problem_size,
         {ThreadblockShape::kM, ThreadblockShape::kN, ThreadblockShape::kK},
         args.batch_count,
         sm_occupancy,
+        device_sms,
         avail_sms);
     }
 
 
     /// Returns the workspace size (in bytes) needed for these parameters
     size_t get_workspace_size() const
     {
@@ -422,15 +431,15 @@
       return Status::kSuccess;
     }
 
 
     /// Returns the GEMM volume in thread block tiles
     cutlass::gemm::GemmCoord get_tiled_shape() const
     {
-      return block_mapping.tiled_shape;
+      return block_mapping.tiled_shape();
     }
 
 
     /// Returns the total number of thread blocks to launch
     int get_grid_blocks() const
     {
       dim3 grid_dims = get_grid_dims();
@@ -529,17 +538,14 @@
 
   /// ID of warp
   int warp_idx;
 
   /// ID of each thread within a warp
   int lane_idx;
 
-  /// Block index
-  int block_idx;
-
   /// Threadblock scoped epilogue
   Epilogue epilogue;
 
 
 public:
 
   //
@@ -547,15 +553,15 @@
   //
 
   /// Determines whether the GEMM problem size satisfies this kernel's
   /// alignment requirements
   static Status can_implement(
     cutlass::gemm::GemmCoord const & problem_size)
   {
-    CUTLASS_TRACE_HOST("GemmUniversal::can_implement()");
+    CUTLASS_TRACE_HOST("GemmUniversalStreamk::can_implement()");
 
     static int const kAlignmentA = (platform::is_same<LayoutA,
                                                       layout::ColumnMajorInterleaved<32>>::value)
                                    ? 32
                                    : (platform::is_same<LayoutA,
                                                         layout::ColumnMajorInterleaved<64>>::value)
                                      ? 64
@@ -636,24 +642,26 @@
 
   //
   // Device-only utility methods
   //
 
   /// Iterator for fetching tile fragments from A
   CUTLASS_DEVICE
-  typename Mma::IteratorA init_iterator_A(TileWorkDesc &tile_work)
+  typename Mma::IteratorA init_iterator_A(
+    TileWorkDesc &tile_work,
+    GemmUniversalMode mode)
   {
     // The input A matrix
     ElementA *ptr_A = static_cast<ElementA *>(params.ptr_A);
 
     // Update input pointers based on batched/array mode
-    if (params.mode == GemmUniversalMode::kBatched) {
+    if (mode == GemmUniversalMode::kBatched) {
       ptr_A += tile_work.tiled_coord.k() * params.batch_stride_A;
     }
-    if (params.mode == GemmUniversalMode::kArray) {
+    if (mode == GemmUniversalMode::kArray) {
       ptr_A = static_cast<ElementA * const *>(params.ptr_A)[tile_work.tiled_coord.k()];
     }
 
     int m_begin = tile_work.tiled_coord.m() * Mma::Shape::kM;
     int m_end = params.block_mapping.problem_size.m();
     return Mma::IteratorA(
         params.params_A,
@@ -663,24 +671,26 @@
         { m_begin, tile_work.k_begin });
 
   }
 
 
   /// Iterator for fetching tile fragments from B
   CUTLASS_DEVICE
-  typename Mma::IteratorB init_iterator_B(TileWorkDesc &tile_work)
+  typename Mma::IteratorB init_iterator_B(
+    TileWorkDesc &tile_work,
+    GemmUniversalMode mode)
   {
     // The input B matrix
     ElementB *ptr_B = static_cast<ElementB *>(params.ptr_B);
 
     // Update input pointers based on batched/array mode
-    if (params.mode == GemmUniversalMode::kBatched) {
+    if (mode == GemmUniversalMode::kBatched) {
       ptr_B += tile_work.tiled_coord.k() * params.batch_stride_B;
     }
-    if (params.mode == GemmUniversalMode::kArray) {
+    if (mode == GemmUniversalMode::kArray) {
       ptr_B = static_cast<ElementB * const *>(params.ptr_B)[tile_work.tiled_coord.k()];
     }
 
     int n_begin = tile_work.tiled_coord.n() * Mma::Shape::kN;
     int n_end = params.block_mapping.problem_size.n();
     return Mma::IteratorB(
         params.params_B,
@@ -696,18 +706,18 @@
       TileWorkDesc &tile_work,
       int tile_idx)
   {
     // The linear tile index
     tile_work.tile_idx = tile_idx;
 
     // The first global-scoped MAC-iteration this threadblock will perform for this tile
-    tile_work.iter_begin = tile_idx * params.block_mapping.iters_per_tile;
+    tile_work.iter_begin = tile_idx * params.block_mapping.iters_per_tile();
 
     // The number of MAC-iterations this threadblock will perform for this tile
-    tile_work.k_iters_remaining = params.block_mapping.iters_per_tile;
+    tile_work.k_iters_remaining = params.block_mapping.iters_per_tile();
 
     // The starting index in the k-domain for MAC-iterations this threadblock will perform for this tile
     tile_work.k_begin = 0;
 
     // The ending index (one-past) in the k-domain for MAC-iterations this threadblock will perform for this tile
     tile_work.k_end = params.block_mapping.problem_size.k();
 
@@ -723,15 +733,15 @@
       int block_iter_begin,
       int block_iter_end)
   {
     // The linear tile index
     tile_work.tile_idx = tile_idx;
 
     // The first global-scoped MAC-iteration for this tile
-    int tile_iter_begin = tile_idx * params.block_mapping.iters_per_tile;
+    int tile_iter_begin = tile_idx * params.block_mapping.iters_per_tile();
 
     // The first global-scoped MAC-iteration this threadblock will perform for this tile
     tile_work.iter_begin = max(block_iter_begin, tile_iter_begin);
 
     // The first tile-scoped MAC-iteration this threadblock will perform for this tile
     int k_iter_begin = tile_work.iter_begin - tile_iter_begin;
 
@@ -752,15 +762,18 @@
     // The location of this tile (in threadblock-tile coordinates) in the output matrix
     tile_work.tiled_coord = params.block_mapping.get_tile_offset(tile_work.tile_idx);
   }
 
 
   /// Share accumulators with peers
   CUTLASS_DEVICE
-  void share_accumulators(AccumulatorTile const &accumulator_tile, int first_block_idx)
+  void share_accumulators(
+    AccumulatorTile const &accumulator_tile,
+    int block_idx,
+    int first_block_idx)
   {
     AccumulatorTile *accum_tile_workspace = reinterpret_cast<AccumulatorTile *>(params.partials_workspace);
 
     int accum_tile_offset = first_block_idx * kThreadCount;
 
     if (block_idx == first_block_idx)
     {
@@ -791,14 +804,15 @@
   }
 
 
   /// Acquire accumulators from peers
   CUTLASS_DEVICE
   void acquire_accumulators(
     AccumulatorTile &accumulator_tile,
+    int block_idx,
     int first_block_idx)
   {
     AccumulatorTile *accum_tile_workspace = reinterpret_cast<AccumulatorTile *>(params.partials_workspace);
 
     // Wait for arrival
     int num_carry_in = block_idx - first_block_idx;
     Barrier::wait_eq_reset(params.barrier_workspace, thread_idx, first_block_idx, num_carry_in);
@@ -864,16 +878,16 @@
   {
     int peer_idx_begin, peer_idx_last, reduce_tile_idx, reduce_fragment_idx;
 
     // Reduce by sk-tile (every tile contributed to by one or more blocks)
     reduce_tile_idx = reduce_idx / Epilogue::kAccumulatorFragments;
     reduce_fragment_idx = reduce_idx % Epilogue::kAccumulatorFragments;
 
-    int iter_tile_first = reduce_tile_idx * params.block_mapping.iters_per_tile;
-    int iter_tile_last = iter_tile_first + params.block_mapping.iters_per_tile - 1;
+    int iter_tile_first = reduce_tile_idx * params.block_mapping.iters_per_tile();
+    int iter_tile_last = iter_tile_first + params.block_mapping.iters_per_tile() - 1;
 
     peer_idx_begin = params.block_mapping.get_sk_block_idx(iter_tile_first);
     peer_idx_last = params.block_mapping.get_sk_block_idx(iter_tile_last);
 
     // Wait for peers to complete
     int peer_idx_end = peer_idx_last + 1;
     int num_peers = peer_idx_end - peer_idx_begin;
@@ -891,24 +905,14 @@
       tiled_coord.m() * Mma::Shape::kM,
       tiled_coord.n() * Mma::Shape::kN
     );
 
     ElementC *ptr_C = static_cast<ElementC *>(params.ptr_C);
     ElementC *ptr_D = static_cast<ElementC *>(params.ptr_D);
 
-    // Update pointers for batched/array mode(s)
-    if (params.mode == GemmUniversalMode::kBatched) {
-      ptr_C += tiled_coord.k() * params.batch_stride_C;
-      ptr_D += tiled_coord.k() * params.batch_stride_D;
-    }
-    if (params.mode == GemmUniversalMode::kArray) {
-      ptr_C = static_cast<ElementC * const *>(params.ptr_C)[tiled_coord.k()];
-      ptr_D = static_cast<ElementC * const *>(params.ptr_D)[tiled_coord.k()];
-    }
-
     // Tile iterator loading from source tensor.
     typename Epilogue::OutputTileIterator iterator_C(
         params.params_C,
         ptr_C,
         params.block_mapping.problem_size.mn(),
         thread_idx,
         threadblock_item_begin);
@@ -932,55 +936,57 @@
         iterator_C);
   }
 
 
   CUTLASS_DEVICE
   void process_tile(
     TileWorkDesc tile_work,
+    int block_idx,
     int dp_start_block_idx,
     int block_iter_begin)
   {
     // Initialize input iterators
-    typename Mma::IteratorA iterator_A = init_iterator_A(tile_work);
-    typename Mma::IteratorB iterator_B = init_iterator_B(tile_work);
+    typename Mma::IteratorA iterator_A = init_iterator_A(tile_work, params.mode);
+    typename Mma::IteratorB iterator_B = init_iterator_B(tile_work, params.mode);
 
     // Initialize accumulators
     AccumulatorTile accumulator_tile;
     accumulator_tile.clear();
 
-    // Perform this tile's range of multiply-accumulate (MAC) iterations
+    // Initialize MMA abstraction
     Mma mma(
       shared_storage.main_loop,
       thread_idx,
       warp_idx,
       lane_idx);
 
+    // Perform this tile's range of multiply-accumulate (MAC) iterations
     mma(tile_work.k_iters_remaining, accumulator_tile, iterator_A, iterator_B, accumulator_tile);
 
     if ((ThreadblockSwizzle::kReductionStrategy == ThreadblockSwizzle::kAtomic) ||
         (params.block_mapping.reduction_blocks == 0) ||
         (block_idx >= dp_start_block_idx))
     {
       //
       // Cooperative SK peer reduction or DP block
       //
 
       int first_block_idx = params.block_mapping.get_first_block_idx(tile_work.tile_idx, block_idx);
 
       if (!tile_work.tile_finished(params)) {
         // Non "finishing" SK blocks must share their partial accumulator sums through global scratch workspace
-        share_accumulators(accumulator_tile, first_block_idx);
+        share_accumulators(accumulator_tile, block_idx, first_block_idx);
       }
       else
       {
         // DP blocks and "finishing" SK blocks must perform epilogue operations and write the output tile
         if (!tile_work.tile_started())
         {
           // A "finishing" SK block must first aggregate its accumulator partial sums with those shared by peer threadblocks
-          acquire_accumulators(accumulator_tile, first_block_idx);
+          acquire_accumulators(accumulator_tile, block_idx, first_block_idx);
         }
 
         do_epilogue(tile_work, accumulator_tile);
       }
     }
     else
     {
@@ -1002,36 +1008,35 @@
 
 
   /// Executes one GEMM
   CUTLASS_DEVICE
   void gemm()
   {
     // Initialize block's iteration range
-    int tile_idx, block_iter_begin, block_iters_remaining;
+    int tile_idx = 0;
+    int block_iter_begin = 0;
+    int block_iters_remaining = 0;
+
+    int block_idx = params.block_mapping.get_block_idx();
 
-    int sk_padding_start_block_idx =  params.block_mapping.sk_regions * params.block_mapping.sk_blocks_per_region;
+    int sk_padding_start_block_idx =  params.block_mapping.sk_regions() * params.block_mapping.sk_blocks_per_region();
     int dp_start_block_idx = params.block_mapping.sk_waves * params.block_mapping.avail_sms;
     int reduce_start_block_idx = dp_start_block_idx + params.block_mapping.dp_blocks;
     int grid_padding_start_block_idx = reduce_start_block_idx + params.block_mapping.reduction_blocks;
 
-    if (block_idx < sk_padding_start_block_idx)
-    {
-      // This is a SK block
-      int block_iter_end;
-      params.block_mapping.get_iter_extents(block_idx, block_iter_begin, block_iter_end);
-      block_iters_remaining = block_iter_end - block_iter_begin;
+    // Initialize tile work descriptor
+    TileWorkDesc tile_work;
 
-      tile_idx = params.block_mapping.get_sk_tile_idx(block_iter_end - 1);
-    }
-    else if (block_idx < dp_start_block_idx)
-    {
-      // This is a filler block
-      return;
-    }
-    else if (block_idx < reduce_start_block_idx)
+    bool dp_block = (block_idx >= dp_start_block_idx) && (block_idx < reduce_start_block_idx);
+    bool sk_block = (block_idx < sk_padding_start_block_idx);
+    bool reduce_block = (block_idx >= reduce_start_block_idx) &&
+            (block_idx < grid_padding_start_block_idx) &&
+            (ThreadblockSwizzle::kReductionStrategy == ThreadblockSwizzle::kMixed);
+
+    if (dp_block)
     {
       // This is a DP block
       int dp_block_idx = block_idx - dp_start_block_idx;
       int first_dp_tile = (params.block_mapping.cohort_raster) ? 0 : params.block_mapping.sk_tiles;
 
       // Blocks in first DP wave get configured number of tiles
       tile_idx = first_dp_tile + dp_block_idx;
@@ -1039,81 +1044,86 @@
 
       // Blocks in subsequent DP waves get 1 tile
       if (dp_block_idx >= params.block_mapping.avail_sms) {
           tile_allottment = 1;
           tile_idx += (params.block_mapping.dp_first_wave_tiles - 1) * params.block_mapping.avail_sms;
       }
 
-      block_iter_begin = 0;
-      block_iters_remaining = params.block_mapping.iters_per_tile * tile_allottment;
+      block_iters_remaining = params.block_mapping.iters_per_tile() * tile_allottment;
+
+      init_dp_tile_work(tile_work, tile_idx);
+
+      // DP blocks exit if out of bounds or overlap an SK tile (only possible during cohort rasterization, where dp_first_wave_tiles must be 1)
+      if ((tile_idx < params.block_mapping.sk_tiles) ||
+          (tile_work.tiled_coord.m() >= params.block_mapping.tiled_shape().m()) ||
+          (tile_work.tiled_coord.n() >= params.block_mapping.tiled_shape().n()))
+      {
+        return;
+      }
     }
-    else if ((ThreadblockSwizzle::kReductionStrategy == ThreadblockSwizzle::kMixed) &&
-             (block_idx < grid_padding_start_block_idx))
+    else if (sk_block)
     {
-      // This is a reduction threadblock
-      int reduce_block_idx = block_idx - reduce_start_block_idx;
-      separate_reduction(reduce_block_idx);
-      return;
+      // This is a SK block
+      int block_iter_end;
+      params.block_mapping.get_iter_extents(block_idx, block_iter_begin, block_iter_end);
+      block_iters_remaining = block_iter_end - block_iter_begin;
+
+      tile_idx = params.block_mapping.get_sk_tile_idx(block_iter_end - 1);
+      init_sk_tile_work(tile_work, tile_idx, block_iter_begin, block_iter_begin + block_iters_remaining);
     }
     else
     {
-      // This is a filler block
+      if (reduce_block)
+      {
+        // This is a reduction threadblock
+        int reduce_block_idx = block_idx - reduce_start_block_idx;
+        separate_reduction(reduce_block_idx);
+      }
+
       return;
     }
 
     // Iteration-processing loop body
     CUTLASS_PRAGMA_NO_UNROLL
     while (true)
     {
-      // Initialize tile work descriptor
-      TileWorkDesc tile_work;
-      if (block_idx >= dp_start_block_idx)
-      {
-        init_dp_tile_work(tile_work, tile_idx);
-
-        // DP blocks exit if out of bounds or overlap an SK tile (only possible during cohort rasterization, where dp_first_wave_tiles must be 1)
-        if ((tile_idx < params.block_mapping.sk_tiles) ||
-          (tile_work.tiled_coord.m() >= params.block_mapping.tiled_shape.m()) ||
-          (tile_work.tiled_coord.n() >= params.block_mapping.tiled_shape.n()))
-        {
-          break;
-        }
-      }
-      else
-      {
-        init_sk_tile_work(tile_work, tile_idx, block_iter_begin, block_iter_begin + block_iters_remaining);
-      }
-
       // Perform this block's share of work for this tile
-      process_tile(tile_work, dp_start_block_idx, block_iter_begin);
+      process_tile(
+        tile_work,
+        block_idx,
+        dp_start_block_idx,
+        block_iter_begin);
 
-      // Update remaining work for this block
       block_iters_remaining -= tile_work.k_iters_remaining;
-      if (block_iters_remaining == 0) {
-        // Done
+
+      if (block_iters_remaining == 0)
+      {
         break;
       }
 
       // Continue to next tile
       __syncthreads();
 
       if (block_idx >= dp_start_block_idx)
       {
         // DP block consume their tiles at stride
         tile_idx += params.block_mapping.avail_sms;
+        init_dp_tile_work(tile_work, tile_idx);
       }
       else
       {
         // SK blocks consume their tiles in backwards order
         tile_idx--;
+        init_sk_tile_work(tile_work, tile_idx, block_iter_begin, block_iter_begin + block_iters_remaining);
       }
     }
 
   }
 
+
 public:
 
   //
   // Device-only API
   //
 
   // Factory invocation
@@ -1134,28 +1144,27 @@
       SharedStorage &shared_storage)
     :
       params(params),
       shared_storage(shared_storage),
       thread_idx(threadIdx.x),
       warp_idx(__shfl_sync(0xffffffff, threadIdx.x / 32, 0)),   // broadcast the warp_id computed by lane 0 to ensure dependent code
       lane_idx(threadIdx.x % 32),
-      block_idx(params.block_mapping.get_block_idx()),
       epilogue(
         shared_storage.epilogue,
         thread_idx,
         warp_idx,
         lane_idx)
   {}
 
 
   /// Executes one GEMM
   CUTLASS_DEVICE
   void operator()()
   {
-    // Do the GEMM
+    // Generic SK code path
     gemm();
 
   }
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_with_fused_epilogue.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_with_fused_epilogue.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -914,15 +914,15 @@
       batch_stride_B(batch_stride_B), 
       batch_stride_C(batch_stride_C), 
       batch_stride_Vector(batch_stride_Vector),
       batch_stride_Tensor(batch_stride_Tensor),
       lda(lda), ldb(ldb), ldc(ldc), ldd(ldd), ldr(ldr), ldt(ldt)
     {
       CUTLASS_TRACE_HOST("GemmWithFusedEpilogue::Arguments::Arguments() - problem_size: " << problem_size);
-      CUTLASS_TRACE_HOST("  ptr_Reduction: " << (void *)this->ptr_Reduction);
+      CUTLASS_TRACE_HOST("  ptr_Vector: " << (void *)this->ptr_Vector);
       CUTLASS_TRACE_HOST("  ptr_Tensor: " << (void *)this->ptr_Tensor);
       CUTLASS_TRACE_HOST("  ldr: " << this->ldr);
       CUTLASS_TRACE_HOST("  ldt: " << this->ldt);
     }
 
     /// Returns arguments for the transposed problem
     Arguments transposed_problem() const {
@@ -1015,15 +1015,15 @@
       batch_stride_A(args.batch_stride_A),
       batch_stride_B(args.batch_stride_B),
       batch_stride_C(args.batch_stride_C),
       batch_stride_Vector(args.batch_stride_Vector),
       batch_stride_Tensor(args.batch_stride_Tensor)
     {
       CUTLASS_TRACE_HOST("GemmWithFusedEpilogue::Params::Params() - problem_size: " << problem_size);
-      CUTLASS_TRACE_HOST("  ptr_Reduction: " << (void *)this->ptr_Reduction);
+      CUTLASS_TRACE_HOST("  ptr_Vector: " << (void *)this->ptr_Vector);
       CUTLASS_TRACE_HOST("  ptr_Tensor: " << (void *)this->ptr_Tensor);
       CUTLASS_TRACE_HOST("  ldr: " << this->ldr);
       CUTLASS_TRACE_HOST("  ldt: " << args.ldt);
     }
 
     /// Lightweight update given a subset of arguments.  Problem geometry is assumed
     /// to remain the same.
@@ -1218,15 +1218,15 @@
       ptr_B,
       {problem_size_k, params.problem_size.n()},
       thread_idx,
       tb_offset_B);
 
     // Broadcast the warp_id computed by lane 0 to ensure dependent code
     // is compiled as warp-uniform.
-    int warp_idx = __shfl_sync(0xffffffff, threadIdx.x / 32, 0);
+    int warp_idx = canonical_warp_idx();
 
     int lane_idx = threadIdx.x % 32;
 
     //
     // Main loop
     //
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_with_k_reduction.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemm_with_k_reduction.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -501,15 +501,15 @@
       ptr_B,
       {problem_size_k, params.problem_size.n()},
       thread_idx,
       tb_offset_B);
 
     // Broadcast the warp_id computed by lane 0 to ensure dependent code
     // is compiled as warp-uniform.
-    int warp_idx = __shfl_sync(0xffffffff, threadIdx.x / 32, 0);
+    int warp_idx = canonical_warp_idx();
 
     int lane_idx = threadIdx.x % 32;
 
     //
     // Main loop
     //
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemv.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemv.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemv_batched_strided.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/gemv_batched_strided.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/grouped_problem_visitor.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/grouped_problem_visitor.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/params_universal_base.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/params_universal_base.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/rank_2k_grouped.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/rank_2k_grouped.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -521,15 +521,15 @@
         ptr_A,
         {problem_size_k, problem_size.n()},
         thread_idx,
         tb_offset_KxN);
 
       // Broadcast the warp_id computed by lane 0 to ensure dependent code
       // is compiled as warp-uniform.
-      int warp_idx = __shfl_sync(0xffffffff, threadIdx.x / 32, 0);
+      int warp_idx = canonical_warp_idx();
 
       int lane_idx = threadIdx.x % 32;
 
       //
       // Main loop
       //
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/rank_2k_grouped_problem_visitor.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/rank_2k_grouped_problem_visitor.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -134,15 +134,15 @@
             r = ThreadblockShape::N / ThreadblockShape::M
             i = (i_macro * r) + (t % r)
             j = j_macro
         else:
             i = i_macro
             j = j_macro
 
-    Handling cases with grid dimensions that aren't multiples of eachother
+    Handling cases with grid dimensions that aren't multiples of each other
     ----------------------------------------------------------------------
     Even though threadblock shapes M and N are typically multiples of one another, the grid
     for a given problem may not have dimensions of the same ratio as that of the threadblock.
     For example, a problem of size 132x132 using a threadblock of shape 64x32 will result
     in a grid of 3x5 tiles. In this case, there is not an integer number of "true tiles"
     per "macro tile."
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/rank_2k_transpose_operands.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/rank_2k_transpose_operands.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/rank_2k_universal.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/rank_2k_universal.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -446,15 +446,15 @@
       ptr_A,
       {problem_size_k, params.problem_size.n()},
       thread_idx,
       tb_offset_KxN);
 
     // Broadcast the warp_id computed by lane 0 to ensure dependent code
     // is compiled as warp-uniform.
-    int warp_idx = __shfl_sync(0xffffffff, threadIdx.x / 32, 0);
+    int warp_idx = canonical_warp_idx();
 
     int lane_idx = threadIdx.x % 32;
 
     //
     // Main loop
     //
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/rank_k_universal.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/sparse_gemm.h`

 * *Files 19% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -24,287 +24,194 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
-
 /*! \file
-    \brief 
-
+    \brief Template for a pipelined GEMM kernel. Does not compute batching or support split-K.
 */
 
 #pragma once
 
-#include "cutlass/blas3.h"
-#include "cutlass/fast_math.h"
+#include "cutlass/cutlass.h"
+
 #include "cutlass/gemm/gemm.h"
 #include "cutlass/matrix_coord.h"
-#include "cutlass/complex.h"
 #include "cutlass/semaphore.h"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace gemm {
 namespace kernel {
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 template <
   typename Mma_,                  ///! Threadblock-scoped matrix multiply-accumulate 
   typename Epilogue_,             ///! Epilogue
   typename ThreadblockSwizzle_,   ///! Threadblock swizzling function
-  FillMode FillModeC_             ///! Fill Mode for C (kLower or kUpper)
+  bool SplitKSerial               ///! If true, code supporting split-K via serial reduction is enabled.
 >
-struct RankKUniversal {
-public:
+struct SparseGemm {
 
   using Mma = Mma_;
   using Epilogue = Epilogue_;
-  using EpilogueOutputOp = typename Epilogue::OutputOp;
+  using OutputOp = typename Epilogue::OutputOp;
   using ThreadblockSwizzle = ThreadblockSwizzle_;
+  static bool const kSplitKSerial = SplitKSerial;
+
+  static int const kSparse = Mma::kSparse;
+  static int const kMetaSizeInBits = Mma::kMetaSizeInBits;
+  static int const kMaxID2 = Mma::kMaxID2;
+  static int const kElementsPerElementE = Mma::kElementsPerElementE;
 
-  using ElementA = typename Mma::IteratorA::Element;
-  using LayoutA = typename Mma::IteratorA::Layout;
-  using ElementB = typename Mma::IteratorB::Element;
-  using LayoutB = typename Mma::IteratorB::Layout;
-  using ElementC = typename Epilogue::OutputTileIterator::Element;
-  using LayoutC = typename Epilogue::OutputTileIterator::Layout;
-  static FillMode const kFillModeC = FillModeC_;
-
-  static ComplexTransform const kTransformA = Mma::kTransformA;
-  static ComplexTransform const kTransformB = Mma::kTransformB;
-  using Operator = typename Mma::Operator;
-
-  using OperatorClass = typename Mma::Operator::OperatorClass;
-  using ThreadblockShape = typename Mma::Shape;
-  using WarpShape = typename Mma::Operator::Shape;
-  using InstructionShape = typename Mma::Policy::Operator::InstructionShape;
-  using ArchTag = typename Mma::ArchTag;
-
-  static int const kStages = Mma::kStages;
-  static int const kAlignmentA = Mma::IteratorA::AccessType::kElements;
-  static int const kAlignmentB = Mma::IteratorB::AccessType::kElements;
-  static int const kAlignmentC = Epilogue::OutputTileIterator::kElementsPerAccess;
+  using ElementE = typename Mma::ElementE;
+  using LayoutE = typename Mma::LayoutE;
 
   /// Warp count (concept: GemmShape)
   using WarpCount = typename Mma::WarpCount;
   static int const kThreadCount = 32 * WarpCount::kCount;
 
-  /// Split-K preserves splits that are 128b aligned
-  static int const kSplitKAlignment = 128 / sizeof_bits<ElementA>::value;
-
-  //
-  // Structures
-  //
-
-  /// Argument structure
-  struct Arguments {
-
-    //
-    // Data members
-    //
-
-    GemmUniversalMode mode;
-    GemmCoord problem_size;
-    int batch_count;
-
-    typename EpilogueOutputOp::Params epilogue;
-
-    void const * ptr_A;
-    void const * ptr_C;
-    void * ptr_D;
-
-    int64_t batch_stride_A;
-    int64_t batch_stride_C;
-    int64_t batch_stride_D;
-
-    typename LayoutA::Stride::Index lda;
-    typename LayoutB::Stride::Index ldb;
-    typename LayoutC::Stride::Index ldc;
-    typename LayoutC::Stride::Index ldd;
-
-    //
-    // Methods
-    //
-    
-    Arguments(): 
-      mode(GemmUniversalMode::kGemm), 
-      batch_count(1), 
-      ptr_A(nullptr), ptr_C(nullptr), ptr_D(nullptr) { }
-
-    /// constructs an arguments structure
-    Arguments(
-      GemmUniversalMode mode,
-      GemmCoord problem_size,
-      int batch_count,
-      typename EpilogueOutputOp::Params epilogue,
-      void const * ptr_A,
-      void const * ptr_C,
-      void * ptr_D,
-      int64_t batch_stride_A,
-      int64_t batch_stride_C,
-      int64_t batch_stride_D,
-      typename LayoutA::Stride::Index lda,
-      typename LayoutC::Stride::Index ldc,
-      typename LayoutC::Stride::Index ldd
-    ):
-      mode(mode), 
-      problem_size(problem_size), 
-      batch_count(batch_count),
-      epilogue(epilogue), 
-      ptr_A(ptr_A), ptr_C(ptr_C), ptr_D(ptr_D), 
-      batch_stride_A(batch_stride_A), batch_stride_C(batch_stride_C), batch_stride_D(batch_stride_D), 
-      lda(lda), ldb(ldb), ldc(ldc), ldd(ldd) {
-
-      }
-
-  };
-
-  //
-  // Structure for precomputing values in host memory and passing to kernels
-  //
-
   /// Parameters structure
   struct Params {
-
     cutlass::gemm::GemmCoord problem_size;
     cutlass::gemm::GemmCoord grid_tiled_shape;
     int swizzle_log_tile;
-   
     typename Mma::IteratorA::Params params_A;
+    typename Mma::IteratorA::TensorRef ref_A;
     typename Mma::IteratorB::Params params_B;
+    typename Mma::IteratorB::TensorRef ref_B;
     typename Epilogue::OutputTileIterator::Params params_C;
+    typename Epilogue::OutputTileIterator::TensorRef ref_C;
     typename Epilogue::OutputTileIterator::Params params_D;
-    
-    typename EpilogueOutputOp::Params output_op;
-
-    GemmUniversalMode mode;
-    int batch_count;
-    int gemm_k_size;
-
-    void * ptr_A;
-    void * ptr_B;
-    void * ptr_C;
-    void * ptr_D;
-
-    int64_t batch_stride_A;
-    int64_t batch_stride_B;
-    int64_t batch_stride_C;
-    int64_t batch_stride_D;
-
+    typename Epilogue::OutputTileIterator::TensorRef ref_D;
+    typename Mma::IteratorE::Params params_E;
+    typename Mma::IteratorE::TensorRef ref_E;
+    typename OutputOp::Params output_op;
     int *semaphore;
+    int gemm_k_iterations;
+    int gemm_k_size;
 
     //
     // Methods
     //
 
     CUTLASS_HOST_DEVICE
-    Params():
-      swizzle_log_tile(0),
-      params_A(0),
-      params_B(0),
-      params_C(0),
-      params_D(0),
-      batch_count(0),
-      gemm_k_size(0),
-      mode(cutlass::gemm::GemmUniversalMode::kGemm),
-      ptr_A(nullptr),
-      ptr_B(nullptr),
-      ptr_C(nullptr),
-      ptr_D(nullptr),
-      batch_stride_A(0),
-      batch_stride_B(0),
-      batch_stride_C(0),
-      batch_stride_D(0),
-      semaphore(nullptr) { }
+    Params(): swizzle_log_tile(0), semaphore(0), gemm_k_iterations(0), gemm_k_size(0) { }
 
     CUTLASS_HOST_DEVICE
     Params(
-      Arguments const &args,
+      cutlass::gemm::GemmCoord const & problem_size,
       cutlass::gemm::GemmCoord const & grid_tiled_shape,
-      int gemm_k_size,
-      void *workspace = nullptr
+      typename Mma::IteratorA::TensorRef ref_A,
+      typename Mma::IteratorB::TensorRef ref_B,
+      typename Epilogue::OutputTileIterator::TensorRef ref_C,
+      typename Epilogue::OutputTileIterator::TensorRef ref_D,
+      typename Mma::IteratorE::TensorRef ref_E,
+      typename OutputOp::Params output_op = typename OutputOp::Params(),
+      int *workspace = nullptr
     ):
-      problem_size(args.problem_size),
+      problem_size(problem_size),
       grid_tiled_shape(grid_tiled_shape),
       swizzle_log_tile(ThreadblockSwizzle().get_log_tile(grid_tiled_shape)),
-      params_A(args.lda),
-      params_B(args.lda),
-      params_C(args.ldc),
-      params_D(args.ldd),
-      output_op(args.epilogue),
-      mode(args.mode),
-      batch_count(args.batch_count),
-      gemm_k_size(gemm_k_size),
-      ptr_A(const_cast<void *>(args.ptr_A)),
-      ptr_B(const_cast<void *>(args.ptr_A)),
-      ptr_C(const_cast<void *>(args.ptr_C)),
-      ptr_D(const_cast<void *>(args.ptr_D)),
-      batch_stride_A(args.batch_stride_A),
-      batch_stride_B(args.batch_stride_A),
-      batch_stride_C(args.batch_stride_C),
-      batch_stride_D(args.batch_stride_D),
-      semaphore(static_cast<int *>(workspace)) {
-    }
-
-    CUTLASS_HOST_DEVICE
-    void update(
-      Arguments const &args,
-      void *workspace = nullptr) {
-
-      ptr_A = const_cast<void *>(args.ptr_A);
-      ptr_B = const_cast<void *>(args.ptr_A);
-      ptr_C = const_cast<void *>(args.ptr_C);
-      ptr_D = args.ptr_D;
+      params_A(ref_A.layout()),
+      ref_A(ref_A),
+      params_B(ref_B.layout()),
+      ref_B(ref_B),
+      params_C(ref_C.layout()),
+      ref_C(ref_C),
+      params_D(ref_D.layout()),
+      ref_D(ref_D),
+      params_E(ref_E.layout()),
+      ref_E(ref_E),
+      output_op(output_op) {
 
-      output_op = args.epilogue;
+      int total_gemm_k_iterations = (problem_size.k() + Mma::Shape::kK - 1) / Mma::Shape::kK;
+      int gemm_k_iterations = (total_gemm_k_iterations + grid_tiled_shape.k() - 1) / grid_tiled_shape.k();
+      
+      gemm_k_size = gemm_k_iterations * Mma::Shape::kK;
 
-      semaphore = static_cast<int *>(workspace);
+    semaphore = workspace;
     }
-
   };
 
   /// Shared memory storage structure
   union SharedStorage {
     typename Mma::SharedStorage main_loop;
     typename Epilogue::SharedStorage epilogue;
   };
 
-public:
-
   //
   // Methods
   //
 
-  CUTLASS_DEVICE
-  RankKUniversal() { } 
+  CUTLASS_HOST_DEVICE
+  SparseGemm() { } 
 
   /// Determines whether kernel satisfies alignment
   static Status can_implement(
-    cutlass::gemm::GemmCoord const & problem_size) {
+      cutlass::gemm::GemmCoord const & problem_size,
+      typename Mma::IteratorA::TensorRef ref_A,
+      typename Mma::IteratorB::TensorRef ref_B,
+      typename Epilogue::OutputTileIterator::TensorRef ref_C,
+      typename Epilogue::OutputTileIterator::TensorRef ref_D,
+      typename Mma::IteratorE::TensorRef ref_E) {
 
     static int const kAlignmentA = Mma::IteratorA::AccessType::kElements;
     static int const kAlignmentB = Mma::IteratorB::AccessType::kElements;
     static int const kAlignmentC = Epilogue::OutputTileIterator::kElementsPerAccess;
+    static int const kAlignmentE = Mma::IteratorE::AccessType::kElements;
+
+    if (!TensorRef_aligned(ref_A, kAlignmentA)) {
+      return Status::kErrorMisalignedOperand;
+    }
 
-    if ((problem_size.m() % kAlignmentA) || (problem_size.k() % kAlignmentA) ||
+    if (!TensorRef_aligned(ref_B, kAlignmentB)) {
+      return Status::kErrorMisalignedOperand;
+    }
+
+    if (!TensorRef_aligned(ref_C, kAlignmentC)) {
+      return Status::kErrorMisalignedOperand;
+    }
+
+    if (!TensorRef_aligned(ref_D, kAlignmentC)) {
+      return Status::kErrorMisalignedOperand;
+    }
+
+    if (!TensorRef_aligned(ref_E, kAlignmentE)) {
+      return Status::kErrorMisalignedOperand;
+    }
+
+    if ((problem_size.m() % kAlignmentA) || ((problem_size.k() / kSparse) % kAlignmentA) ||
       (problem_size.n() % kAlignmentB) || (problem_size.k() % kAlignmentB) ||
-      (problem_size.m() % kAlignmentC) || (problem_size.n() % kAlignmentC)) {
+      (problem_size.m() % kAlignmentC) || (problem_size.n() % kAlignmentC) ||
+      (problem_size.m() % kAlignmentE) || ((problem_size.k() / kSparse) % kAlignmentE)) {
 
       return Status::kErrorMisalignedOperand;
     }
 
-    return Status::kSuccess;
-  }
+    // The k dimension has to be the multiple of the Threadblock k because out
+    // of bound meta data would be initialized to 0 by acync.zfill but 0 is not
+    // a valid meta data.
+    if (problem_size.k() % Mma::Shape::kK) {
+      return Status::kErrorMisalignedOperand;
+    }
 
-  static Status can_implement(Arguments const &args) {
-    return can_implement(args.problem_size);
+    // M dimension has to be multiple of 32 (sparse float) or 16 (sparse int) 
+    // because of the row reordering of operand E
+    static int const kAlignmentM = (sizeof(ElementE) == 2) ? 32 : 16;
+
+    if (problem_size.m() % kAlignmentM) {
+      return Status::kErrorMisalignedOperand;
+    }
+
+    return Status::kSuccess;
   }
 
   /// Executes one GEMM
   CUTLASS_DEVICE
   void operator()(Params const &params, SharedStorage &shared_storage) {
 
     // Compute threadblock location
@@ -312,132 +219,92 @@
 
     cutlass::gemm::GemmCoord threadblock_tile_offset =
         threadblock_swizzle.get_tile_offset(params.swizzle_log_tile);
 
     // Early exit if CTA is out of range
     if (params.grid_tiled_shape.m() <= threadblock_tile_offset.m() ||
       params.grid_tiled_shape.n() <= threadblock_tile_offset.n()) {
-      return;
-    }
-   
-    // Early exit if Fill Mode is Lower and
-    // if the entire tile is above the main diagonal (bottom-left corner is at or above the diagonal)
-    if (kFillModeC == cutlass::FillMode::kLower &&
-        (threadblock_tile_offset.m() + 1) * Mma::Shape::kM <= threadblock_tile_offset.n() * Mma::Shape::kN) {
-      return;
-    }    
-    
-    // Early exit if Fill Mode is Upper and
-    // if the entire tile is below the main diagonal (top-right corner is at or below the diagonal)
-    if (kFillModeC == cutlass::FillMode::kUpper &&
-        threadblock_tile_offset.m() * Mma::Shape::kM >= (threadblock_tile_offset.n() + 1) * Mma::Shape::kN) {
-      return;
-    }    
-    
-    bool tile_on_diagonal = false;
-    // Mark tiles that are being crossed by the main diagonal
-    // (top-right and bottom-left corners are on either side of the diagonal)
-    if ((threadblock_tile_offset.m() + 1) * Mma::Shape::kM > threadblock_tile_offset.n() * Mma::Shape::kN
-        && threadblock_tile_offset.m() * Mma::Shape::kM < (threadblock_tile_offset.n() + 1) * Mma::Shape::kN) {
-      tile_on_diagonal = true;
-    }
 
-    int offset_k = 0;
-    int problem_size_k = params.problem_size.k();
-
-    ElementA *ptr_A = static_cast<ElementA *>(params.ptr_A); 
-    ElementB *ptr_B = static_cast<ElementB *>(params.ptr_B);
-
-    //
-    // Fetch pointers based on mode.
-    //
-    if (params.mode == GemmUniversalMode::kGemm || 
-      params.mode == GemmUniversalMode::kGemmSplitKParallel) {
-
-      if (threadblock_tile_offset.k() + 1 < params.grid_tiled_shape.k()) {
-
-        problem_size_k = (threadblock_tile_offset.k() + 1) * params.gemm_k_size; 
-      }
-
-      offset_k = threadblock_tile_offset.k() * params.gemm_k_size;
-    }
-    else if (params.mode == GemmUniversalMode::kBatched) {
-      ptr_A += threadblock_tile_offset.k() * params.batch_stride_A;
-      ptr_B += threadblock_tile_offset.k() * params.batch_stride_B;
-    }
-    else if (params.mode == GemmUniversalMode::kArray) {
-      ptr_A = static_cast<ElementA * const *>(params.ptr_A)[threadblock_tile_offset.k()];
-      ptr_B = static_cast<ElementB * const *>(params.ptr_B)[threadblock_tile_offset.k()];
+      return;
     }
 
-    __syncthreads();
-
     // Compute initial location in logical coordinates
     cutlass::MatrixCoord tb_offset_A{
       threadblock_tile_offset.m() * Mma::Shape::kM,
-      offset_k,
+      threadblock_tile_offset.k() * params.gemm_k_size / kSparse,
     };
 
     cutlass::MatrixCoord tb_offset_B{
-      offset_k,
+      threadblock_tile_offset.k() * params.gemm_k_size,
       threadblock_tile_offset.n() * Mma::Shape::kN
     };
 
+    cutlass::MatrixCoord tb_offset_E{
+      threadblock_tile_offset.m() * Mma::Shape::kM,
+      threadblock_tile_offset.k() * params.gemm_k_size / kSparse,
+    };
+
+    // Problem size is a function of threadblock index in the K dimension
+    int problem_size_k = min(
+      params.problem_size.k(), 
+      (threadblock_tile_offset.k() + 1) * params.gemm_k_size);
+
+    // Compute threadblock-scoped matrix multiply-add
+    int gemm_k_iterations = (problem_size_k - tb_offset_B.row() + Mma::Shape::kK - 1) / Mma::Shape::kK;
 
     // Compute position within threadblock
     int thread_idx = threadIdx.x;
 
-    // Construct iterators to A and B operands
+    // Construct iterators to A, B, and E operands
     typename Mma::IteratorA iterator_A(
       params.params_A,
-      ptr_A,
-      {params.problem_size.m(), problem_size_k},
+      params.ref_A.data(),
+      {params.problem_size.m(), problem_size_k / kSparse},
       thread_idx,
       tb_offset_A);
 
     typename Mma::IteratorB iterator_B(
       params.params_B,
-      ptr_B,
+      params.ref_B.data(),
       {problem_size_k, params.problem_size.n()},
       thread_idx,
       tb_offset_B);
 
+    typename Mma::IteratorE iterator_E(
+        params.params_E, params.ref_E.data(),
+        {params.problem_size.m(),
+         problem_size_k / kSparse / kElementsPerElementE},
+        thread_idx, tb_offset_E);
+
     // Broadcast the warp_id computed by lane 0 to ensure dependent code
     // is compiled as warp-uniform.
-    int warp_idx = __shfl_sync(0xffffffff, threadIdx.x / 32, 0);
-
+    int warp_idx = canonical_warp_idx();
     int lane_idx = threadIdx.x % 32;
 
     //
     // Main loop
     //
 
     // Construct thread-scoped matrix multiply
     Mma mma(shared_storage.main_loop, thread_idx, warp_idx, lane_idx);
 
     typename Mma::FragmentC accumulators;
 
     accumulators.clear();
 
-    // Compute threadblock-scoped matrix multiply-add
-    int gemm_k_iterations = (problem_size_k - offset_k + Mma::Shape::kK - 1) / Mma::Shape::kK;
-
-    // Compute threadblock-scoped matrix multiply-add
-    mma(
-      gemm_k_iterations, 
-      accumulators, 
-      iterator_A, 
-      iterator_B, 
-      accumulators);
+    if (!kSplitKSerial || gemm_k_iterations > 0) {
+      // Compute threadblock-scoped matrix multiply-add
+      mma(gemm_k_iterations, accumulators, iterator_A, iterator_B, iterator_E, accumulators);
+    }
 
     //
     // Epilogue
     //
 
-    EpilogueOutputOp output_op(params.output_op);
+    OutputOp output_op(params.output_op);
 
     //
     // Masked tile iterators constructed from members
     //
 
     threadblock_tile_offset =
         threadblock_swizzle.get_tile_offset(params.swizzle_log_tile);
@@ -446,120 +313,88 @@
     MatrixCoord threadblock_offset(
       threadblock_tile_offset.m() * Mma::Shape::kM,
       threadblock_tile_offset.n() * Mma::Shape::kN
     );
 
     int block_idx = threadblock_tile_offset.m() + threadblock_tile_offset.n() * params.grid_tiled_shape.m();
 
-    ElementC *ptr_C = static_cast<ElementC *>(params.ptr_C); 
-    ElementC *ptr_D = static_cast<ElementC *>(params.ptr_D);
-
-    //
-    // Fetch pointers based on mode.
-    //
-    
     // Construct the semaphore.
     Semaphore semaphore(params.semaphore + block_idx, thread_idx);
 
-    if (params.mode == GemmUniversalMode::kGemm) {
-
-      // If performing a reduction via split-K, fetch the initial synchronization
-      if (params.grid_tiled_shape.k() > 1) {
-        
-        // Fetch the synchronization lock initially but do not block.
-        semaphore.fetch();
+    // If performing a reduction via split-K, fetch the initial synchronization
+    if (kSplitKSerial && params.grid_tiled_shape.k() > 1) {
+      
+      // Fetch the synchronization lock initially but do not block.
+      semaphore.fetch();
 
-        // Indicate which position in a serial reduction the output operator is currently updating
-        output_op.set_k_partition(threadblock_tile_offset.k(), params.grid_tiled_shape.k());
-      }
-    }
-    else if (params.mode == GemmUniversalMode::kGemmSplitKParallel) {
-      ptr_D += threadblock_tile_offset.k() * params.batch_stride_D;
+      // Indicate which position in a serial reduction the output operator is currently updating
+      output_op.set_k_partition(threadblock_tile_offset.k(), params.grid_tiled_shape.k());
     }
-    else if (params.mode == GemmUniversalMode::kBatched) {
-      ptr_C += threadblock_tile_offset.k() * params.batch_stride_C;
-      ptr_D += threadblock_tile_offset.k() * params.batch_stride_D;
-    }
-    else if (params.mode == GemmUniversalMode::kArray) {
-      ptr_C = static_cast<ElementC * const *>(params.ptr_C)[threadblock_tile_offset.k()];
-      ptr_D = static_cast<ElementC * const *>(params.ptr_D)[threadblock_tile_offset.k()];
-    }
-
-    
-    // If CTA not on diagonal, FillMode doesn't apply. 
-    FillMode kFillModeCTA = tile_on_diagonal ? kFillModeC : FillMode::kNone;
 
     // Tile iterator loading from source tensor.
     typename Epilogue::OutputTileIterator iterator_C(
       params.params_C,
-      ptr_C,
+      params.ref_C.data(),
       params.problem_size.mn(),
       thread_idx,
-      threadblock_offset,
-      kFillModeCTA
+      threadblock_offset
     );
 
     // Tile iterator writing to destination tensor.
     typename Epilogue::OutputTileIterator iterator_D(
       params.params_D,
-      ptr_D,
+      params.ref_D.data(),
       params.problem_size.mn(),
       thread_idx,
-      threadblock_offset,
-      kFillModeCTA
+      threadblock_offset
     );
 
     Epilogue epilogue(
       shared_storage.epilogue, 
       thread_idx, 
       warp_idx, 
       lane_idx);
 
     // Wait on the semaphore - this latency may have been covered by iterator construction
-    if (params.mode == GemmUniversalMode::kGemm && params.grid_tiled_shape.k() > 1) {
+    if (kSplitKSerial && params.grid_tiled_shape.k() > 1) {
         
       // For subsequent threadblocks, the source matrix is held in the 'D' tensor.
       if (threadblock_tile_offset.k()) {
         iterator_C = iterator_D;
       }
 
       semaphore.wait(threadblock_tile_offset.k());
 
       __threadfence();
     }
 
     // Execute the epilogue operator to update the destination tensor.
-    epilogue(
-      output_op, 
-      iterator_D, 
-      accumulators, 
-      iterator_C); 
+    epilogue(output_op, iterator_D, accumulators, iterator_C); 
     
     //
     // Release the semaphore
     //
 
-    if (params.mode == GemmUniversalMode::kGemm && params.grid_tiled_shape.k() > 1) { 
-
+    if (kSplitKSerial && params.grid_tiled_shape.k() > 1) {
+      
       int lock = 0;
       if (params.grid_tiled_shape.k() == threadblock_tile_offset.k() + 1) {
 
         // The final threadblock resets the semaphore for subsequent grids.
         lock = 0;
       }
       else {
         // Otherwise, the semaphore is incremented
         lock = threadblock_tile_offset.k() + 1;
       }
-      
+
+      __threadfence();
       semaphore.release(lock);
     }
   }
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 } // namespace kernel
 } // namespace gemm
 } // namespace cutlass
-
-/////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/sparse_gemm.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_planar_complex_testbed.h`

 * *Files 24% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -25,376 +25,328 @@
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /*! \file
-    \brief Template for a pipelined GEMM kernel. Does not compute batching or support split-K.
+    \brief Unit testbed for kernel-level GEMM
 */
 
 #pragma once
 
+#include <fstream>
+
+#include "../../common/cutlass_unit_test.h"
+
 #include "cutlass/cutlass.h"
+#include "cutlass/platform/platform.h"
 
+#include "cutlass/aligned_buffer.h"
 #include "cutlass/gemm/gemm.h"
-#include "cutlass/matrix_coord.h"
-#include "cutlass/semaphore.h"
+#include "cutlass/layout/matrix.h"
+#include "cutlass/layout/vector.h"
+#include "cutlass/numeric_types.h"
+
+#include "cutlass/core_io.h"
+#include "cutlass/util/host_tensor_planar_complex.h"
+#include "cutlass/util/tensor_view_io.h"
+
+#include "cutlass/util/distribution.h"
+#include "cutlass/util/reference/host/gemm_planar_complex.h"
+#include "cutlass/util/reference/host/tensor_compare.h"
+#include "cutlass/util/reference/host/tensor_fill.h"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-namespace cutlass {
+namespace test {
 namespace gemm {
-namespace kernel {
+namespace threadblock {
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-template <
-  typename Mma_,                  ///! Threadblock-scoped matrix multiply-accumulate 
-  typename Epilogue_,             ///! Epilogue
-  typename ThreadblockSwizzle_,   ///! Threadblock swizzling function
-  bool SplitKSerial               ///! If true, code supporting split-K via serial reduction is enabled.
->
-struct SparseGemm {
+template <typename Mma>
+__global__ void kernel_mma_planar_complex(
+  cutlass::gemm::GemmCoord problem_size,
+  typename Mma::IteratorA::Params params_A,
+  typename Mma::IteratorA::Element *ptr_A,
+  int64_t imaginary_stride_A,
+  typename Mma::IteratorB::Params params_B,
+  typename Mma::IteratorB::Element *ptr_B,
+  int64_t imaginary_stride_B,
+  typename Mma::ElementC *ptr_C, 
+  typename Mma::LayoutC::Stride::Index ldc, int64_t imaginary_stride_C) {
+
+  // Shared storage needed by threadblock-scoped matrix multiply-accumulate
+  __shared__ typename Mma::SharedStorage shared_storage;
+
+  // Compute threadblock location
+  cutlass::gemm::GemmCoord tb_tile_offset = {int(blockIdx.x), int(blockIdx.y),
+                                             0};
+
+  cutlass::MatrixCoord tb_offset_A{tb_tile_offset.m() * Mma::Shape::kM,
+                                   tb_tile_offset.k()};
+
+  cutlass::MatrixCoord tb_offset_B{tb_tile_offset.k(),
+                                   tb_tile_offset.n() * Mma::Shape::kN};
+
+  // Compute position within threadblock
+  int tb_thread_id = threadIdx.y * blockDim.x + threadIdx.x;
+
+  // Construct iterators to A operand
+  typename Mma::IteratorA iterator_A_real(params_A, ptr_A,
+                                     {problem_size.m(), problem_size.k()},
+                                     tb_thread_id, tb_offset_A);
+  
+  typename Mma::IteratorA iterator_A_imag(params_A, ptr_A + imaginary_stride_A,
+                                     {problem_size.m(), problem_size.k()},
+                                     tb_thread_id, tb_offset_A);
+  
+  // Construct iterators to B operand
+  typename Mma::IteratorB iterator_B_real(params_B, ptr_B,
+                                     {problem_size.k(), problem_size.n()},
+                                     tb_thread_id, tb_offset_B);
+
+  typename Mma::IteratorB iterator_B_imag(params_B, ptr_B + imaginary_stride_B,
+                                     {problem_size.k(), problem_size.n()},
+                                     tb_thread_id, tb_offset_B);
+
+  int warp_id = threadIdx.y;
+  int lane_id = threadIdx.x;
+
+  // Construct thread-scoped matrix multiply
+  Mma mma(shared_storage, tb_thread_id, warp_id, threadIdx.x);
+
+  typename Mma::FragmentC accum;
+
+  accum.clear();
+
+  int gemm_k_iterations = (problem_size.k() + Mma::Shape::kK - 1) / Mma::Shape::kK;
+
+  // Compute threadblock-scoped matrix multiply-add
+  mma(gemm_k_iterations, accum, iterator_A_real, iterator_A_imag, iterator_B_real, iterator_B_imag, accum);
+
+  // Output results
+  typename Mma::Operator::IteratorC iterator_C({ptr_C, ldc}, lane_id);
+
+  iterator_C.add_tile_offset(
+      {(tb_tile_offset.m() * Mma::WarpCount::kM) +
+           (warp_id % Mma::WarpCount::kM),
+       (tb_tile_offset.n() * Mma::WarpCount::kN) +
+           (warp_id / Mma::WarpCount::kM)});
 
-  using Mma = Mma_;
-  using Epilogue = Epilogue_;
-  using OutputOp = typename Epilogue::OutputOp;
-  using ThreadblockSwizzle = ThreadblockSwizzle_;
-  static bool const kSplitKSerial = SplitKSerial;
-
-  static int const kSparse = Mma::kSparse;
-  static int const kMetaSizeInBits = Mma::kMetaSizeInBits;
-  static int const kMaxID2 = Mma::kMaxID2;
-  static int const kElementsPerElementE = Mma::kElementsPerElementE;
-
-  using ElementE = typename Mma::ElementE;
-  using LayoutE = typename Mma::LayoutE;
-
-  /// Warp count (concept: GemmShape)
-  using WarpCount = typename Mma::WarpCount;
-  static int const kThreadCount = 32 * WarpCount::kCount;
-
-  /// Parameters structure
-  struct Params {
-    cutlass::gemm::GemmCoord problem_size;
-    cutlass::gemm::GemmCoord grid_tiled_shape;
-    int swizzle_log_tile;
-    typename Mma::IteratorA::Params params_A;
-    typename Mma::IteratorA::TensorRef ref_A;
-    typename Mma::IteratorB::Params params_B;
-    typename Mma::IteratorB::TensorRef ref_B;
-    typename Epilogue::OutputTileIterator::Params params_C;
-    typename Epilogue::OutputTileIterator::TensorRef ref_C;
-    typename Epilogue::OutputTileIterator::Params params_D;
-    typename Epilogue::OutputTileIterator::TensorRef ref_D;
-    typename Mma::IteratorE::Params params_E;
-    typename Mma::IteratorE::TensorRef ref_E;
-    typename OutputOp::Params output_op;
-    int *semaphore;
-    int gemm_k_iterations;
-    int gemm_k_size;
+  iterator_C.store(accum.real);
 
-    //
-    // Methods
-    //
-
-    CUTLASS_HOST_DEVICE
-    Params(): swizzle_log_tile(0), semaphore(0), gemm_k_iterations(0), gemm_k_size(0) { }
+  iterator_C.store_with_pointer_offset(accum.imag, imaginary_stride_C);
+}
 
-    CUTLASS_HOST_DEVICE
-    Params(
-      cutlass::gemm::GemmCoord const & problem_size,
-      cutlass::gemm::GemmCoord const & grid_tiled_shape,
-      typename Mma::IteratorA::TensorRef ref_A,
-      typename Mma::IteratorB::TensorRef ref_B,
-      typename Epilogue::OutputTileIterator::TensorRef ref_C,
-      typename Epilogue::OutputTileIterator::TensorRef ref_D,
-      typename Mma::IteratorE::TensorRef ref_E,
-      typename OutputOp::Params output_op = typename OutputOp::Params(),
-      int *workspace = nullptr
-    ):
-      problem_size(problem_size),
-      grid_tiled_shape(grid_tiled_shape),
-      swizzle_log_tile(ThreadblockSwizzle().get_log_tile(grid_tiled_shape)),
-      params_A(ref_A.layout()),
-      ref_A(ref_A),
-      params_B(ref_B.layout()),
-      ref_B(ref_B),
-      params_C(ref_C.layout()),
-      ref_C(ref_C),
-      params_D(ref_D.layout()),
-      ref_D(ref_D),
-      params_E(ref_E.layout()),
-      ref_E(ref_E),
-      output_op(output_op) {
-
-      int total_gemm_k_iterations = (problem_size.k() + Mma::Shape::kK - 1) / Mma::Shape::kK;
-      int gemm_k_iterations = (total_gemm_k_iterations + grid_tiled_shape.k() - 1) / grid_tiled_shape.k();
-      
-      gemm_k_size = gemm_k_iterations * Mma::Shape::kK;
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
-    semaphore = workspace;
-    }
-  };
+/// Structure to compute the matrix product
+template <
+    /// Threadblock-level matrix multiply-accumulate
+    typename Mma_>
+struct TestbedPlanarComplex {
 
-  /// Shared memory storage structure
-  union SharedStorage {
-    typename Mma::SharedStorage main_loop;
-    typename Epilogue::SharedStorage epilogue;
-  };
+  using Mma = Mma_;
+  using ThreadblockShape = typename Mma::Shape;
+  using IteratorA = typename Mma::IteratorA;
+  using ElementA = typename Mma::IteratorA::Element;
+  using LayoutA = typename Mma::IteratorA::Layout;
+  using IteratorB = typename Mma::IteratorB;
+  using ElementB = typename Mma::IteratorB::Element;
+  using LayoutB = typename Mma::IteratorB::Layout;
+  using ElementC = typename Mma::ElementC;
+  using ElementAccumulator = typename Mma::ElementC;
+  using LayoutC = typename Mma::LayoutC;
+  using ThreadMapA = typename Mma::IteratorA::ThreadMap;
+  using ThreadMapB = typename Mma::IteratorB::ThreadMap;
+  using AccessTypeA = cutlass::Array<ElementA, ThreadMapA::kElementsPerAccess>;
+  using AccessTypeB = cutlass::Array<ElementB, ThreadMapB::kElementsPerAccess>;
+  static int const Stages = Mma::kStages;
+  static cutlass::arch::CacheOperation::Kind const CacheOpA =
+      Mma::kCacheOpA;
+  static cutlass::arch::CacheOperation::Kind const CacheOpB =
+      Mma::kCacheOpB;
 
   //
-  // Methods
+  // Data members
   //
 
-  CUTLASS_HOST_DEVICE
-  SparseGemm() { } 
+  cutlass::HostTensorPlanarComplex<ElementA, LayoutA> matrix_A;
+  cutlass::HostTensorPlanarComplex<ElementB, LayoutB> matrix_B;
+  cutlass::HostTensorPlanarComplex<ElementC, LayoutC> matrix_C_computed;
+  cutlass::HostTensorPlanarComplex<ElementC, LayoutC> matrix_C_reference;
 
-  /// Determines whether kernel satisfies alignment
-  static Status can_implement(
-      cutlass::gemm::GemmCoord const & problem_size,
-      typename Mma::IteratorA::TensorRef ref_A,
-      typename Mma::IteratorB::TensorRef ref_B,
-      typename Epilogue::OutputTileIterator::TensorRef ref_C,
-      typename Epilogue::OutputTileIterator::TensorRef ref_D,
-      typename Mma::IteratorE::TensorRef ref_E) {
-
-    static int const kAlignmentA = Mma::IteratorA::AccessType::kElements;
-    static int const kAlignmentB = Mma::IteratorB::AccessType::kElements;
-    static int const kAlignmentC = Epilogue::OutputTileIterator::kElementsPerAccess;
-    static int const kAlignmentE = Mma::IteratorE::AccessType::kElements;
-
-    if (!TensorRef_aligned(ref_A, kAlignmentA)) {
-      return Status::kErrorMisalignedOperand;
-    }
-
-    if (!TensorRef_aligned(ref_B, kAlignmentB)) {
-      return Status::kErrorMisalignedOperand;
-    }
+  cutlass::gemm::GemmCoord problem_size;
 
-    if (!TensorRef_aligned(ref_C, kAlignmentC)) {
-      return Status::kErrorMisalignedOperand;
-    }
-
-    if (!TensorRef_aligned(ref_D, kAlignmentC)) {
-      return Status::kErrorMisalignedOperand;
-    }
+  //
+  // Methods
+  //
 
-    if (!TensorRef_aligned(ref_E, kAlignmentE)) {
-      return Status::kErrorMisalignedOperand;
-    }
+  /// Allocates workspace in device memory
+  TestbedPlanarComplex(int m, int n, int k)
+      : problem_size(m, n, k) {
+
+    matrix_A.reset(cutlass::make_Coord(m, k));
+    matrix_B.reset(cutlass::make_Coord(k, n));
+    matrix_C_computed.reset(cutlass::make_Coord(m, n));
+    matrix_C_reference.reset(cutlass::make_Coord(m, n), false);
+  }
 
-    if ((problem_size.m() % kAlignmentA) || ((problem_size.k() / kSparse) % kAlignmentA) ||
-      (problem_size.n() % kAlignmentB) || (problem_size.k() % kAlignmentB) ||
-      (problem_size.m() % kAlignmentC) || (problem_size.n() % kAlignmentC) ||
-      (problem_size.m() % kAlignmentE) || ((problem_size.k() / kSparse) % kAlignmentE)) {
+  /// Runs the test
+  bool run(
+      dim3 grid, dim3 block,
+      cutlass::Distribution::Kind init_A = cutlass::Distribution::Uniform,
+      cutlass::Distribution::Kind init_B = cutlass::Distribution::Uniform) {
 
-      return Status::kErrorMisalignedOperand;
-    }
+    //
+    // initialize device memory
+    //
 
-    // The k dimension has to be the multiple of the Threadblock k because out
-    // of bound meta data would be initialized to 0 by acync.zfill but 0 is not
-    // a valid meta data.
-    if (problem_size.k() % Mma::Shape::kK) {
-      return Status::kErrorMisalignedOperand;
-    }
+    if (init_A == cutlass::Distribution::Uniform) {
+      
+      int scope_max = 8;
+      int scope_min = -8;
 
-    // M dimension has to be multiple of 32 (sparse float) or 16 (sparse int) 
-    // because of the row reordering of operand E
-    static int const kAlignmentM = (sizeof(ElementE) == 2) ? 32 : 16;
+      if (cutlass::sizeof_bits<ElementA>::value == 4) {
+        scope_max = 2;
+        scope_min = -2;
+      } else if (cutlass::sizeof_bits<ElementA>::value == 1) {
+        scope_max = 2;
+        scope_min = 0;
+      }
 
-    if (problem_size.m() % kAlignmentM) {
-      return Status::kErrorMisalignedOperand;
+      uint64_t seed = 7;
+      cutlass::reference::host::TensorFillRandomUniform(
+          matrix_A.host_view(), seed, scope_max, scope_min, 0);
+      
+    } else if (init_A == cutlass::Distribution::Sequential) {
+      
+      for (int i = 0; i < matrix_A.capacity() * 2; ++i) {
+        matrix_A.host_data()[i] = cutlass::half_t(float(i % 5) - 2);
+      }
+      /*
+      cutlass::reference::host::BlockFillSequential(matrix_A.host_data(),
+                                                    matrix_A.capacity() * 2);
+      */
+    } else if (init_A == cutlass::Distribution::Identity) {
+      //cutlass::reference::host::TensorFillIdentity(matrix_A.host_view());
+    } else {
+      // TODO: Implement the rest
+      return false;
     }
 
-    return Status::kSuccess;
-  }
-
-  /// Executes one GEMM
-  CUTLASS_DEVICE
-  void operator()(Params const &params, SharedStorage &shared_storage) {
-
-    // Compute threadblock location
-    ThreadblockSwizzle threadblock_swizzle;
+    if (init_B == cutlass::Distribution::Uniform) {
 
-    cutlass::gemm::GemmCoord threadblock_tile_offset =
-        threadblock_swizzle.get_tile_offset(params.swizzle_log_tile);
+      
+      int scope_max = 8;
+      int scope_min = -8;
 
-    // Early exit if CTA is out of range
-    if (params.grid_tiled_shape.m() <= threadblock_tile_offset.m() ||
-      params.grid_tiled_shape.n() <= threadblock_tile_offset.n()) {
+      if (cutlass::sizeof_bits<ElementB>::value == 4) {
+        scope_max = 2;
+        scope_min = -2;
+      } else if (cutlass::sizeof_bits<ElementB>::value == 1) {
+        scope_max = 2;
+        scope_min = 0;
+      }
 
-      return;
-    }
+      uint64_t seed = 7;
+      cutlass::reference::host::TensorFillRandomUniform(
+          matrix_B.host_view(), seed + 16, scope_max, scope_min, 0);
+      
 
-    // Compute initial location in logical coordinates
-    cutlass::MatrixCoord tb_offset_A{
-      threadblock_tile_offset.m() * Mma::Shape::kM,
-      threadblock_tile_offset.k() * params.gemm_k_size / kSparse,
-    };
-
-    cutlass::MatrixCoord tb_offset_B{
-      threadblock_tile_offset.k() * params.gemm_k_size,
-      threadblock_tile_offset.n() * Mma::Shape::kN
-    };
-
-    cutlass::MatrixCoord tb_offset_E{
-      threadblock_tile_offset.m() * Mma::Shape::kM,
-      threadblock_tile_offset.k() * params.gemm_k_size / kSparse,
-    };
-
-    // Problem size is a function of threadblock index in the K dimension
-    int problem_size_k = min(
-      params.problem_size.k(), 
-      (threadblock_tile_offset.k() + 1) * params.gemm_k_size);
-
-    // Compute threadblock-scoped matrix multiply-add
-    int gemm_k_iterations = (problem_size_k - tb_offset_B.row() + Mma::Shape::kK - 1) / Mma::Shape::kK;
-
-    // Compute position within threadblock
-    int thread_idx = threadIdx.x;
-
-    // Construct iterators to A, B, and E operands
-    typename Mma::IteratorA iterator_A(
-      params.params_A,
-      params.ref_A.data(),
-      {params.problem_size.m(), problem_size_k / kSparse},
-      thread_idx,
-      tb_offset_A);
-
-    typename Mma::IteratorB iterator_B(
-      params.params_B,
-      params.ref_B.data(),
-      {problem_size_k, params.problem_size.n()},
-      thread_idx,
-      tb_offset_B);
-
-    typename Mma::IteratorE iterator_E(
-        params.params_E, params.ref_E.data(),
-        {params.problem_size.m(),
-         problem_size_k / kSparse / kElementsPerElementE},
-        thread_idx, tb_offset_E);
-
-    // Broadcast the warp_id computed by lane 0 to ensure dependent code
-    // is compiled as warp-uniform.
-    int warp_idx = __shfl_sync(0xffffffff, threadIdx.x / 32, 0);
-    int lane_idx = threadIdx.x % 32;
+    } else if (init_B == cutlass::Distribution::Sequential) {
 
-    //
-    // Main loop
-    //
+      cutlass::reference::host::BlockFillSequential(matrix_B.host_data(),
+                                                    matrix_B.capacity() * 2);
 
-    // Construct thread-scoped matrix multiply
-    Mma mma(shared_storage.main_loop, thread_idx, warp_idx, lane_idx);
+      for (int i = 0; i < matrix_B.capacity() * 2; ++i) {
+        matrix_B.host_data()[i] = cutlass::half_t(float((i + 3) % 5) - 2);
+      }
 
-    typename Mma::FragmentC accumulators;
 
-    accumulators.clear();
+    } else if (init_B == cutlass::Distribution::Identity) {
 
-    if (!kSplitKSerial || gemm_k_iterations > 0) {
-      // Compute threadblock-scoped matrix multiply-add
-      mma(gemm_k_iterations, accumulators, iterator_A, iterator_B, iterator_E, accumulators);
-    }
+      //cutlass::reference::host::TensorFillIdentity(matrix_B.host_view());
 
-    //
-    // Epilogue
-    //
+    } else {
+      // TODO: Implement the rest
+      return false;
+    }
+
+    matrix_A.sync_device();
+    matrix_B.sync_device();
+    matrix_C_computed.sync_device();
+
+    typename IteratorA::Params params_A(matrix_A.layout());
+    typename IteratorB::Params params_B(matrix_B.layout());
+
+    test::gemm::threadblock::kernel_mma_planar_complex<Mma><<<grid, block>>>(
+        problem_size, 
+        params_A, 
+        matrix_A.device_data(),
+        matrix_A.imaginary_stride(),
+        params_B,
+        matrix_B.device_data(), 
+        matrix_B.imaginary_stride(),
+        matrix_C_computed.device_data(),
+        matrix_C_computed.layout().stride(0), 
+        matrix_C_computed.imaginary_stride()
+      );
 
-    OutputOp output_op(params.output_op);
 
     //
-    // Masked tile iterators constructed from members
+    // Check error code
     //
 
-    threadblock_tile_offset =
-        threadblock_swizzle.get_tile_offset(params.swizzle_log_tile);
-
-    //assume identity swizzle
-    MatrixCoord threadblock_offset(
-      threadblock_tile_offset.m() * Mma::Shape::kM,
-      threadblock_tile_offset.n() * Mma::Shape::kN
+    cudaError_t result = cudaDeviceSynchronize();
+    EXPECT_EQ(result, cudaSuccess)
+        << " kernel error: " << cudaGetErrorString(result);
+
+    matrix_C_computed.sync_host();
+
+    cutlass::reference::host::GemmPlanarComplex<
+      ElementA, LayoutA,
+      ElementB, LayoutB,
+      ElementC, LayoutC,
+      ElementAccumulator
+    >(
+      problem_size,
+      cutlass::complex<ElementAccumulator>(ElementAccumulator(1)),
+      matrix_A.host_ref(),
+      Mma::kTransformA,
+      matrix_B.host_ref(),
+      Mma::kTransformB,
+      cutlass::complex<ElementAccumulator>(ElementAccumulator(0)),
+      matrix_C_reference.host_ref(),
+      matrix_C_reference.host_ref()
     );
-
-    int block_idx = threadblock_tile_offset.m() + threadblock_tile_offset.n() * params.grid_tiled_shape.m();
-
-    // Construct the semaphore.
-    Semaphore semaphore(params.semaphore + block_idx, thread_idx);
-
-    // If performing a reduction via split-K, fetch the initial synchronization
-    if (kSplitKSerial && params.grid_tiled_shape.k() > 1) {
-      
-      // Fetch the synchronization lock initially but do not block.
-      semaphore.fetch();
-
-      // Indicate which position in a serial reduction the output operator is currently updating
-      output_op.set_k_partition(threadblock_tile_offset.k(), params.grid_tiled_shape.k());
-    }
-
-    // Tile iterator loading from source tensor.
-    typename Epilogue::OutputTileIterator iterator_C(
-      params.params_C,
-      params.ref_C.data(),
-      params.problem_size.mn(),
-      thread_idx,
-      threadblock_offset
-    );
-
-    // Tile iterator writing to destination tensor.
-    typename Epilogue::OutputTileIterator iterator_D(
-      params.params_D,
-      params.ref_D.data(),
-      params.problem_size.mn(),
-      thread_idx,
-      threadblock_offset
+    
+    bool passed = cutlass::reference::host::TensorEquals(
+      matrix_C_computed.host_view(), 
+      matrix_C_reference.host_view()
     );
 
-    Epilogue epilogue(
-      shared_storage.epilogue, 
-      thread_idx, 
-      warp_idx, 
-      lane_idx);
-
-    // Wait on the semaphore - this latency may have been covered by iterator construction
-    if (kSplitKSerial && params.grid_tiled_shape.k() > 1) {
-        
-      // For subsequent threadblocks, the source matrix is held in the 'D' tensor.
-      if (threadblock_tile_offset.k()) {
-        iterator_C = iterator_D;
-      }
+    EXPECT_TRUE(passed);
 
-      semaphore.wait(threadblock_tile_offset.k());
+    if (!passed) {
+      std::ofstream output("mma_pipelined_testbed_errors.txt");
 
-      __threadfence();
+      output
+        << "A:\n" << matrix_A.host_view() << "\n"
+        << "B:\n" << matrix_B.host_view() << "\n"
+        << "Reference:\n"
+        << matrix_C_reference.host_view() << "\n"
+        << "Computed:\n"
+        << matrix_C_computed.host_view() << "\n";
     }
 
-    // Execute the epilogue operator to update the destination tensor.
-    epilogue(output_op, iterator_D, accumulators, iterator_C); 
-    
-    //
-    // Release the semaphore
-    //
-
-    if (kSplitKSerial && params.grid_tiled_shape.k() > 1) {
-      
-      int lock = 0;
-      if (params.grid_tiled_shape.k() == threadblock_tile_offset.k() + 1) {
-
-        // The final threadblock resets the semaphore for subsequent grids.
-        lock = 0;
-      }
-      else {
-        // Otherwise, the semaphore is incremented
-        lock = threadblock_tile_offset.k() + 1;
-      }
-
-      __threadfence();
-      semaphore.release(lock);
-    }
+    return passed;
   }
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-} // namespace kernel
-} // namespace gemm
-} // namespace cutlass
+}  // namespace threadblock
+}  // namespace gemm
+}  // namespace test
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/symm_universal.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/symm_universal.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -411,15 +411,15 @@
     };
 
     // Compute position within threadblock
     int thread_idx = threadIdx.x;
 
     // Broadcast the warp_id computed by lane 0 to ensure dependent code
     // is compiled as warp-uniform.
-    int warp_idx = __shfl_sync(0xffffffff, threadIdx.x / 32, 0);
+    int warp_idx = canonical_warp_idx();
 
     int lane_idx = threadIdx.x % 32;
 
     //
     // Main loop
     //
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/trmm_universal.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/kernel/trmm_universal.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -376,15 +376,15 @@
     };
 
     // Compute position within threadblock
     int thread_idx = threadIdx.x;
 
     // Broadcast the warp_id computed by lane 0 to ensure dependent code
     // is compiled as warp-uniform.
-    int warp_idx = __shfl_sync(0xffffffff, threadIdx.x / 32, 0);
+    int warp_idx = canonical_warp_idx();
 
     int lane_idx = threadIdx.x % 32;
 
     //
     // Main loop
     //
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/thread/mma.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/thread/mma.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/thread/mma_sm50.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/thread/mma_sm50.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/thread/mma_sm60.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/thread/mma_sm60.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/thread/mma_sm61.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/thread/mma_sm61.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_ell_mma.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_ell_mma.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_gemv_core.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_gemv_core.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_core.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_core.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_core_simt.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_core_simt.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sm70.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sm70.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sm75.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sm75.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sm80.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sm80.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sparse_sm80.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_core_sparse_sm80.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_core_with_access_size.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_core_with_access_size.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_core_with_reduction.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_core_with_reduction.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_core_wmma.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_core_wmma.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_layernorm_mainloop_fusion.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_layernorm_mainloop_fusion.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_planar_complex_multistage.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_planar_complex_multistage.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_planar_complex_pipelined.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_planar_complex_pipelined.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_softmax_mainloop_fusion.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_softmax_mainloop_fusion.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_mma_with_reduction.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_multistage_mma_complex.h`

 * *Files 15% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -24,118 +24,136 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
+
 /*! \file
-    \brief Template for a pipelined GEMM kernel. Does not compute batching or support split-K.
+    \brief Template for a multistage GEMM kernel. Does not compute batching or support split-K.
 */
 
 #pragma once
 
+#include "cutlass/arch/arch.h"
 #include "cutlass/cutlass.h"
+#include "cutlass/gemm/threadblock/default_mma_core_sm80.h"
 #include "cutlass/numeric_types.h"
-#include "cutlass/arch/arch.h"
-
-#include "cutlass/layout/matrix.h"
 #include "cutlass/transform/threadblock/predicated_tile_iterator.h"
-#include "cutlass/transform/threadblock/predicated_tile_iterator_2dthreadtile.h"
-#include "cutlass/gemm/threadblock/default_mma_core_with_reduction.h"
+#include "cutlass/gemm/threadblock/default_multistage_mma_complex_core_sm80.h"
 
 ////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace gemm {
 namespace threadblock {
 
 ////////////////////////////////////////////////////////////////////////////////
 
 template <
     /// Element type for A matrix operand
+    typename ElementA_,
+    /// Layout type for A matrix operand
+    typename LayoutA_,
+    /// Element type for B matrix operand
+    typename ElementB_,
+    /// Layout type for B matrix operand
+    typename LayoutB_,
+    /// Element type for internal accumulation
+    typename ElementAccumulator_,
+    /// Layout type for C and D matrix operands
+    typename LayoutC_,
+    /// Operator class tag
+    typename OperatorClass_,
+    /// Tag indicating architecture to tune for
+    typename ArchTag_,
+    /// Threadblock-level tile size (concept: GemmShape)
+    typename ThreadblockShape_,
+    /// Warp-level tile size (concept: GemmShape)
+    typename WarpShape_,
+    /// Instruction-level tile size (concept: GemmShape)
+    typename InstructionShape_,
+    /// Number of stages used in the pipelined mainloop
+    int Stages,
+    /// Complex transformation on operand A
+    ComplexTransform TransformA = ComplexTransform::kNone,
+    /// Complex transformation on operand B
+    ComplexTransform TransformB = ComplexTransform::kNone,
+    /// Multiply-add operator (arch::OpMultiplyAddComplex, arch::OpMultiplyGaussianComplex)
+    typename Operator = arch::OpMultiplyAddComplex,
+    /// Store the accumulators in row major or column major.  Row major is used
+    /// when output layout is interleaved.
+    bool AccumulatorsInRowMajor = false>
+struct DefaultMultistageMmaComplex;
+
+////////////////////////////////////////////////////////////////////////////////
+
+/// Specialization for row-major output
+template <
+    /// Element type for A matrix operand
     typename ElementA,
     /// Layout type for A matrix operand
     typename LayoutA,
-    /// Access granularity of A matrix in units of elements
-    int kAlignmentA,
     /// Element type for B matrix operand
     typename ElementB,
     /// Layout type for B matrix operand
     typename LayoutB,
-    /// Access granularity of B matrix in units of elements
-    int kAlignmentB,
     /// Element type for internal accumulation
     typename ElementAccumulator,
-    /// Layout type for C and D matrix operands
-    typename LayoutC,
-    /// Operator class tag
+    /// Tag indicating architecture to tune for
     typename OperatorClass,
-    ///                                                                                               
-    bool ReduceKForA_,
     /// Tag indicating architecture to tune for
     typename ArchTag,
     /// Threadblock-level tile size (concept: GemmShape)
     typename ThreadblockShape,
     /// Warp-level tile size (concept: GemmShape)
     typename WarpShape,
     /// Instruction-level tile size (concept: GemmShape)
     typename InstructionShape,
-    /// Number of stages used in the pipelined mainloop
+    /// Number of stages used in the multistage mainloop
     int Stages,
-    /// Operation perfomed by GEMM
-    typename Operator,
-    /// Store the accumulators in row major or column major.  Row major is used
-    /// when output layout is interleaved.
-    bool AccumulatorsInRowMajor = false,
-    /// Use zfill or predicate for SM80 out-of-bound cp.async 
-    SharedMemoryClearOption SharedMemoryClear = SharedMemoryClearOption::kNone
-    >
-struct DefaultMmaWithReduction {
-
-  static cutlass::arch::CacheOperation::Kind const CacheOpA =
-      ((sizeof_bits<ElementA>::value * kAlignmentA) == 128)
-          ? cutlass::arch::CacheOperation::Global
-          : cutlass::arch::CacheOperation::Always;
-
-  static cutlass::arch::CacheOperation::Kind const CacheOpB =
-      ((sizeof_bits<ElementB>::value * kAlignmentB) == 128)
-          ? cutlass::arch::CacheOperation::Global
-          : cutlass::arch::CacheOperation::Always;
-
+    /// Complex transformation on operand A
+    ComplexTransform TransformA,
+    /// Complex transformation on operand B
+    ComplexTransform TransformB,
+    /// Multiply-add operator (arch::OpMultiplyAddComplex, arch::OpMultiplyGaussianComplex)
+    typename Operator>
+struct DefaultMultistageMmaComplex<ElementA, LayoutA, ElementB, LayoutB,
+                            ElementAccumulator, layout::RowMajor, OperatorClass,
+                            ArchTag, ThreadblockShape, WarpShape,
+                            InstructionShape, Stages, TransformA, TransformB, Operator> {
   // Define the MmaCore components
-  using MmaCore = typename cutlass::gemm::threadblock::DefaultMmaWithReductionCore<
-      ThreadblockShape, WarpShape, InstructionShape, ElementA, LayoutA,
-      ElementB, LayoutB, ElementAccumulator, layout::RowMajor, arch::OpClassTensorOp,
-      ReduceKForA_,  Stages, Operator, false, CacheOpA, CacheOpB>;
+  using MmaCore = typename cutlass::gemm::threadblock::DefaultMultistageMmaComplexCore<
+      ThreadblockShape, WarpShape, InstructionShape, ElementA, LayoutA, 
+      ElementB, LayoutB, ElementAccumulator, layout::RowMajor, OperatorClass,
+      Stages, TransformA, TransformB, Operator>;
 
   // Define iterators over tiles from the A operand
   using ThreadMapA = typename MmaCore::IteratorThreadMapA;
-  using AccessTypeA = cutlass::Array<ElementA, kAlignmentA>;
+  using AccessTypeA = cutlass::Array<ElementA, ThreadMapA::kElementsPerAccess>;
   using IteratorA =
       cutlass::transform::threadblock::PredicatedTileAccessIterator<
           cutlass::MatrixShape<ThreadblockShape::kM, ThreadblockShape::kK>,
           ElementA, LayoutA, 1, ThreadMapA, AccessTypeA>;
 
   // Define iterators over tiles from the B operand
   using ThreadMapB = typename MmaCore::IteratorThreadMapB;
-  using AccessTypeB = cutlass::Array<ElementB, kAlignmentB>;
+  using AccessTypeB = cutlass::Array<ElementB, ThreadMapB::kElementsPerAccess>;
   using IteratorB =
       cutlass::transform::threadblock::PredicatedTileAccessIterator<
           cutlass::MatrixShape<ThreadblockShape::kK, ThreadblockShape::kN>,
           ElementB, LayoutB, 0, ThreadMapB, AccessTypeB>;
 
   // Define the threadblock-scoped multistage matrix multiply
-  using ThreadblockMma = cutlass::gemm::threadblock::MmaWithReductionMultistage<
+  using ThreadblockMma = cutlass::gemm::threadblock::MmaMultistage<
       typename MmaCore::Shape, IteratorA, typename MmaCore::SmemIteratorA,
       MmaCore::kCacheOpA, IteratorB, typename MmaCore::SmemIteratorB,
       MmaCore::kCacheOpB, ElementAccumulator, layout::RowMajor,
-      typename MmaCore::MmaPolicy, Stages, SharedMemoryClear>;
+      typename MmaCore::MmaPolicy, Stages>;
 };
 
-////////////////////////////////////////////////////////////////////////////////
-
-} // namespace threadblock
-} // namespace gemm
-} // namespace cutlass 
+}  // namespace threadblock
+}  // namespace gemm
+}  // namespace cutlass
 
 ////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_multistage_mma_complex.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/gemm/find_default_mma.h`

 * *Files 23% similar despite different names*

```diff
@@ -1,22 +1,22 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
  *
  * 2. Redistributions in binary form must reproduce the above copyright notice,
  * this list of conditions and the following disclaimer in the documentation
  * and/or other materials provided with the distribution.
  *
- * 3. Neither the name of the copyright holder nor the names of its
+ * 3. Neither the name of the copyright holdvr nor the names of its
  * contributors may be used to endorse or promote products derived from
  * this software without specific prior written permission.
  *
  * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
  * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
  * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
@@ -26,134 +26,166 @@
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 
 /*! \file
-    \brief Template for a multistage GEMM kernel. Does not compute batching or support split-K.
+    \brief Cutlass provides helper template functions to figure out the right
+   datastructures to instanciate to run a GEMM with various parameters (see
+   `cutlass/gemm/threadblock/default_mma.h`). However, due to template
+   instantiation priority rules, it will only create an MmaMultiStage with
+   kStages=3 (otherwise creates an MmePipelined - which is not compatible with
+   FastF32). kStages=3 uses too much shared memory and we want to use kStages=2,
+   so we just copy-pasted some code from `default_mma.h` and
+   `default_mma_core.h` files and wrapped this template to allow our usecase.
+
+    This is really only for the FastF32 case - aka using TensorCores with fp32.
 */
 
 #pragma once
 
-#include "cutlass/arch/arch.h"
-#include "cutlass/cutlass.h"
+#include "cutlass/gemm/threadblock/default_mma.h"
+#include "cutlass/gemm/threadblock/default_mma_core_simt.h"
+#include "cutlass/gemm/threadblock/default_mma_core_sm70.h"
+#include "cutlass/gemm/threadblock/default_mma_core_sm75.h"
 #include "cutlass/gemm/threadblock/default_mma_core_sm80.h"
-#include "cutlass/numeric_types.h"
-#include "cutlass/transform/threadblock/predicated_tile_iterator.h"
-#include "cutlass/gemm/threadblock/default_multistage_mma_complex_core_sm80.h"
-
-////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace gemm {
 namespace threadblock {
 
-////////////////////////////////////////////////////////////////////////////////
-
 template <
     /// Element type for A matrix operand
-    typename ElementA_,
+    typename ElementA,
     /// Layout type for A matrix operand
-    typename LayoutA_,
+    typename LayoutA,
+    /// Access granularity of A matrix in units of elements
+    int kAlignmentA,
     /// Element type for B matrix operand
-    typename ElementB_,
+    typename ElementB,
     /// Layout type for B matrix operand
-    typename LayoutB_,
+    typename LayoutB,
+    /// Access granularity of B matrix in units of elements
+    int kAlignmentB,
     /// Element type for internal accumulation
-    typename ElementAccumulator_,
-    /// Layout type for C and D matrix operands
-    typename LayoutC_,
+    typename ElementAccumulator,
+    /// Layout type for C and D matrix operand
+    typename LayoutC,
     /// Operator class tag
-    typename OperatorClass_,
+    typename OperatorClass,
     /// Tag indicating architecture to tune for
-    typename ArchTag_,
+    typename ArchTag,
     /// Threadblock-level tile size (concept: GemmShape)
-    typename ThreadblockShape_,
+    typename ThreadblockShape,
     /// Warp-level tile size (concept: GemmShape)
-    typename WarpShape_,
+    typename WarpShape,
     /// Instruction-level tile size (concept: GemmShape)
-    typename InstructionShape_,
+    typename InstructionShape,
     /// Number of stages used in the pipelined mainloop
     int Stages,
-    /// Complex transformation on operand A
-    ComplexTransform TransformA = ComplexTransform::kNone,
-    /// Complex transformation on operand B
-    ComplexTransform TransformB = ComplexTransform::kNone,
-    /// Multiply-add operator (arch::OpMultiplyAddComplex, arch::OpMultiplyGaussianComplex)
-    typename Operator = arch::OpMultiplyAddComplex,
-    /// Store the accumulators in row major or column major.  Row major is used
-    /// when output layout is interleaved.
-    bool AccumulatorsInRowMajor = false>
-struct DefaultMultistageMmaComplex;
-
-////////////////////////////////////////////////////////////////////////////////
+    /// Operation perfomed by GEMM
+    typename Operator,
+    typename Enable_ = void>
+struct FindDefaultMma {
+  static constexpr bool AccumulatorsInRowMajor = false;
+  static constexpr SharedMemoryClearOption SharedMemoryClear =
+      SharedMemoryClearOption::kNone;
+  using DefaultMma = cutlass::gemm::threadblock::DefaultMma<
+      ElementA,
+      LayoutA,
+      kAlignmentA,
+      ElementB,
+      LayoutB,
+      kAlignmentB,
+      ElementAccumulator,
+      LayoutC,
+      OperatorClass,
+      ArchTag,
+      ThreadblockShape,
+      WarpShape,
+      InstructionShape,
+      Stages,
+      Operator,
+      AccumulatorsInRowMajor,
+      SharedMemoryClear>;
+};
 
-/// Specialization for row-major output
+/// Specialization for sm80 / FastF32 / multistage with kStages=2
 template <
-    /// Element type for A matrix operand
-    typename ElementA,
+    typename ElementA_,
     /// Layout type for A matrix operand
-    typename LayoutA,
-    /// Element type for B matrix operand
-    typename ElementB,
+    typename LayoutA_,
+    /// Access granularity of A matrix in units of elements
+    int kAlignmentA,
+    typename ElementB_,
     /// Layout type for B matrix operand
-    typename LayoutB,
-    /// Element type for internal accumulation
+    typename LayoutB_,
+    /// Access granularity of B matrix in units of elements
+    int kAlignmentB,
     typename ElementAccumulator,
-    /// Tag indicating architecture to tune for
-    typename OperatorClass,
-    /// Tag indicating architecture to tune for
-    typename ArchTag,
     /// Threadblock-level tile size (concept: GemmShape)
     typename ThreadblockShape,
     /// Warp-level tile size (concept: GemmShape)
     typename WarpShape,
     /// Instruction-level tile size (concept: GemmShape)
     typename InstructionShape,
-    /// Number of stages used in the multistage mainloop
-    int Stages,
-    /// Complex transformation on operand A
-    ComplexTransform TransformA,
-    /// Complex transformation on operand B
-    ComplexTransform TransformB,
-    /// Multiply-add operator (arch::OpMultiplyAddComplex, arch::OpMultiplyGaussianComplex)
+    int kStages,
     typename Operator>
-struct DefaultMultistageMmaComplex<ElementA, LayoutA, ElementB, LayoutB,
-                            ElementAccumulator, layout::RowMajor, OperatorClass,
-                            ArchTag, ThreadblockShape, WarpShape,
-                            InstructionShape, Stages, TransformA, TransformB, Operator> {
-  // Define the MmaCore components
-  using MmaCore = typename cutlass::gemm::threadblock::DefaultMultistageMmaComplexCore<
-      ThreadblockShape, WarpShape, InstructionShape, ElementA, LayoutA, 
-      ElementB, LayoutB, ElementAccumulator, layout::RowMajor, OperatorClass,
-      Stages, TransformA, TransformB, Operator>;
-
-  // Define iterators over tiles from the A operand
-  using ThreadMapA = typename MmaCore::IteratorThreadMapA;
-  using AccessTypeA = cutlass::Array<ElementA, ThreadMapA::kElementsPerAccess>;
-  using IteratorA =
-      cutlass::transform::threadblock::PredicatedTileAccessIterator<
-          cutlass::MatrixShape<ThreadblockShape::kM, ThreadblockShape::kK>,
-          ElementA, LayoutA, 1, ThreadMapA, AccessTypeA>;
-
-  // Define iterators over tiles from the B operand
-  using ThreadMapB = typename MmaCore::IteratorThreadMapB;
-  using AccessTypeB = cutlass::Array<ElementB, ThreadMapB::kElementsPerAccess>;
-  using IteratorB =
-      cutlass::transform::threadblock::PredicatedTileAccessIterator<
-          cutlass::MatrixShape<ThreadblockShape::kK, ThreadblockShape::kN>,
-          ElementB, LayoutB, 0, ThreadMapB, AccessTypeB>;
-
-  // Define the threadblock-scoped multistage matrix multiply
-  using ThreadblockMma = cutlass::gemm::threadblock::MmaMultistage<
-      typename MmaCore::Shape, IteratorA, typename MmaCore::SmemIteratorA,
-      MmaCore::kCacheOpA, IteratorB, typename MmaCore::SmemIteratorB,
-      MmaCore::kCacheOpB, ElementAccumulator, layout::RowMajor,
-      typename MmaCore::MmaPolicy, Stages>;
+struct FindDefaultMma<
+    ElementA_,
+    LayoutA_,
+    kAlignmentA,
+    ElementB_,
+    LayoutB_,
+    kAlignmentB,
+    ElementAccumulator,
+    layout::RowMajor,
+    arch::OpClassTensorOp,
+    arch::Sm80,
+    ThreadblockShape,
+    WarpShape,
+    InstructionShape,
+    kStages,
+    Operator,
+    typename cutlass::platform::enable_if<(kAlignmentA > 1)>::type> {
+  using LayoutC = layout::RowMajor;
+  using OperatorClass = arch::OpClassTensorOp;
+  using ArchTag = arch::Sm80;
+
+  using DefaultMma_ = cutlass::gemm::threadblock::DefaultMma<
+      ElementA_,
+      LayoutA_,
+      kAlignmentA,
+      ElementB_,
+      LayoutB_,
+      kAlignmentB,
+      ElementAccumulator,
+      LayoutC,
+      OperatorClass,
+      ArchTag,
+      ThreadblockShape,
+      WarpShape,
+      InstructionShape,
+      3,
+      Operator>;
+  struct DefaultMma : DefaultMma_ {
+    using MmaCore_ = typename DefaultMma_::MmaCore;
+    // Define the threadblock-scoped multistage matrix multiply
+    using ThreadblockMma = cutlass::gemm::threadblock::MmaMultistage<
+        typename MmaCore_::Shape,
+        typename DefaultMma_::IteratorA,
+        typename MmaCore_::SmemIteratorA,
+        MmaCore_::kCacheOpA,
+        typename DefaultMma_::IteratorB,
+        typename MmaCore_::SmemIteratorB,
+        MmaCore_::kCacheOpB,
+        ElementAccumulator,
+        LayoutC,
+        typename MmaCore_::MmaPolicy,
+        kStages>;
+  };
 };
 
-}  // namespace threadblock
-}  // namespace gemm
-}  // namespace cutlass
-
-////////////////////////////////////////////////////////////////////////////////
+} // namespace threadblock
+} // namespace gemm
+} // namespace cutlass
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_multistage_mma_complex_core.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_multistage_mma_complex_core.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_multistage_mma_complex_core_sm80.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_multistage_mma_complex_core_sm80.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_multistage_trmm_complex.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_multistage_trmm_complex.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_sparse_mma.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_sparse_mma.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_trmm.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/default_trmm.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/ell_mma_multistage.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/ell_mma_multistage.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/ell_mma_pipelined.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/ell_mma_pipelined.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -267,15 +267,15 @@
       iterator_A.ell_add_mask(ell_iterator.get_blocksize());
     }
     else {
       iterator_B.ell_add_mask(ell_iterator.get_blocksize());
     }
 
     // Issue loads during the first warp-level matrix multiply-add *AFTER* issuing 
-    // shared memory loads (which have the tighest latency requirement).
+    // shared memory loads (which have the tightest latency requirement).
 
     //
     // Mainloop
     //
 
     // Note: The main loop does not support Base::kWarpGemmIterations == 2.
     CUTLASS_GEMM_LOOP
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/gemv.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/gemv.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/index_remat.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/index_remat.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_base.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_base.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_blas3_multistage.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_blas3_multistage.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -680,15 +680,15 @@
                           arch::OpMultiplyAddFastF32>::value
       || platform::is_same<typename Operator::MathOperator,
                            arch::OpMultiplyAddComplexFastF32>::value) {
       accum = plus_accum(accum, tmp_accum); 
     }
  
     if (SharedMemoryClear == SharedMemoryClearOption::kZfill) {
-      // commit and drain all pending and predicated LDGSTS pnz from the GEMM mainloop
+      // commit and drain all pending and predicated cp.async pnz from the GEMM mainloop
       cutlass::arch::cp_async_fence();
       cutlass::arch::cp_async_wait<0>();
       __syncthreads();
     }
 
   }
 };
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_layernorm_mainloop_fusion_multistage.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_layernorm_mainloop_fusion_multistage.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -843,15 +843,15 @@
               warp_loaded_frag_A_gamma_beta[(warp_mma_k + 1) % 2]);
         }
       }
 
     }
     
     if (SharedMemoryClear == SharedMemoryClearOption::kZfill) {
-      // commit and drain all pending and predicated LDGSTS pnz from the GEMM mainloop
+      // commit and drain all pending and predicated cp.async pnz from the GEMM mainloop
       cutlass::arch::cp_async_fence();
       cutlass::arch::cp_async_wait<0>();
       __syncthreads();
     }
 
   }
 };
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_multistage.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_multistage.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -659,15 +659,15 @@
     }
 
     if (Detail::kStagedAccumulation) {
       plus<FragmentC> plus_accum;
       accum = plus_accum(accum, pipe_state.tmp_accum_);
     }
 
-    // Optionally commit and drain all pending and predicated LDGSTS pnz from the GEMM mainloop
+    // Optionally commit and drain all pending and predicated cp.async pnz from the GEMM mainloop
     if (SharedMemoryClear == SharedMemoryClearOption::kZfill) {
       cutlass::arch::cp_async_fence();
       cutlass::arch::cp_async_wait<0>();
       __syncthreads();
     }
 
   }
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_pipelined.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_pipelined.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_planar_complex_base.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/45_dual_gemm/threadblock/dual_mma_base.h`

 * *Files 14% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -38,167 +38,191 @@
 #include "cutlass/arch/memory.h"
 #include "cutlass/array.h"
 #include "cutlass/cutlass.h"
 #include "cutlass/gemm/gemm.h"
 #include "cutlass/matrix_shape.h"
 #include "cutlass/numeric_types.h"
 
+#include "cutlass/gemm/threadblock/mma_base.h"
+
 ////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace gemm {
 namespace threadblock {
 
 ////////////////////////////////////////////////////////////////////////////////
 
 /// Structure to compute the matrix product targeting CUDA cores and SIMT math
 /// instructions.
 template <
     /// Size of the Gemm problem - concept: gemm::GemmShape<>
     typename Shape_,
     /// Policy describing tuning details (concept: MmaPolicy)
-    typename Policy_,
+    typename Policy0_,
+    /// B1-specific version of the policy (concept: MmaPolicy)
+    typename Policy1_,
     /// Number of stages,
     int Stages,
     /// Used for partial specialization
     typename Enable = bool>
-class MmaPlanarComplexBase {
+class DualMmaBase {
  public:
   ///< Size of the Gemm problem - concept: gemm::GemmShape<>
   using Shape = Shape_;
 
   ///< Policy describing tuning details
-  using Policy = Policy_;
+  using Policy0 = Policy0_;
+  using Policy1 = Policy1_;
 
   //
   // Dependent types
   //
 
   /// Warp-level Mma
-  using Operator = typename Policy::Operator;
+  using Operator0 = typename Policy0::Operator;
+  using Operator1 = typename Policy1::Operator;
 
   /// Shape describing the overall GEMM computed from shared memory
   /// by each warp.
-  using WarpGemm = typename Policy::Operator::Shape;
+  using WarpGemm = typename Policy0::Operator::Shape;
 
   /// Shape describing the number of warps filling the CTA
   using WarpCount = GemmShape<Shape::kM / WarpGemm::kM,
                               Shape::kN / WarpGemm::kN,
                               Shape::kK / WarpGemm::kK>;
 
   /// Number of warp-level GEMM oeprations
   static int const kWarpGemmIterations =
-      (WarpGemm::kK / Operator::Policy::MmaShape::kK);
+      (WarpGemm::kK / Operator0::Policy::MmaShape::kK);
 
   /// Number of stages
   static int const kStages = Stages;
 
   /// Tensor reference to the A operand
-  using TensorRefA = TensorRef<typename Operator::ElementA, typename Operator::LayoutA>;
+  using TensorRefA = TensorRef<typename Operator0::ElementA, typename Operator0::LayoutA>;
 
   /// Tensor reference to the B operand
-  using TensorRefB = TensorRef<typename Operator::ElementB, typename Operator::LayoutB>;
+  using TensorRefB0 = TensorRef<typename Operator0::ElementB, typename Operator0::LayoutB>;
+  using TensorRefB1 = TensorRef<typename Operator1::ElementB, typename Operator1::LayoutB>;
+
+  static_assert(kWarpGemmIterations > 1,
+                "The pipelined structure requires at least two warp-level "
+                "GEMM operations.");
+
+  static_assert((kWarpGemmIterations % 2) == 0,
+                "Inner loop iteration must be an even number.");
 
   //
   // Nested structs
   //
 
   /// Shared storage object needed by threadblock-scoped GEMM
   class SharedStorage {
    public:
     //
     // Type definitions
     //
 
     /// Shape of the A matrix operand in shared memory
-    using ShapeA = MatrixShape<Shape::kM + Policy::SmemPaddingA::kRow,
+    using ShapeA = MatrixShape<Shape::kM + Policy0::SmemPaddingA::kRow,
                                Shape::kK * kStages +
-                                   Policy::SmemPaddingA::kColumn>;
-
-    /// Stride to the imaginary part of the A operand
-    static int const kImaginaryStrideA = ShapeA::kCount;
+                                   Policy0::SmemPaddingA::kColumn>;
 
     /// Shape of the B matrix operand in shared memory
-    using ShapeB =
-        MatrixShape<Shape::kK * kStages + Policy::SmemPaddingB::kRow,
-                    Shape::kN + Policy::SmemPaddingB::kColumn>;
-
-    /// Stride to the imaginary part of the A operand
-    static int const kImaginaryStrideB = ShapeB::kCount;
+    using ShapeB0 =
+        MatrixShape<Shape::kK * kStages + Policy0::SmemPaddingB::kRow,
+                    Shape::kN + Policy0::SmemPaddingB::kColumn>;
+    using ShapeB1 =
+        MatrixShape<Shape::kK * kStages + Policy1::SmemPaddingB::kRow,
+                    Shape::kN + Policy1::SmemPaddingB::kColumn>;
 
    public:
     //
     // Data members
     //
 
     /// Buffer for A operand
-    AlignedBuffer<typename Operator::ElementA, ShapeA::kCount + kImaginaryStrideA> operand_A;
+    AlignedBuffer<typename Operator0::ElementA, ShapeA::kCount> operand_A;
 
     /// Buffer for B operand
-    AlignedBuffer<typename Operator::ElementB, ShapeB::kCount + kImaginaryStrideB> operand_B;
+    AlignedBuffer<typename Operator0::ElementB, ShapeB0::kCount> operand_B0;
+    AlignedBuffer<typename Operator1::ElementB, ShapeB1::kCount> operand_B1;
 
    public:
 
     //
     // Methods
     //
 
     /// Returns a layout object for the A matrix
     CUTLASS_DEVICE
-    static typename Operator::LayoutA LayoutA() {
-      return Operator::LayoutA::packed({ShapeA::kRow, ShapeA::kColumn});
+    static typename Operator0::LayoutA LayoutA() {
+      return Operator0::LayoutA::packed({ShapeA::kRow, ShapeA::kColumn});
     }
 
     /// Returns a layout object for the B matrix
     CUTLASS_HOST_DEVICE
-    static typename Operator::LayoutB LayoutB() {
-      return Operator::LayoutB::packed({ShapeB::kRow, ShapeB::kColumn});
+    static typename Operator0::LayoutB LayoutB0() {
+      return Operator0::LayoutB::packed({ShapeB0::kRow, ShapeB0::kColumn});
+    }
+
+    /// Returns a layout object for the B matrix
+    CUTLASS_HOST_DEVICE
+    static typename Operator1::LayoutB LayoutB1() {
+      return Operator1::LayoutB::packed({ShapeB1::kRow, ShapeB1::kColumn});
     }
 
     /// Returns a TensorRef to the A operand
     CUTLASS_HOST_DEVICE
     TensorRefA operand_A_ref() {
       return TensorRefA{operand_A.data(), LayoutA()};
     }
 
     /// Returns a TensorRef to the B operand
     CUTLASS_HOST_DEVICE
-    TensorRefB operand_B_ref() {
-      return TensorRefB{operand_B.data(), LayoutB()};
+    TensorRefB0 operand_B0_ref() {
+      return TensorRefB0{operand_B0.data(), LayoutB0()};
+    }
+    CUTLASS_HOST_DEVICE
+    TensorRefB1 operand_B1_ref() {
+      return TensorRefB1{operand_B1.data(), LayoutB1()};
     }
   };
 
  protected:
 
   //
   // Data members
   //
 
   /// Iterator to load a warp-scoped tile of A operand from shared memory
-  typename Operator::IteratorA warp_tile_iterator_A_;
+  typename Operator0::IteratorA warp_tile_iterator_A_;
 
   /// Iterator to load a warp-scoped tile of B operand from shared memory
-  typename Operator::IteratorB warp_tile_iterator_B_;
+  typename Operator0::IteratorB warp_tile_iterator_B0_;
+  typename Operator1::IteratorB warp_tile_iterator_B1_;
 
 public:
 
   /// Construct from tensor references
   CUTLASS_DEVICE
-  MmaPlanarComplexBase(
+  DualMmaBase(
       ///< Shared storage needed for internal use by threadblock-scoped GEMM
       SharedStorage &shared_storage,
       ///< ID within the threadblock
       int thread_idx,
       ///< ID of warp
       int warp_idx,
       ///< ID of each thread within a warp
       int lane_idx
     ):
       warp_tile_iterator_A_(shared_storage.operand_A_ref(), lane_idx),
-      warp_tile_iterator_B_(shared_storage.operand_B_ref(), lane_idx) {
+      warp_tile_iterator_B0_(shared_storage.operand_B0_ref(), lane_idx),
+      warp_tile_iterator_B1_(shared_storage.operand_B1_ref(), lane_idx) {
 
   }
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 }  // namespace threadblock
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_planar_complex_multistage.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_planar_complex_multistage.h`

 * *Files 6% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -146,32 +146,30 @@
   /// Internal structure exposed for introspection.
   struct Detail {
 
     static_assert(Base::kWarpGemmIterations > 1,
                   "The pipelined structure requires at least two warp-level "
                   "GEMM operations.");
 
-    /// Number of LDGSTS instructions to load one stage of operand A
-    static int const TBLDGSTSIterationsA =
+    /// Number of cp.async instructions to load one stage of operand A
+    static int const TBLoadIterationsA =
         IteratorA::ThreadMap::Iterations::kCount;
 
-    /// Number of LDGSTS instructions to load one stage of operand B
-    static int const TBLDGSTSIterationsB =
+    /// Number of cp.async instructions to load one stage of operand B
+    static int const TBLoadIterationsB =
         IteratorB::ThreadMap::Iterations::kCount;
 
     /// Number of stages
     static int const kStages = Stages;
 
-    /// Number of LDGSTS instructions to load on group of operand A
     static int const kAccessesPerGroupA =
-        (TBLDGSTSIterationsA + Base::kWarpGemmIterations - 1) / Base::kWarpGemmIterations;
+        (TBLoadIterationsA + Base::kWarpGemmIterations - 1) / Base::kWarpGemmIterations;
 
-    /// Number of LDGSTS instructions to load on group of operand B
     static int const kAccessesPerGroupB =
-        (TBLDGSTSIterationsB + Base::kWarpGemmIterations - 1) / Base::kWarpGemmIterations;
+        (TBLoadIterationsB + Base::kWarpGemmIterations - 1) / Base::kWarpGemmIterations;
   };
 
  private:
 
   using WarpFragmentA = typename Operator::FragmentA;
   using WarpFragmentB = typename Operator::FragmentB;
 
@@ -235,15 +233,15 @@
     int group_start_A = 0, 
     int group_start_B = 0) {
 
     iterator_A_real.set_iteration_index(group_start_A * IteratorA::kAccessesPerVector);
     iterator_A_imag.set_iteration_index(group_start_A * IteratorA::kAccessesPerVector);
     this->smem_iterator_A_.set_iteration_index(group_start_A);
 
-    // LDGSTS for operand A
+    // Load for operand A
     CUTLASS_PRAGMA_UNROLL
     for (int j = 0; j < Detail::kAccessesPerGroupA; ++j) {
         
       typename IteratorA::AccessType *dst_ptr = 
         reinterpret_cast<typename IteratorA::AccessType *>(this->smem_iterator_A_.get());
           
       int const kSrcBytes = 
@@ -273,15 +271,15 @@
       ++this->smem_iterator_A_;
     }
 
     iterator_B_real.set_iteration_index(group_start_B * IteratorB::kAccessesPerVector);
     iterator_B_imag.set_iteration_index(group_start_B * IteratorB::kAccessesPerVector);
     this->smem_iterator_B_.set_iteration_index(group_start_B);
 
-    // LDGSTS for operand B
+    // Load for operand B
     CUTLASS_PRAGMA_UNROLL
     for (int j = 0; j < Detail::kAccessesPerGroupB; ++j) {
       typename IteratorB::AccessType *dst_ptr = 
         reinterpret_cast<typename IteratorB::AccessType *>(this->smem_iterator_B_.get());
       
       int const kSrcBytes = 
         sizeof_bits<typename IteratorB::Element>::value * 
@@ -382,17 +380,17 @@
       iterator_B_imag.clear_mask(gemm_k_iterations == 0);
 
       iterator_A_real.set_iteration_index(0);
       iterator_A_imag.set_iteration_index(0);
 
       this->smem_iterator_A_.set_iteration_index(0);
 
-      // LDGSTS for operand A
+      // Load for operand A
       CUTLASS_PRAGMA_UNROLL
-      for (int j = 0; j < Detail::TBLDGSTSIterationsA; ++j) {
+      for (int j = 0; j < Detail::TBLoadIterationsA; ++j) {
 
         typename IteratorA::AccessType *dst_ptr = 
           reinterpret_cast<typename IteratorA::AccessType *>(this->smem_iterator_A_.get());
 
         CUTLASS_PRAGMA_UNROLL
         for (int v = 0; v < IteratorA::kAccessesPerVector; ++v) {
 
@@ -423,17 +421,17 @@
       }
 
       iterator_B_real.set_iteration_index(0);
       iterator_B_imag.set_iteration_index(0);
 
       this->smem_iterator_B_.set_iteration_index(0);
 
-      // LDGSTS for operand B
+      // Load for operand B
       CUTLASS_PRAGMA_UNROLL
-      for (int j = 0; j < Detail::TBLDGSTSIterationsB; ++j) {
+      for (int j = 0; j < Detail::TBLoadIterationsB; ++j) {
 
         typename IteratorB::AccessType *dst_ptr = 
           reinterpret_cast<typename IteratorB::AccessType *>(this->smem_iterator_B_.get());
 
         CUTLASS_PRAGMA_UNROLL
         for (int v = 0; v < IteratorB::kAccessesPerVector; ++v) {
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_planar_complex_pipelined.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_planar_complex_pipelined.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -317,15 +317,15 @@
     iterator_A_real.clear_mask(gemm_k_iterations <= 1);
     iterator_A_imag.clear_mask(gemm_k_iterations <= 1);
     
     iterator_B_real.clear_mask(gemm_k_iterations <= 1);
     iterator_B_imag.clear_mask(gemm_k_iterations <= 1);
 
     // Issue loads during the first warp-level matrix multiply-add *AFTER* issuing 
-    // shared memory loads (which have the tighest latency requirement).
+    // shared memory loads (which have the tightest latency requirement).
 
     //
     // Mainloop
     //
 
     // Note: The main loop does not support Base::kWarpGemmIterations == 2.
     CUTLASS_GEMM_LOOP
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_singlestage.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_singlestage.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_softmax_mainloop_fusion_multistage.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_softmax_mainloop_fusion_multistage.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -729,15 +729,15 @@
               }
         }
       }
 
     }
     
     if (SharedMemoryClear == SharedMemoryClearOption::kZfill) {
-      // commit and drain all pending and predicated LDGSTS pnz from the GEMM mainloop
+      // commit and drain all pending and predicated cp.async pnz from the GEMM mainloop
       cutlass::arch::cp_async_fence();
       cutlass::arch::cp_async_wait<0>();
       __syncthreads();
     }
 
   }
 };
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_sparse_base.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_sparse_base.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_sparse_multistage.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_sparse_multistage.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -153,39 +153,39 @@
   /// Complex transform on B operand
   static ComplexTransform const kTransformB = Operator::kTransformB;
 
   /// Internal structure exposed for introspection.
   struct Detail {
 
     /// Number of async copies to load one stage of operand A
-    static int const TBLDGSTSIterationsA =
+    static int const TBLoadIterationsA =
         IteratorA::ThreadMap::Iterations::kCount;
 
     /// Number of async copies to load one stage of operand B
-    static int const TBLDGSTSIterationsB =
+    static int const TBLoadIterationsB =
         IteratorB::ThreadMap::Iterations::kCount;
 
     /// Number of async copies to load one stage of operand E
-    static int const TBLDGSTSIterationsE =
+    static int const TBLoadIterationsE =
         IteratorE::ThreadMap::Iterations::kCount;
 
     /// Number of stages
     static int const kStages = Stages;
 
     /// Number of async copies to load one group of operand A
     static int const kAccessesPerGroupA =
-        (TBLDGSTSIterationsA + Base::kWarpGemmIterations - 1) / Base::kWarpGemmIterations;
+        (TBLoadIterationsA + Base::kWarpGemmIterations - 1) / Base::kWarpGemmIterations;
 
     /// Number of async copies to load one group of operand B
     static int const kAccessesPerGroupB =
-        (TBLDGSTSIterationsB + Base::kWarpGemmIterations - 1) / Base::kWarpGemmIterations;
+        (TBLoadIterationsB + Base::kWarpGemmIterations - 1) / Base::kWarpGemmIterations;
 
     /// Number of async copies to load one group of operand E
     static int const kAccessesPerGroupE =
-        (TBLDGSTSIterationsE + Base::kWarpGemmIterations - 1) / Base::kWarpGemmIterations;
+        (TBLoadIterationsE + Base::kWarpGemmIterations - 1) / Base::kWarpGemmIterations;
 
     /// E operand is tiny.  For the most of time, not all the warps are needed
     /// to load it from the global memory.
     static int const kValidWarps = IteratorE::ThreadMap::kThreads / 32;
 
     /// B operand is twice as big as A which brings very high register pressure.
     /// We have to sacrifice the double buffer when the warp tile size is big.
@@ -275,15 +275,15 @@
     iterator_A.set_iteration_index(group_start_A *
                                    IteratorA::kAccessesPerVector);
     this->smem_iterator_A_.set_iteration_index(group_start_A);
 
     // async copy for operand A
     CUTLASS_PRAGMA_UNROLL
     for (int j = 0; j < Detail::kAccessesPerGroupA; ++j) {
-      if (group_start_A + j < Detail::TBLDGSTSIterationsA) {
+      if (group_start_A + j < Detail::TBLoadIterationsA) {
         typename IteratorA::AccessType *dst_ptr =
             reinterpret_cast<typename IteratorA::AccessType *>(
                 this->smem_iterator_A_.get());
 
         int const kSrcBytes = sizeof_bits<typename IteratorA::Element>::value *
                               IteratorA::ThreadMap::kElementsPerAccess /
                               IteratorA::kAccessesPerVector / 8;
@@ -305,15 +305,15 @@
     iterator_B.set_iteration_index(group_start_B *
                                    IteratorB::kAccessesPerVector);
     this->smem_iterator_B_.set_iteration_index(group_start_B);
 
     // async copy for operand B
     CUTLASS_PRAGMA_UNROLL
     for (int j = 0; j < Detail::kAccessesPerGroupB; ++j) {
-      if (group_start_B + j < Detail::TBLDGSTSIterationsB) {
+      if (group_start_B + j < Detail::TBLoadIterationsB) {
         typename IteratorB::AccessType *dst_ptr =
             reinterpret_cast<typename IteratorB::AccessType *>(
                 this->smem_iterator_B_.get());
 
         int const kSrcBytes = sizeof_bits<typename IteratorB::Element>::value *
                               IteratorB::ThreadMap::kElementsPerAccess /
                               IteratorB::kAccessesPerVector / 8;
@@ -333,15 +333,15 @@
 
     iterator_E.set_iteration_index(group_start_E);
     this->smem_iterator_E_.set_iteration_index(group_start_E);
 
     // async copy for operand E
     CUTLASS_PRAGMA_UNROLL
     for (int j = 0; j < Detail::kAccessesPerGroupE; ++j) {
-      if (group_start_E + j < Detail::TBLDGSTSIterationsE) {
+      if (group_start_E + j < Detail::TBLoadIterationsE) {
         typename IteratorE::AccessType *dst_ptr =
             reinterpret_cast<typename IteratorE::AccessType *>(
                 this->smem_iterator_E_.get());
 
         int const kSrcBytes = sizeof_bits<typename IteratorE::Element>::value *
                               IteratorE::ThreadMap::kElementsPerAccess / 8;
 
@@ -386,15 +386,15 @@
       iterator_E.clear_mask(gemm_k_iterations == 0);
 
       iterator_A.set_iteration_index(0);
       this->smem_iterator_A_.set_iteration_index(0);
 
       // async copy for operand A
       CUTLASS_PRAGMA_UNROLL
-      for (int j = 0; j < Detail::TBLDGSTSIterationsA; ++j) {
+      for (int j = 0; j < Detail::TBLoadIterationsA; ++j) {
         typename IteratorA::AccessType *dst_ptr =
             reinterpret_cast<typename IteratorA::AccessType *>(
                 this->smem_iterator_A_.get());
 
         CUTLASS_PRAGMA_UNROLL
         for (int v = 0; v < IteratorA::kAccessesPerVector; ++v) {
           int const kSrcBytes =
@@ -412,15 +412,15 @@
       }
 
       iterator_B.set_iteration_index(0);
       this->smem_iterator_B_.set_iteration_index(0);
 
       // async copy for operand B
       CUTLASS_PRAGMA_UNROLL
-      for (int j = 0; j < Detail::TBLDGSTSIterationsB; ++j) {
+      for (int j = 0; j < Detail::TBLoadIterationsB; ++j) {
         typename IteratorB::AccessType *dst_ptr =
             reinterpret_cast<typename IteratorB::AccessType *>(
                 this->smem_iterator_B_.get());
 
         CUTLASS_PRAGMA_UNROLL
         for (int v = 0; v < IteratorB::kAccessesPerVector; ++v) {
           int const kSrcBytes =
@@ -438,15 +438,15 @@
       }
 
       iterator_E.set_iteration_index(0);
       this->smem_iterator_E_.set_iteration_index(0);
 
       // async copy for operand E
       CUTLASS_PRAGMA_UNROLL
-      for (int j = 0; j < Detail::TBLDGSTSIterationsE; ++j) {
+      for (int j = 0; j < Detail::TBLoadIterationsE; ++j) {
         typename IteratorE::AccessType *dst_ptr =
             reinterpret_cast<typename IteratorE::AccessType *>(
                 this->smem_iterator_E_.get());
 
         int const kSrcBytes = sizeof_bits<typename IteratorE::Element>::value *
                               IteratorE::ThreadMap::kElementsPerAccess / 8;
         if (is_warp_valid_)
@@ -463,22 +463,21 @@
       iterator_B.add_tile_offset({1, 0});
       iterator_E.add_tile_offset({0, 1});
 
       this->smem_iterator_A_.add_tile_offset({0, 1});
       this->smem_iterator_B_.add_tile_offset({1, 0});
       this->smem_iterator_E_.add_tile_offset({0, 1});
 
-      // LDGDEPBAR - completes a stage
+      // cp.async.commit_group - completes a stage
       cutlass::arch::cp_async_fence();
     }
 
     // Perform accumulation in the 'd' output operand
     accum = src_accum;
 
-    // DEPBAR+SYNC
     cutlass::arch::cp_async_wait<Base::kStages - 2>();
     __syncthreads();
 
     // Pair of fragments used to overlap shared memory loads and math
     // instructions
     WarpLoadedFragmentA warp_loaded_frag_A[2];
     WarpLoadedFragmentB warp_loaded_frag_B[Detail::kBBufferSize];
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_with_reduction_multistage.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/mma_with_reduction_multistage.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -525,15 +525,15 @@
                              warp_loaded_frag_A[(warp_mma_k + 1) % 2],
                              warp_loaded_frag_B[(warp_mma_k + 1) % 2]);
       }
 
     }
     
     if (SharedMemoryClear == SharedMemoryClearOption::kZfill) {
-      // commit and drain all pending and predicated LDGSTS pnz from the GEMM mainloop
+      // commit and drain all pending and predicated cp.async pnz from the GEMM mainloop
       cutlass::arch::cp_async_fence();
       cutlass::arch::cp_async_wait<0>();
       __syncthreads();
     }
 
   }
 };
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/threadblock_swizzle.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/threadblock_swizzle.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/threadblock_swizzle_streamk.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/threadblock/threadblock_swizzle_streamk.h`

 * *Files 9% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -39,18 +39,19 @@
 #include "cutlass/layout/matrix.h"
 #include "cutlass/platform/platform.h"
 #include "cutlass/gemm/gemm.h"
 #include "cutlass/conv/conv2d_problem_size.h"
 #include "cutlass/conv/conv3d_problem_size.h"
 #include "cutlass/gemm/threadblock/index_remat.h"
 
+#if !defined(__CUDACC_RTC__)
 #include <iostream>
 #include "cutlass/core_io.h"
 #include "cutlass/trace.h"
-
+#endif
 
 
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 namespace gemm {
@@ -111,99 +112,135 @@
   static int const kFixupPeerIterEquiv = 3;
 
 
   //
   // Member state
   //
 
+
   /// The 3D value-extents of the GEMM computation volume (m,n,k)
   GemmCoord problem_size;
 
-  /// The 2D tile-extents of the output matrix (m,n)
-  GemmCoord tiled_shape;
-
-  /// Number of iterations per output tile
-  int iters_per_tile;
-
-  /// Number of reduction blocks in the grid
-  int reduction_blocks;
+  /// Div/mod accelerators
+  FastDivmod div_mod_tiled_shape_m;
+  FastDivmod div_mod_tiled_shape_n;
+  FastDivmod div_mod_tiled_cohort_shape_n;
+  FastDivmod div_mod_iters_per_tile;
 
-  int dp_blocks;                            /// Number of data-parallel thread blocks in the grid
-  int dp_first_wave_tiles;                  /// Number of output tiles each CTA in the first DP wave will produce
+  /// Whether to perform cohort CTA rasterization
+  bool cohort_raster;
 
-  int sk_tiles;
-  int sk_regions;
-  int sk_blocks_per_region;
-  int sk_big_blocks_per_region;
-  int sk_iters_per_region;
-  int sk_iters_per_normal_block;            /// Number of iterations for normal SK-blocks
-  int sk_waves;                             /// Number of SK waves in the grid
+  // Whether to pad and remap block indices
+  bool remap_block_indices;
 
   /// CTA occupancy per SM
   int sm_occupancy;
 
   /// Number of SMs for dispatch heuristics to load-balance using Stream-K CTAs (wave size)
   int avail_sms;
 
-  /// Whether to perform cohort CTA rasterization
-  bool cohort_raster;
+  int dp_blocks;                            /// Number of data-parallel thread blocks in the grid
+  int dp_first_wave_tiles;                  /// Number of output tiles each CTA in the first DP wave will produce
+
+  /// Number of reduction blocks in the grid
+  int reduction_blocks;
+
+  int sk_waves;
+  int sk_tiles;
+  int sk_big_blocks_per_region;
+  int sk_iters_per_region;
 
   /// Div/mod accelerators
-  struct
-  {
-    FastDivmod tiled_shape_m;
-    FastDivmod tiled_shape_n;
-    FastDivmod tiled_cohort_shape_n;
-    FastDivmod iters_per_tile;
-    FastDivmod sk_iters_per_normal_block;
-    FastDivmod sk_iters_per_big_block;
-    FastDivmod sk_iters_per_region;
-    FastDivmod sk_blocks_per_region;
-    FastDivmod sm_occupancy;
+  FastDivmod div_mod_sk_iters_per_normal_block;
+  FastDivmod div_mod_sk_iters_per_big_block;
+  FastDivmod div_mod_sk_iters_per_region;
+  FastDivmod div_mod_sk_regions;                      //!! used in block map
+  FastDivmod div_mod_sk_blocks_per_region;            //!! used in block map
 
-  } div_mod;
+  /// The batch count
+  int batch_count;
 
 
   //
   // Host+device interface
   //
 
   /// Constructor
   CUTLASS_HOST_DEVICE
   ThreadblockSwizzleStreamK() {}
 
+  /// Returns the GEMM volume in thread block tiles
+  CUTLASS_HOST_DEVICE
+  GemmCoord tiled_shape() const
+  {
+    return GemmCoord(
+        static_cast<int>(div_mod_tiled_shape_m),
+        static_cast<int>(div_mod_tiled_shape_n),
+        batch_count);
+  }
+
+  /// Number of iterations per output tile
+  CUTLASS_HOST_DEVICE
+  int iters_per_tile() const
+  {
+    return static_cast<int>(div_mod_iters_per_tile);
+  }
+
+  /// Number of iterations for normal SK-blocks
+  CUTLASS_HOST_DEVICE
+  int sk_iters_per_normal_block() const
+  {
+    return static_cast<int>(div_mod_sk_iters_per_normal_block);
+  }
+
+  /// Number of SK regions
+  CUTLASS_HOST_DEVICE
+  int sk_regions() const
+  {
+    return static_cast<int>(div_mod_sk_regions);
+  }
+
+  /// Number of SK blocks per region (splitting factor)
+  CUTLASS_HOST_DEVICE
+  int sk_blocks_per_region() const
+  {
+    return static_cast<int>(div_mod_sk_blocks_per_region);
+  }
 
 
   //
   // Host-side interface
   //
 
   /// Debug print
   void Print()
   {
 #ifndef __CUDA_ARCH__
-    int tiles = tiled_shape.m() * tiled_shape.n();
+    auto tiles = tiled_shape().mn().product();
     std::cout <<
         "problem_size: (" << problem_size.m() << "," << problem_size.n() << ")" <<
-        ", reduction_blocks: " << reduction_blocks <<
-        ", dp_blocks: " << dp_blocks <<
-        ", sk_blocks_per_region: " << sk_blocks_per_region <<
-        ", sk_regions: " << sk_regions <<
-        ", sk_iters_per_normal_block: " << sk_iters_per_normal_block <<
-        ", sk_big_blocks_per_region: " << sk_big_blocks_per_region <<
-        ", dp_first_wave_tiles: " << dp_first_wave_tiles <<
-        ", tiled_shape: (" << tiled_shape.m() << "," << tiled_shape.n() << ")" <<
+        ", tiled_shape: (" << tiled_shape().m() << "," << tiled_shape().n() << ")" <<
         ", tiles: " << tiles <<
-        ", iters_per_tile: " << iters_per_tile <<
         ", dp_tiles: " << tiles - sk_tiles <<
         ", sk_tiles: " << sk_tiles <<
-        ", avail_sms: " << avail_sms <<
+        ", iters_per_tile: " << iters_per_tile() <<
+        ", reduction_blocks: " << reduction_blocks <<
+        ", dp_blocks: " << dp_blocks <<
+        ", dp_waves: " << dp_blocks / avail_sms <<
+        ", dp_first_wave_tiles: " << dp_first_wave_tiles <<
+        ", sk_blocks_per_region: " << sk_blocks_per_region() <<
+        ", sk_regions: " << sk_regions() <<
+        ", sk_waves: " << sk_waves <<
+        ", sk_iters_per_normal_block: " << sk_iters_per_normal_block() <<
+        ", sk_big_blocks_per_region: " << sk_big_blocks_per_region <<
+        ", remap_block_indices: " << remap_block_indices <<
+        ", cohort_raster: " << cohort_raster <<
         ", sm_occupancy: " << sm_occupancy <<
         ", avail_sms: " << avail_sms <<
-        ", cohort_raster: " << cohort_raster <<
+        ", num_blocks: " << get_num_blocks() <<
         "\n\n";
 #endif
   }
 
 
   // Compute sk_blocks to dispatch for a given number of sk_tiles
   static void get_sk_blocks(
@@ -312,17 +349,18 @@
         }
 
         return;
     }
 
     // We're at (or greater) than GPU occupancy
 
-    if (full_waves % sm_occupancy == sm_occupancy - 1)
+    if ((sm_occupancy > 1 ) && (full_waves % sm_occupancy == sm_occupancy - 1))
     {
-        // Form the SK wave from the partial wave to get us to full GPU occupancy
+        // If occupancy is more than one CTA per SM, form the SK wave from the partial
+        // wave to get us to full GPU occupancy
         int max_sk_occupancy = 1;
 
         dp_tiles = full_wave_tiles;
 
         get_sk_blocks(
           sk_blocks,
           score,
@@ -363,68 +401,75 @@
   /// Constructor: *Gemm* problem size (m, n, k)
   template <typename GemmKernel>
   ThreadblockSwizzleStreamK(
     KernelTraits<GemmKernel> const kernel_traits_,
     GemmUniversalMode const mode_,
     GemmCoord const problem_size_,
     GemmCoord const tile_size_,
-    int const batch_count_,                      /// Batch count (when mode_ == GemmUniversalMode::kBatched) or split-K-override splitting factor (when mode_ == GemmUniversalMode::kGemm)
+    int const batch_split_,                        /// Either (mode == GemmUniversalMode::kBatched) the batch count, or (mode == GemmUniversalMode::kGemm) the tile-splitting factor (1 defaults to StreamK, >1 emulates Split-K)
     int const sm_occupancy_,
-    int const avail_sms_)
+    int const device_sms_,
+    int const avail_sms_)                          /// The number of SMs that StreamK dispatch heuristics will attempt to load-balance across (-1 defaults to device width, 1 implies classic data-parallel scheduling)
   :
     problem_size(problem_size_),
-    tiled_shape(
-      (problem_size.m() + tile_size_.m() - 1) / tile_size_.m(),
-      (problem_size.n() + tile_size_.n() - 1) / tile_size_.n(),
-      (mode_ == GemmUniversalMode::kBatched) ? batch_count_ : 1),
-    iters_per_tile((problem_size.k() + tile_size_.k() - 1) / tile_size_.k()),
+    batch_count((mode_ == GemmUniversalMode::kBatched) ? batch_split_ : 1),
     reduction_blocks(0),
     dp_blocks(0),
     dp_first_wave_tiles(1),     // Default: one tile per DP-block in the first wave of DP blocks
     sk_tiles(0),
-    sk_regions(1),              // Default: a single region of iteration space (across all SK tiles)
-    sk_blocks_per_region(0),
     sk_big_blocks_per_region(0),
     sk_iters_per_region(0),
-    sk_iters_per_normal_block(0),
     sk_waves(0),
     sm_occupancy(sm_occupancy_),
+    remap_block_indices(false),
     avail_sms(fast_max(1, avail_sms_)),
     cohort_raster(false)
   {
+    int gpu_occupancy = device_sms_ * sm_occupancy;
+    int iters_per_tile = (problem_size.k() + tile_size_.k() - 1) / tile_size_.k();
+    int sk_iters_per_normal_block = 0;
+
+    int sk_regions = 1;              // Default: a single region of iteration space (across all SK tiles)
+    int sk_blocks_per_region = 0;
+
+    GemmCoord tiled_shape(
+      (problem_size.m() + tile_size_.m() - 1) / tile_size_.m(),
+      (problem_size.n() + tile_size_.n() - 1) / tile_size_.n(),
+      batch_count);
+
     size_t problem_bytes =
               (sizeof(typename GemmKernel::ElementC) * problem_size.m() * problem_size.n()) +
               (sizeof(typename GemmKernel::ElementA) * problem_size.m() * problem_size.k()) +
               (sizeof(typename GemmKernel::ElementB) * problem_size.k() * problem_size.n());
 
     size_t problem_flops = size_t(problem_size.m()) * size_t(problem_size.n()) * size_t(problem_size.k()) * 2;
 
     float flops_per_byte = float(problem_flops) / float(problem_bytes);
 
-    int gpu_occupancy = avail_sms * sm_occupancy;
     int output_tiles = tiled_shape.m() * tiled_shape.n();
     int waves = (output_tiles + avail_sms - 1) / avail_sms;
     float dp_efficiency = float(output_tiles) / float(waves * avail_sms);
 
     //
     // Determine dispatch composition of DP-tiles and SK-blocks
     //
 
     // Start with a DP-only configuration
     int dp_tiles = output_tiles;    // Number of data-parallel tiles
     int sk_blocks = 0;              // Number of thread blocks to produce the remaining SK tiles
 
-    // kGemm mode allows for SK load balancing
+    // Only kGemm mode allows for SK load balancing
     if (mode_ == GemmUniversalMode::kGemm)
     {
-      if (batch_count_ > 1)
+      int split_factor = batch_split_;
+      if (split_factor > 1)
       {
         // Split-K override
         dp_tiles = 0;
-        sk_blocks = output_tiles * batch_count_;
+        sk_blocks = output_tiles * split_factor;
       }
       else if ((kReductionStrategy != kNone) &&   // Load-balancing strategy statically enabled
         (avail_sms > 1))                         // Plurality of SMs to load balance across
       {
         // Use heuristics
         get_blocks(
           dp_tiles,      /// [out]
@@ -457,44 +502,59 @@
         sk_regions = sk_tiles;
       }
 
       sk_blocks_per_region = sk_blocks / sk_regions;
       sk_big_blocks_per_region = sk_big_blocks / sk_regions;
       sk_iters_per_region = sk_iters / sk_regions;
 
-      div_mod.sk_iters_per_normal_block = FastDivmod(sk_iters_per_normal_block);
-      div_mod.sk_iters_per_big_block = FastDivmod(sk_iters_per_normal_block + 1);
-      div_mod.sk_iters_per_region = FastDivmod(sk_iters_per_region);
-      div_mod.sk_blocks_per_region = FastDivmod(sk_blocks_per_region);
-
-      // Separate reduction heuristic
+      // Use a separate reduction wave when all of:
+      // - Non-atomic reduction stratgy
+      // - The number of SK waves won't fully occupy the GPU (Otherwise we don't have
+      //   a strong-scaling case for more parallel reduction)
+      // - More than three peers working on an SK tile.  (This occurs when the ratio of
+      //   SK-blocks to SK-tiles > 2, as a single tile may be covered by four SK-blocks,
+      //   e.g.:[partial-block | block | block | partial-block] ).  With three or
+      //   less peers, the two non-finishing SK-blocks are not expexted to contend.
       if ((kReductionStrategy == kMixed) &&
-          (sk_blocks > 2 * sk_tiles))       // Use a separate reduction wave whenever we would have more than three
-                                            // peers working on an SK tile.  (This occurs when the ratio of SK-blocks
-                                            // to SK-tiles > 2, as a single tile may be covered by four SK-blocks,
-                                            // e.g.:[partial-block | block | block | partial-block] ).  With three or
-                                            // less peers, the two non-finishing SK-blocks are not expexted to contend.
+          (sk_waves < sm_occupancy) &&
+          (sk_blocks > 2 * sk_tiles))
       {
-        // Launch a reduction block every accumulator fragment in each SK-tile
+        // Launch a reduction block for every accumulator fragment in each SK-tile
         static const int kAccumulatorFragments = GemmKernel::Epilogue::kAccumulatorFragments;
         reduction_blocks = sk_tiles * kAccumulatorFragments;
 
       }
+
+      // When we have a multi-occupancy kernel and at least two waves of active blocks (where
+      // at least one wave is SK blocks), we need to (1) dispatch at least four waves, and (2)
+      // remap the block indices so that we can reliably spread the SK blocks evenly across the
+      // device's first SM occupancy valence. Also see get_num_blocks() and get_block_idx().
+      remap_block_indices = (
+          (sm_occupancy > 1) &&
+          (device_sms_ == avail_sms) &&
+          (get_num_active_blocks() > avail_sms * 2));
+
+      // Initialize fast div/mod members related to SK
+      div_mod_sk_iters_per_normal_block = FastDivmod(sk_iters_per_normal_block);
+      div_mod_sk_iters_per_big_block = FastDivmod(sk_iters_per_normal_block + 1);
+      div_mod_sk_iters_per_region = FastDivmod(sk_iters_per_region);
+      div_mod_sk_regions = FastDivmod(sk_regions);
+      div_mod_sk_blocks_per_region = FastDivmod(sk_blocks_per_region);
     }
 
     //
     // Compute DP blocks
     //
 
     dp_blocks = dp_tiles;
 
     cutlass::gemm::GemmCoord tiled_cohort_shape(
         (tiled_shape.m() + kCohortCtasM - 1) / kCohortCtasM,
         (tiled_shape.n() + kCohortCtasN - 1) / kCohortCtasN,
-        batch_count_);
+        tiled_shape.k());
     int cohort_blocks = (tiled_cohort_shape.m() * tiled_cohort_shape.n()) * kCtasPerCohort;
     float cohort_efficiency = float(dp_blocks) / float(cohort_blocks);
 
     // Check if the SK tiles would be in cohorts that are in-bounds
     bool sk_in_range = true;
     if (sk_tiles > 0)
     {
@@ -506,19 +566,20 @@
         cohort_tile_idx % tiled_cohort_shape.n();
 
       if ((((cohort_grid_m + 1) * kCohortCtasM) >= tiled_shape.m()) ||
           (((cohort_grid_n + 1) * kCohortCtasN) >= tiled_shape.n()))
       {
         sk_in_range = false;
       }
+
     }
 
     // Decide if we're going to be doing cohort raster
     if (sk_in_range &&
-        (dp_blocks >= gpu_occupancy) &&
+        (dp_blocks >= gpu_occupancy * 2) &&
         (cohort_efficiency > 0.85f))
     {
       cohort_raster = true;
       dp_blocks = cohort_blocks;
     }
     else if (sk_waves > 0)
     {
@@ -529,108 +590,54 @@
       int waveset_excess = (sk_waves + dp_tile_waves) % sm_occupancy;
 
       if (dp_first_wave_tiles + waveset_excess <= full_dp_tile_waves)
       {
         dp_first_wave_tiles += waveset_excess;
         dp_blocks -= (waveset_excess * avail_sms);
       }
-
     }
 
     // Setup fast-div/mod for device-side usage
-    div_mod.tiled_shape_m = FastDivmod(tiled_shape.m());
-    div_mod.tiled_shape_n = FastDivmod(tiled_shape.n());
-    div_mod.tiled_cohort_shape_n = FastDivmod(tiled_cohort_shape.n());
-    div_mod.iters_per_tile = FastDivmod(iters_per_tile);
-    div_mod.sm_occupancy = FastDivmod(sm_occupancy);
-  }
-
-
-  /// Constructor: *ImplicitGemm* Conv2d problem size: conv_operator(NPQK, NHWC, KRSC)
-  template <typename GemmKernel>
-  ThreadblockSwizzleStreamK(
-    KernelTraits<GemmKernel> kernel_traits_,
-    GemmUniversalMode mode_,
-    cutlass::conv::Operator conv_operator,
-    cutlass::conv::Conv2dProblemSize const &problem_size_,
-    GemmCoord tile_size_,
-    int batch_count_,
-    int sm_occupancy_,
-    int avail_sms_,                         /// When the below are defaulted, the number of SMs that dispatch heuristics will attempt to load-balance
-    int dp_tiles_ = -1,                     /// Dispatch override: number of output tiles to assign to independent, data-parallel CTAs
-    int sk_blocks_ = -1)                    /// Dispatch override: number of Stream-K CTAs for cooperatively processing the remaining output tiles
-  :
-    ThreadblockSwizzleStreamK(
-      kernel_traits_,
-      mode_,
-      cutlass::conv::implicit_gemm_problem_size(conv_operator, problem_size_),
-      tile_size_,
-      batch_count_,
-      sm_occupancy_,
-      avail_sms_,
-      dp_tiles_,
-      sk_blocks_)
-  {}
-
+    div_mod_tiled_shape_m = FastDivmod(tiled_shape.m());
+    div_mod_tiled_shape_n = FastDivmod(tiled_shape.n());
+    div_mod_tiled_cohort_shape_n = FastDivmod(tiled_cohort_shape.n());
+    div_mod_iters_per_tile = FastDivmod(iters_per_tile);
 
-  /// Constructor: *ImplicitGemm* Conv3d problem size: conv_operator(NZPQK, NDHWC, KTRSC)
-  template <typename GemmKernel>
-  ThreadblockSwizzleStreamK(
-    KernelTraits<GemmKernel> kernel_traits_,
-    GemmUniversalMode mode_,
-    cutlass::conv::Operator conv_operator,
-    cutlass::conv::Conv3dProblemSize const &problem_size_,
-    GemmCoord tile_size_,
-    int batch_count_,
-    int sm_occupancy_,
-    int avail_sms_,                         /// When the below are defaulted, the number of SMs that dispatch heuristics will attempt to load-balance
-    int dp_tiles_ = -1,                     /// Dispatch override: number of output tiles to assign to independent, data-parallel CTAs
-    int sk_blocks_ = -1)                    /// Dispatch override: number of Stream-K CTAs for cooperatively processing the remaining output tiles
-  :
-    ThreadblockSwizzleStreamK(
-      kernel_traits_,
-      mode_,
-      cutlass::conv::implicit_gemm_problem_size(conv_operator, problem_size_),
-      tile_size_,
-      batch_count_,
-      sm_occupancy_,
-      avail_sms_,
-      dp_tiles_,
-      sk_blocks_)
-  {}
+  }
 
+  /// Number of blocks performing useful work
+  int get_num_active_blocks() const
+  {
+    return (sk_waves * avail_sms) + dp_blocks + reduction_blocks;
+  }
 
   /// Obtains number of threadblocks per GEMM
   int get_num_blocks() const
   {
-//    int reduction_waves = (reduction_blocks + avail_sms - 1) / avail_sms;
-//    return ((sk_waves + reduction_waves) * avail_sms) + dp_blocks;
-
-
-    int work_blocks = (sk_waves * avail_sms) + dp_blocks + reduction_blocks;
-
-    if (work_blocks < avail_sms)
+    int active_blocks = get_num_active_blocks();
+    if (remap_block_indices)
     {
-      return work_blocks;
+      // Add padding blocks if we are performing remapping in order to dispatch a grid of at least four waves
+      return fast_max(active_blocks, avail_sms * 4);
     }
 
-    int gpu_occupancy = sm_occupancy * avail_sms;
-    int gpu_wavesets = (work_blocks + gpu_occupancy - 1) / gpu_occupancy;
-    return gpu_wavesets * gpu_occupancy;
-
+    return active_blocks;
   }
 
 
   /// Obtains grid extents in CTAs
   dim3 get_grid_dims() const
   {
-    return dim3(get_num_blocks(), 1, tiled_shape.k());
+    return dim3(get_num_blocks(), 1, batch_count);
   }
 
 
+// Guards needed for PyCUTLASS library generation
+#if defined(__NVCC__) || (defined(__clang__) && defined(__CUDA__)) || defined(__CUDACC_RTC__)
+
   //
   // Device-side interface
   //
 
   /// Obtains number of threadblocks per GEMM
   CUTLASS_DEVICE
   int device_num_blocks() const
@@ -638,115 +645,135 @@
     return gridDim.x;
   }
 
   /// Obtains tile index for the given sk iteration
   CUTLASS_DEVICE
   int get_sk_tile_idx(int iter) const
   {
-    return div_mod.iters_per_tile.div(iter);
+    int tile_idx = div_mod_iters_per_tile.div(iter);
+    return tile_idx;
   }
 
+  /// Obtains the batch index
+  CUTLASS_DEVICE
+  int get_batch_idx() const
+  {
+    return RematerializeBlockIdxZ();
+  }
 
   /// Obtains the calling threadblock's tiled coordinates for the given tile index
   CUTLASS_DEVICE
   GemmCoord get_tile_offset(int tile_idx) const
   {
     int m, n;
 
+    // row-major raster
+    div_mod_tiled_shape_n(m, n, tile_idx);
+
+    if (tiled_shape().m() < tiled_shape().n())
+    {
+      // column-major raster
+      div_mod_tiled_shape_m(n, m, tile_idx);
+    }
+
     if (cohort_raster)
     {
       // tiled cohort raster
       int cohort_tile_idx = tile_idx / kCtasPerCohort;
       int cohort_grid_m, cohort_grid_n;
-      div_mod.tiled_cohort_shape_n(cohort_grid_m, cohort_grid_n, cohort_tile_idx);
+      div_mod_tiled_cohort_shape_n(cohort_grid_m, cohort_grid_n, cohort_tile_idx);
 
       int block_idx_cohort = tile_idx % kCtasPerCohort;
       int block_cohort_m = block_idx_cohort / kCohortCtasN;
       int block_cohort_n = block_idx_cohort % kCohortCtasN;
 
       m = (cohort_grid_m * kCohortCtasM) + block_cohort_m;
       n = (cohort_grid_n * kCohortCtasN) + block_cohort_n;
     }
-    else if (tiled_shape.m() < tiled_shape.n())
-    {
-      // column-major raster
-      div_mod.tiled_shape_m(n, m, tile_idx);
-    }
-    else
-    {
-      // row-major raster
-      div_mod.tiled_shape_n(m, n, tile_idx);
-    }
 
-    int block_idx_k = RematerializeBlockIdxZ();
-    return GemmCoord{m, n, block_idx_k};
+    return GemmCoord(m, n, get_batch_idx());
   }
 
+  /// Obtains the calling threadblock's tiled coordinates for the given tile index (row-major rastorization)
+  CUTLASS_DEVICE
+  GemmCoord get_tile_offset_row_major(int tile_idx) const
+  {
+    // row-major raster
+    int m, n;
+    div_mod_tiled_shape_n(m, n, tile_idx);
+    return GemmCoord(m, n, get_batch_idx());
+  }
 
   /// Obtains calling threadblock's linear threadblock index
   CUTLASS_DEVICE
   int get_block_idx() const
   {
     int block_idx = RematerializeBlockIdxX();
 
-    int gpu_occupancy = avail_sms * sm_occupancy;
-    int num_blocks = device_num_blocks();
-    int dest_sm, dest_wave;
-
-    div_mod.sm_occupancy(dest_sm, dest_wave, block_idx);
-
-    int remapped_block_idx = dest_sm + (dest_wave * avail_sms);
+    // Remap the block indices for the first two waves of thread blocks if
+    // we have multi-occupancy and the grid constitutes four or more waves
+    if (remap_block_indices && (block_idx < avail_sms * 2))
+    {
+      int dest_sm = block_idx / 2;
+      int dest_wave = block_idx % 2;
+      int remapped_block_idx = dest_sm + (dest_wave * avail_sms);
+      block_idx = remapped_block_idx;
+    }
 
-    // remapping the first gpu_occupancy blocks
-    if ((block_idx < gpu_occupancy) && (num_blocks > gpu_occupancy))
+    // Remap block indices to interleave SK regions to limit intra-region waiting
+    if (block_idx < sk_regions() * sk_blocks_per_region())
     {
-      block_idx = remapped_block_idx;
+      int block_in_region;
+      int region;
+      div_mod_sk_regions(block_in_region, region, block_idx);
+      block_idx = (region * sk_blocks_per_region()) + block_in_region;
     }
 
-    // Block-index is blockIdx.x for DP blocks
     return block_idx;
   }
 
 
   /// Obtains calling linear threadblock index of the first block to work on the given tile
   CUTLASS_DEVICE
   int get_sk_block_idx(int iter) const
   {
     int region_idx;
     int iter_in_region;
-    div_mod.sk_iters_per_region(region_idx, iter_in_region, iter);
+    div_mod_sk_iters_per_region(region_idx, iter_in_region, iter);
 
-    int big_block_iters = (sk_big_blocks_per_region * sk_iters_per_normal_block) + sk_big_blocks_per_region;   // number of iterations in the region's big blocks
+    int big_block_iters = (sk_big_blocks_per_region * sk_iters_per_normal_block()) + sk_big_blocks_per_region;   // number of iterations in the region's big blocks
     int normal_block_iters = iter_in_region - big_block_iters;                                                 // number of iterations in the region's normal bocks
 
-    int big_block_idx_in_region = div_mod.sk_iters_per_big_block.div(iter_in_region);
-    int normal_block_idx_in_region = sk_big_blocks_per_region + div_mod.sk_iters_per_normal_block.div(normal_block_iters);
+    int big_block_idx_in_region = div_mod_sk_iters_per_big_block.div(iter_in_region);
+    int normal_block_idx_in_region = sk_big_blocks_per_region + div_mod_sk_iters_per_normal_block.div(normal_block_iters);
 
     int block_idx_in_region = (big_block_idx_in_region < sk_big_blocks_per_region) ?
         big_block_idx_in_region :
         normal_block_idx_in_region;
 
-    return (sk_blocks_per_region * region_idx) + block_idx_in_region;
+    int owning_block_idx = (sk_blocks_per_region() * region_idx) + block_idx_in_region;
+
+    return owning_block_idx;
   }
 
   /// Obtains iteration extends for the given SK block index
   CUTLASS_DEVICE
   void get_iter_extents(
       int sk_block_idx,
       int &block_iter_begin,
       int &block_iter_end) const
   {
     int region_idx;
     int block_idx_in_region;
-    div_mod.sk_blocks_per_region(region_idx, block_idx_in_region, sk_block_idx);
+    div_mod_sk_blocks_per_region(region_idx, block_idx_in_region, sk_block_idx);
 
-    block_iter_begin = (region_idx * sk_iters_per_region) + (block_idx_in_region * sk_iters_per_normal_block);
+    block_iter_begin = (region_idx * sk_iters_per_region) + (block_idx_in_region * sk_iters_per_normal_block());
 
     // Adjust extents for the first "num_big_blocks" blocks that get one extra iteration
-    int block_iters = sk_iters_per_normal_block;
+    int block_iters = sk_iters_per_normal_block();
     if (block_idx_in_region < sk_big_blocks_per_region) {
       // This is a +1 iteration block
       block_iter_begin += block_idx_in_region;
       block_iters++;
     } else {
       // This is a regular block
       block_iter_begin += sk_big_blocks_per_region;
@@ -760,18 +787,20 @@
   int get_first_block_idx(int tile_idx, int block_idx) const
   {
     if (tile_idx >= sk_tiles) {
       // DP tile
       return block_idx;
     }
 
-    int iter = tile_idx * iters_per_tile;
+    int iter = tile_idx * iters_per_tile();
     return get_sk_block_idx(iter);
   }
 
+#endif // defined(__NVCC__) || (defined(__clang__) && defined(__CUDA__)) || defined(__CUDACC_RTC__)
+
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 } // namespace threadblock
 } // namespace gemm
 } // namespace cutlass
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/default_mma_complex_tensor_op.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/default_mma_complex_tensor_op.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/default_mma_sparse_tensor_op.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/default_mma_sparse_tensor_op.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/default_mma_tensor_op.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/default_mma_tensor_op.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/default_mma_tensor_op_sm80.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/default_mma_tensor_op_sm80.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/default_mma_with_reduction_tensor_op.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/default_mma_with_reduction_tensor_op.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/default_mma_wmma_tensor_op.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/default_mma_wmma_tensor_op.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/layernorm_scale_bias_transform.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/layernorm_scale_bias_transform.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/binary_ops.h`

 * *Files 14% similar despite different names*

```diff
@@ -1,60 +1,84 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
  *
  * 2. Redistributions in binary form must reproduce the above copyright notice,
  * this list of conditions and the following disclaimer in the documentation
  * and/or other materials provided with the distribution.
  *
  * 3. Neither the name of the copyright holder nor the names of its
  * contributors may be used to endorse or promote products derived from
- * this software without specific prior written permission.
+ * this layernormware without specific prior written permission.
  *
  * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
  * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
  * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
  * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
+
 /*! \file
-    \brief Templates exposing architecture support for warp-level multiply-add operations
+  
+  \brief A file contains the binary ops
 */
 
 #pragma once
-
 #include "cutlass/cutlass.h"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
-namespace gemm {
-namespace warp {
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-/// Query the number of threads per warp
-template <typename OperatorClass>
-struct WarpSize {
-  static int const value = 32;
+
+/// Scalar multiplication
+template <typename T, int N>
+struct VectorAdd {
+
+    struct Arguments {
+        int tmp;
+
+        CUTLASS_HOST_DEVICE
+        Arguments():tmp(0){ }
+
+        CUTLASS_HOST_DEVICE
+        Arguments(int tmp): tmp(tmp) { }
+    };
+    
+    struct Params {
+
+        CUTLASS_HOST_DEVICE
+        Params(Arguments const &args) { }
+    };
+
+    CUTLASS_HOST_DEVICE
+    VectorAdd(
+        Params const &params
+    ) { }
+
+    CUTLASS_HOST_DEVICE
+    Array<T, N> operator()(Array<T, N> const &lhs, Array<T, N> const &rhs) const {
+        cutlass::plus<Array<T, N>> add_op;
+        return add_op(lhs, rhs);
+    }
+
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-} // namespace warp
-} // namespace gemm
 } // namespace cutlass
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
-
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_complex_tensor_op.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_complex_tensor_op.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_complex_tensor_op_fast_f32.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_complex_tensor_op_fast_f32.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_complex_tensor_op_tile_iterator_sm80.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_complex_tensor_op_tile_iterator_sm80.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_gaussian_complex_tensor_op.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_gaussian_complex_tensor_op.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_gaussian_complex_tensor_op_tile_iterator_sm80.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_gaussian_complex_tensor_op_tile_iterator_sm80.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_planar_complex.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_planar_complex.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_simt.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_simt.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_simt_policy.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_simt_policy.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_simt_tile_iterator.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_simt_tile_iterator.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_sparse_tensor_op.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_sparse_tensor_op.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_fast_f32.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_fast_f32.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_fragment_iterator.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_fragment_iterator.h`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_policy.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_policy.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_sm70.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_sm70.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_access_iterator.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_access_iterator.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator.h`

 * *Files 3% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -233,17 +233,14 @@
   MmaTensorOpMultiplicandTileIterator(
     TensorRef const &ref, 
     int lane_id
   ):
     stride_(ref.stride(0) / Layout::kElementsPerAccess), byte_offset_(0),
     k_group_idx_(0) {
       
-    if ((threadIdx.x == 0) && (blockIdx.x == 0) && (blockIdx.y == 0) && (blockIdx.z == 0)) {
-        printf("tidx = %d, Shape::kContiguous = %d, Shape::kStrided = %d, InstructionShape::kContiguous = %d, InstructionShape::kStrided = %d\n", threadIdx.x, int(Shape::kContiguous), int(Shape::kStrided), int(InstructionShape::kContiguous), int(InstructionShape::kStrided));
-    }
     int quad_pair = (lane_id >> 3);
     int quad_quad = (lane_id >> 4);
     int lane_in_quad = (lane_id & 3);
     int lane_in_quad_pair = (lane_id & 7);
     int lane_in_quad_quad = (lane_id & 15);
 
     CUTLASS_PRAGMA_UNROLL
@@ -273,17 +270,14 @@
                  kOperand == Operand::kB) {
         // Matrix multiply 16816 B
         // Q0 Q2
         // Q1 Q3
         partition_contiguous_idx = ((lane_in_quad_pair >> 2) ^ (i >> 1));
         access_contiguous_idx = ((quad_quad + ((i & 1) << 1)) ^ lane_in_quad);
         access_strided_idx = lane_in_quad_quad;
-        if (((threadIdx.x / 32 == 0) && (threadIdx.x % 1 == 0)) && (blockIdx.x == 0) && (blockIdx.y == 0) && (blockIdx.z == 0)) {
-            printf("tidx = %d, i = %d, lane_in_quad_pair = %d, quad_quad = %d, lane_in_quad = %d, lane_in_quad_quad = %d, partition_contiguous_idx = %d, access_contiguous_idx = %d, access_strided_idx = %d\n", threadIdx.x, i, lane_in_quad_pair, quad_quad, lane_in_quad, lane_in_quad_quad, partition_contiguous_idx, access_contiguous_idx, access_strided_idx);
-        }
       } else if (Policy::LdsmShape::kContiguous == 1) {
         // Matrix multiply 16832.SP B
         // Q0
         // Q1
         // Q2
         // Q3
         partition_contiguous_idx = ((lane_in_quad_pair >> 2) ^ (i >> 2)); 
@@ -293,19 +287,14 @@
 
       int access_contiguous =
           partition_contiguous_idx * Layout::PartitionShape::kContiguous +
           access_contiguous_idx;
 
       int access_strided = access_strided_idx;
 
-      if (((threadIdx.x / 32 == 0) && (threadIdx.x % 1 == 0)) && (blockIdx.x == 0) && (blockIdx.y == 0) && (blockIdx.z == 0)) {
-          // printf("i = %d, PartitionShape:kContiguous = %d\n", i, Layout::PartitionShape::kContiguous);
-          // printf("i = %d, PartitionShape:kStrided = %d\n", i, Layout::PartitionShape::kStrided);
-          printf("tidx = %d, i = %d, kGroupsPerTile = %d, access_contiguous = %d, access_strided = %d, stride_ = %d, pointer offset = %d\n", threadIdx.x, i, int(Policy::kGroupsPerTile), access_contiguous, access_strided, stride_, access_contiguous + access_strided * stride_);
-      }
       pointer_[i] = reinterpret_cast<AccessType const *>(ref.data()) +
                     access_contiguous + access_strided * stride_;
     }
   }
 
   /// Adds a pointer offset to internal pointer(s) to advance through memory
   CUTLASS_DEVICE
@@ -414,17 +403,14 @@
         AccessType const *source_ptr =
             pointer_[c % kPointerCount] +
             Layout::TileShape::kContiguous * (c / kPointerCount) +
             Policy::kLdsmOpInner * Policy::LdsmShape::kStrided * s * stride_;
 
         char const *source_byte_ptr = reinterpret_cast<char const *>(source_ptr) + byte_offset + byte_offset_;
 
-        if (((threadIdx.x / 32 == 0) && threadIdx.x % 1 == 0) && (blockIdx.x == 0) && (blockIdx.y == 0) && (blockIdx.z == 0)) {
-            printf("tidx = %d, s = %d, c = %d, access_idx = %d, pointer_ = 0x%p, source_ptr = %p, source_byte_ptr = %p\n", threadIdx.x, s, c, access_idx, pointer_[c % kPointerCount], source_ptr, source_byte_ptr);
-        }
         cutlass::arch::ldsm<layout::ColumnMajor, Policy::LdsmShape::kCount>(
           fetch_ptr[access_idx],
           source_byte_ptr
         );
       }
     }
   }
@@ -1498,19 +1484,14 @@
 
     // Turing silicon requires all 32 threads in a warp provide valid addresses
     // even for LDSM.1 and LDSM.2
 #if (defined(__CUDA_ARCH__) && (__CUDA_ARCH__ == 750))
     lane_id = lane_id % (Policy::LdsmShape::kCount * Policy::kLdsmOpInner);
 #endif
 
-    if ((threadIdx.x == 0) && (blockIdx.x == 0) && (blockIdx.y == 0) && (blockIdx.z == 0)) {
-        printf("Load Crosswise, tidx = %d, Shape::kContiguous = %d, Shape::kStrided = %d, InstructionShape::kContiguous = %d, InstructionShape::kStrided = %d, LdsmIter kStrided = %d, sections = %d\n", threadIdx.x, int(Shape::kContiguous), int(Shape::kStrided), int(InstructionShape::kContiguous), int(InstructionShape::kStrided), int(Policy::LdsmIterations::kStrided), sections_);
-    }
-
-
     int quad_quad = (lane_id >> 4);
     int quad_pair = (lane_id >> 3);
     int lane_in_pair = (lane_id & 1);
     int lane_in_quad = (lane_id & 3);
     int lane_in_quad_pair = (lane_id & 7);
     int lane_in_quad_quad = (lane_id & 15);
 
@@ -1583,17 +1564,14 @@
         // Q0 Q1
         // Q2 Q3
         partition_contiguous_idx = (lane_id % Layout::kFactor);
         access_contiguous_idx =
             ((quad_pair & 1) ^ (lane_in_quad_pair / Layout::kFactor));
         access_strided_idx =
             (lane_in_quad_pair + (lane_id >> 4 << 3)) / Layout::kFactor;
-        if (((threadIdx.x / 32 == 0) && (threadIdx.x % 1 == 0)) && (blockIdx.x == 0) && (blockIdx.y == 0) && (blockIdx.z == 0)) {
-            printf("Load Crosswise kFactor=2, tidx = %d, lane_in_quad_pair = %d, quad_quad = %d, lane_in_quad = %d, lane_in_quad_quad = %d, partition_contiguous_idx = %d, access_contiguous_idx = %d, access_strided_idx = %d\n", threadIdx.x, lane_in_quad_pair, quad_quad, lane_in_quad, lane_in_quad_quad, partition_contiguous_idx, access_contiguous_idx, access_strided_idx);
-        }
       } 
       else if (Policy::LdsmShape::kContiguous == Policy::LdsmShape::kCount) {
         // Matrix multiply 16832.SP B
         // Q0 Q1 Q2 Q3
         partition_contiguous_idx = (lane_id % Layout::kFactor);
         access_contiguous_idx =
             (quad_pair ^ (lane_in_quad_pair / Layout::kFactor));
@@ -1624,44 +1602,32 @@
                  kOperand == Operand::kB) {
         // Matrix multiply 16816|1688.TF32 B
         // Q0 Q1
         // Q2 Q3
         partition_contiguous_idx = (lane_in_quad_pair >> 2);
         access_contiguous_idx = ((quad_pair & 1) ^ lane_in_quad);
         access_strided_idx = lane_in_quad_pair + (lane_id >> 4 << 3);
-        if (((threadIdx.x / 32 == 0) && (threadIdx.x % 1 == 0)) && (blockIdx.x == 0) && (blockIdx.y == 0) && (blockIdx.z == 0)) {
-            printf("Load Crosswise kFactor=1,, tidx = %d, lane_in_quad_pair = %d, quad_quad = %d, lane_in_quad = %d, lane_in_quad_quad = %d, partition_contiguous_idx = %d, access_contiguous_idx = %d, access_strided_idx = %d\n", threadIdx.x, lane_in_quad_pair, quad_quad, lane_in_quad, lane_in_quad_quad, partition_contiguous_idx, access_contiguous_idx, access_strided_idx);
-        }
-      }
+      } 
       else if (Policy::LdsmShape::kContiguous == Policy::LdsmShape::kCount) {
         // Matrix multiply 16832.SP B
         // Q0 Q1 Q2 Q3
         partition_contiguous_idx = (lane_in_quad_pair >> 2);
         access_contiguous_idx = (quad_pair ^ lane_in_quad);
         access_strided_idx = lane_in_quad_pair;
-        if (((threadIdx.x / 32 == 0) && (threadIdx.x % 1 == 0)) && (blockIdx.x == 0) && (blockIdx.y == 0) && (blockIdx.z == 0)) {
-            printf("Load Crosswise,, tidx = %d, lane_in_quad_pair = %d, quad_quad = %d, lane_in_quad = %d, lane_in_quad_quad = %d, partition_contiguous_idx = %d, access_contiguous_idx = %d, access_strided_idx = %d\n", threadIdx.x, lane_in_quad_pair, quad_quad, lane_in_quad, lane_in_quad_quad, partition_contiguous_idx, access_contiguous_idx, access_strided_idx);
-        }
       }
     }
 
     int access_contiguous =
         partition_contiguous_idx * Layout::PartitionShape::kContiguous +
         access_contiguous_idx;
 
     int access_strided = access_strided_idx;
 
     byte_offset_ = (access_contiguous + access_strided * stride_) *
                    sizeof_bits<Element>::value * Layout::kElementsPerAccess / 8;
-    if (((threadIdx.x / 32 == 0) && (threadIdx.x % 1 == 0)) && (blockIdx.x == 0) && (blockIdx.y == 0) && (blockIdx.z == 0)) {
-          // printf("i = %d, PartitionShape:kContiguous = %d\n", i, Layout::PartitionShape::kContiguous);
-          // printf("i = %d, PartitionShape:kStrided = %d\n", i, Layout::PartitionShape::kStrided);
-        printf("Load Crosswise, tidx = %d, kGroupsPerTile = %d, access_contiguous = %d, access_strided = %d, stride_ = %d, byte offset = %d\n", threadIdx.x, int(Policy::kGroupsPerTile), access_contiguous, access_strided, stride_, byte_offset_);
-      }
-
   }
 
   /// Adds a pointer offset to internal pointer(s) to advance through memory
   CUTLASS_DEVICE
   MmaTensorOpMultiplicandTileIterator &add_pointer_offset(LongIndex offset) {
     byte_offset_ += offset * sizeof_bits<Element>::value / 8;
 
@@ -1823,17 +1789,14 @@
             Policy::kLdsmOpInner / Layout::kFactor *
                 Policy::LdsmShape::kStrided * s * stride_;
 
         char const *source_byte_ptr =
             reinterpret_cast<char const *>(source_ptr) + byte_offset +
             byte_offset_;
 
-        if (((threadIdx.x / 32 == 0) && threadIdx.x % 1 == 0) && (blockIdx.x == 0) && (blockIdx.y == 0) && (blockIdx.z == 0)) {
-            printf("Load Crosswise, tidx = %d, s = %d, c = %d, access_idx = %d, pointer_ = 0x%p, source_ptr = %p, byte_offset_ = %d, source_byte_ptr = %p\n", threadIdx.x, s, c, access_idx, pointer_, source_ptr, byte_offset_, source_byte_ptr);
-        }
         cutlass::arch::ldsm<layout::RowMajor, Policy::LdsmShape::kCount>(
             fetch_ptr[access_idx], source_byte_ptr);
       }
     }
   }
 
   /// Loads a fragment from memory with additional logical offset
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_sm70.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_sm70.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_sm80.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_sm80.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_sparse.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_sparse.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_wmma.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_tile_iterator_wmma.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_wmma.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_tensor_op_wmma.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_with_reduction_tensor_op.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/mma_with_reduction_tensor_op.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -40,15 +40,15 @@
 #include "cutlass/platform/platform.h"
 
 #include "cutlass/numeric_conversion.h"
 #include "cutlass/numeric_types.h"
 #include "cutlass/matrix_shape.h"
 
 #include "cutlass/arch/memory_sm75.h"
-#include "cutlass/arch/mma_sm75.h" 
+#include "cutlass/arch/mma_sm75.h"
 #include "cutlass/arch/mma_sm80.h"
 
 #include "cutlass/gemm/gemm.h"
 #include "cutlass/gemm/warp/mma.h"
 
 #include "cutlass/gemm/warp/mma_tensor_op_policy.h"
 #include "cutlass/gemm/warp/mma_tensor_op.h"
@@ -116,17 +116,17 @@
 
   /// Shape of the warp in units of thread (concept: MmaLanePolicySimt)
   using Policy = Policy_;
 
   /// Underlying matrix multiply operator (concept: arch::Mma)
   using ArchMmaOperator = typename Policy::Operator;
 
-  /// Indicates math operator 
+  /// Indicates math operator
   using MathOperator = typename ArchMmaOperator::Operator;
-  
+
   /// Architecture tag from underlying instruction
   using ArchTag = typename ArchMmaOperator::ArchTag;
 
   /// Indicates class of matrix operator
   using OperatorClass = arch::OpClassTensorOp;
 
   /// Shape of underlying instruction
@@ -219,30 +219,30 @@
   /// Ctor
   CUTLASS_DEVICE
   MmaWithReductionTensorOp() {}
 
   /// Performs a warp-level matrix multiply-accumulate operation
   CUTLASS_DEVICE
   void operator()(
-    FragmentC &D, 
-    TransformedFragmentA const &A, 
-    TransformedFragmentB const &B, 
+    FragmentC &D,
+    TransformedFragmentA const &A,
+    TransformedFragmentB const &B,
     FragmentC const &C,
     FragmentReduction &gemm_k_reduction
   ) const {
 
     using MmaOperandA = typename ArchMmaOperator::FragmentA;
     using MmaOperandB = typename ArchMmaOperator::FragmentB;
     using MmaOperandC = typename ArchMmaOperator::FragmentC;
 
     D = C;
 
-    MmaOperandA const *ptr_A = reinterpret_cast<MmaOperandA const *>(&A);
-    MmaOperandB const *ptr_B = reinterpret_cast<MmaOperandB const *>(&B);
-    MmaOperandC *ptr_D = reinterpret_cast<MmaOperandC *>(&D);
+    [[maybe_unused]] MmaOperandA const *ptr_A = reinterpret_cast<MmaOperandA const *>(&A);
+    [[maybe_unused]] MmaOperandB const *ptr_B = reinterpret_cast<MmaOperandB const *>(&B);
+    [[maybe_unused]] MmaOperandC *ptr_D = reinterpret_cast<MmaOperandC *>(&D);
 
     #if defined(__CUDA_ARCH__) && (__CUDA_ARCH__ < 800)
       assert(0);
     #elif defined(__CUDA_ARCH__) && (__CUDA_ARCH__ >= 800)
       // Serpentine visitation order maximizing reuse of Ra
       CUTLASS_PRAGMA_UNROLL
       for (int m = 0; m < MmaIterations::kRow; ++m) {
@@ -254,15 +254,15 @@
 
           mma(ptr_D[m + n_serpentine * MmaIterations::kRow],
               ptr_A[m],
               ptr_B[n_serpentine],
               ptr_D[m + n_serpentine * MmaIterations::kRow]);
 
           if (!kReduceKForA && m == 0) {
-            #if 0 
+            #if 0
             gemm_k_reduction[n_serpentine] += float(B[n_serpentine * 4]);
             gemm_k_reduction[n_serpentine] += float(B[n_serpentine * 4 + 1]);
             gemm_k_reduction[n_serpentine] += float(B[n_serpentine * 4 + 2]);
             gemm_k_reduction[n_serpentine] += float(B[n_serpentine * 4 + 3]);
             #else
             uint32_t const *tmp = reinterpret_cast<uint32_t const *>(&B);
 
@@ -302,20 +302,20 @@
             } else {
                 assert(0);
             }
             #endif
           }
 
           if (kReduceKForA && (n == 0)) {
-            #if 0 
+            #if 0
             gemm_k_reduction[m * 2] += float(A[m * 8]);
             gemm_k_reduction[m * 2] += float(A[m * 8 + 1]);
             gemm_k_reduction[m * 2] += float(A[m * 8 + 4]);
             gemm_k_reduction[m * 2] += float(A[m * 8 + 5]);
-  
+
             gemm_k_reduction[m * 2 + 1] += float(A[m * 8 + 2]);
             gemm_k_reduction[m * 2 + 1] += float(A[m * 8 + 3]);
             gemm_k_reduction[m * 2 + 1] += float(A[m * 8 + 6]);
             gemm_k_reduction[m * 2 + 1] += float(A[m * 8 + 7]);
             #else
             uint32_t const *tmp = reinterpret_cast<uint32_t const *>(&A);
 
@@ -407,17 +407,17 @@
                             FragmentB::kElements / 2, kRoundB>
           convert_B;
       Array<ElementB, FragmentB::kElements / 2> const *ptr_B =
           reinterpret_cast<Array<ElementB, FragmentB::kElements / 2> const *>(&B);
       Array<typename ArchMmaOperator::ElementB, FragmentB::kElements / 2> *
           ptr_dst_B = reinterpret_cast<Array<typename ArchMmaOperator::ElementB,
                                              FragmentB::kElements / 2> *>(&dst_B);
-  
+
       dst_A = convert_A(A);
-  
+
       ptr_dst_B[0] = convert_B(ptr_B[0]);
       ptr_dst_B[1] = convert_B(ptr_B[1]);
 
     #elif defined(__CUDA_ARCH__) && (__CUDA_ARCH__ >= 800)
       detail::ConvertAndPack<typename ArchMmaOperator::ElementA, ElementA,
                             FragmentA::kElements / 2, kRoundA>
           convert_A;
@@ -425,17 +425,17 @@
                             FragmentB::kElements, kRoundB>
           convert_B;
       Array<ElementA, FragmentA::kElements / 2> const *ptr_A =
           reinterpret_cast<Array<ElementA, FragmentA::kElements / 2> const *>(&A);
       Array<typename ArchMmaOperator::ElementA, FragmentA::kElements / 2> *
           ptr_dst_A = reinterpret_cast<Array<typename ArchMmaOperator::ElementA,
                                              FragmentA::kElements / 2> *>(&dst_A);
-  
+
       dst_B = convert_B(B);
-  
+
       ptr_dst_A[0] = convert_A(ptr_A[0]);
       ptr_dst_A[1] = convert_A(ptr_A[1]);
     #else
       assert(0);
     #endif
   }
 };
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/scale_bias_tile_iterator.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/scale_bias_tile_iterator.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/softmax_scale_bias_transform.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/softmax_scale_bias_transform.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/tile_iterator_planar_complex.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/gemm/warp/tile_iterator_planar_complex.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/half.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/half.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/integer_subbyte.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/integer_subbyte.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/kernel_launch.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/kernel_launch.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/layout/layout.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/layout/layout.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/layout/matrix.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/layout/matrix.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -35,14 +35,16 @@
     data to describe strides between elements.
 
     Layout functions must implement all members in the public interface of IdentityTensorLayout<>
     defined in cutlass/tensor_ref.h.
 */
 #pragma once
 
+#include "cute/layout.hpp"
+
 #include "cutlass/cutlass.h"
 #include "cutlass/fast_math.h"
 #include "cutlass/matrix_coord.h"
 #include "cutlass/pitch_linear_coord.h"
 
 namespace cutlass {
 namespace layout {
@@ -139,14 +141,23 @@
   }
 
   /// Compute the number of contiguous elements needed to store a tensor with the given size
   CUTLASS_HOST_DEVICE
   LongIndex capacity(MatrixCoord const &extent) const {
     return LongIndex(extent.row()) * LongIndex(stride_[0]);
   }
+
+  CUTLASS_HOST_DEVICE
+  cute::Layout<cute::Shape<int, int>, cute::Stride<int64_t, cute::Int<1> > > 
+  to_cute_layout(MatrixCoord const &extent) const {
+    return cute::Layout<cute::Shape<int, int>, cute::Stride<int64_t, cute::Int<1> > >{
+      {extent[0], extent[1]},
+      {stride(0), cute::Int<1>{}}
+    };
+  }
 };
 
 /// Mapping function for column-major matrices.
 class ColumnMajor {
 public:
   /// Logical rank of tensor
   static int const kRank = 2;
@@ -232,14 +243,23 @@
   }
 
   /// Compute the number of contiguous elements needed to store a tensor with the given size
   CUTLASS_HOST_DEVICE
   LongIndex capacity(MatrixCoord const &extent) const {
     return LongIndex(extent.column()) * LongIndex(stride_[0]);
   }
+
+  CUTLASS_HOST_DEVICE
+  cute::Layout<cute::Shape<int, int>, cute::Stride< cute::Int<1>, int64_t> > 
+  to_cute_layout(MatrixCoord const &extent) const {
+    return cute::Layout<cute::Shape<int, int>, cute::Stride<cute::Int<1>, int64_t> >{
+      {extent[0], extent[1]},
+      {cute::Int<1>{}, stride(0)}
+    };
+  }
 };
 
 /// Mapping function for interleaved matrices. Matrix is structured
 /// as row-major arrangement of fixed-size columns.
 template <int Interleave>
 struct RowMajorInterleaved {
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/layout/permute.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/layout/permute.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/layout/pitch_linear.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/layout/pitch_linear.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/layout/tensor.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/layout/tensor.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/layout/tensor_op_multiplicand_sm70.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/layout/tensor_op_multiplicand_sm70.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/layout/tensor_op_multiplicand_sm75.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/layout/tensor_op_multiplicand_sm75.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/layout/tensor_op_multiplicand_sm80.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/layout/tensor_op_multiplicand_sm80.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/layout/vector.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/layout/vector.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/matrix.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/matrix.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/matrix_coord.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/matrix_coord.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/matrix_shape.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/matrix_shape.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/numeric_conversion.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/numeric_conversion.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/numeric_types.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/numeric_types.h`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/pitch_linear_coord.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/pitch_linear_coord.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/platform/platform.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/platform/platform.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/predicate_vector.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/predicate_vector.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/quaternion.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/quaternion.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -741,14 +741,13 @@
     w += -a.y() * b.y();
     w += -a.z() * b.z();
 
     return cutlass::make_Quaternion(x, y, z, w);
   }
 };
 
-
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 } // namespace cutlass
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/real.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/real.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/reduction/device/reduce_split_k.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/reduction/device/reduce_split_k.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/reduction/device/tensor_reduce.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/reduction/device/tensor_reduce.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/reduction/device/tensor_reduce_affine_contiguous.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/reduction/device/tensor_reduce_affine_contiguous.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/reduction/device/tensor_reduce_affine_strided.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/reduction/device/tensor_reduce_affine_strided.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/reduction/kernel/reduce_softmax_final.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/reduction/kernel/reduce_softmax_final.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/reduction/kernel/reduce_split_k.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/reduction/kernel/reduce_split_k.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/reduction/kernel/tensor_reduce_affine_contiguous.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/reduction/kernel/tensor_reduce_affine_contiguous.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -79,15 +79,15 @@
   int64_t workspace_stride;                     /// stride (units of bytes) between workspace
   int workspace_count;                          /// number of workspaces
   
   uint64_t inner_count;                          /// Number of elements in reduced index space
   uint64_t outer_count;                          /// Number of elements in outer index space
 
   ElementOutput * destination;                  /// Pointer to output tensor of rank kReducedRank
-  ElementSource const * source;                 /// Poitner to source pointer of rank kRank
+  ElementSource const * source;                 /// Pointer to source pointer of rank kRank
   ReductionOp reduction_op;                     /// Reduction operator
   ElementCompute reduction_identity;            /// Identity element used by reduction operator
   ElementCompute *device_workspace;             /// Pointer to device workspace for inter-CTA reductions
 
   //
   // Methods
   //
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/reduction/kernel/tensor_reduce_affine_strided.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/reduction/kernel/tensor_reduce_affine_strided.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -81,15 +81,15 @@
   int64_t workspace_outer_stride;               /// stride (units of bytes) between 'rows' of the workspace
   int workspace_count;                          /// number of workspaces
   
   uint64_t inner_count;                          /// Number of elements in reduced index space
   uint64_t outer_count;                          /// Number of elements in outer index space
 
   ElementOutput * destination;                  /// Pointer to output tensor of rank kReducedRank
-  ElementSource const * source;                 /// Poitner to source pointer of rank kRank
+  ElementSource const * source;                 /// Pointer to source pointer of rank kRank
   ReductionOp reduction_op;                     /// Reduction operator
   ElementCompute reduction_identity;            /// Identity element for reduction operator
   ElementCompute *device_workspace;             /// Pointer to device workspace for inter-CTA reductions
 
   //
   // Methods
   //
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/reduction/thread/reduce.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/reduction/thread/reduce.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/reduction/thread/reduction_operators.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/reduction/thread/reduction_operators.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/reduction/threadblock_swizzle.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/reduction/threadblock_swizzle.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/relatively_equal.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/relatively_equal.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/semaphore.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/semaphore.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/subbyte_reference.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/subbyte_reference.h`

 * *Files 10% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -290,16 +290,26 @@
   explicit operator double() const {
     return double(get());
   }
 };
 
 template <
   typename Element_,              /// CUTLASS numeric element type.
-  typename Storage_ = uint8_t     /// Underlying storage type. Must be able to hold an integer 
+  typename Storage_ =             /// Underlying storage type. Must be able to hold an integer
                                   ///   number of objects of type Element.
+
+#if defined(__CUDA_ARCH__)        /// Default size depends on width of atomicCas() overloads.
+  #if (__CUDA_ARCH__ >= 700)      ///
+  uint16_t
+  #else
+  uint32_t
+  #endif
+#else
+  uint8_t
+#endif
 >
 class SubbyteReference {
 public:
 
   using Element = Element_;
   using Storage = Storage_;
   using StoragePointer = Storage *;
@@ -383,22 +393,49 @@
     return reinterpret_cast<Element const &>(item);
   }
 
   /// Stores an element to memory
   CUTLASS_HOST_DEVICE
   SubbyteReference & set(Element const &x) {
 
-    Storage item = (reinterpret_cast<Storage const &>(x) & kMask);
+    Storage item        = (reinterpret_cast<Storage const &>(x) & kMask);
+    Storage kUpdateMask = Storage(~(kMask << (offset_ * cutlass::sizeof_bits<Element>::value)));
+    Storage new_bits    = Storage(item << (offset_ * cutlass::sizeof_bits<Element>::value));
+
+#if defined(__CUDA_ARCH__)
+
+    //
+    // Homebrew read-modify-write
+    //
+    Storage original;
+    Storage updated;
+
+    do {
+
+      original = (*ptr_);
 
-    Storage kUpdateMask = Storage(~(kMask << (offset_ * sizeof_bits<Element>::value)));
-    *ptr_ = Storage((*ptr_ & kUpdateMask) | Storage(item << (offset_ * sizeof_bits<Element>::value)));
+      updated  = Storage((original & kUpdateMask) | new_bits);
+
+      original = atomicCAS(ptr_, original, updated);
+
+    } while (updated != original);
+
+#else
+
+    Storage original = (*ptr_);
+    Storage updated  = Storage((original & kUpdateMask) | new_bits);
+    *ptr_ = updated;
+
+#endif
 
     return *this;
   }
 
+  ////
+
   /// Unpacks an element from memory
   CUTLASS_HOST_DEVICE
   operator Element() const {
     return get();
   }
 
   /// Stores an element to memory
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/tensor_coord.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/tensor_coord.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/tensor_ref.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/tensor_ref.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/tensor_ref_planar_complex.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/tensor_ref_planar_complex.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/tensor_view.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/tensor_view.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/tensor_view_planar_complex.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/tensor_view_planar_complex.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/tfloat32.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/tfloat32.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/thread/matrix.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/thread/matrix.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/trace.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/trace.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/pitch_linear_thread_map.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/pitch_linear_thread_map.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -25,15 +25,15 @@
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /*! \file
-    \brief Templates implementing how threads are mapped to a given tile. 
+    \brief Templates implementing how threads are mapped to a given tile.
 
 */
 
 #pragma once
 
 #include "cutlass/cutlass.h"
 #include "cutlass/array.h"
@@ -159,17 +159,17 @@
   using TensorCoord = layout::PitchLinearCoord;
 
   static int const kThreads = Threads;
   static int const kElementsPerAccess = ElementsPerAccess;
 
   using Iterations = layout::PitchLinearShape<
                       Shape::kContiguous / (kThreads * kElementsPerAccess),
-                      Shape::kStrided>;                      
+                      Shape::kStrided>;
 
-  using Delta = layout::PitchLinearShape<1, 1>;  
+  using Delta = layout::PitchLinearShape<1, 1>;
 
   CUTLASS_HOST_DEVICE
   static TensorCoord initial_offset(int thread_id)
   {
     return TensorCoord(thread_id * Iterations::kContiguous * kElementsPerAccess, 0);
   }
 };
@@ -179,32 +179,32 @@
   int Threads,
   int ElementsPerAccess = 1
 >
 struct PitchLinearTilePolicyStripminedThreadStrided
 {
   static_assert((Shape::kStrided % Threads == 0),
                 "Strided shape must divide number of threads");
-  
+
   using TensorCoord = layout::PitchLinearCoord;
 
   static int const kThreads = Threads;
   static int const kElementsPerAccess = ElementsPerAccess;
 
   using Iterations = layout::PitchLinearShape<
                       Shape::kContiguous / kElementsPerAccess,
-                      Shape::kStrided / kThreads>;       
+                      Shape::kStrided / kThreads>;
 
-  using Delta = layout::PitchLinearShape<1, 1>;  
+  using Delta = layout::PitchLinearShape<1, 1>;
 
   using ShapeVec = Shape;
 
   CUTLASS_HOST_DEVICE
   static TensorCoord initial_offset(int thread_id)
   {
-    
+
     return TensorCoord(0, thread_id * Iterations::kStrided);
   }
 };
 
 
 ////////////////////////////////////////////////////////////////////////////////
 
@@ -330,15 +330,15 @@
     // This is the offset of a specific thread within a warp (units of vectors)
     layout::PitchLinearCoord thread_offset_in_warp{
       lane_id % Detail::WarpThreadArrangement::kContiguous,
       lane_id / Detail::WarpThreadArrangement::kContiguous
     };
 
     // This is the offset of a thread within a threadblock tile (units of vectors)
-    layout::PitchLinearCoord thread_offset_in_threadblock_tile_vec = 
+    layout::PitchLinearCoord thread_offset_in_threadblock_tile_vec =
       warp_footprint * warp_offset + thread_offset_in_warp;
 
     // This is the offset of a thread within a threadblock tile (units of elements)
     layout::PitchLinearCoord thread_offset_in_threadblock_tile_base{
       thread_offset_in_threadblock_tile_vec.contiguous() * kElementsPerAccess,
       thread_offset_in_threadblock_tile_vec.strided()
     };
@@ -456,15 +456,15 @@
     // This is the offset of a specific thread within a warp (units of vectors)
     layout::PitchLinearCoord thread_offset_in_warp{
       lane_id % Detail::WarpThreadArrangement::kContiguous,
       lane_id / Detail::WarpThreadArrangement::kContiguous
     };
 
     // This is the offset of a thread within a threadblock tile (units of vectors)
-    layout::PitchLinearCoord thread_offset_in_threadblock_tile_vec = 
+    layout::PitchLinearCoord thread_offset_in_threadblock_tile_vec =
       warp_footprint * warp_offset + thread_offset_in_warp;
 
     // This is the offset of a thread within a threadblock tile (units of elements)
     layout::PitchLinearCoord thread_offset_in_threadblock_tile_base{
       thread_offset_in_threadblock_tile_vec.contiguous() * kElementsPerAccess,
       thread_offset_in_threadblock_tile_vec.strided()
     };
@@ -597,29 +597,29 @@
     static int const kThreads = ThreadMap::kThreads;
 
     /// Extract vector length from Layout
     static int const kElementsPerAccess = ThreadMap::kElementsPerAccess;
 
     static_assert(kElementsPerAccess == 1 , "Simt transpose requires elements per access to be 1");
     ///< Iterations along each dimension (concept: PitchLinearShape)
-    using Iterations = 
+    using Iterations =
         layout::PitchLinearShape<ThreadMap::Iterations::kStrided,
         ThreadMap::Iterations::kContiguous>;
 
     static_assert(Iterations::kCount, "Number of iterations must be non-zero");
 
     static_assert(Iterations::kStrided == 1,
       "Strided iteration has to be one to reuse the same shared store function with those that don't need transpose");
 
     /// Shape of access by each thread
     using ThreadAccessShape = typename ThreadMap::ThreadAccessShape;
 
     ///< Delta betweeen accesses (units of elements, concept: PitchLinearShape)
     using Delta =
-        layout::PitchLinearShape<ThreadMap::Delta::kStrided, 
+        layout::PitchLinearShape<ThreadMap::Delta::kStrided,
         ThreadMap::Delta::kContiguous>;
 
 
     /// Maps thread ID to a coordinate offset within the tensor's logical
     /// coordinate space Note this is slightly different from the one of
     /// PitchLinearWarpRakedThreadMap.
     CUTLASS_HOST_DEVICE
@@ -689,20 +689,20 @@
     using WarpAccessIterations = layout::PitchLinearShape<
       ShapeInAccesses::kContiguous / WarpThreadArrangement::kContiguous,
       ShapeInAccesses::kStrided / WarpThreadArrangement::kStrided
     >;
 
     // Divide it into the number of warps, first partitioning the strided dimension then the
     // contiguous.
-    static int const kWarpsStrided = 
-      (WarpAccessIterations::kStrided >= kWarpCount 
+    static int const kWarpsStrided =
+      (WarpAccessIterations::kStrided >= kWarpCount
         ? kWarpCount : (kWarpCount / WarpAccessIterations::kStrided));
 
-    static int const kWarpsContiguous = 
-      (kWarpCount > WarpAccessIterations::kStrided ? 
+    static int const kWarpsContiguous =
+      (kWarpCount > WarpAccessIterations::kStrided ?
         WarpAccessIterations::kContiguous / kWarpsStrided : 1);
 
     /// Arrangement of warps within a threadblock-scoped tile
     using WarpArrangement = layout::PitchLinearShape<
       kWarpsContiguous, kWarpsStrided
     >;
   };
@@ -748,15 +748,15 @@
     // This is the offset of a specific thread within a warp (units of vectors)
     layout::PitchLinearCoord thread_offset_in_warp{
       lane_id % Detail::WarpThreadArrangement::kContiguous,
       lane_id / Detail::WarpThreadArrangement::kContiguous
     };
 
     // This is the offset of a thread within a threadblock tile (units of vectors)
-    layout::PitchLinearCoord thread_offset_in_threadblock_tile_vec = 
+    layout::PitchLinearCoord thread_offset_in_threadblock_tile_vec =
       warp_footprint * warp_offset + thread_offset_in_warp;
 
     // This is the offset of a thread within a threadblock tile (units of elements)
     layout::PitchLinearCoord thread_offset_in_threadblock_tile_base{
       thread_offset_in_threadblock_tile_vec.contiguous() * kElementsPerAccess,
       thread_offset_in_threadblock_tile_vec.strided()
     };
@@ -772,15 +772,15 @@
 /// The tile must be divisible by the thread count such that all threads may execute the same
 /// number of iterations with the same delta to exhaustively cover the tile.
 ///
 /// This class satisfies the "RegularThreadMapping" concept.
 template <
   typename Shape_,
   int Threads,
-	typename ThreadTileShape
+        typename ThreadTileShape
 >
 struct PitchLinear2DThreadTileStripminedThreadMap;
 
 
 template <
   typename Shape_,
   int Threads
@@ -863,15 +863,15 @@
 
     return TensorCoord(
       (thread_id % Detail::ShapeVec::kContiguous) * ThreadAccessShape::kContiguous,
       (thread_id / Detail::ShapeVec::kContiguous) * ThreadAccessShape::kStrided);
   }
 };
 
-/// Thread Mapping a 2D threadtiled mapping as a tranposed Pitchlinear2DThreadTile mapping
+/// Thread Mapping a 2D threadtiled mapping as a transposed Pitchlinear2DThreadTile mapping
 template <typename ThreadMap_>
 struct TransposePitchLinearThreadMap2DThreadTile {
     /// Underlying ThreadMap
     using ThreadMap = ThreadMap_;
 
     /// Tensor coordinate
     using TensorCoord = typename ThreadMap::TensorCoord;
@@ -884,26 +884,26 @@
 
     /// Extract vector length from Layout
     static int const kElementsPerAccess = ThreadMap::kElementsPerAccess;
 
 
     static_assert(kElementsPerAccess > 1 , "Simt transpose requires elements per access to be 1");
     ///< Iterations along each dimension (concept: PitchLinearShape)
-    using Iterations = 
+    using Iterations =
         layout::PitchLinearShape<ThreadMap::Iterations::kStrided,
         ThreadMap::Iterations::kContiguous>;
 
     static_assert(Iterations::kCount, "Number of iterations must be non-zero");
 
     /// Shape of access by each thread
     using ThreadAccessShape = typename ThreadMap::ThreadAccessShape;
 
     ///< Delta betweeen accesses (units of elements, concept: PitchLinearShape)
     using Delta =
-        layout::PitchLinearShape<ThreadMap::Delta::kStrided, 
+        layout::PitchLinearShape<ThreadMap::Delta::kStrided,
         ThreadMap::Delta::kContiguous>;
 
 
     /// Maps thread ID to a coordinate offset within the tensor's logical
     /// coordinate space Note this is slightly different from the one of
     /// PitchLinearWarpRakedThreadMap.
     CUTLASS_HOST_DEVICE
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/thread/transpose.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/thread/transpose.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/thread/unaryOp.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/thread/unary_op.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/ell_iterator.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/ell_iterator.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/ell_predicated_tile_access_iterator.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/ell_predicated_tile_access_iterator.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/ell_predicated_tile_iterator.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/ell_predicated_tile_iterator.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_scale_bias_vector_access_iterator.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_scale_bias_vector_access_iterator.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_scale_bias_vector_iterator.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_scale_bias_vector_iterator.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -395,15 +395,15 @@
   /// Internal pointer to first access of tile
   BytePointer pointer_;
 
   /// Used for out-of-order visitation
   bool is_residue_tile_;
 
   /// Below is used when Gather is turned on.  We need to record strided_offset
-  /// and contiguous_offset seperated to compute the offset by using
+  /// and contiguous_offset separated to compute the offset by using
   ///
   /// offset = contiguous_offset + indices[strided_offset]
   ///
 
   /// Gather indices
   int const *indices_;
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator_2dthreadtile.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator_2dthreadtile.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator_params.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator_params.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator_triangular_matrix.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator_triangular_matrix.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_tile_iterator.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_tile_iterator.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_tile_iterator_2dthreadtile.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_tile_iterator_2dthreadtile.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_tile_iterator_triangular_matrix.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_tile_iterator_triangular_matrix.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_vector_access_iterator.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_vector_access_iterator.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_scale_bias_vector_access_iterator.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_scale_bias_vector_access_iterator.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_pitch_linear.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_pitch_linear.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_pitch_linear_direct_conv.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_pitch_linear_direct_conv.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_tensor_op.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_tensor_op.h`

 * *Files 6% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -147,17 +147,14 @@
           thread_offset_base +
           layout::PitchLinearCoord{
               0, ThreadMap::Detail::WarpThreadArrangement::kStrided * i};
 
       // initialize pointer
       pointer_[i] = reinterpret_cast<AccessType *>(
           ref.data() + ref.offset(thread_offset_in_threadblock_tile));
-      if (((threadIdx.x / 32 == 0)) && (blockIdx.x == 0) && (blockIdx.y == 0) && (blockIdx.z == 0)) {
-          printf("Congruous, tidx = %d, i = %d, thread_offset_base kContiguous = %d, kStrided = %d, thread_offset_in_threadblock_tile kContiguous = %d, kStrided = %d, pointer_ = 0x%p\n", threadIdx.x, i, thread_offset_base.contiguous(), thread_offset_base.strided(), thread_offset_in_threadblock_tile.contiguous(), thread_offset_in_threadblock_tile.strided(), pointer_[i]);
-      }
     }
 
     set_iteration_index(0);
   }
 
   /// Overrides the internal iteration index
   CUTLASS_HOST_DEVICE
@@ -180,22 +177,14 @@
 
     int access_offset = stride_idx * ThreadMap::Delta::kStrided * stride_ +
                         iteration_contiguous_ * ThreadMap::Delta::kContiguous /
                             ThreadMap::kElementsPerAccess;
 
     char *access_byte_ptr =
         reinterpret_cast<char *>(access_ptr + access_offset);
-    if ((threadIdx.x == 0) && (blockIdx.x == 0) && (blockIdx.y == 0) && (blockIdx.z == 0)) {
-        printf("Congruous, tidx = %d, ts kContiguous = %d\n", threadIdx.x, Layout::TileShape::kContiguous);
-        printf("Congruous, tidx = %d, tm kStrided = %d\n", threadIdx.x, ThreadMap::Delta::kStrided);
-        printf("Congruous, tidx = %d, tm kContiguous = %d\n", threadIdx.x, ThreadMap::Delta::kContiguous);
-    }
-    if (((threadIdx.x / 32 == 0)) && (blockIdx.x == 0) && (blockIdx.y == 0) && (blockIdx.z == 0)) {
-        printf("Congruous, tidx = %d, access_ptr = 0x%p, stride_idx = %d, stride_ = %d, it_stride = %d, it_cont = %d, access_offset = %d, access_byte_ptr = 0x%p\n", threadIdx.x, access_ptr, stride_idx, stride_, iteration_strided_, iteration_contiguous_, access_offset, access_byte_ptr);
-    }
     return reinterpret_cast<AccessType *>(access_byte_ptr + byte_offset_);
   }
 
   /// Advances to the next tile in memory.
   CUTLASS_HOST_DEVICE
   RegularTileAccessIterator &operator++() {
     ++iteration_contiguous_;
@@ -547,17 +536,14 @@
           thread_offset_base +
           layout::PitchLinearCoord{
               0, ThreadMap::Detail::WarpThreadArrangement::kStrided * i};
       // initialize pointer
       pointer_[i] = reinterpret_cast<AccessType *>(ref.data()) +
                     ref.offset(thread_offset_in_threadblock_tile) /
                         Layout::kElementsPerAccess;
-      if (((threadIdx.x / 32 == 0)) && (blockIdx.x == 0) && (blockIdx.y == 0) && (blockIdx.z == 0)) {
-          printf("Crosswise, tidx = %d, i = %d, sections_ = %d, sections_per_stage_ = %d, thread_offset_base kContiguous = %d, kStrided = %d, thread_offset_in_threadblock_tile kContiguous = %d, kStrided = %d, pointer_ = 0x%p\n", threadIdx.x, i, sections_, sections_per_stage_, thread_offset_base.contiguous(), thread_offset_base.strided(), thread_offset_in_threadblock_tile.contiguous(), thread_offset_in_threadblock_tile.strided(), pointer_[i]);
-      }
     }
 
     set_iteration_index(0);
   }
 
   /// Overrides the internal iteration index
   CUTLASS_HOST_DEVICE
@@ -582,22 +568,14 @@
         stride_idx * ThreadMap::Delta::kStrided * stride_ / Layout::kFactor +
         // kCrosswise elements in the contiguous dimension would span to a
         // shared memory cache line.
         iteration_contiguous_ * (ThreadMap::Delta::kContiguous / kCrosswise) *
             Layout::TileShape::kContiguous;
     char *access_byte_ptr =
         reinterpret_cast<char *>(access_ptr + access_offset);
-    if ((threadIdx.x == 0) && (blockIdx.x == 0) && (blockIdx.y == 0) && (blockIdx.z == 0)) {
-        printf("Crosswise, tidx = %d, ts kContiguous = %d\n", threadIdx.x, Layout::TileShape::kContiguous);
-        printf("Crosswise, tidx = %d, tm kStrided = %d\n", threadIdx.x, ThreadMap::Delta::kStrided);
-        printf("Crosswise, tidx = %d, tm kContiguous = %d\n", threadIdx.x, ThreadMap::Delta::kContiguous);
-    }
-    if ((threadIdx.x / 32 == 0) && (blockIdx.x == 0) && (blockIdx.y == 0) && (blockIdx.z == 0)) {
-        printf("Crosswise, tidx = %d, access_ptr = 0x%p, stride_idx = %d, stride_ = %d, it_stride = %d, it_cont = %d, access_offset = %d, access_byte_ptr = 0x%p\n", threadIdx.x, access_ptr, stride_idx, stride_, iteration_strided_, iteration_contiguous_, access_offset, access_byte_ptr);
-    }
     return reinterpret_cast<AccessType *>(access_byte_ptr + byte_offset_);
   }
 
   /// Advances to the next tile in memory.
   CUTLASS_HOST_DEVICE
   RegularTileAccessIterator &operator++() {
     ++iteration_contiguous_;
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_tensor_op_sm80.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_tile_access_iterator_tensor_op_sm80.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_pitch_linear.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_pitch_linear.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_pitch_linear_2dthreadtile.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_pitch_linear_2dthreadtile.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_tensor_op.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_tensor_op.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -201,17 +201,14 @@
       CUTLASS_PRAGMA_UNROLL
       for (int c = 0; c < ThreadMap::Iterations::kContiguous; ++c) {
         int access_idx = c + s * ThreadMap::Iterations::kContiguous;
 
         char *byte_ptr = reinterpret_cast<char *>(address_iterator_.get()) + byte_offset;
         AccessType *access_ptr = reinterpret_cast<AccessType *>(byte_ptr);
 
-        if (((threadIdx.x / 32 == 0)) && (blockIdx.x == 0) && (blockIdx.y == 0) && (blockIdx.z == 0)) {
-            printf("Congruous, tidx = %d, s = %d, c = %d, access_idx = %d, byte_ptr = 0x%p\n", threadIdx.x, s, c, access_idx, byte_ptr);
-        }
         *access_ptr = frag_ptr[access_idx];
         ++address_iterator_;
       }
     }
   }
 
   /// Store a fragment to memory
@@ -608,17 +605,14 @@
       CUTLASS_PRAGMA_UNROLL
       for (int c = 0; c < ThreadMap::Iterations::kContiguous; ++c) {
         int access_idx = c + s * ThreadMap::Iterations::kContiguous;
 
         char *byte_ptr = reinterpret_cast<char *>(address_iterator_.get()) + byte_offset;
         AccessType *access_ptr = reinterpret_cast<AccessType *>(byte_ptr);
 
-        if (((threadIdx.x / 32 == 0)) && (blockIdx.x == 0) && (blockIdx.y == 0) && (blockIdx.z == 0)) {
-            printf("Crosswise, tidx = %d, s = %d, c = %d, access_idx = %d, byte_ptr = 0x%p\n", threadIdx.x, s, c, access_idx, byte_ptr);
-        }
         *access_ptr = frag_ptr[access_idx];
         ++address_iterator_;
       }
     }
   }
 
   /// Store a fragment to memory
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_tensor_op_sm70.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/regular_tile_iterator_tensor_op_sm70.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -1075,15 +1075,15 @@
 
  private:
   //
   // Data members
   //
 
   /// The crosswised elements will be stored in a line.
-  /// line_size is size of crosswised dimention plus padding.
+  /// line_size is size of crosswised dimension plus padding.
   /// in units of AccessType
   Index line_size;
 
   /// Internal pointer to first access of tile
   AccessType *pointer_[Detail::kPointerCount];
 
   /// Internal byte offset
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/vector_iterator.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/vector_iterator.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/transform/warp/vector_fragment_iterator.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/transform/warp/vector_fragment_iterator.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/uint128.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/include/cutlass/uint128.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -50,15 +50,15 @@
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 namespace cutlass {
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Optionally enable GCC's built-in type
-#if defined(__x86_64) && !defined(__CUDA_ARCH__) && defined(__GNUC__)
+#if (defined(__x86_64) || defined (__aarch64__)) && !defined(__CUDA_ARCH__) && defined(__GNUC__)
 #define CUTLASS_UINT128_NATIVE
 #elif defined(_MSC_VER) && defined(_M_AMD64) && !defined(__CUDA_ARCH__)
 #define CUTLASS_INT128_ARITHMETIC
 #include <intrin.h>
 #if _MSC_VER >= 1920
 #define CUTLASS_INT128_ARITHMETIC_DIV
 #include <immintrin.h>
@@ -67,15 +67,15 @@
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 ///! Unsigned 128b integer type
 struct uint128_t {
 
   /// Size of one part of the uint's storage in bits
-  int const kPartSize = sizeof_bits<uint64_t>::value;
+  static constexpr int kPartSize = sizeof_bits<uint64_t>::value;
 
   struct hilo {
     uint64_t lo;
     uint64_t hi;
 
     hilo() = default;
 
@@ -154,15 +154,15 @@
 #endif
     return y;
   }
 
   /// Multiply by unsigned 64b integer yielding 128b integer
   CUTLASS_HOST_DEVICE
   uint128_t operator*(uint64_t const &rhs) const {
-    uint128_t y;
+    uint128_t y{};
 #if defined(CUTLASS_UINT128_NATIVE)
     y.native = native * rhs;
 #elif defined(CUTLASS_INT128_ARITHMETIC)
     // Multiply by the low part
     y.hilo_.lo = _umul128(hilo_.lo, rhs, &y.hilo_.hi);
 
     // Add the high part and ignore the overflow
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/include/cutlass/wmma_array.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/cute.cpp`

 * *Files 19% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -24,70 +24,31 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
-/*! \file
-    \brief Statically sized array of elements that accommodates all CUTLASS-supported numeric types
-           and is safe to use in a union.
+/* \file
+   \brief binding CuTe C++ APIs to Python
 */
 
-#pragma once
+#include <pybind11/pybind11.h>
+#include <pybind11/stl_bind.h>
 
-#include "cutlass/arch/wmma.h"
+#include "cute/arch/mma_sm90_gmma.hpp"
 
-#if defined(CUTLASS_ARCH_WMMA_ENABLED)
+namespace py = pybind11;
 
-#include "cutlass/cutlass.h"
-#include "cutlass/array.h"
-#include "cutlass/functional.h"
 
-namespace cutlass {
+PYBIND11_MODULE(cute, m) {
 
-////////////////////////////////////////////////////////////////////////////////////////////////////
-
-/// Wmma array type (WmmaFragmentArray holds elements of of type nvcuda::wmma::fragment)
-template <
-  /// Element type
-  typename T,
-  /// Number of elements in the array
-  int N
->
-class WmmaFragmentArray: public Array<T, N, true> {
-public:
-
-  /// Efficient clear method (override Array::clear())
-  CUTLASS_HOST_DEVICE
-  void clear()
-  {
-    for(int i = 0; i < Array<T, N, true>::kElements; i++)
-    {
-      nvcuda::wmma::fill_fragment((*this)[i], (typename T::element_type)0);
-    }
-  }
-
-  CUTLASS_HOST_DEVICE
-  WmmaFragmentArray<T, N>& operator+=(const WmmaFragmentArray<T, N>& rhs)
-  {
-    using element_type = typename T::element_type;
-    plus<T> add;
-
-    for (int i = 0; i < Array<T, N, true>::kElements; i++)
-    {
-      (*this)[i] = add((*this)[i], rhs[i]);
-    }
-
-    return *this;
-  }
-
-};
-
-////////////////////////////////////////////////////////////////////////////////////////////////////
-
-} // namespace cutlass
-
-///////////////////////////////////////////////////////////////////////////////////////////////////
-
-#endif // if defined(CUTLASS_ARCH_WMMA_ENABLED)
+    // module doc
+    m.doc() = "CuTe C++ bindings";
 
+    py::enum_<cute::GMMA::Major>(m, "GMMAMajor",
+        R"pbdoc(classification of CuTe GMMA tensor major specification)pbdoc")
+        .value("K", cute::GMMA::Major::K,
+            R"pbdoc(Tensor is contiguous in reduction dimension)pbdoc")
+        .value("MN", cute::GMMA::Major::MN,
+            R"pbdoc(Tensor is contiguous in non-reduction dimension)pbdoc");
+}
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/common/cutlass_unit_test.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/common/cutlass_unit_test.h`

 * *Files 23% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -26,37 +26,47 @@
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 
 #pragma once
-#pragma warning (disable : 4068 ) /* disable unknown pragma warnings for vistual studio */
+#pragma warning (disable : 4068 ) /* disable unknown pragma warnings for visual studio */
 
 #pragma nv_diag_suppress boolean_controlling_expr_is_constant
 #include <gtest/gtest.h>
 #pragma nv_diag_warning boolean_controlling_expr_is_constant
 #pragma warning( disable : 4503)
 
 #include <cstdlib>
 #include <string>
+
+#include <cuda_runtime_api.h>
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+/// Gets a CUDA device
+cudaDeviceProp GetCudaDevice();
+
+/// Prints device properties
+std::ostream &operator<<(std::ostream &out, cudaDeviceProp const &device);
+
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Sets flags for Unit test
 void FilterArchitecture();
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Reads environment variable `CUTLASS_UNIT_TEST_PROBLEM_COUNT` to control the number and order
 //  of problem sizes run by CUTLASS unit tests
 int CutlassUnitTestProblemCount();
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-
 // active test macro
 #define CUTLASS_TEST_LEVEL_ACTIVE(LEVEL,NAME_STATIC,NAME_DYNAMIC,...) \
     TEST(NAME_STATIC,L##LEVEL##_##NAME_DYNAMIC) __VA_ARGS__
 
 // disabled test macro
 #define CUTLASS_TEST_LEVEL_DISABLED(LEVEL,NAME_STATIC,NAME_DYNAMIC,...) \
     TEST(NAME_STATIC,DISABLED_L##LEVEL##_##NAME_DYNAMIC) {}
@@ -74,7 +84,19 @@
 #define CUTLASS_TEST_L1(NAME_STATIC,NAME_DYNAMIC,...)   CUTLASS_TEST_LEVEL_ACTIVE(1,NAME_STATIC,NAME_DYNAMIC,__VA_ARGS__)
 #define CUTLASS_TEST_L2(NAME_STATIC,NAME_DYNAMIC,...)   CUTLASS_TEST_LEVEL_ACTIVE(2,NAME_STATIC,NAME_DYNAMIC,__VA_ARGS__)
 #endif
 
 #if !defined(CUTLASS_TEST_UNIT_ENABLE_WARNINGS)
 #define CUTLASS_TEST_UNIT_ENABLE_WARNINGS false
 #endif
+
+#if (__CUDACC_VER_MAJOR__ >= 12)
+  #define CUDA_12_0_SM90_FEATURES_SUPPORTED true
+#else
+  #define CUDA_12_0_SM90_FEATURES_SUPPORTED false
+#endif
+
+#include <cutlass/cutlass.h>
+#include <cutlass/numeric_types.h>
+#include <cutlass/trace.h>
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/common/filter_architecture.cpp` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/common/filter_architecture.cpp`

 * *Files 23% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -31,17 +31,57 @@
 
 #include <cuda_runtime_api.h>
 
 #include "cutlass_unit_test.h"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
+/// Gets a CUDA device
+cudaDeviceProp GetCudaDevice() {
+
+  cudaError_t err;
+
+  int cudaDeviceId;
+  err = cudaGetDevice(&cudaDeviceId);
+  if (cudaSuccess != err) {
+    std::cerr << "*** Error: Could not detect active GPU device ID"
+              << " [" << cudaGetErrorString(err) << "]" << std::endl;
+    exit(1);
+  }
+
+  cudaDeviceProp deviceProperties;
+  err = cudaGetDeviceProperties(&deviceProperties, cudaDeviceId);
+
+  return deviceProperties;
+}
+
+/// Prints device properties
+std::ostream &operator<<(std::ostream &out, cudaDeviceProp const &deviceProperties) {
+
+  int deviceMajorMinor = deviceProperties.major * 10 + deviceProperties.minor;
+  if (deviceMajorMinor) {
+    int32_t clock_MHz = deviceProperties.clockRate / 1000;
+    out << "GPU(compute_"
+      << deviceMajorMinor << ", "
+      << deviceProperties.multiProcessorCount << " SMs @ " << clock_MHz << " MHz)";
+  }
+  else {
+    out << "No CUDA device.";
+  }
+
+  return out;
+}
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
 /// Sets flags for Unit test
 void FilterArchitecture() {
   // Default flags can be overwritten by --gtest_filter from commandline
+
+  int const kMaxDevice = 999;
+
   cudaError_t err;
 
   int cudaDeviceId;
   err = cudaGetDevice(&cudaDeviceId);
   if (cudaSuccess != err) {
     std::cerr << "*** Error: Could not detect active GPU device ID"
               << " [" << cudaGetErrorString(err) << "]" << std::endl;
@@ -53,15 +93,14 @@
   if (cudaSuccess != err) {
     std::cerr << "*** Error: Could not get device properties for GPU " << cudaDeviceId << " ["
               << cudaGetErrorString(err) << "]" << std::endl;
     exit(1);
   }
 
   int deviceMajorMinor = deviceProperties.major * 10 + deviceProperties.minor;
-  int const kMaxDevice = 999;
 
   // Defines text filters for each GEMM kernel based on minimum supported compute capability
   struct {
 
     /// Unit test filter string
     char const *filter;
 
@@ -74,15 +113,15 @@
   test_filters[] = {
     { "SM50*",                      50, kMaxDevice},
     { "SM60*",                      60, kMaxDevice},
     { "SM61*",                      61, kMaxDevice},
     { "SM70*",                      70, 75},
     { "SM75*",                      75, kMaxDevice},
     { "SM80*",                      80, kMaxDevice},
-    { "SM90*",                      90, kMaxDevice},
+    { "SM90*",                      90, 90        },
     { 0, 0, false }
   };
 
   // Set negative test filters
   std::stringstream ss;
   ss << "-";
   for (int i = 0, j = 0; test_filters[i].filter; ++i) {
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/cache_testbed_output.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/cache_testbed_output.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm50.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm50.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f16_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f16_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm70.cu`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_dgrad_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_few_channels_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_few_channels_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_fixed_channels_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_fixed_channels_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm50.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm50.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f16_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f16_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm70.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm50.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm50.cu`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_qf32nhwc_qf32nhwc_qf32nhwc_simt_f32_sm50.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_qf32nhwc_qf32nhwc_qf32nhwc_simt_f32_sm50.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4ncxhwx_s4cxrskx_s4ncxhwx_tensor_op_s32_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4ncxhwx_s4cxrskx_s4ncxhwx_tensor_op_s32_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4ncxhwx_s4cxrskx_s4ncxhwx_tensor_op_s32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4ncxhwx_s4cxrskx_s4ncxhwx_tensor_op_s32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4nhwc_s4nhwc_s32nhwc_tensor_op_s32_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4nhwc_s4nhwc_s32nhwc_tensor_op_s32_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4nhwc_s4nhwc_s32nhwc_tensor_op_s32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s4nhwc_s4nhwc_s32nhwc_tensor_op_s32_sm80.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8ncxhwx_s8cxrskx_s8ncxhwx_tensor_op_s32_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8ncxhwx_s8cxrskx_s8ncxhwx_tensor_op_s32_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8ncxhwx_s8cxrskx_s8ncxhwx_tensor_op_s32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8ncxhwx_s8cxrskx_s8ncxhwx_tensor_op_s32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8nhwc_s8nhwc_s32nhwc_tensor_op_s32_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8nhwc_s8nhwc_s32nhwc_tensor_op_s32_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8nhwc_s8nhwc_s32nhwc_tensor_op_s32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_s8nhwc_s8nhwc_s32nhwc_tensor_op_s32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_with_broadcast_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_with_broadcast_sm70.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_with_broadcast_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_with_broadcast_sm75.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_with_reduction_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_fprop_with_reduction_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_problems.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_problems.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_strided_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_strided_dgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_strided_dgrad_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_strided_dgrad_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_testbed.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_testbed.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -569,15 +569,15 @@
 
   return true;
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////////////
 // TestAllConv: Runs cutlass::conv::device::ImplicitGemmConvolution operator and compares it with reference
 // TestAllConv runs conv operator on default conv problem sizes from test::conv::device::TestbedConv2dProblemSizes
-// Additionaly, each conv2d test can provide conv problem sizes (conv_test_sizes) and blacklist of sizes 
+// Additionally, each conv2d test can provide conv problem sizes (conv_test_sizes) and blacklist of sizes
 // (conv_blacklist_sizes)
 /////////////////////////////////////////////////////////////////////////////////////////////////////////////
 template <typename ImplicitGemm>
 bool TestAllConv2d(
   const Conv2dProblemVector & conv_test_sizes = Conv2dProblemVector(),
   const Conv2dProblemVector & conv_blacklist_sizes = Conv2dProblemVector()) {
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_testbed_interleaved.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_testbed_interleaved.h`

 * *Files 3% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -182,21 +182,57 @@
     tensor_B.sync_device();
     tensor_B_reordered.sync_device();
     tensor_C.sync_device();
     tensor_D_computed.sync_device();
     tensor_D_reference.sync_device();
   }
 
+  bool sufficient() const {
+    //
+    // Determine SMEM requirements and waive if not satisfied
+    //
+
+    int smem_size = int(sizeof(typename Conv2d::UnderlyingKernel::SharedStorage));
+
+    cudaDeviceProp properties;
+    int device_idx;
+    cudaError_t result = cudaGetDevice(&device_idx);
+
+    if (result != cudaSuccess) {
+      throw std::runtime_error("cudaGetDevice() API call failed.");
+    }
+
+    result = cudaGetDeviceProperties(&properties, device_idx);
+
+    if (result != cudaSuccess) {
+      throw std::runtime_error("cudaGetDeviceProperties() failed");
+    }
+
+    if (properties.sharedMemPerMultiprocessor < smem_size) {
+      return false;
+    }
+
+    return true;
+  }
+
   /// Executes one test
   bool run(
     cutlass::conv::Conv2dProblemSize const &problem_size,
     cutlass::conv::SplitKMode const &split_k_mode = cutlass::conv::SplitKMode::kSerial,
     ElementCompute alpha = ElementCompute(1),
     ElementCompute beta = ElementCompute(0)) {
 
+    // Waive test if insufficient CUDA device
+    if (!sufficient()) {
+      if (CUTLASS_TEST_UNIT_ENABLE_WARNINGS) {
+        std::cerr << "Test waived due to insufficient CUDA device." << std::endl;
+      }
+      return true;
+    }
+
 #if 0 //display conv2d problem size for debugging
     std::cout << problem_size << std::endl
               << "alpha, beta: (" << float(alpha) << ", " << float(beta) << ")" << std::endl
               << "split_k_mode: " << ((split_k_mode == cutlass::conv::SplitKMode::kSerial) ? "(serial)" : "(parallel)") << std::endl
               << std::endl;
 #endif
 
@@ -477,15 +513,15 @@
   }
 
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////////////
 // TestAllConv: Runs cutlass::conv::device::ImplicitGemmConvolution operator and compares it with reference
 // TestAllConv runs conv operator on default conv problem sizes from test::conv::device::TestbedConv2dProblemSizes
-// Additionaly, each conv2d test can provide conv problem sizes (conv_test_sizes) and blacklist of sizes 
+// Additionally, each conv2d test can provide conv problem sizes (conv_test_sizes) and blacklist of sizes
 // (conv_blacklist_sizes)
 /////////////////////////////////////////////////////////////////////////////////////////////////////////////
 template <typename ImplicitGemm, int InterleavedK>
 bool TestAllInterleavedConv2d(
   const Conv2dProblemVector & conv_test_sizes = Conv2dProblemVector(),
   const Conv2dProblemVector & conv_blacklist_sizes = Conv2dProblemVector()) {
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm50.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm50.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_cf32nhwc_cf32nhwc_cf32nhwc_simt_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f16_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f16_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm70.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f16nhwc_f16nhwc_f32nhwc_tensor_op_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_f32nhwc_f32nhwc_f32nhwc_simt_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_wgrad_implicit_gemm_tf32nhwc_tf32nhwc_f32nhwc_tensor_op_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_with_broadcast_testbed.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_with_broadcast_testbed.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -116,14 +116,15 @@
   using ElementC = typename Conv2d::ElementC;
   using LayoutC = typename Conv2d::LayoutC;
   using ElementAccumulator = typename Conv2d::ElementAccumulator;
   using ElementCompute = typename Conv2d::ElementCompute;
   using EpilogueOutputOp = typename Conv2d::EpilogueOutputOp;
   using ElementZ = typename EpilogueOutputOp::ElementZ;
   using ElementT = typename EpilogueOutputOp::ElementT;
+  using ElementVector = typename EpilogueOutputOp::ElementVector;
 
   static cutlass::conv::Operator const kConvolutionalOperator = Conv2d::kConvolutionalOperator;
   static const bool kAddBroadcastFirst = AddBroadcastFirst;
   static const bool kStoreT = EpilogueOutputOp::kStoreT;
 
 public:
 
@@ -138,15 +139,15 @@
   cutlass::HostTensor<ElementC, LayoutC> tensor_C;
   cutlass::HostTensor<ElementAccumulator, LayoutC> tensor_C_reference;
   cutlass::HostTensor<ElementZ, LayoutC> tensor_Z_computed;
   cutlass::HostTensor<ElementZ, LayoutC> tensor_Z_reference;
   cutlass::HostTensor<ElementT, LayoutC> tensor_T_computed;
   cutlass::HostTensor<ElementT, LayoutC> tensor_T_reference;
   cutlass::HostTensor<ElementAccumulator, LayoutC> tensor_Y_reference;
-  cutlass::HostTensor<ElementC, LayoutC> tensor_Broadcast;                 // Input Broadcast
+  cutlass::HostTensor<ElementVector, LayoutC> tensor_Broadcast;            // Input Broadcast
 
 public:
 
   TestbedConv2dWithBroadcast(
     cutlass::Distribution::Kind init_A_ = cutlass::Distribution::Uniform,
     cutlass::Distribution::Kind init_B_ = cutlass::Distribution::Uniform,
     cutlass::Distribution::Kind init_C_ = cutlass::Distribution::Uniform,
@@ -497,15 +498,15 @@
     return passed;
   }
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////////////
 // TestAllConv: Runs cutlass::conv::device::ImplicitGemmConvolution operator and compares it with reference
 // TestAllConv runs conv operator on default conv problem sizes from test::conv::device::TestbedConv2dProblemSizes
-// Additionaly, each conv2d test can provide conv problem sizes (conv_test_sizes) and blacklist of sizes 
+// Additionally, each conv2d test can provide conv problem sizes (conv_test_sizes) and blacklist of sizes
 // (conv_blacklist_sizes)
 /////////////////////////////////////////////////////////////////////////////////////////////////////////////
 template <typename ImplicitGemm,
           typename ReferenceOp = Conv2dWithBroadcastReferenceOp<ImplicitGemm>,
           bool AddBroadcastFirst = false,
           bool TestSplitK = true 
 >
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_with_reduction_testbed.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv2d_with_reduction_testbed.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -460,15 +460,15 @@
     return passed;
   }
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////////////
 // TestAllConv: Runs cutlass::conv::device::ImplicitGemmConvolution operator and compares it with reference
 // TestAllConv runs conv operator on default conv problem sizes from test::conv::device::TestbedConv2dProblemSizes
-// Additionaly, each conv2d test can provide conv problem sizes (conv_test_sizes) and blacklist of sizes 
+// Additionally, each conv2d test can provide conv problem sizes (conv_test_sizes) and blacklist of sizes
 // (conv_blacklist_sizes)
 /////////////////////////////////////////////////////////////////////////////////////////////////////////////
 template <typename ImplicitGemm>
 bool TestAllConv2dWithReduction(
   const Conv2dProblemVector & conv_test_sizes = Conv2dProblemVector(),
   const Conv2dProblemVector & conv_blacklist_sizes = Conv2dProblemVector()) {
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_dgrad_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_dgrad_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_dgrad_implicit_gemm_tf32ndhwc_tf32ndhwc_f32ndhwc_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_dgrad_implicit_gemm_tf32ndhwc_tf32ndhwc_f32ndhwc_tensor_op_f32_sm80.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_fprop_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_fprop_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_fprop_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_fprop_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_fprop_implicit_gemm_tf32ndhwc_tf32ndhwc_f32ndhwc_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_fprop_implicit_gemm_tf32ndhwc_tf32ndhwc_f32ndhwc_tensor_op_f32_sm80.cu`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_problems.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_problems.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_testbed.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_testbed.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -518,15 +518,15 @@
   }
 
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////////////
 // TestAllConv: Runs cutlass::conv::device::ImplicitGemmConvolution operator and compares it with reference
 // TestAllConv runs conv operator on default conv problem sizes from test::conv::device::TestbedConv2dProblemSizes
-// Additionaly, each conv3d test can provide conv problem sizes (conv_test_sizes) and blacklist of sizes 
+// Additionally, each conv3d test can provide conv problem sizes (conv_test_sizes) and blacklist of sizes
 // (conv_blacklist_sizes)
 /////////////////////////////////////////////////////////////////////////////////////////////////////////////
 
 template <typename ImplicitGemm>
 bool TestAllConv3d(
   const Conv3dProblemVector & conv_test_sizes = Conv3dProblemVector(),
   const Conv3dProblemVector & conv_blacklist_sizes = Conv3dProblemVector()) {
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm75.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm80.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_tf32ndhwc_tf32ndhwc_f32ndhwc_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_tf32ndhwc_tf32ndhwc_f32ndhwc_tensor_op_f32_sm80.cu`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/depthwise_conv2d_direct_conv_testbed.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/depthwise_conv2d_direct_conv_testbed.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_direct_conv_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_direct_conv_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -324,14 +324,15 @@
   using Direct2dConv = cutlass::conv::device::DirectConvolution<DepthwiseDirect2dConv>;
 
   /// Run all unit test sizes with device-level Conv2d instance
   EXPECT_TRUE(test::conv::device::TestSpecificDepthwiseDirectConv2d<Direct2dConv>(
       DepthwiseFpropProblemSizes_filter5x5()));
 }
 
+#if 0
 ////////////////////////////////////////////////////////////////////////////////
 TEST(
     SM60_Device_Depthwise_conv2d_Fprop_Direct_Conv_Optimized_f16nhwc_f16nhwc_f16nhwc_simt_f16,
     64x32_3_16x32_5x37) {
 
   using ElementInputA = cutlass::half_t;
   using ElementInputB = cutlass::half_t;
@@ -420,7 +421,9 @@
 
   using Direct2dConv = cutlass::conv::device::DirectConvolution<DepthwiseDirect2dConv>;
 
   /// Run all unit test sizes with device-level Conv2d instance
   EXPECT_TRUE(test::conv::device::TestSpecificDepthwiseDirectConv2d<Direct2dConv>(
       DepthwiseFpropProblemSizes_filter5x37()));
 }
+#endif
+
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_direct_conv_fixed_stride_dilation_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_direct_conv_fixed_stride_dilation_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/conv/device/group_conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/conv/device/group_conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/core/array.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/core/array.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/core/bfloat16.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/core/bfloat16.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/core/complex.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/core/complex.cu`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/core/float8.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/core/float8.cu`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/core/functional.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/core/functional.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/core/half.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/core/half.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/core/matrix.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/core/matrix.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/core/matrix_coord.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/core/matrix_coord.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/core/numeric_conversion.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/core/numeric_conversion.cu`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -148,17 +148,15 @@
   test::core::kernel::run_test<Destination, Source, kN>();
 }
 
 TEST(NumericConversion, f32_to_fe5m2_rn_array) {
   int const kN = 27;
   using Source = float;
   using Destination = cutlass::float_e5m2_t;
-
   test::core::kernel::run_test<Destination, Source, kN>();
-
 }
 
 TEST(NumericConversion, f16_to_fe4m3_rn) {
   int const kN = 1;
   using Source = cutlass::half_t;
   using Destination = cutlass::float_e4m3_t;
   test::core::kernel::run_test<Destination, Source, kN>();
@@ -246,24 +244,27 @@
 TEST(NumericConversion, fe4m3_to_f32_rn) {
   int const kN = 1;
   using Source = cutlass::float_e4m3_t;
   using Destination = float;
   test::core::kernel::run_test<Destination, Source, kN>();
 }
 
-TEST(NumericConversion, fe4m3_to_f32_array) {
-  int const kN = 27;
-  using Source = cutlass::float_e4m3_t;
-  using Destination = float;
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+TEST(NumericConversion, f32x8_to_s8x8_rn) {
+
+  int const kN = 8;
+  using Source = float;
+  using Destination = int8_t;
   test::core::kernel::run_test<Destination, Source, kN>();
 }
 
-TEST(NumericConversion, fe5m2_to_f32_rn) {
-  int const kN = 1;
-  using Source = cutlass::float_e5m2_t;
+TEST(NumericConversion, fe4m3_to_f32_array) {
+  int const kN = 27;
+  using Source = cutlass::float_e4m3_t;
   using Destination = float;
   test::core::kernel::run_test<Destination, Source, kN>();
 }
 
 TEST(NumericConversion, fe5m2_to_f32_array) {
   int const kN = 27;
   using Source = cutlass::float_e5m2_t;
@@ -324,39 +325,7 @@
   int const kN = 27;
   using Source = cutlass::float_e5m2_t;
   using Destination = cutlass::bfloat16_t;
   test::core::kernel::run_test<Destination, Source, kN>();
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
-
-TEST(NumericConversion, f32x8_to_s8x8_rn) {
-
-  int const kN = 8;
-  using Source = float;
-  using Destination = int8_t;
-
-  dim3 grid(1, 1);
-  dim3 block(1, 1);
-
-  cutlass::HostTensor<Destination, cutlass::layout::RowMajor> destination({1, kN});
-  cutlass::HostTensor<Source, cutlass::layout::RowMajor> source({1, kN});
-
-  for (int i = 0; i < kN; ++i) {
-    source.host_data()[i] = float(i);
-  }
-
-  source.sync_device();
-
-  test::core::kernel::convert<Destination, Source, kN><<< grid, block >>>(
-    reinterpret_cast<cutlass::Array<Destination, kN> *>(destination.device_data()),
-    reinterpret_cast<cutlass::Array<Source, kN> const *>(source.device_data())
-  );
-
-  destination.sync_host();
-
-  for (int i = 0; i < kN; ++i) {
-    EXPECT_TRUE(float(destination.host_data()[i]) == source.host_data()[i]);
-  }
-}
-
-/////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/core/predicate_vector.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/core/predicate_vector.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/core/quaternion.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/core/quaternion.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/core/tensor_ref.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/core/tensor_ref.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/core/tensor_view.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/core/tensor_view.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/core/test_unit_core.cpp` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/core/test_unit_core.cpp`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/core/tfloat32.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/core/tfloat32.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/thread/activation.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/thread/activation.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/thread/linear_combination.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/thread/linear_combination.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/thread/linear_combination_planar_complex.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/thread/linear_combination_planar_complex.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/epilogue_planar_complex.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/epilogue_planar_complex.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/epilogue_simt.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/epilogue_simt.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/epilogue_simt_sm60.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/epilogue_simt_sm60.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/epilogue_simt_sm61.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/epilogue_simt_sm61.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/epilogue_tensor_op.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/epilogue_tensor_op.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/epilogue_volta_tensor_op.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/epilogue_volta_tensor_op.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/epilogue_with_reduction_tensor_op.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/epilogue_with_reduction_tensor_op.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/epilogue_with_reduction_testbed.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/epilogue_with_reduction_testbed.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/epilogue_wmma_tensor_op_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/epilogue_wmma_tensor_op_sm70.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/output_tile_threadmap.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/output_tile_threadmap.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/predicated_tile_iterator.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/predicated_tile_iterator.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/testbed.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/testbed.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/testbed_planar_complex.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/testbed_planar_complex.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/warp/fragment_iterator_tensor_op.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/warp/fragment_iterator_tensor_op.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/warp/fragment_iterator_volta_tensor_op.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/warp/fragment_iterator_volta_tensor_op.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/epilogue/warp/fragment_iterator_wmma_tensor_op.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/epilogue/warp/fragment_iterator_wmma_tensor_op.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32n_tensor_op_s32_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32n_tensor_op_s32_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32n_tensor_op_s32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32n_tensor_op_s32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /**************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32n_wmma_tensor_op_s32_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32n_wmma_tensor_op_s32_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32t_tensor_op_s32_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32t_tensor_op_s32_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32t_tensor_op_s32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32t_tensor_op_s32_sm80.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /**************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32t_wmma_tensor_op_s32_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_b1t_b1n_s32t_wmma_tensor_op_s32_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_bf16n_bf16n_f32t_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_bf16n_bf16n_f32t_tensor_op_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_bf16t_bf16t_bf16t_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_bf16t_bf16t_bf16t_tensor_op_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_cf32n_cf32t_cf32t_tensor_op_tf32_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_cf32n_cf32t_cf32t_tensor_op_tf32_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_cf32t_cf32n_cf32t_tensor_op_tf32_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_cf32t_cf32n_cf32t_tensor_op_tf32_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_gaussian_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_gaussian_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_gaussian_sm90.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_gaussian_sm90.cu`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -46,15 +46,15 @@
 #include "cutlass/util/reference/host/tensor_fill.h"
 #include "cutlass/util/tensor_view_io.h"
 
 #include "testbed_complex.h"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-#if defined(CUTLASS_ARCH_MMA_SM90_SUPPORTED)
+#if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 TEST(SM90_Device_Gemm_cf64n_cf64t_cf64t_tensor_op_f64_gaussian, 32x32x16_16x16x16) {
 
   using Element = cutlass::complex<double>; 
 
@@ -189,10 +189,10 @@
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemmComplex<Gemm>());
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-#endif // #if defined(CUTLASS_ARCH_MMA_SM90_SUPPORTED)
+#endif // #if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_sm90.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_cf64n_cf64t_cf64t_tensor_op_f64_sm90.cu`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -46,15 +46,15 @@
 #include "cutlass/util/reference/host/tensor_fill.h"
 #include "cutlass/util/tensor_view_io.h"
 
 #include "testbed_complex.h"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-#if defined(CUTLASS_ARCH_MMA_SM90_SUPPORTED)
+#if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 TEST(SM90_Device_Gemm_cf64n_cf64t_cf64t_tensor_op_f64, 32x32x16_16x16x16) {
 
   using Element = cutlass::complex<double>;
 
@@ -243,10 +243,10 @@
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemmComplex<Gemm>());
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-#endif // #if defined(CUTLASS_ARCH_MMA_SM90_SUPPORTED)
+#endif // #if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_gaussian_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_gaussian_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_gaussian_sm90.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_gaussian_sm90.cu`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -46,15 +46,15 @@
 #include "cutlass/util/reference/host/tensor_fill.h"
 #include "cutlass/util/tensor_view_io.h"
 
 #include "testbed_complex.h"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-#if defined(CUTLASS_ARCH_MMA_SM90_SUPPORTED)
+#if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 TEST(SM90_Device_Gemm_cf64t_cf64n_cf64t_tensor_op_f64_gaussian, 32x32x8_16x16x8) {
   
   using Element = cutlass::complex<double>;
 
@@ -187,11 +187,11 @@
 
   EXPECT_TRUE(test::gemm::device::TestAllGemmComplex<Gemm>());
 }
 
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-#endif // #if defined(CUTLASS_ARCH_MMA_SM90_SUPPORTED)
+#endif // #if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_sm90.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_cf64t_cf64n_cf64t_tensor_op_f64_sm90.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -46,15 +46,15 @@
 #include "cutlass/util/reference/host/tensor_fill.h"
 #include "cutlass/util/tensor_view_io.h"
 
 #include "testbed_complex.h"
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-#if defined(CUTLASS_ARCH_MMA_SM90_SUPPORTED)
+#if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 TEST(SM90_Device_Gemm_cf64t_cf64n_cf64t_tensor_op_f64, 32x32x8_16x16x8) {
   
   using Element = cutlass::complex<double>;
 
@@ -295,11 +295,11 @@
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemmComplex<Gemm>());
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-#endif // #if defined(CUTLASS_ARCH_MMA_SM90_SUPPORTED)
+#endif // #if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16n_direct_store_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16n_direct_store_tensor_op_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16n_wmma_tensor_op_f16_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16n_wmma_tensor_op_f16_sm70.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16n_wmma_tensor_op_f32_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16n_wmma_tensor_op_f32_sm70.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_tensor_op_f32_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_tensor_op_f32_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_tensor_op_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_tensor_op_f32_sparse_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_tensor_op_f32_sparse_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_volta_tensor_op_f32_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_volta_tensor_op_f32_sm70.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_wmma_tensor_op_f16_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_wmma_tensor_op_f16_sm70.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_wmma_tensor_op_f32_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f16t_wmma_tensor_op_f32_sm70.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32n_tensor_op_f32_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32n_tensor_op_f32_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32n_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32n_tensor_op_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32n_wmma_tensor_op_f32_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32n_wmma_tensor_op_f32_sm70.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_tensor_op_f32_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_tensor_op_f32_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_tensor_op_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_tensor_op_f32_sparse_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_tensor_op_f32_sparse_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_volta_tensor_op_f32_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_volta_tensor_op_f32_sm70.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_wmma_tensor_op_f32_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16n_f32t_wmma_tensor_op_f32_sm70.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16n_wmma_tensor_op_f16_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16n_wmma_tensor_op_f16_sm70.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16n_wmma_tensor_op_f32_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16n_wmma_tensor_op_f32_sm70.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_slicedk_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_slicedk_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_slicedk_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_slicedk_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -26,14 +26,15 @@
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /*! \file
     \brief Tests for device-wide GEMM interface
+
 */
 
 #include <iostream>
 
 #include "cutlass/cutlass.h"
 #include "cutlass/gemm/device/gemm.h"
 
@@ -48,24 +49,24 @@
 
 #include "testbed.h"
 
 #if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Gemm_f16n_f16t_f16t_tensor_op_f16_sliced_k, 128x64x64_64x64x32) {
+TEST(SM80_Device_Gemm_f16t_f16n_f16t_tensor_op_f16_sliced_k, 128x64x64_64x64x32) {
 
   using ElementOutput = cutlass::half_t;
   using ElementAccumulator = cutlass::half_t;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
-    cutlass::layout::ColumnMajor,
-    cutlass::half_t,
     cutlass::layout::RowMajor,
+    cutlass::half_t,
+    cutlass::layout::ColumnMajor,
     ElementOutput,
     cutlass::layout::RowMajor,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm80,
     cutlass::gemm::GemmShape<128, 64, 64>,
     cutlass::gemm::GemmShape<64, 64, 32>,
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_sparse_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_sparse_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f32_sm80.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_volta_tensor_op_f16_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_volta_tensor_op_f32_sm70.cu`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -41,18 +41,18 @@
 
 #include "testbed.h"
 
 #if defined(CUTLASS_ARCH_MMA_SM70_SUPPORTED)
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM70_Device_Gemm_f16n_f16t_f16t_volta_tensor_op_f16, 128x256x32_64x64x32) {
+TEST(SM70_Device_Gemm_f16n_f16t_f32t_volta_tensor_op_f32, 128x256x32_64x64x32) {
 
-  using ElementOutput = cutlass::half_t;
-  using ElementAccumulator = cutlass::half_t;
+  using ElementOutput = float;
+  using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
     cutlass::layout::ColumnMajor,
     cutlass::half_t,
     cutlass::layout::RowMajor,
     ElementOutput,
@@ -68,22 +68,22 @@
       128 / cutlass::sizeof_bits<ElementOutput>::value,
       ElementAccumulator,
       ElementAccumulator
     >,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     2
   >;
-  
+
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM70_Device_Gemm_f16n_f16t_f16t_volta_tensor_op_f16, 256x128x32_64x64x32) {
+TEST(SM70_Device_Gemm_f16n_f16t_f32t_volta_tensor_op_f32, 256x128x32_64x64x32) {
 
-  using ElementOutput = cutlass::half_t;
-  using ElementAccumulator = cutlass::half_t;
+  using ElementOutput = float;
+  using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
     cutlass::layout::ColumnMajor,
     cutlass::half_t,
     cutlass::layout::RowMajor,
     ElementOutput,
@@ -103,18 +103,18 @@
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     2
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM70_Device_Gemm_f16n_f16t_f16t_volta_tensor_op_f16, 128x128x32_64x64x32) {
+TEST(SM70_Device_Gemm_f16n_f16t_f32t_volta_tensor_op_f32, 128x128x32_64x64x32) {
 
-  using ElementOutput = cutlass::half_t;
-  using ElementAccumulator = cutlass::half_t;
+  using ElementOutput = float;
+  using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
     cutlass::layout::ColumnMajor,
     cutlass::half_t,
     cutlass::layout::RowMajor,
     ElementOutput,
@@ -134,18 +134,18 @@
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     2
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM70_Device_Gemm_f16n_f16t_f16t_volta_tensor_op_f16, 128x64x32_64x32x32) {
+TEST(SM70_Device_Gemm_f16n_f16t_f32t_volta_tensor_op_f32, 128x64x32_64x32x32) {
 
-  using ElementOutput = cutlass::half_t;
-  using ElementAccumulator = cutlass::half_t;
+  using ElementOutput = float;
+  using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
     cutlass::layout::ColumnMajor,
     cutlass::half_t,
     cutlass::layout::RowMajor,
     ElementOutput,
@@ -165,18 +165,18 @@
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     2
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM70_Device_Gemm_f16n_f16t_f16t_volta_tensor_op_f16, 64x128x32_32x64x32) {
+TEST(SM70_Device_Gemm_f16n_f16t_f32t_volta_tensor_op_f32, 64x128x32_32x64x32) {
 
-  using ElementOutput = cutlass::half_t;
-  using ElementAccumulator = cutlass::half_t;
+  using ElementOutput = float;
+  using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
     cutlass::layout::ColumnMajor,
     cutlass::half_t,
     cutlass::layout::RowMajor,
     ElementOutput,
@@ -196,18 +196,18 @@
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     2
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM70_Device_Gemm_f16n_f16t_f16t_volta_tensor_op_f16, 64x64x32_64x64x32) {
+TEST(SM70_Device_Gemm_f16n_f16t_f32t_volta_tensor_op_f32, 64x64x32_64x64x32) {
 
-  using ElementOutput = cutlass::half_t;
-  using ElementAccumulator = cutlass::half_t;
+  using ElementOutput = float;
+  using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
     cutlass::layout::ColumnMajor,
     cutlass::half_t,
     cutlass::layout::RowMajor,
     ElementOutput,
@@ -227,18 +227,18 @@
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     2
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM70_Device_Gemm_f16n_f16t_f16t_volta_tensor_op_f16, 64x64x32_32x32x32) {
+TEST(SM70_Device_Gemm_f16n_f16t_f32t_volta_tensor_op_f32, 64x64x32_32x32x32) {
 
-  using ElementOutput = cutlass::half_t;
-  using ElementAccumulator = cutlass::half_t;
+  using ElementOutput = float;
+  using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
     cutlass::layout::ColumnMajor,
     cutlass::half_t,
     cutlass::layout::RowMajor,
     ElementOutput,
@@ -260,8 +260,8 @@
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-#endif
+#endif // if (CUTLASS_ENABLE_TENSOR_CORE_MMA)
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_wmma_tensor_op_f16_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_wmma_tensor_op_f16_sm70.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_wmma_tensor_op_f32_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_wmma_tensor_op_f32_sm70.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32n_wmma_tensor_op_f32_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32n_wmma_tensor_op_f32_sm70.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_tensor_op_f32_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_tensor_op_f32_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_tensor_op_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_tensor_op_f32_sparse_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_tensor_op_f32_sparse_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_volta_tensor_op_f32_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_volta_tensor_op_f32_sm70.cu`

 * *Files 3% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -35,30 +35,37 @@
 #include <iostream>
 
 #include "cutlass/cutlass.h"
 #include "cutlass/gemm/device/gemm.h"
 
 #include "../../common/cutlass_unit_test.h"
 
+#include "cutlass/util/host_tensor.h"
+#include "cutlass/util/tensor_view_io.h"
+#include "cutlass/util/reference/host/tensor_fill.h"
+#include "cutlass/util/reference/host/tensor_copy.h"
+#include "cutlass/util/reference/host/tensor_compare.h"
+#include "cutlass/util/reference/host/gemm.h"
+
 #include "testbed.h"
 
 #if defined(CUTLASS_ARCH_MMA_SM70_SUPPORTED)
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM70_Device_Gemm_f16n_f16t_f32t_volta_tensor_op_f32, 128x256x32_64x64x32) {
+TEST(SM70_Device_Gemm_f16t_f16n_f32t_volta_tensor_op_f32, 128x256x32_64x64x32) {
 
   using ElementOutput = float;
   using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
-    cutlass::layout::ColumnMajor,
-    cutlass::half_t,
     cutlass::layout::RowMajor,
+    cutlass::half_t,
+    cutlass::layout::ColumnMajor,
     ElementOutput,
     cutlass::layout::RowMajor,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm70,
     cutlass::gemm::GemmShape<128, 256, 32>,
     cutlass::gemm::GemmShape<64, 64, 32>,
@@ -72,24 +79,24 @@
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     2
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM70_Device_Gemm_f16n_f16t_f32t_volta_tensor_op_f32, 256x128x32_64x64x32) {
+TEST(SM70_Device_Gemm_f16t_f16n_f32t_volta_tensor_op_f32, 256x128x32_64x64x32) {
 
   using ElementOutput = float;
   using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
-    cutlass::layout::ColumnMajor,
-    cutlass::half_t,
     cutlass::layout::RowMajor,
+    cutlass::half_t,
+    cutlass::layout::ColumnMajor,
     ElementOutput,
     cutlass::layout::RowMajor,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm70,
     cutlass::gemm::GemmShape<256, 128, 32>,
     cutlass::gemm::GemmShape<64, 64, 32>,
@@ -103,24 +110,24 @@
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     2
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM70_Device_Gemm_f16n_f16t_f32t_volta_tensor_op_f32, 128x128x32_64x64x32) {
+TEST(SM70_Device_Gemm_f16t_f16n_f32t_volta_tensor_op_f32, 128x128x32_64x64x32) {
 
   using ElementOutput = float;
   using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
-    cutlass::layout::ColumnMajor,
-    cutlass::half_t,
     cutlass::layout::RowMajor,
+    cutlass::half_t,
+    cutlass::layout::ColumnMajor,
     ElementOutput,
     cutlass::layout::RowMajor,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm70,
     cutlass::gemm::GemmShape<128, 128, 32>,
     cutlass::gemm::GemmShape<64, 64, 32>,
@@ -134,24 +141,24 @@
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     2
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM70_Device_Gemm_f16n_f16t_f32t_volta_tensor_op_f32, 128x64x32_64x32x32) {
+TEST(SM70_Device_Gemm_f16t_f16n_f32t_volta_tensor_op_f32, 128x64x32_64x32x32) {
 
   using ElementOutput = float;
   using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
-    cutlass::layout::ColumnMajor,
-    cutlass::half_t,
     cutlass::layout::RowMajor,
+    cutlass::half_t,
+    cutlass::layout::ColumnMajor,
     ElementOutput,
     cutlass::layout::RowMajor,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm70,
     cutlass::gemm::GemmShape<128, 64, 32>,
     cutlass::gemm::GemmShape<64, 32, 32>,
@@ -165,24 +172,24 @@
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     2
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM70_Device_Gemm_f16n_f16t_f32t_volta_tensor_op_f32, 64x128x32_32x64x32) {
+TEST(SM70_Device_Gemm_f16t_f16n_f32t_volta_tensor_op_f32, 64x128x32_32x64x32) {
 
   using ElementOutput = float;
   using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
-    cutlass::layout::ColumnMajor,
-    cutlass::half_t,
     cutlass::layout::RowMajor,
+    cutlass::half_t,
+    cutlass::layout::ColumnMajor,
     ElementOutput,
     cutlass::layout::RowMajor,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm70,
     cutlass::gemm::GemmShape<64, 128, 32>,
     cutlass::gemm::GemmShape<32, 64, 32>,
@@ -196,24 +203,24 @@
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     2
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM70_Device_Gemm_f16n_f16t_f32t_volta_tensor_op_f32, 64x64x32_64x64x32) {
+TEST(SM70_Device_Gemm_f16t_f16n_f32t_volta_tensor_op_f32, 64x64x32_64x64x32) {
 
   using ElementOutput = float;
   using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
-    cutlass::layout::ColumnMajor,
-    cutlass::half_t,
     cutlass::layout::RowMajor,
+    cutlass::half_t,
+    cutlass::layout::ColumnMajor,
     ElementOutput,
     cutlass::layout::RowMajor,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm70,
     cutlass::gemm::GemmShape<64, 64, 32>,
     cutlass::gemm::GemmShape<64, 64, 32>,
@@ -227,24 +234,24 @@
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     2
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM70_Device_Gemm_f16n_f16t_f32t_volta_tensor_op_f32, 64x64x32_32x32x32) {
+TEST(SM70_Device_Gemm_f16t_f16n_f32t_volta_tensor_op_f32, 64x64x32_32x32x32) {
 
   using ElementOutput = float;
   using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
-    cutlass::layout::ColumnMajor,
-    cutlass::half_t,
     cutlass::layout::RowMajor,
+    cutlass::half_t,
+    cutlass::layout::ColumnMajor,
     ElementOutput,
     cutlass::layout::RowMajor,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm70,
     cutlass::gemm::GemmShape<64, 64, 32>,
     cutlass::gemm::GemmShape<32, 32, 32>,
@@ -260,8 +267,8 @@
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-#endif // if (CUTLASS_ENABLE_TENSOR_CORE_MMA)
+#endif
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_wmma_tensor_op_f32_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f32t_wmma_tensor_op_f32_sm70.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16n_singlestage_wmma_tensor_op_f16_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16n_singlestage_wmma_tensor_op_f16_sm70.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16n_wmma_tensor_op_f16_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16n_wmma_tensor_op_f16_sm70.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16n_wmma_tensor_op_f32_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16n_wmma_tensor_op_f32_sm70.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_singlestage_wmma_tensor_op_f16_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_singlestage_wmma_tensor_op_f16_sm70.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_broadcast_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_broadcast_sm80.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_slicedk_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_slicedk_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_slicedk_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16n_f16t_f16t_tensor_op_f16_slicedk_sm80.cu`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -26,15 +26,14 @@
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /*! \file
     \brief Tests for device-wide GEMM interface
-
 */
 
 #include <iostream>
 
 #include "cutlass/cutlass.h"
 #include "cutlass/gemm/device/gemm.h"
 
@@ -49,24 +48,24 @@
 
 #include "testbed.h"
 
 #if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Gemm_f16t_f16n_f16t_tensor_op_f16_sliced_k, 128x64x64_64x64x32) {
+TEST(SM80_Device_Gemm_f16n_f16t_f16t_tensor_op_f16_sliced_k, 128x64x64_64x64x32) {
 
   using ElementOutput = cutlass::half_t;
   using ElementAccumulator = cutlass::half_t;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
-    cutlass::layout::RowMajor,
-    cutlass::half_t,
     cutlass::layout::ColumnMajor,
+    cutlass::half_t,
+    cutlass::layout::RowMajor,
     ElementOutput,
     cutlass::layout::RowMajor,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm80,
     cutlass::gemm::GemmShape<128, 64, 64>,
     cutlass::gemm::GemmShape<64, 64, 32>,
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_sparse_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_tensor_op_f16_sparse_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_volta_tensor_op_f16_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_volta_tensor_op_f16_sm70.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_wmma_tensor_op_f16_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_wmma_tensor_op_f16_sm70.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_wmma_tensor_op_f32_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f16t_wmma_tensor_op_f32_sm70.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32n_wmma_tensor_op_f32_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32n_wmma_tensor_op_f32_sm70.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_singlestage_wmma_tensor_op_f32_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_singlestage_wmma_tensor_op_f32_sm70.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_tensor_op_f32_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_tensor_op_f32_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_tensor_op_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_tensor_op_f32_sparse_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_tensor_op_f32_sparse_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_volta_tensor_op_f32_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_volta_tensor_op_f32_sm70.cu`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -48,24 +48,24 @@
 
 #include "testbed.h"
 
 #if defined(CUTLASS_ARCH_MMA_SM70_SUPPORTED)
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM70_Device_Gemm_f16t_f16n_f32t_volta_tensor_op_f32, 128x256x32_64x64x32) {
+TEST(SM70_Device_Gemm_f16t_f16t_f32t_volta_tensor_op_f32, 128x256x32_64x64x32) {
 
   using ElementOutput = float;
   using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
     cutlass::layout::RowMajor,
     cutlass::half_t,
-    cutlass::layout::ColumnMajor,
+    cutlass::layout::RowMajor,
     ElementOutput,
     cutlass::layout::RowMajor,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm70,
     cutlass::gemm::GemmShape<128, 256, 32>,
     cutlass::gemm::GemmShape<64, 64, 32>,
@@ -79,24 +79,24 @@
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     2
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM70_Device_Gemm_f16t_f16n_f32t_volta_tensor_op_f32, 256x128x32_64x64x32) {
+TEST(SM70_Device_Gemm_f16t_f16t_f32t_volta_tensor_op_f32, 256x128x32_64x64x32) {
 
   using ElementOutput = float;
   using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
     cutlass::layout::RowMajor,
     cutlass::half_t,
-    cutlass::layout::ColumnMajor,
+    cutlass::layout::RowMajor,
     ElementOutput,
     cutlass::layout::RowMajor,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm70,
     cutlass::gemm::GemmShape<256, 128, 32>,
     cutlass::gemm::GemmShape<64, 64, 32>,
@@ -110,24 +110,24 @@
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     2
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM70_Device_Gemm_f16t_f16n_f32t_volta_tensor_op_f32, 128x128x32_64x64x32) {
+TEST(SM70_Device_Gemm_f16t_f16t_f32t_volta_tensor_op_f32, 128x128x32_64x64x32) {
 
   using ElementOutput = float;
   using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
     cutlass::layout::RowMajor,
     cutlass::half_t,
-    cutlass::layout::ColumnMajor,
+    cutlass::layout::RowMajor,
     ElementOutput,
     cutlass::layout::RowMajor,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm70,
     cutlass::gemm::GemmShape<128, 128, 32>,
     cutlass::gemm::GemmShape<64, 64, 32>,
@@ -137,59 +137,28 @@
       128 / cutlass::sizeof_bits<ElementOutput>::value,
       ElementAccumulator,
       ElementAccumulator
     >,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     2
   >;
-
+  
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM70_Device_Gemm_f16t_f16n_f32t_volta_tensor_op_f32, 128x64x32_64x32x32) {
+TEST(SM70_Device_Gemm_f16t_f16t_f32t_volta_tensor_op_f32, 64x128x32_32x64x32) {
 
   using ElementOutput = float;
   using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
     cutlass::layout::RowMajor,
     cutlass::half_t,
-    cutlass::layout::ColumnMajor,
-    ElementOutput,
-    cutlass::layout::RowMajor,
-    ElementAccumulator,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm70,
-    cutlass::gemm::GemmShape<128, 64, 32>,
-    cutlass::gemm::GemmShape<64, 32, 32>,
-    cutlass::gemm::GemmShape<8, 8, 4>,
-    cutlass::epilogue::thread::LinearCombination<
-      ElementOutput,
-      128 / cutlass::sizeof_bits<ElementOutput>::value,
-      ElementAccumulator,
-      ElementAccumulator
-    >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    2
-  >;
-
-  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
-}
-
-TEST(SM70_Device_Gemm_f16t_f16n_f32t_volta_tensor_op_f32, 64x128x32_32x64x32) {
-
-  using ElementOutput = float;
-  using ElementAccumulator = float;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-    cutlass::half_t,
     cutlass::layout::RowMajor,
-    cutlass::half_t,
-    cutlass::layout::ColumnMajor,
     ElementOutput,
     cutlass::layout::RowMajor,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm70,
     cutlass::gemm::GemmShape<64, 128, 32>,
     cutlass::gemm::GemmShape<32, 64, 32>,
@@ -203,55 +172,55 @@
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     2
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM70_Device_Gemm_f16t_f16n_f32t_volta_tensor_op_f32, 64x64x32_64x64x32) {
+TEST(SM70_Device_Gemm_f16t_f16t_f32t_volta_tensor_op_f32, 128x64x32_64x32x32) {
 
   using ElementOutput = float;
   using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
     cutlass::layout::RowMajor,
     cutlass::half_t,
-    cutlass::layout::ColumnMajor,
+    cutlass::layout::RowMajor,
     ElementOutput,
     cutlass::layout::RowMajor,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm70,
-    cutlass::gemm::GemmShape<64, 64, 32>,
-    cutlass::gemm::GemmShape<64, 64, 32>,
+    cutlass::gemm::GemmShape<128, 64, 32>,
+    cutlass::gemm::GemmShape<64, 32, 32>,
     cutlass::gemm::GemmShape<8, 8, 4>,
     cutlass::epilogue::thread::LinearCombination<
       ElementOutput,
       128 / cutlass::sizeof_bits<ElementOutput>::value,
       ElementAccumulator,
       ElementAccumulator
     >,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     2
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM70_Device_Gemm_f16t_f16n_f32t_volta_tensor_op_f32, 64x64x32_32x32x32) {
+TEST(SM70_Device_Gemm_f16t_f16t_f32t_volta_tensor_op_f32, 64x64x32_32x32x32) {
 
   using ElementOutput = float;
   using ElementAccumulator = float;
 
   using Gemm = cutlass::gemm::device::Gemm<
     cutlass::half_t,
     cutlass::layout::RowMajor,
     cutlass::half_t,
-    cutlass::layout::ColumnMajor,
+    cutlass::layout::RowMajor,
     ElementOutput,
     cutlass::layout::RowMajor,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm70,
     cutlass::gemm::GemmShape<64, 64, 32>,
     cutlass::gemm::GemmShape<32, 32, 32>,
@@ -267,8 +236,8 @@
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-#endif
+#endif // if (CUTLASS_ENABLE_TENSOR_CORE_MMA)
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_wmma_tensor_op_f32_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16n_f32t_wmma_tensor_op_f32_sm70.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16n_wmma_tensor_op_f16_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16n_wmma_tensor_op_f16_sm70.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16n_wmma_tensor_op_f32_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16n_wmma_tensor_op_f32_sm70.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16t_wmma_tensor_op_f16_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16t_wmma_tensor_op_f16_sm70.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16t_wmma_tensor_op_f32_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f16t_wmma_tensor_op_f32_sm70.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32n_tensor_op_f32_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32n_tensor_op_f32_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32n_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32n_tensor_op_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32n_wmma_tensor_op_f32_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32n_wmma_tensor_op_f32_sm70.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_tensor_op_f32_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_tensor_op_f32_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_tensor_op_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_tensor_op_f32_sparse_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_tensor_op_f32_sparse_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_volta_tensor_op_f32_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_f64n_f64n_tensor_op_f64_sm80.cu`

 * *Files 12% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -25,219 +25,229 @@
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /*! \file
-    \brief Tests for device-wide GEMM interface
+    \brief Tests for device-wide SYRK interface
+  
 */
 
 #include <iostream>
 
-#include "cutlass/cutlass.h"
-#include "cutlass/gemm/device/gemm.h"
-
 #include "../../common/cutlass_unit_test.h"
-
+#include "cutlass/blas3.h"
+#include "cutlass/gemm/device/rank_2k.h"
 #include "cutlass/util/host_tensor.h"
-#include "cutlass/util/tensor_view_io.h"
-#include "cutlass/util/reference/host/tensor_fill.h"
-#include "cutlass/util/reference/host/tensor_copy.h"
+#include "cutlass/util/reference/host/rank_2k.h"
 #include "cutlass/util/reference/host/tensor_compare.h"
-#include "cutlass/util/reference/host/gemm.h"
+#include "cutlass/util/reference/host/tensor_copy.h"
+#include "cutlass/util/reference/host/tensor_fill.h"
+#include "cutlass/util/tensor_view_io.h"
 
-#include "testbed.h"
+#include "testbed_rank2k_universal.h"
 
-#if defined(CUTLASS_ARCH_MMA_SM70_SUPPORTED)
+#if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM70_Device_Gemm_f16t_f16t_f32t_volta_tensor_op_f32, 128x256x32_64x64x32) {
+TEST(SM80_Device_Syr2k_f64n_f64n_l_tensor_op_f64, 32x32x16_16x16x16) {
 
-  using ElementOutput = float;
-  using ElementAccumulator = float;
+  using ElementA = double;
+  using LayoutA = cutlass::layout::ColumnMajor;
+  using ElementB = double;
+  using LayoutB = cutlass::layout::ColumnMajor;
+  using ElementC = double;
+  using LayoutC = cutlass::layout::ColumnMajor;
+  using ElementAccumulator = double;
 
-  using Gemm = cutlass::gemm::device::Gemm<
-    cutlass::half_t,
-    cutlass::layout::RowMajor,
-    cutlass::half_t,
-    cutlass::layout::RowMajor,
-    ElementOutput,
-    cutlass::layout::RowMajor,
+  using Rank2K = cutlass::gemm::device::Rank2K<
+    ElementA,
+    LayoutA,
+    ElementB,
+    LayoutB,
+    ElementC,
+    LayoutC,
+    cutlass::FillMode::kLower,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm70,
-    cutlass::gemm::GemmShape<128, 256, 32>,
-    cutlass::gemm::GemmShape<64, 64, 32>,
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<32, 32, 16>,
+    cutlass::gemm::GemmShape<16, 16, 16>,
     cutlass::gemm::GemmShape<8, 8, 4>,
     cutlass::epilogue::thread::LinearCombination<
-      ElementOutput,
-      128 / cutlass::sizeof_bits<ElementOutput>::value,
+      ElementC,
+      1,
       ElementAccumulator,
       ElementAccumulator
     >,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    2
+    4
   >;
 
-  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
+  EXPECT_TRUE(test::gemm::device::TestAllRank2KUniversal<Rank2K>());
+
 }
 
-TEST(SM70_Device_Gemm_f16t_f16t_f32t_volta_tensor_op_f32, 256x128x32_64x64x32) {
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM80_Device_Syr2k_f64n_f64n_l_tensor_op_f64, 64x64x16_32x32x16) {
 
-  using ElementOutput = float;
-  using ElementAccumulator = float;
+  using ElementA = double;
+  using LayoutA = cutlass::layout::ColumnMajor;
+  using ElementB = double;
+  using LayoutB = cutlass::layout::ColumnMajor;
+  using ElementC = double;
+  using LayoutC = cutlass::layout::ColumnMajor;
+  using ElementAccumulator = double;
 
-  using Gemm = cutlass::gemm::device::Gemm<
-    cutlass::half_t,
-    cutlass::layout::RowMajor,
-    cutlass::half_t,
-    cutlass::layout::RowMajor,
-    ElementOutput,
-    cutlass::layout::RowMajor,
+  using Rank2K = cutlass::gemm::device::Rank2K<
+    ElementA,
+    LayoutA,
+    ElementB,
+    LayoutB,
+    ElementC,
+    LayoutC,
+    cutlass::FillMode::kLower,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm70,
-    cutlass::gemm::GemmShape<256, 128, 32>,
-    cutlass::gemm::GemmShape<64, 64, 32>,
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<64, 64, 16>,
+    cutlass::gemm::GemmShape<32, 32, 16>,
     cutlass::gemm::GemmShape<8, 8, 4>,
     cutlass::epilogue::thread::LinearCombination<
-      ElementOutput,
-      128 / cutlass::sizeof_bits<ElementOutput>::value,
+      ElementC,
+      1,
       ElementAccumulator,
       ElementAccumulator
     >,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    2
+    4
   >;
 
-  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
-}
-
-TEST(SM70_Device_Gemm_f16t_f16t_f32t_volta_tensor_op_f32, 128x128x32_64x64x32) {
+  EXPECT_TRUE(test::gemm::device::TestAllRank2KUniversal<Rank2K>());
 
-  using ElementOutput = float;
-  using ElementAccumulator = float;
-
-  using Gemm = cutlass::gemm::device::Gemm<
-    cutlass::half_t,
-    cutlass::layout::RowMajor,
-    cutlass::half_t,
-    cutlass::layout::RowMajor,
-    ElementOutput,
-    cutlass::layout::RowMajor,
-    ElementAccumulator,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm70,
-    cutlass::gemm::GemmShape<128, 128, 32>,
-    cutlass::gemm::GemmShape<64, 64, 32>,
-    cutlass::gemm::GemmShape<8, 8, 4>,
-    cutlass::epilogue::thread::LinearCombination<
-      ElementOutput,
-      128 / cutlass::sizeof_bits<ElementOutput>::value,
-      ElementAccumulator,
-      ElementAccumulator
-    >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    2
-  >;
-  
-  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
-TEST(SM70_Device_Gemm_f16t_f16t_f32t_volta_tensor_op_f32, 64x128x32_32x64x32) {
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM80_Device_Syr2k_f64n_f64n_l_tensor_op_f64, 128x64x16_64x32x16) {
 
-  using ElementOutput = float;
-  using ElementAccumulator = float;
+  using ElementA = double;
+  using LayoutA = cutlass::layout::ColumnMajor;
+  using ElementB = double;
+  using LayoutB = cutlass::layout::ColumnMajor;
+  using ElementC = double;
+  using LayoutC = cutlass::layout::ColumnMajor;
+  using ElementAccumulator = double;
 
-  using Gemm = cutlass::gemm::device::Gemm<
-    cutlass::half_t,
-    cutlass::layout::RowMajor,
-    cutlass::half_t,
-    cutlass::layout::RowMajor,
-    ElementOutput,
-    cutlass::layout::RowMajor,
+  using Rank2K = cutlass::gemm::device::Rank2K<
+    ElementA,
+    LayoutA,
+    ElementB,
+    LayoutB,
+    ElementC,
+    LayoutC,
+    cutlass::FillMode::kLower,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm70,
-    cutlass::gemm::GemmShape<64, 128, 32>,
-    cutlass::gemm::GemmShape<32, 64, 32>,
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<128, 64, 16>,
+    cutlass::gemm::GemmShape<64, 32, 16>,
     cutlass::gemm::GemmShape<8, 8, 4>,
     cutlass::epilogue::thread::LinearCombination<
-      ElementOutput,
-      128 / cutlass::sizeof_bits<ElementOutput>::value,
+      ElementC,
+      1,
       ElementAccumulator,
       ElementAccumulator
     >,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    2
+    4
   >;
 
-  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
+  EXPECT_TRUE(test::gemm::device::TestAllRank2KUniversal<Rank2K>());
+
 }
 
-TEST(SM70_Device_Gemm_f16t_f16t_f32t_volta_tensor_op_f32, 128x64x32_64x32x32) {
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM80_Device_Syr2k_f64n_f64n_l_tensor_op_f64, 128x128x16_32x64x16) {
 
-  using ElementOutput = float;
-  using ElementAccumulator = float;
+  using ElementA = double;
+  using LayoutA = cutlass::layout::ColumnMajor;
+  using ElementB = double;
+  using LayoutB = cutlass::layout::ColumnMajor;
+  using ElementC = double;
+  using LayoutC = cutlass::layout::ColumnMajor;
+  using ElementAccumulator = double;
 
-  using Gemm = cutlass::gemm::device::Gemm<
-    cutlass::half_t,
-    cutlass::layout::RowMajor,
-    cutlass::half_t,
-    cutlass::layout::RowMajor,
-    ElementOutput,
-    cutlass::layout::RowMajor,
+  using Rank2K = cutlass::gemm::device::Rank2K<
+    ElementA,
+    LayoutA,
+    ElementB,
+    LayoutB,
+    ElementC,
+    LayoutC,
+    cutlass::FillMode::kLower,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm70,
-    cutlass::gemm::GemmShape<128, 64, 32>,
-    cutlass::gemm::GemmShape<64, 32, 32>,
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<128, 128, 16>,
+    cutlass::gemm::GemmShape<32, 64, 16>,
     cutlass::gemm::GemmShape<8, 8, 4>,
     cutlass::epilogue::thread::LinearCombination<
-      ElementOutput,
-      128 / cutlass::sizeof_bits<ElementOutput>::value,
+      ElementC,
+      1,
       ElementAccumulator,
       ElementAccumulator
     >,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    2
+    3
   >;
 
-  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
+  EXPECT_TRUE(test::gemm::device::TestAllRank2KUniversal<Rank2K>());
+
 }
 
-TEST(SM70_Device_Gemm_f16t_f16t_f32t_volta_tensor_op_f32, 64x64x32_32x32x32) {
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM80_Device_Syr2k_f64n_f64n_u_tensor_op_f64, 32x32x16_16x16x16) {
 
-  using ElementOutput = float;
-  using ElementAccumulator = float;
+  using ElementA = double;
+  using LayoutA = cutlass::layout::ColumnMajor;
+  using ElementB = double;
+  using LayoutB = cutlass::layout::ColumnMajor;
+  using ElementC = double;
+  using LayoutC = cutlass::layout::ColumnMajor;
+  using ElementAccumulator = double;
 
-  using Gemm = cutlass::gemm::device::Gemm<
-    cutlass::half_t,
-    cutlass::layout::RowMajor,
-    cutlass::half_t,
-    cutlass::layout::RowMajor,
-    ElementOutput,
-    cutlass::layout::RowMajor,
+  using Rank2K = cutlass::gemm::device::Rank2K<
+    ElementA,
+    LayoutA,
+    ElementB,
+    LayoutB,
+    ElementC,
+    LayoutC,
+    cutlass::FillMode::kUpper,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm70,
-    cutlass::gemm::GemmShape<64, 64, 32>,
-    cutlass::gemm::GemmShape<32, 32, 32>,
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<32, 32, 16>,
+    cutlass::gemm::GemmShape<16, 16, 16>,
     cutlass::gemm::GemmShape<8, 8, 4>,
     cutlass::epilogue::thread::LinearCombination<
-      ElementOutput,
-      128 / cutlass::sizeof_bits<ElementOutput>::value,
+      ElementC,
+      1,
       ElementAccumulator,
       ElementAccumulator
     >,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    2
+    4
   >;
 
-  EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
+  EXPECT_TRUE(test::gemm::device::TestAllRank2KUniversal<Rank2K>());
+
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
-
-#endif // if (CUTLASS_ENABLE_TENSOR_CORE_MMA)
+#endif // #if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_wmma_tensor_op_f32_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f16t_f16t_f32t_wmma_tensor_op_f32_sm70.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f32n_f32n_f32t_tensor_op_bf16_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f32n_f32n_f32t_tensor_op_bf16_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f32n_f32n_f32t_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f32n_f32n_f32t_tensor_op_f32_sm80.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f32n_f32n_f32t_tensor_op_f32_sparse_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f32n_f32n_f32t_tensor_op_f32_sparse_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f32n_f32t_f32t_tensor_op_f32_sparse_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f32n_f32t_f32t_tensor_op_f32_sparse_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f32t_f32n_f32t_tensor_op_f32_sparse_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f32t_f32n_f32t_tensor_op_f32_sparse_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f32t_f32t_f32t_tensor_op_f32_sparse_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f32t_f32t_f32t_tensor_op_f32_sparse_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f64n_f64t_f64t_tensor_op_f64_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f64n_f64t_f64t_tensor_op_f64_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f64n_f64t_f64t_tensor_op_f64_sm90.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f64n_f64t_f64t_tensor_op_f64_sm90.cu`

 * *Files 3% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -42,15 +42,15 @@
 #include "cutlass/util/reference/host/tensor_compare.h"
 #include "cutlass/util/reference/host/tensor_copy.h"
 #include "cutlass/util/reference/host/tensor_fill.h"
 #include "cutlass/util/tensor_view_io.h"
 
 #include "testbed.h"
 
-#if defined(CUTLASS_ARCH_MMA_SM90_SUPPORTED)
+#if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 TEST(SM90_Device_Gemm_f64n_f64t_f64t_tensor_op_f64, 32x32x16_16x16x16_16x8x4) {
 
   using ElementOutput = double;
   using ElementAccumulator = double;
@@ -216,8 +216,8 @@
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-#endif // if defined(CUTLASS_ARCH_MMA_SM90_SUPPORTED)
+#endif // if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f64t_f64n_f64t_tensor_op_f64_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f64t_f64n_f64t_tensor_op_f64_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f64t_f64n_f64t_tensor_op_f64_sm90.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_f64t_f64n_f64t_tensor_op_f64_sm90.cu`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -42,15 +42,15 @@
 #include "cutlass/util/reference/host/tensor_compare.h"
 #include "cutlass/util/reference/host/tensor_copy.h"
 #include "cutlass/util/reference/host/tensor_fill.h"
 #include "cutlass/util/tensor_view_io.h"
 
 #include "testbed.h"
 
-#if defined(CUTLASS_ARCH_MMA_SM90_SUPPORTED)
+#if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 TEST(SM90_Device_Gemm_f64t_f64n_f64t_tensor_op_f64, 32x32x16_16x16x16_16x8x4) {
 
   using ElementOutput = double;
   using ElementAccumulator = double;
@@ -216,8 +216,8 @@
     3
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllGemm<Gemm>());
 }
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-#endif // if (CUTLASS_ARCH_MMA_SM90_SUPPORTED)
+#endif // if (CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_grouped_scheduler_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_grouped_scheduler_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_grouped_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_grouped_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_planar_complex_f16_f16_f32_tensor_op_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_planar_complex_f16_f16_f32_tensor_op_sm70.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_planar_complex_f16_f16_f32_tensor_op_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_planar_complex_f16_f16_f32_tensor_op_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_planar_complex_f16_f16_f32_tensor_op_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_planar_complex_f16_f16_f32_tensor_op_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4n_s4t_s4n_tensor_op_s32_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4n_s4t_s4n_tensor_op_s32_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4n_s4t_s4n_tensor_op_s32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4n_s4t_s4n_tensor_op_s32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32n_tensor_op_s32_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32n_tensor_op_s32_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32n_tensor_op_s32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32n_tensor_op_s32_sm80.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /**************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32n_wmma_tensor_op_s32_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32n_wmma_tensor_op_s32_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_tensor_op_s32_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_tensor_op_s32_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_tensor_op_s32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_tensor_op_s32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /**************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_tensor_op_s32_sparse_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_tensor_op_s32_sparse_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /**************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_wmma_tensor_op_s32_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s32t_wmma_tensor_op_s32_sm75.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4n_tensor_op_s32_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4n_tensor_op_s32_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4n_tensor_op_s32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4n_tensor_op_s32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /**************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4t_tensor_op_s32_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4t_tensor_op_s32_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4t_tensor_op_s32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s4t_s4n_s4t_tensor_op_s32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /**************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8n_s8t_s8n_tensor_op_s32_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8n_s8t_s8n_tensor_op_s32_sm75.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8n_s8t_s8n_tensor_op_s32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8n_s8t_s8n_tensor_op_s32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32n_tensor_op_s32_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32n_tensor_op_s32_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32n_tensor_op_s32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32n_tensor_op_s32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /**************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32n_wmma_tensor_op_s32_sm72.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32n_wmma_tensor_op_s32_sm72.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_tensor_op_s32_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_tensor_op_s32_sm75.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_tensor_op_s32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_tensor_op_s32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /**************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_tensor_op_s32_sparse_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_tensor_op_s32_sparse_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /**************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_wmma_tensor_op_s32_sm72.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s32t_wmma_tensor_op_s32_sm72.cu`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8n_tensor_op_s32_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8n_tensor_op_s32_sm75.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8n_tensor_op_s32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8n_tensor_op_s32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /**************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8n_wmma_tensor_op_s32_sm72.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8n_wmma_tensor_op_s32_sm72.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8t_tensor_op_s32_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8t_tensor_op_s32_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8t_tensor_op_s32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8t_tensor_op_s32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /**************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8t_wmma_tensor_op_s32_sm72.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_s8t_s8n_s8t_wmma_tensor_op_s32_sm72.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_splitk_serial_tensor_op_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_splitk_serial_tensor_op_sm75.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_splitk_simt_sm50.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_splitk_simt_sm50.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_splitk_tensor_op_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_splitk_tensor_op_sm70.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_splitk_tensor_op_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_splitk_tensor_op_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_tf32n_tf32n_f32t_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_tf32n_tf32n_f32t_tensor_op_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_tf32n_tf32t_f32t_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_tf32n_tf32t_f32t_tensor_op_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_tf32t_tf32n_f32t_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_tf32t_tf32n_f32t_tensor_op_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_tf32t_tf32t_f32t_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_tf32t_tf32t_f32t_tensor_op_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_u8t_u8n_s32t_wmma_tensor_op_s32_sm72.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_u8t_u8n_s32t_wmma_tensor_op_s32_sm72.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_universal_cf32n_cf32n_cf32n_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_universal_cf32n_cf32n_cf32n_tensor_op_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_universal_cf64n_cf64t_cf64t_tensor_op_f64_gaussian_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_universal_cf64n_cf64t_cf64t_tensor_op_f64_gaussian_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_universal_cf64n_cf64t_cf64t_tensor_op_f64_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_universal_cf64n_cf64t_cf64t_tensor_op_f64_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_universal_f16n_f16t_f32n_tensor_op_f32_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_universal_f16n_f16t_f32n_tensor_op_f32_sm75.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_universal_f16n_f16t_f32t_tensor_op_f32_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_universal_f16n_f16t_f32t_tensor_op_f32_sm75.cu`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_with_broadcast_f16n_f16n_f16n_tensorop_f32_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_with_broadcast_f16n_f16n_f16n_tensorop_f32_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_with_reduction_f16n_f16n_f16n_tensorop_f32_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_with_reduction_f16n_f16n_f16n_tensorop_f32_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_with_reduction_f16t_f16n_f16n_tensorop_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemm_with_reduction_f16t_f16n_f16n_tensorop_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/gemv.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/gemv.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_f32_ls_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_f32_ls_sm80.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_f32_rs_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_f32_rs_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_fast_f32_ls_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_fast_f32_ls_sm80.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_fast_f32_rs_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/hemm_cf32h_cf32n_tensor_op_fast_f32_rs_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/hemm_cf64_cf64_cf64_tensor_op_f64_sm90.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/hemm_cf64_cf64_cf64_tensor_op_f64_sm90.cu`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -44,15 +44,15 @@
 #include "cutlass/util/reference/host/tensor_compare.h"
 #include "cutlass/util/reference/host/tensor_copy.h"
 #include "cutlass/util/reference/host/tensor_fill.h"
 #include "cutlass/util/tensor_view_io.h"
 
 #include "testbed_symm_universal.h"
 
-#if defined(CUTLASS_ARCH_MMA_SM90_SUPPORTED)
+#if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 TEST(SM90_Device_Hemm_cf64h_cf64n_ls_l_tensor_op_f64_gaussian, 32x32x16_16x16x16) {
 
   using ElementOutput = cutlass::complex<double>;
   using ElementAccumulator = cutlass::complex<double>;
@@ -128,8 +128,8 @@
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllSymmUniversal<Hemm>());
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-#endif // #if defined(CUTLASS_ARCH_MMA_SM90_SUPPORTED)
+#endif // #if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/hemm_cf64h_cf64n_cf64n_tensor_op_ls_f64_gaussian_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/hemm_cf64h_cf64n_cf64n_tensor_op_ls_f64_gaussian_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/hemm_cf64h_cf64n_cf64n_tensor_op_ls_f64_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/hemm_cf64h_cf64n_cf64n_tensor_op_ls_f64_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/hemm_cf64h_cf64n_cf64n_tensor_op_rs_f64_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/hemm_cf64h_cf64n_cf64n_tensor_op_rs_f64_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/her2k_cf32h_cf32n_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/her2k_cf32h_cf32n_tensor_op_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/her2k_cf32h_cf32n_tensor_op_fast_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/her2k_cf32h_cf32n_tensor_op_fast_f32_sm80.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/her2k_cf64_cf64_tensor_op_f64_sm90.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/her2k_cf64n_cf64n_tensor_op_f64_sm80.cu`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -42,19 +42,19 @@
 #include "cutlass/util/reference/host/tensor_compare.h"
 #include "cutlass/util/reference/host/tensor_copy.h"
 #include "cutlass/util/reference/host/tensor_fill.h"
 #include "cutlass/util/tensor_view_io.h"
 
 #include "testbed_rank2k_universal.h"
 
-#if defined(CUTLASS_ARCH_MMA_SM90_SUPPORTED)
+#if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM90_Device_Her2k_cf64n_cf64n_l_tensor_op_f64, 32x32x16_16x16x16) {
+TEST(SM80_Device_Her2k_cf64n_cf64n_l_tensor_op_f64, 32x32x16_16x16x16) {
 
   using ElementA = cutlass::complex<double>;
   using LayoutA = cutlass::layout::ColumnMajor;
 
   using ElementB = cutlass::complex<double>;
   using LayoutB = cutlass::layout::ColumnMajor;
 
@@ -68,18 +68,18 @@
     ElementB,
     LayoutB,
     ElementC,
     LayoutC,
     cutlass::FillMode::kLower,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm90,
+    cutlass::arch::Sm80,
     cutlass::gemm::GemmShape<32, 32, 16>,
     cutlass::gemm::GemmShape<16, 16, 16>,
-    cutlass::gemm::GemmShape<16, 8, 4>,
+    cutlass::gemm::GemmShape<8, 8, 4>,
     cutlass::epilogue::thread::LinearCombination<
       ElementC,
       1,
       ElementAccumulator,
       ElementAccumulator
     >,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
@@ -94,15 +94,15 @@
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllRank2KHermitianUniversal<Rank2K>());
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM90_Device_Her2k_cf64c_cf64n_u_tensor_op_f64, 32x32x16_16x16x16) {
+TEST(SM80_Device_Her2k_cf64h_cf64n_u_tensor_op_f64, 32x32x16_16x16x16) {
 
   using ElementA = cutlass::complex<double>;
   using LayoutA = cutlass::layout::RowMajor;
 
   using ElementB = cutlass::complex<double>;
   using LayoutB = cutlass::layout::RowMajor;
 
@@ -116,18 +116,18 @@
     ElementB,
     LayoutB,
     ElementC,
     LayoutC,
     cutlass::FillMode::kUpper,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm90,
+    cutlass::arch::Sm80,
     cutlass::gemm::GemmShape<32, 32, 16>,
     cutlass::gemm::GemmShape<16, 16, 16>,
-    cutlass::gemm::GemmShape<16, 8, 4>,
+    cutlass::gemm::GemmShape<8, 8, 4>,
     cutlass::epilogue::thread::LinearCombination<
       ElementC,
       1,
       ElementAccumulator,
       ElementAccumulator
     >,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
@@ -142,8 +142,8 @@
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllRank2KHermitianUniversal<Rank2K>());
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-#endif // #if defined(CUTLASS_ARCH_MMA_SM90_SUPPORTED)
+#endif // #if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/her2k_cf64h_cf64n_tensor_op_f64_grouped_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/her2k_cf64h_cf64n_tensor_op_f64_grouped_sm80.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/her2k_cf64n_cf64n_tensor_op_f64_grouped_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/her2k_cf64n_cf64n_tensor_op_f64_grouped_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/her2k_cf64n_cf64n_tensor_op_f64_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/her2k_cf64_cf64_tensor_op_f64_sm90.cu`

 * *Files 3% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -42,19 +42,19 @@
 #include "cutlass/util/reference/host/tensor_compare.h"
 #include "cutlass/util/reference/host/tensor_copy.h"
 #include "cutlass/util/reference/host/tensor_fill.h"
 #include "cutlass/util/tensor_view_io.h"
 
 #include "testbed_rank2k_universal.h"
 
-#if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
+#if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Her2k_cf64n_cf64n_l_tensor_op_f64, 32x32x16_16x16x16) {
+TEST(SM90_Device_Her2k_cf64n_cf64n_l_tensor_op_f64, 32x32x16_16x16x16) {
 
   using ElementA = cutlass::complex<double>;
   using LayoutA = cutlass::layout::ColumnMajor;
 
   using ElementB = cutlass::complex<double>;
   using LayoutB = cutlass::layout::ColumnMajor;
 
@@ -68,18 +68,18 @@
     ElementB,
     LayoutB,
     ElementC,
     LayoutC,
     cutlass::FillMode::kLower,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm80,
+    cutlass::arch::Sm90,
     cutlass::gemm::GemmShape<32, 32, 16>,
     cutlass::gemm::GemmShape<16, 16, 16>,
-    cutlass::gemm::GemmShape<8, 8, 4>,
+    cutlass::gemm::GemmShape<16, 8, 4>,
     cutlass::epilogue::thread::LinearCombination<
       ElementC,
       1,
       ElementAccumulator,
       ElementAccumulator
     >,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
@@ -94,15 +94,15 @@
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllRank2KHermitianUniversal<Rank2K>());
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Her2k_cf64h_cf64n_u_tensor_op_f64, 32x32x16_16x16x16) {
+TEST(SM90_Device_Her2k_cf64c_cf64n_u_tensor_op_f64, 32x32x16_16x16x16) {
 
   using ElementA = cutlass::complex<double>;
   using LayoutA = cutlass::layout::RowMajor;
 
   using ElementB = cutlass::complex<double>;
   using LayoutB = cutlass::layout::RowMajor;
 
@@ -116,18 +116,18 @@
     ElementB,
     LayoutB,
     ElementC,
     LayoutC,
     cutlass::FillMode::kUpper,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm80,
+    cutlass::arch::Sm90,
     cutlass::gemm::GemmShape<32, 32, 16>,
     cutlass::gemm::GemmShape<16, 16, 16>,
-    cutlass::gemm::GemmShape<8, 8, 4>,
+    cutlass::gemm::GemmShape<16, 8, 4>,
     cutlass::epilogue::thread::LinearCombination<
       ElementC,
       1,
       ElementAccumulator,
       ElementAccumulator
     >,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
@@ -142,8 +142,8 @@
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllRank2KHermitianUniversal<Rank2K>());
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-#endif // #if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
+#endif // #if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/her2k_cf64n_cf64t_tensor_op_f64_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/her2k_cf64n_cf64t_tensor_op_f64_sm80.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/herk_cf32h_cf32n_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/herk_cf32h_cf32n_tensor_op_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/herk_cf32h_cf32n_tensor_op_fast_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/herk_cf32h_cf32n_tensor_op_fast_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/herk_cf64_cf64_tensor_op_f64_sm90.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/herk_cf64_cf64_tensor_op_f64_sm90.cu`

 * *Files 6% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -42,15 +42,15 @@
 #include "cutlass/util/reference/host/tensor_compare.h"
 #include "cutlass/util/reference/host/tensor_copy.h"
 #include "cutlass/util/reference/host/tensor_fill.h"
 #include "cutlass/util/tensor_view_io.h"
 
 #include "testbed_rank_k_universal.h"
 
-#if defined(CUTLASS_ARCH_MMA_SM90_SUPPORTED)
+#if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 // HERK operator on CUBLAS_OP_C (row-major + conj) input layouts
 TEST(SM90_Device_Herk_cf64h_cf64n_l_tensor_op_f64, 64x64x16_32x32x16) {
 
   using ElementA = cutlass::complex<double>;
   using LayoutA = cutlass::layout::RowMajor;
@@ -86,8 +86,8 @@
     cutlass::BlasMode::kHermitian
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllRankKUniversal<RankK>());
 }
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-#endif // #if defined(CUTLASS_ARCH_MMA_SM90_SUPPORTED)
+#endif // #if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/herk_cf64h_cf64n_tensor_op_f64_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/herk_cf64h_cf64n_tensor_op_f64_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/multistage_testbed.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/multistage_testbed.h`

 * *Files 3% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -54,14 +54,19 @@
 namespace gemm {
 namespace device {
 
 ////////////////////////////////////////////////////////////////////////////////
 
 template <typename Gemm>
 struct MultistageTestbed {
+
+  using ElementA = typename Gemm::ElementA;
+  using ElementB = typename Gemm::ElementB;
+  using ElementC = typename Gemm::ElementC;
+
   using ElementAccumulator = typename Gemm::ElementAccumulator;
   using ElementCompute =
       typename Gemm::GemmKernel::Epilogue::OutputOp::ElementCompute;
 
   /// Initialization
   cutlass::Distribution::Kind init_A;
   cutlass::Distribution::Kind init_B;
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/multistage_testbed_interleaved.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/multistage_testbed_interleaved.h`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -55,14 +55,17 @@
 namespace device {
 
 ////////////////////////////////////////////////////////////////////////////////
 
 template <typename Gemm, int InterleavedK>
 struct MultistageInterleavedTestbed {
 
+  using ElementA = typename Gemm::ElementA;
+  using ElementB = typename Gemm::ElementB;
+  using ElementC = typename Gemm::ElementC;
   using ElementAccumulator = typename Gemm::ElementAccumulator;
   using ElementCompute = typename Gemm::GemmKernel::Epilogue::OutputOp::ElementCompute;
 
   /// Initialization
   cutlass::Distribution::Kind init_A;
   cutlass::Distribution::Kind init_B;
   cutlass::Distribution::Kind init_C;
@@ -106,20 +109,57 @@
       EXPECT_TRUE(false) << "Not implemented";
       return false;
     }
 
     return true;
   }
 
+  /// Returns true if the CUDA device is sufficient to execute the kernel.
+  bool sufficient() const {
+    //
+    // Determine SMEM requirements and waive if not satisfied
+    //
+
+    int smem_size = int(sizeof(typename Gemm::GemmKernel::SharedStorage));
+
+    cudaDeviceProp properties;
+    int device_idx;
+    cudaError_t result = cudaGetDevice(&device_idx);
+
+    if (result != cudaSuccess) {
+      throw std::runtime_error("cudaGetDevice() API call failed.");
+    }
+
+    result = cudaGetDeviceProperties(&properties, device_idx);
+
+    if (result != cudaSuccess) {
+      throw std::runtime_error("cudaGetDeviceProperties() failed");
+    }
+
+    if (properties.sharedMemPerMultiprocessor < smem_size) {
+      return false;
+    }
+
+    return true;
+  }
+
   /// Executes one test
   bool run(
     cutlass::gemm::GemmCoord problem_size, 
     ElementCompute alpha = ElementCompute(1), 
     ElementCompute beta = ElementCompute(0)) {
     
+    // Waive test if insufficient CUDA device
+    if (!sufficient()) {
+      if (CUTLASS_TEST_UNIT_ENABLE_WARNINGS) {
+        std::cerr << "Test waived due to insufficient CUDA device." << std::endl;
+      }
+      return true;
+    }
+
     //
     // Allocate the GEMM workspace
     //
 
     cutlass::HostTensor<
       typename Gemm::ElementA, 
       typename Gemm::LayoutA> tensor_A(problem_size.mk());
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/rank_2k_grouped_scheduler_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/rank_2k_grouped_scheduler_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_cgemm_nn_sm50.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_cgemm_nn_sm50.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_cgemm_nt_sm50.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_cgemm_nt_sm50.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_cgemm_nt_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_cgemm_nt_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_cgemm_tn_sm50.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_cgemm_tn_sm50.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_cgemm_tn_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_cgemm_tn_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_cgemm_tt_sm50.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_cgemm_tt_sm50.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_dgemm_nn_sm50.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_dgemm_nn_sm50.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_dgemm_nt_sm50.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_dgemm_nt_sm50.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_dgemm_tn_sm50.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_dgemm_tn_sm50.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_dgemm_tt_sm50.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_dgemm_tt_sm50.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_f8gemm_tn_sm50.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_f8gemm_tn_sm50.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_hgemm_nn_sm50.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_hgemm_nn_sm50.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_hgemm_nt_sm50.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_hgemm_nt_sm50.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_hgemm_tn_sm50.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_hgemm_tn_sm50.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_hgemm_tt_sm50.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_hgemm_tt_sm50.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_igemm_nn_sm50.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_igemm_nn_sm50.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_igemm_nt_sm50.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_igemm_nt_sm50.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_igemm_tn_sm50.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_igemm_tn_sm50.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_igemm_tt_sm50.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_igemm_tt_sm50.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_int8_igemm_sm61.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_int8_igemm_sm61.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_int8_igemm_sm61_perf.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_int8_igemm_sm61_perf.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_int8_igemm_sm61_sliced_k.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_int8_igemm_sm61_sliced_k.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_qgemm_nn_sm50.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_qgemm_nn_sm50.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_qgemm_nt_sm50.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_qgemm_nt_sm50.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_qgemm_tn_sm50.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_qgemm_tn_sm50.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_qgemm_tt_sm50.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_qgemm_tt_sm50.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_sgemm_nn_sm50.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_sgemm_nn_sm50.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_sgemm_nt_sm50.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_sgemm_nt_sm50.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_sgemm_nt_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_sgemm_nt_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_sgemm_tn_sm50.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_sgemm_tn_sm50.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_sgemm_tn_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_sgemm_tn_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_sgemm_tt_sm50.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_sgemm_tt_sm50.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_zgemm_nn_sm50.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_zgemm_nn_sm50.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_zgemm_nt_sm50.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_zgemm_nt_sm50.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_zgemm_tn_sm50.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_zgemm_tn_sm50.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_zgemm_tt_sm50.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/simt_zgemm_tt_sm50.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_f32_ls_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_f32_ls_sm80.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_f32_rs_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_f32_rs_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_fast_f32_ls_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_fast_f32_ls_sm80.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_fast_f32_rs_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_fast_f32_rs_sm80.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_cf64_cf64_cf64_tensor_op_f64_sm90.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_cf64_cf64_cf64_tensor_op_f64_sm90.cu`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -44,15 +44,15 @@
 #include "cutlass/util/reference/host/tensor_compare.h"
 #include "cutlass/util/reference/host/tensor_copy.h"
 #include "cutlass/util/reference/host/tensor_fill.h"
 #include "cutlass/util/tensor_view_io.h"
 
 #include "testbed_symm_universal.h"
 
-#if defined(CUTLASS_ARCH_MMA_SM90_SUPPORTED)
+#if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 TEST(SM90_Device_Symm_cf64n_cf64n_ls_l_tensor_op_f64_gaussian, 32x32x16_16x16x16) {
 
   using ElementOutput = cutlass::complex<double>;
   using ElementAccumulator = cutlass::complex<double>;
@@ -126,8 +126,8 @@
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllSymmUniversal<Symm>());
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-#endif // #if defined(CUTLASS_ARCH_MMA_SM90_SUPPORTED)
+#endif // #if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_cf64n_cf64n_cf64n_tensor_op_ls_f64_gaussian_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_cf64n_cf64n_cf64n_tensor_op_ls_f64_gaussian_sm80.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_cf64n_cf64n_cf64n_tensor_op_ls_f64_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_cf64n_cf64n_cf64n_tensor_op_ls_f64_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_cf64n_cf64n_cf64n_tensor_op_rs_f64_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_cf64n_cf64n_cf64n_tensor_op_rs_f64_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f32n_f32n_tensor_op_fast_f32_ls_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f32n_f32n_tensor_op_fast_f32_ls_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f32n_f32n_tensor_op_fast_f32_rs_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f32n_f32n_tensor_op_fast_f32_rs_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f32t_f32t_tensor_op_fast_f32_ls_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f32t_f32t_tensor_op_fast_f32_ls_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f64_f64_tensor_op_f64_sm90.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f64_f64_tensor_op_f64_sm90.cu`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -43,15 +43,15 @@
 #include "cutlass/util/reference/host/tensor_compare.h"
 #include "cutlass/util/reference/host/tensor_copy.h"
 #include "cutlass/util/reference/host/tensor_fill.h"
 #include "cutlass/util/tensor_view_io.h"
 
 #include "testbed_symm_universal.h"
 
-#if defined(CUTLASS_ARCH_MMA_SM90_SUPPORTED)
+#if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 TEST(SM90_Device_Symm_f64n_f64n_rs_l_tensor_op_f64, 32x32x16_16x16x16) {
 
   using ElementA = double;
   using LayoutA = cutlass::layout::ColumnMajor;
@@ -128,8 +128,8 @@
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllSymmUniversal<Symm>());
 
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
-#endif // #if defined(CUTLASS_ARCH_MMA_SM90_SUPPORTED)
+#endif // #if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f64n_f64n_tensor_op_f64_ls_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f64n_f64n_tensor_op_f64_ls_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f64n_f64n_tensor_op_f64_rs_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f64n_f64n_tensor_op_f64_rs_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f64n_f64t_tensor_op_f64_ls_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f64n_f64t_tensor_op_f64_ls_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f64n_f64t_tensor_op_f64_rs_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f64n_f64t_tensor_op_f64_rs_sm80.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f64t_f64n_tensor_op_f64_ls_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f64t_f64n_tensor_op_f64_ls_sm80.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f64t_f64n_tensor_op_f64_rs_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f64t_f64n_tensor_op_f64_rs_sm80.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f64t_f64t_tensor_op_f64_ls_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f64t_f64t_tensor_op_f64_ls_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f64t_f64t_tensor_op_f64_rs_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_f64t_f64t_tensor_op_f64_rs_sm80.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_tf32n_f32n_tensor_op_f32_ls_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_tf32n_f32n_tensor_op_f32_ls_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_tf32n_f32n_tensor_op_f32_rs_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_tf32n_f32n_tensor_op_f32_rs_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_tf32t_f32t_tensor_op_f32_ls_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/symm_tf32t_f32t_tensor_op_f32_ls_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32n_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32n_tensor_op_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32n_tensor_op_fast_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32n_tensor_op_fast_f32_sm80.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32t_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32t_tensor_op_f32_sm80.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32t_tensor_op_fast_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf32n_cf32t_tensor_op_fast_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf64_cf64_tensor_op_f64_sm90.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf64_cf64_tensor_op_f64_sm90.cu`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -43,15 +43,15 @@
 #include "cutlass/util/reference/host/tensor_compare.h"
 #include "cutlass/util/reference/host/tensor_copy.h"
 #include "cutlass/util/reference/host/tensor_fill.h"
 #include "cutlass/util/tensor_view_io.h"
 
 #include "testbed_rank2k_universal.h"
 
-#if defined(CUTLASS_ARCH_MMA_SM90_SUPPORTED)
+#if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 TEST(SM90_Device_Syr2k_cf64n_cf64n_l_tensor_op_f64, 32x32x16_16x16x16) {
 
   using ElementA = cutlass::complex<double>;
   using LayoutA = cutlass::layout::ColumnMajor;
@@ -143,8 +143,8 @@
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllRank2KUniversal<Rank2K>());
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-#endif // #if defined(CUTLASS_ARCH_MMA_SM90_SUPPORTED)
+#endif // #if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64n_tensor_op_f64_grouped_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64n_tensor_op_f64_grouped_sm80.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64n_tensor_op_f64_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64n_tensor_op_f64_sm80.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64t_tensor_op_f64_grouped_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64t_tensor_op_f64_grouped_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64t_tensor_op_f64_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf64n_cf64t_tensor_op_f64_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf64t_cf64n_tensor_op_f64_grouped_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf64t_cf64n_tensor_op_f64_grouped_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf64t_cf64t_tensor_op_f64_grouped_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_cf64t_cf64t_tensor_op_f64_grouped_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_f32n_f32n_tensor_op_fast_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_f32n_f32n_tensor_op_fast_f32_sm80.cu`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_f32t_f32n_tensor_op_fast_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_f32t_f32n_tensor_op_fast_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_f64_f64_tensor_op_f64_sm90.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_f64_f64_tensor_op_f64_sm90.cu`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -43,15 +43,15 @@
 #include "cutlass/util/reference/host/tensor_compare.h"
 #include "cutlass/util/reference/host/tensor_copy.h"
 #include "cutlass/util/reference/host/tensor_fill.h"
 #include "cutlass/util/tensor_view_io.h"
 
 #include "testbed_rank2k_universal.h"
 
-#if defined(CUTLASS_ARCH_MMA_SM90_SUPPORTED)
+#if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 TEST(SM90_Device_Syr2k_f64n_f64n_l_tensor_op_f64, 32x32x16_16x16x16) {
 
   using ElementA = double;
   using LayoutA = cutlass::layout::ColumnMajor;
@@ -127,8 +127,8 @@
 
   EXPECT_TRUE(test::gemm::device::TestAllRank2KUniversal<Rank2K>());
 
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-#endif // #if defined(CUTLASS_ARCH_MMA_SM90_SUPPORTED)
+#endif // #if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_f64n_f64n_tensor_op_f64_grouped_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_f64n_f64n_tensor_op_f64_grouped_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_f64n_f64n_tensor_op_f64_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_f64n_f64t_tensor_op_f64_sm80.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -47,22 +47,22 @@
 
 #include "testbed_rank2k_universal.h"
 
 #if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Syr2k_f64n_f64n_l_tensor_op_f64, 32x32x16_16x16x16) {
+TEST(SM80_Device_Syr2k_f64n_f64t_l_tensor_op_f64, 32x32x16_16x16x16) {
 
   using ElementA = double;
   using LayoutA = cutlass::layout::ColumnMajor;
   using ElementB = double;
   using LayoutB = cutlass::layout::ColumnMajor;
   using ElementC = double;
-  using LayoutC = cutlass::layout::ColumnMajor;
+  using LayoutC = cutlass::layout::RowMajor;
   using ElementAccumulator = double;
 
   using Rank2K = cutlass::gemm::device::Rank2K<
     ElementA,
     LayoutA,
     ElementB,
     LayoutB,
@@ -87,22 +87,22 @@
 
   EXPECT_TRUE(test::gemm::device::TestAllRank2KUniversal<Rank2K>());
 
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Syr2k_f64n_f64n_l_tensor_op_f64, 64x64x16_32x32x16) {
+TEST(SM80_Device_Syr2k_f64n_f64t_l_tensor_op_f64, 64x64x16_32x32x16) {
 
   using ElementA = double;
   using LayoutA = cutlass::layout::ColumnMajor;
   using ElementB = double;
   using LayoutB = cutlass::layout::ColumnMajor;
   using ElementC = double;
-  using LayoutC = cutlass::layout::ColumnMajor;
+  using LayoutC = cutlass::layout::RowMajor;
   using ElementAccumulator = double;
 
   using Rank2K = cutlass::gemm::device::Rank2K<
     ElementA,
     LayoutA,
     ElementB,
     LayoutB,
@@ -127,22 +127,22 @@
 
   EXPECT_TRUE(test::gemm::device::TestAllRank2KUniversal<Rank2K>());
 
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Syr2k_f64n_f64n_l_tensor_op_f64, 128x64x16_64x32x16) {
+TEST(SM80_Device_Syr2k_f64n_f64t_l_tensor_op_f64, 128x64x16_64x32x16) {
 
   using ElementA = double;
   using LayoutA = cutlass::layout::ColumnMajor;
   using ElementB = double;
   using LayoutB = cutlass::layout::ColumnMajor;
   using ElementC = double;
-  using LayoutC = cutlass::layout::ColumnMajor;
+  using LayoutC = cutlass::layout::RowMajor;
   using ElementAccumulator = double;
 
   using Rank2K = cutlass::gemm::device::Rank2K<
     ElementA,
     LayoutA,
     ElementB,
     LayoutB,
@@ -167,22 +167,22 @@
 
   EXPECT_TRUE(test::gemm::device::TestAllRank2KUniversal<Rank2K>());
 
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Syr2k_f64n_f64n_l_tensor_op_f64, 128x128x16_32x64x16) {
+TEST(SM80_Device_Syr2k_f64n_f64t_l_tensor_op_f64, 128x128x16_32x64x16) {
 
   using ElementA = double;
   using LayoutA = cutlass::layout::ColumnMajor;
   using ElementB = double;
   using LayoutB = cutlass::layout::ColumnMajor;
   using ElementC = double;
-  using LayoutC = cutlass::layout::ColumnMajor;
+  using LayoutC = cutlass::layout::RowMajor;
   using ElementAccumulator = double;
 
   using Rank2K = cutlass::gemm::device::Rank2K<
     ElementA,
     LayoutA,
     ElementB,
     LayoutB,
@@ -207,22 +207,22 @@
 
   EXPECT_TRUE(test::gemm::device::TestAllRank2KUniversal<Rank2K>());
 
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Syr2k_f64n_f64n_u_tensor_op_f64, 32x32x16_16x16x16) {
+TEST(SM80_Device_Syr2k_f64n_f64t_u_tensor_op_f64, 32x32x16_16x16x16) {
 
   using ElementA = double;
   using LayoutA = cutlass::layout::ColumnMajor;
   using ElementB = double;
   using LayoutB = cutlass::layout::ColumnMajor;
   using ElementC = double;
-  using LayoutC = cutlass::layout::ColumnMajor;
+  using LayoutC = cutlass::layout::RowMajor;
   using ElementAccumulator = double;
 
   using Rank2K = cutlass::gemm::device::Rank2K<
     ElementA,
     LayoutA,
     ElementB,
     LayoutB,
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_f64n_f64t_tensor_op_f64_grouped_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_f64n_f64t_tensor_op_f64_grouped_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_f64n_f64t_tensor_op_f64_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_f64t_f64n_tensor_op_f64_sm80.cu`

 * *Files 5% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -47,22 +47,22 @@
 
 #include "testbed_rank2k_universal.h"
 
 #if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Syr2k_f64n_f64t_l_tensor_op_f64, 32x32x16_16x16x16) {
+TEST(SM80_Device_Syr2k_f64t_f64n_l_tensor_op_f64, 32x32x16_16x16x16) {
 
   using ElementA = double;
-  using LayoutA = cutlass::layout::ColumnMajor;
+  using LayoutA = cutlass::layout::RowMajor;
   using ElementB = double;
-  using LayoutB = cutlass::layout::ColumnMajor;
+  using LayoutB = cutlass::layout::RowMajor;
   using ElementC = double;
-  using LayoutC = cutlass::layout::RowMajor;
+  using LayoutC = cutlass::layout::ColumnMajor;
   using ElementAccumulator = double;
 
   using Rank2K = cutlass::gemm::device::Rank2K<
     ElementA,
     LayoutA,
     ElementB,
     LayoutB,
@@ -87,22 +87,22 @@
 
   EXPECT_TRUE(test::gemm::device::TestAllRank2KUniversal<Rank2K>());
 
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Syr2k_f64n_f64t_l_tensor_op_f64, 64x64x16_32x32x16) {
+TEST(SM80_Device_Syr2k_f64t_f64n_l_tensor_op_f64, 64x64x16_32x32x16) {
 
   using ElementA = double;
-  using LayoutA = cutlass::layout::ColumnMajor;
+  using LayoutA = cutlass::layout::RowMajor;
   using ElementB = double;
-  using LayoutB = cutlass::layout::ColumnMajor;
+  using LayoutB = cutlass::layout::RowMajor;
   using ElementC = double;
-  using LayoutC = cutlass::layout::RowMajor;
+  using LayoutC = cutlass::layout::ColumnMajor;
   using ElementAccumulator = double;
 
   using Rank2K = cutlass::gemm::device::Rank2K<
     ElementA,
     LayoutA,
     ElementB,
     LayoutB,
@@ -127,22 +127,22 @@
 
   EXPECT_TRUE(test::gemm::device::TestAllRank2KUniversal<Rank2K>());
 
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Syr2k_f64n_f64t_l_tensor_op_f64, 128x64x16_64x32x16) {
+TEST(SM80_Device_Syr2k_f64t_f64n_l_tensor_op_f64, 128x64x16_64x32x16) {
 
   using ElementA = double;
-  using LayoutA = cutlass::layout::ColumnMajor;
+  using LayoutA = cutlass::layout::RowMajor;
   using ElementB = double;
-  using LayoutB = cutlass::layout::ColumnMajor;
+  using LayoutB = cutlass::layout::RowMajor;
   using ElementC = double;
-  using LayoutC = cutlass::layout::RowMajor;
+  using LayoutC = cutlass::layout::ColumnMajor;
   using ElementAccumulator = double;
 
   using Rank2K = cutlass::gemm::device::Rank2K<
     ElementA,
     LayoutA,
     ElementB,
     LayoutB,
@@ -167,22 +167,22 @@
 
   EXPECT_TRUE(test::gemm::device::TestAllRank2KUniversal<Rank2K>());
 
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Syr2k_f64n_f64t_l_tensor_op_f64, 128x128x16_32x64x16) {
+TEST(SM80_Device_Syr2k_f64t_f64n_l_tensor_op_f64, 128x128x16_32x64x16) {
 
   using ElementA = double;
-  using LayoutA = cutlass::layout::ColumnMajor;
+  using LayoutA = cutlass::layout::RowMajor;
   using ElementB = double;
-  using LayoutB = cutlass::layout::ColumnMajor;
+  using LayoutB = cutlass::layout::RowMajor;
   using ElementC = double;
-  using LayoutC = cutlass::layout::RowMajor;
+  using LayoutC = cutlass::layout::ColumnMajor;
   using ElementAccumulator = double;
 
   using Rank2K = cutlass::gemm::device::Rank2K<
     ElementA,
     LayoutA,
     ElementB,
     LayoutB,
@@ -207,22 +207,22 @@
 
   EXPECT_TRUE(test::gemm::device::TestAllRank2KUniversal<Rank2K>());
 
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Syr2k_f64n_f64t_u_tensor_op_f64, 32x32x16_16x16x16) {
+TEST(SM80_Device_Syr2k_f64t_f64n_u_tensor_op_f64, 32x32x16_16x16x16) {
 
   using ElementA = double;
-  using LayoutA = cutlass::layout::ColumnMajor;
+  using LayoutA = cutlass::layout::RowMajor;
   using ElementB = double;
-  using LayoutB = cutlass::layout::ColumnMajor;
+  using LayoutB = cutlass::layout::RowMajor;
   using ElementC = double;
-  using LayoutC = cutlass::layout::RowMajor;
+  using LayoutC = cutlass::layout::ColumnMajor;
   using ElementAccumulator = double;
 
   using Rank2K = cutlass::gemm::device::Rank2K<
     ElementA,
     LayoutA,
     ElementB,
     LayoutB,
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_f64t_f64n_tensor_op_f64_grouped_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_f64t_f64n_tensor_op_f64_grouped_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_f64t_f64n_tensor_op_f64_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_f64t_f64n_tensor_op_f64_sm80.cu`

 * *Files 14% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -33,43 +33,39 @@
   
 */
 
 #include <iostream>
 
 #include "../../common/cutlass_unit_test.h"
 #include "cutlass/blas3.h"
-#include "cutlass/gemm/device/rank_2k.h"
+#include "cutlass/gemm/device/rank_k.h"
 #include "cutlass/util/host_tensor.h"
-#include "cutlass/util/reference/host/rank_2k.h"
+#include "cutlass/util/reference/host/rank_k_complex.h"
 #include "cutlass/util/reference/host/tensor_compare.h"
 #include "cutlass/util/reference/host/tensor_copy.h"
 #include "cutlass/util/reference/host/tensor_fill.h"
 #include "cutlass/util/tensor_view_io.h"
 
-#include "testbed_rank2k_universal.h"
+#include "testbed_rank_k_universal.h"
 
 #if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Syr2k_f64t_f64n_l_tensor_op_f64, 32x32x16_16x16x16) {
+TEST(SM80_Device_Syrk_f64t_f64n_l_tensor_op_f64, 32x32x16_16x16x16) {
 
   using ElementA = double;
   using LayoutA = cutlass::layout::RowMajor;
-  using ElementB = double;
-  using LayoutB = cutlass::layout::RowMajor;
   using ElementC = double;
   using LayoutC = cutlass::layout::ColumnMajor;
   using ElementAccumulator = double;
 
-  using Rank2K = cutlass::gemm::device::Rank2K<
+  using RankK = cutlass::gemm::device::RankK<
     ElementA,
     LayoutA,
-    ElementB,
-    LayoutB,
     ElementC,
     LayoutC,
     cutlass::FillMode::kLower,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm80,
     cutlass::gemm::GemmShape<32, 32, 16>,
@@ -81,35 +77,30 @@
       ElementAccumulator,
       ElementAccumulator
     >,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     4
   >;
 
-  EXPECT_TRUE(test::gemm::device::TestAllRank2KUniversal<Rank2K>());
-
+  EXPECT_TRUE(test::gemm::device::TestAllRankKUniversal<RankK>());
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Syr2k_f64t_f64n_l_tensor_op_f64, 64x64x16_32x32x16) {
+TEST(SM80_Device_Syrk_f64t_f64n_l_tensor_op_f64, 64x64x16_32x32x16) {
 
   using ElementA = double;
   using LayoutA = cutlass::layout::RowMajor;
-  using ElementB = double;
-  using LayoutB = cutlass::layout::RowMajor;
   using ElementC = double;
   using LayoutC = cutlass::layout::ColumnMajor;
   using ElementAccumulator = double;
 
-  using Rank2K = cutlass::gemm::device::Rank2K<
+  using RankK = cutlass::gemm::device::RankK<
     ElementA,
     LayoutA,
-    ElementB,
-    LayoutB,
     ElementC,
     LayoutC,
     cutlass::FillMode::kLower,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm80,
     cutlass::gemm::GemmShape<64, 64, 16>,
@@ -121,35 +112,30 @@
       ElementAccumulator,
       ElementAccumulator
     >,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     4
   >;
 
-  EXPECT_TRUE(test::gemm::device::TestAllRank2KUniversal<Rank2K>());
-
+  EXPECT_TRUE(test::gemm::device::TestAllRankKUniversal<RankK>());
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Syr2k_f64t_f64n_l_tensor_op_f64, 128x64x16_64x32x16) {
+TEST(SM80_Device_Syrk_f64t_f64n_l_tensor_op_f64, 128x64x16_64x32x16) {
 
   using ElementA = double;
   using LayoutA = cutlass::layout::RowMajor;
-  using ElementB = double;
-  using LayoutB = cutlass::layout::RowMajor;
   using ElementC = double;
   using LayoutC = cutlass::layout::ColumnMajor;
   using ElementAccumulator = double;
 
-  using Rank2K = cutlass::gemm::device::Rank2K<
+  using RankK = cutlass::gemm::device::RankK<
     ElementA,
     LayoutA,
-    ElementB,
-    LayoutB,
     ElementC,
     LayoutC,
     cutlass::FillMode::kLower,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm80,
     cutlass::gemm::GemmShape<128, 64, 16>,
@@ -161,35 +147,30 @@
       ElementAccumulator,
       ElementAccumulator
     >,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     4
   >;
 
-  EXPECT_TRUE(test::gemm::device::TestAllRank2KUniversal<Rank2K>());
-
+  EXPECT_TRUE(test::gemm::device::TestAllRankKUniversal<RankK>());
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Syr2k_f64t_f64n_l_tensor_op_f64, 128x128x16_32x64x16) {
+TEST(SM80_Device_Syrk_f64t_f64n_l_tensor_op_f64, 128x128x16_32x64x16) {
 
   using ElementA = double;
   using LayoutA = cutlass::layout::RowMajor;
-  using ElementB = double;
-  using LayoutB = cutlass::layout::RowMajor;
   using ElementC = double;
   using LayoutC = cutlass::layout::ColumnMajor;
   using ElementAccumulator = double;
 
-  using Rank2K = cutlass::gemm::device::Rank2K<
+  using RankK = cutlass::gemm::device::RankK<
     ElementA,
     LayoutA,
-    ElementB,
-    LayoutB,
     ElementC,
     LayoutC,
     cutlass::FillMode::kLower,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm80,
     cutlass::gemm::GemmShape<128, 128, 16>,
@@ -201,35 +182,30 @@
       ElementAccumulator,
       ElementAccumulator
     >,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     3
   >;
 
-  EXPECT_TRUE(test::gemm::device::TestAllRank2KUniversal<Rank2K>());
-
+  EXPECT_TRUE(test::gemm::device::TestAllRankKUniversal<RankK>());
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Syr2k_f64t_f64n_u_tensor_op_f64, 32x32x16_16x16x16) {
+TEST(SM80_Device_Syrk_f64t_f64n_u_tensor_op_f64, 32x32x16_16x16x16) {
 
   using ElementA = double;
   using LayoutA = cutlass::layout::RowMajor;
-  using ElementB = double;
-  using LayoutB = cutlass::layout::RowMajor;
   using ElementC = double;
   using LayoutC = cutlass::layout::ColumnMajor;
   using ElementAccumulator = double;
 
-  using Rank2K = cutlass::gemm::device::Rank2K<
+  using RankK = cutlass::gemm::device::RankK<
     ElementA,
     LayoutA,
-    ElementB,
-    LayoutB,
     ElementC,
     LayoutC,
     cutlass::FillMode::kUpper,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm80,
     cutlass::gemm::GemmShape<32, 32, 16>,
@@ -241,13 +217,85 @@
       ElementAccumulator,
       ElementAccumulator
     >,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     4
   >;
 
-  EXPECT_TRUE(test::gemm::device::TestAllRank2KUniversal<Rank2K>());
+  EXPECT_TRUE(test::gemm::device::TestAllRankKUniversal<RankK>());
+}
+
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM80_Device_Syrk_f64t_f64n_u_tensor_op_f64, 128x64x16_64x32x16) {
+
+  using ElementA = double;
+  using LayoutA = cutlass::layout::RowMajor;
+  using ElementC = double;
+  using LayoutC = cutlass::layout::ColumnMajor;
+  using ElementAccumulator = double;
+
+  using RankK = cutlass::gemm::device::RankK<
+    ElementA,
+    LayoutA,
+    ElementC,
+    LayoutC,
+    cutlass::FillMode::kUpper,
+    ElementAccumulator,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<128, 64, 16>,
+    cutlass::gemm::GemmShape<64, 32, 16>,
+    cutlass::gemm::GemmShape<8, 8, 4>,
+    cutlass::epilogue::thread::LinearCombination<
+      ElementC,
+      1,
+      ElementAccumulator,
+      ElementAccumulator
+    >,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
+    4
+  >;
+
+  EXPECT_TRUE(test::gemm::device::TestAllRankKUniversal<RankK>());
+}
+
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM80_Device_Syrk_f64t_f64n_u_tensor_op_f64, 128x128x16_32x64x16) {
+
+  using ElementA = double;
+  using LayoutA = cutlass::layout::RowMajor;
+  using ElementC = double;
+  using LayoutC = cutlass::layout::ColumnMajor;
+  using ElementAccumulator = double;
 
+  using RankK = cutlass::gemm::device::RankK<
+    ElementA,
+    LayoutA,
+    ElementC,
+    LayoutC,
+    cutlass::FillMode::kUpper,
+    ElementAccumulator,
+    cutlass::arch::OpClassTensorOp,
+    cutlass::arch::Sm80,
+    cutlass::gemm::GemmShape<128, 128, 16>,
+    cutlass::gemm::GemmShape<32, 64, 16>,
+    cutlass::gemm::GemmShape<8, 8, 4>,
+    cutlass::epilogue::thread::LinearCombination<
+      ElementC,
+      1,
+      ElementAccumulator,
+      ElementAccumulator
+    >,
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
+    3
+  >;
+
+  EXPECT_TRUE(test::gemm::device::TestAllRankKUniversal<RankK>());
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
+
 #endif // #if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_f64t_f64t_tensor_op_f64_grouped_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_f64t_f64t_tensor_op_f64_grouped_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_tf32n_f32n_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_tf32n_f32n_tensor_op_f32_sm80.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_tf32t_f32n_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syr2k_tf32t_f32n_tensor_op_f32_sm80.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_cf32n_cf32n_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_cf32n_cf32n_tensor_op_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_cf32n_cf32n_tensor_op_fast_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_cf32n_cf32n_tensor_op_fast_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_cf32n_cf32t_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_cf32n_cf32t_tensor_op_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_cf32n_cf32t_tensor_op_fast_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_cf32n_cf32t_tensor_op_fast_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_cf64_cf64_tensor_op_f64_sm90.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_cf64n_cf64n_tensor_op_f64_sm80.cu`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -43,19 +43,19 @@
 #include "cutlass/util/reference/host/tensor_compare.h"
 #include "cutlass/util/reference/host/tensor_copy.h"
 #include "cutlass/util/reference/host/tensor_fill.h"
 #include "cutlass/util/tensor_view_io.h"
 
 #include "testbed_rank_k_universal.h"
 
-#if defined(CUTLASS_ARCH_MMA_SM90_SUPPORTED)
+#if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM90_Device_Syrk_cf64n_cf64n_l_tensor_op_f64, 32x32x16_16x16x16) {
+TEST(SM80_Device_Syrk_cf64n_cf64n_l_tensor_op_f64, 32x32x16_16x16x16) {
 
   using ElementA = cutlass::complex<double>;
   using LayoutA = cutlass::layout::ColumnMajor;
 
   using ElementC = cutlass::complex<double>;
   using LayoutC = cutlass::layout::ColumnMajor;
   using ElementAccumulator = cutlass::complex<double>;
@@ -64,18 +64,18 @@
     ElementA,
     LayoutA,
     ElementC,
     LayoutC,
     cutlass::FillMode::kLower,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm90,
+    cutlass::arch::Sm80,
     cutlass::gemm::GemmShape<32, 32, 16>,
     cutlass::gemm::GemmShape<16, 16, 16>,
-    cutlass::gemm::GemmShape<16, 8, 4>,
+    cutlass::gemm::GemmShape<8, 8, 4>,
     cutlass::epilogue::thread::LinearCombination<
       ElementC,
       1,
       ElementAccumulator,
       ElementAccumulator
     >,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
@@ -88,49 +88,49 @@
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllRankKUniversal<RankK>());
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM90_Device_Syrk_cf64n_cf64t_l_tensor_op_f64_gaussian, 32x32x16_16x16x16) {
+TEST(SM80_Device_Syrk_cf64n_cf64n_u_tensor_op_f64, 32x32x16_16x16x16) {
 
   using ElementA = cutlass::complex<double>;
   using LayoutA = cutlass::layout::ColumnMajor;
 
   using ElementC = cutlass::complex<double>;
-  using LayoutC = cutlass::layout::RowMajor;
+  using LayoutC = cutlass::layout::ColumnMajor;
   using ElementAccumulator = cutlass::complex<double>;
 
   using RankK = cutlass::gemm::device::RankK<
     ElementA,
     LayoutA,
     ElementC,
     LayoutC,
-    cutlass::FillMode::kLower,
+    cutlass::FillMode::kUpper,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm90,
+    cutlass::arch::Sm80,
     cutlass::gemm::GemmShape<32, 32, 16>,
     cutlass::gemm::GemmShape<16, 16, 16>,
-    cutlass::gemm::GemmShape<16, 8, 4>,
+    cutlass::gemm::GemmShape<8, 8, 4>,
     cutlass::epilogue::thread::LinearCombination<
       ElementC,
       1,
       ElementAccumulator,
       ElementAccumulator
     >,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     4,     // kStages 
     1,     // AlignmentA
     false, // SplitKSerial
-    cutlass::arch::OpMultiplyAddGaussianComplex,
+    cutlass::arch::OpMultiplyAddComplex,
     cutlass::ComplexTransform::kNone,
     cutlass::BlasMode::kSymmetric
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllRankKUniversal<RankK>());
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-#endif // #if defined(CUTLASS_ARCH_MMA_SM90_SUPPORTED)
+#endif // #if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_cf64n_cf64n_tensor_op_f64_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_cf64n_cf64t_tensor_op_f64_sm80.cu`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -47,21 +47,21 @@
 
 #include "testbed_rank_k_universal.h"
 
 #if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Syrk_cf64n_cf64n_l_tensor_op_f64, 32x32x16_16x16x16) {
+TEST(SM80_Device_Syrk_cf64n_cf64t_l_tensor_op_f64, 32x32x16_16x16x16) {
 
   using ElementA = cutlass::complex<double>;
   using LayoutA = cutlass::layout::ColumnMajor;
 
   using ElementC = cutlass::complex<double>;
-  using LayoutC = cutlass::layout::ColumnMajor;
+  using LayoutC = cutlass::layout::RowMajor;
   using ElementAccumulator = cutlass::complex<double>;
 
   using RankK = cutlass::gemm::device::RankK<
     ElementA,
     LayoutA,
     ElementC,
     LayoutC,
@@ -88,21 +88,21 @@
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllRankKUniversal<RankK>());
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Syrk_cf64n_cf64n_u_tensor_op_f64, 32x32x16_16x16x16) {
+TEST(SM80_Device_Syrk_cf64n_cf64t_u_tensor_op_f64, 32x32x16_16x16x16) {
 
   using ElementA = cutlass::complex<double>;
   using LayoutA = cutlass::layout::ColumnMajor;
 
   using ElementC = cutlass::complex<double>;
-  using LayoutC = cutlass::layout::ColumnMajor;
+  using LayoutC = cutlass::layout::RowMajor;
   using ElementAccumulator = cutlass::complex<double>;
 
   using RankK = cutlass::gemm::device::RankK<
     ElementA,
     LayoutA,
     ElementC,
     LayoutC,
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_cf64n_cf64t_tensor_op_f64_gaussian_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_cf64n_cf64t_tensor_op_f64_gaussian_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_cf64n_cf64t_tensor_op_f64_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_cf64_cf64_tensor_op_f64_sm90.cu`

 * *Files 3% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -43,39 +43,39 @@
 #include "cutlass/util/reference/host/tensor_compare.h"
 #include "cutlass/util/reference/host/tensor_copy.h"
 #include "cutlass/util/reference/host/tensor_fill.h"
 #include "cutlass/util/tensor_view_io.h"
 
 #include "testbed_rank_k_universal.h"
 
-#if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
+#if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Syrk_cf64n_cf64t_l_tensor_op_f64, 32x32x16_16x16x16) {
+TEST(SM90_Device_Syrk_cf64n_cf64n_l_tensor_op_f64, 32x32x16_16x16x16) {
 
   using ElementA = cutlass::complex<double>;
   using LayoutA = cutlass::layout::ColumnMajor;
 
   using ElementC = cutlass::complex<double>;
-  using LayoutC = cutlass::layout::RowMajor;
+  using LayoutC = cutlass::layout::ColumnMajor;
   using ElementAccumulator = cutlass::complex<double>;
 
   using RankK = cutlass::gemm::device::RankK<
     ElementA,
     LayoutA,
     ElementC,
     LayoutC,
     cutlass::FillMode::kLower,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm80,
+    cutlass::arch::Sm90,
     cutlass::gemm::GemmShape<32, 32, 16>,
     cutlass::gemm::GemmShape<16, 16, 16>,
-    cutlass::gemm::GemmShape<8, 8, 4>,
+    cutlass::gemm::GemmShape<16, 8, 4>,
     cutlass::epilogue::thread::LinearCombination<
       ElementC,
       1,
       ElementAccumulator,
       ElementAccumulator
     >,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
@@ -88,49 +88,49 @@
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllRankKUniversal<RankK>());
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Syrk_cf64n_cf64t_u_tensor_op_f64, 32x32x16_16x16x16) {
+TEST(SM90_Device_Syrk_cf64n_cf64t_l_tensor_op_f64_gaussian, 32x32x16_16x16x16) {
 
   using ElementA = cutlass::complex<double>;
   using LayoutA = cutlass::layout::ColumnMajor;
 
   using ElementC = cutlass::complex<double>;
   using LayoutC = cutlass::layout::RowMajor;
   using ElementAccumulator = cutlass::complex<double>;
 
   using RankK = cutlass::gemm::device::RankK<
     ElementA,
     LayoutA,
     ElementC,
     LayoutC,
-    cutlass::FillMode::kUpper,
+    cutlass::FillMode::kLower,
     ElementAccumulator,
     cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm80,
+    cutlass::arch::Sm90,
     cutlass::gemm::GemmShape<32, 32, 16>,
     cutlass::gemm::GemmShape<16, 16, 16>,
-    cutlass::gemm::GemmShape<8, 8, 4>,
+    cutlass::gemm::GemmShape<16, 8, 4>,
     cutlass::epilogue::thread::LinearCombination<
       ElementC,
       1,
       ElementAccumulator,
       ElementAccumulator
     >,
     cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
     4,     // kStages 
     1,     // AlignmentA
     false, // SplitKSerial
-    cutlass::arch::OpMultiplyAddComplex,
+    cutlass::arch::OpMultiplyAddGaussianComplex,
     cutlass::ComplexTransform::kNone,
     cutlass::BlasMode::kSymmetric
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllRankKUniversal<RankK>());
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-#endif // #if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
+#endif // #if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_f32n_f32t_tensor_op_fast_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_f32n_f32t_tensor_op_fast_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_f32t_f32t_tensor_op_fast_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_f32t_f32t_tensor_op_fast_f32_sm80.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_f64_f64_tensor_op_f64_sm90.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_f64_f64_tensor_op_f64_sm90.cu`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -43,15 +43,15 @@
 #include "cutlass/util/reference/host/tensor_compare.h"
 #include "cutlass/util/reference/host/tensor_copy.h"
 #include "cutlass/util/reference/host/tensor_fill.h"
 #include "cutlass/util/tensor_view_io.h"
 
 #include "testbed_rank_k_universal.h"
 
-#if defined(CUTLASS_ARCH_MMA_SM90_SUPPORTED)
+#if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 TEST(SM90_Device_Syrk_f64n_f64t_l_tensor_op_f64, 128x64x16_64x32x16) {
 
   using ElementA = double;
   using LayoutA = cutlass::layout::ColumnMajor;
@@ -119,8 +119,8 @@
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllRankKUniversal<RankK>());
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-#endif // #if defined(CUTLASS_ARCH_MMA_SM90_SUPPORTED)
+#endif // #if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_f64n_f64t_tensor_op_f64_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_f64n_f64t_tensor_op_f64_sm80.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_f64t_f64n_tensor_op_f64_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_tf32n_tf32t_f32t_tensor_op_f32_rs_sm80.cu`

 * *Files 18% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -25,277 +25,228 @@
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /*! \file
-    \brief Tests for device-wide SYRK interface
+    \brief Tests for device-wide TRMM interface
+
   
 */
 
 #include <iostream>
 
 #include "../../common/cutlass_unit_test.h"
 #include "cutlass/blas3.h"
-#include "cutlass/gemm/device/rank_k.h"
+#include "cutlass/gemm/device/trmm.h"
 #include "cutlass/util/host_tensor.h"
-#include "cutlass/util/reference/host/rank_k_complex.h"
+#include "cutlass/util/reference/host/trmm.h"
 #include "cutlass/util/reference/host/tensor_compare.h"
 #include "cutlass/util/reference/host/tensor_copy.h"
 #include "cutlass/util/reference/host/tensor_fill.h"
 #include "cutlass/util/tensor_view_io.h"
 
-#include "testbed_rank_k_universal.h"
+#include "testbed_trmm_universal.h"
 
 #if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
-
-TEST(SM80_Device_Syrk_f64t_f64n_l_tensor_op_f64, 32x32x16_16x16x16) {
-
-  using ElementA = double;
-  using LayoutA = cutlass::layout::RowMajor;
-  using ElementC = double;
-  using LayoutC = cutlass::layout::ColumnMajor;
-  using ElementAccumulator = double;
-
-  using RankK = cutlass::gemm::device::RankK<
-    ElementA,
-    LayoutA,
-    ElementC,
-    LayoutC,
-    cutlass::FillMode::kLower,
-    ElementAccumulator,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<32, 32, 16>,
-    cutlass::gemm::GemmShape<16, 16, 16>,
-    cutlass::gemm::GemmShape<8, 8, 4>,
-    cutlass::epilogue::thread::LinearCombination<
-      ElementC,
-      1,
-      ElementAccumulator,
-      ElementAccumulator
-    >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    4
-  >;
-
-  EXPECT_TRUE(test::gemm::device::TestAllRankKUniversal<RankK>());
-}
+////////////////////////////////////////////Test name//////////////////////////////////////////////////
+//                             
+// SM80_Device_Trmm_{ElementA}{LayoutA}_{ElementB}{LayoutB}_{ElementC}{LayoutC}_{SideMode}_{FillMode}\
+//    _{DiagType}_tensor_op_{ElementAccumulator}_align{AlignmentA}_align{AlignmentB}
+//
+///////////////////////////////////////////////////////////////////////////////////////////////////////
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Syrk_f64t_f64n_l_tensor_op_f64, 64x64x16_32x32x16) {
+TEST(SM80_Device_Trmm_tf32n_tf32t_f32t_rs_u_nu_tensor_op_f32_align1_align1, 64x128x32_32x64x32) {
 
-  using ElementA = double;
-  using LayoutA = cutlass::layout::RowMajor;
-  using ElementC = double;
-  using LayoutC = cutlass::layout::ColumnMajor;
-  using ElementAccumulator = double;
-
-  using RankK = cutlass::gemm::device::RankK<
-    ElementA,
-    LayoutA,
-    ElementC,
-    LayoutC,
-    cutlass::FillMode::kLower,
-    ElementAccumulator,
+using Trmm = cutlass::gemm::device::Trmm<
+    float, cutlass::layout::ColumnMajor,
+    cutlass::SideMode::kRight, cutlass::FillMode::kUpper, cutlass::DiagType::kNonUnit,
+    float, cutlass::layout::RowMajor,
+    float, cutlass::layout::RowMajor,
+    float,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<64, 64, 16>,
-    cutlass::gemm::GemmShape<32, 32, 16>,
-    cutlass::gemm::GemmShape<8, 8, 4>,
+    cutlass::gemm::GemmShape<64, 128, 32>,
+    cutlass::gemm::GemmShape<32, 64, 32>,
+    cutlass::gemm::GemmShape<16, 8, 8>,
     cutlass::epilogue::thread::LinearCombination<
-      ElementC,
+      float,
       1,
-      ElementAccumulator,
-      ElementAccumulator
+      float,
+      float
     >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    4
-  >;
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<8>,
+    3,
+    1,
+    1,
+    false,
+    cutlass::arch::OpMultiplyAdd
+>;
 
-  EXPECT_TRUE(test::gemm::device::TestAllRankKUniversal<RankK>());
+  EXPECT_TRUE(test::gemm::device::TestAllTrmmUniversal<Trmm>());
 }
-
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Syrk_f64t_f64n_l_tensor_op_f64, 128x64x16_64x32x16) {
+TEST(SM80_Device_Trmm_tf32n_tf32t_f32t_rs_u_nu_tensor_op_f32_align1_align1, 128x64x32_32x64x32) {
 
-  using ElementA = double;
-  using LayoutA = cutlass::layout::RowMajor;
-  using ElementC = double;
-  using LayoutC = cutlass::layout::ColumnMajor;
-  using ElementAccumulator = double;
-
-  using RankK = cutlass::gemm::device::RankK<
-    ElementA,
-    LayoutA,
-    ElementC,
-    LayoutC,
-    cutlass::FillMode::kLower,
-    ElementAccumulator,
+using Trmm = cutlass::gemm::device::Trmm<
+    float, cutlass::layout::ColumnMajor,
+    cutlass::SideMode::kRight, cutlass::FillMode::kUpper, cutlass::DiagType::kNonUnit,
+    float, cutlass::layout::RowMajor,
+    float, cutlass::layout::RowMajor,
+    float,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<128, 64, 16>,
-    cutlass::gemm::GemmShape<64, 32, 16>,
-    cutlass::gemm::GemmShape<8, 8, 4>,
+    cutlass::gemm::GemmShape<128, 64, 32>,
+    cutlass::gemm::GemmShape<32, 64, 32>,
+    cutlass::gemm::GemmShape<16, 8, 8>,
     cutlass::epilogue::thread::LinearCombination<
-      ElementC,
+      float,
       1,
-      ElementAccumulator,
-      ElementAccumulator
+      float,
+      float
     >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    4
-  >;
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<8>,
+    3,
+    1,
+    1,
+    false,
+    cutlass::arch::OpMultiplyAdd
+>;
 
-  EXPECT_TRUE(test::gemm::device::TestAllRankKUniversal<RankK>());
+  EXPECT_TRUE(test::gemm::device::TestAllTrmmUniversal<Trmm>());
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Syrk_f64t_f64n_l_tensor_op_f64, 128x128x16_32x64x16) {
+TEST(SM80_Device_Trmm_tf32n_tf32t_f32t_rs_l_nu_tensor_op_f32_align1_align1, 64x128x32_32x64x32) {
 
-  using ElementA = double;
-  using LayoutA = cutlass::layout::RowMajor;
-  using ElementC = double;
-  using LayoutC = cutlass::layout::ColumnMajor;
-  using ElementAccumulator = double;
-
-  using RankK = cutlass::gemm::device::RankK<
-    ElementA,
-    LayoutA,
-    ElementC,
-    LayoutC,
-    cutlass::FillMode::kLower,
-    ElementAccumulator,
+using Trmm = cutlass::gemm::device::Trmm<
+    float, cutlass::layout::ColumnMajor,
+    cutlass::SideMode::kRight, cutlass::FillMode::kLower, cutlass::DiagType::kNonUnit,
+    float, cutlass::layout::RowMajor,
+    float, cutlass::layout::RowMajor,
+    float,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<128, 128, 16>,
-    cutlass::gemm::GemmShape<32, 64, 16>,
-    cutlass::gemm::GemmShape<8, 8, 4>,
+    cutlass::gemm::GemmShape<64, 128, 32>,
+    cutlass::gemm::GemmShape<32, 64, 32>,
+    cutlass::gemm::GemmShape<16, 8, 8>,
     cutlass::epilogue::thread::LinearCombination<
-      ElementC,
+      float,
       1,
-      ElementAccumulator,
-      ElementAccumulator
+      float,
+      float
     >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    3
-  >;
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<8>,
+    3,
+    1,
+    1,
+    false,
+    cutlass::arch::OpMultiplyAdd
+>;
 
-  EXPECT_TRUE(test::gemm::device::TestAllRankKUniversal<RankK>());
+  EXPECT_TRUE(test::gemm::device::TestAllTrmmUniversal<Trmm>());
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Syrk_f64t_f64n_u_tensor_op_f64, 32x32x16_16x16x16) {
 
-  using ElementA = double;
-  using LayoutA = cutlass::layout::RowMajor;
-  using ElementC = double;
-  using LayoutC = cutlass::layout::ColumnMajor;
-  using ElementAccumulator = double;
-
-  using RankK = cutlass::gemm::device::RankK<
-    ElementA,
-    LayoutA,
-    ElementC,
-    LayoutC,
-    cutlass::FillMode::kUpper,
-    ElementAccumulator,
+TEST(SM80_Device_Trmm_tf32n_tf32t_f32t_rs_u_nu_tensor_op_f32_align1_align4, 64x128x32_32x64x32) {
+
+using Trmm = cutlass::gemm::device::Trmm<
+    float, cutlass::layout::ColumnMajor,
+    cutlass::SideMode::kRight, cutlass::FillMode::kUpper, cutlass::DiagType::kNonUnit,
+    float, cutlass::layout::RowMajor,
+    float, cutlass::layout::RowMajor,
+    float,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<32, 32, 16>,
-    cutlass::gemm::GemmShape<16, 16, 16>,
-    cutlass::gemm::GemmShape<8, 8, 4>,
+    cutlass::gemm::GemmShape<64, 128, 32>,
+    cutlass::gemm::GemmShape<32, 64, 32>,
+    cutlass::gemm::GemmShape<16, 8, 8>,
     cutlass::epilogue::thread::LinearCombination<
-      ElementC,
+      float,
       1,
-      ElementAccumulator,
-      ElementAccumulator
+      float,
+      float
     >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    4
-  >;
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<8>,
+    3,
+    1,
+    4,
+    false,
+    cutlass::arch::OpMultiplyAdd
+>;
 
-  EXPECT_TRUE(test::gemm::device::TestAllRankKUniversal<RankK>());
+  EXPECT_TRUE(test::gemm::device::TestAllTrmmUniversal<Trmm>());
 }
-
-
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Syrk_f64t_f64n_u_tensor_op_f64, 128x64x16_64x32x16) {
+TEST(SM80_Device_Trmm_tf32n_tf32t_f32t_rs_u_nu_tensor_op_f32_align1_align4, 128x64x32_32x64x32) {
 
-  using ElementA = double;
-  using LayoutA = cutlass::layout::RowMajor;
-  using ElementC = double;
-  using LayoutC = cutlass::layout::ColumnMajor;
-  using ElementAccumulator = double;
-
-  using RankK = cutlass::gemm::device::RankK<
-    ElementA,
-    LayoutA,
-    ElementC,
-    LayoutC,
-    cutlass::FillMode::kUpper,
-    ElementAccumulator,
+using Trmm = cutlass::gemm::device::Trmm<
+    float, cutlass::layout::ColumnMajor,
+    cutlass::SideMode::kRight, cutlass::FillMode::kUpper, cutlass::DiagType::kNonUnit,
+    float, cutlass::layout::RowMajor,
+    float, cutlass::layout::RowMajor,
+    float,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<128, 64, 16>,
-    cutlass::gemm::GemmShape<64, 32, 16>,
-    cutlass::gemm::GemmShape<8, 8, 4>,
+    cutlass::gemm::GemmShape<128, 64, 32>,
+    cutlass::gemm::GemmShape<32, 64, 32>,
+    cutlass::gemm::GemmShape<16, 8, 8>,
     cutlass::epilogue::thread::LinearCombination<
-      ElementC,
+      float,
       1,
-      ElementAccumulator,
-      ElementAccumulator
+      float,
+      float
     >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    4
-  >;
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<8>,
+    3,
+    1,
+    4,
+    false,
+    cutlass::arch::OpMultiplyAdd
+>;
 
-  EXPECT_TRUE(test::gemm::device::TestAllRankKUniversal<RankK>());
+  EXPECT_TRUE(test::gemm::device::TestAllTrmmUniversal<Trmm>());
 }
 
-
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Syrk_f64t_f64n_u_tensor_op_f64, 128x128x16_32x64x16) {
+TEST(SM80_Device_Trmm_tf32n_tf32t_f32t_rs_l_nu_tensor_op_f32_align1_align4, 64x128x32_32x64x32) {
 
-  using ElementA = double;
-  using LayoutA = cutlass::layout::RowMajor;
-  using ElementC = double;
-  using LayoutC = cutlass::layout::ColumnMajor;
-  using ElementAccumulator = double;
-
-  using RankK = cutlass::gemm::device::RankK<
-    ElementA,
-    LayoutA,
-    ElementC,
-    LayoutC,
-    cutlass::FillMode::kUpper,
-    ElementAccumulator,
+using Trmm = cutlass::gemm::device::Trmm<
+    float, cutlass::layout::ColumnMajor,
+    cutlass::SideMode::kRight, cutlass::FillMode::kLower, cutlass::DiagType::kNonUnit,
+    float, cutlass::layout::RowMajor,
+    float, cutlass::layout::RowMajor,
+    float,
     cutlass::arch::OpClassTensorOp,
     cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<128, 128, 16>,
-    cutlass::gemm::GemmShape<32, 64, 16>,
-    cutlass::gemm::GemmShape<8, 8, 4>,
+    cutlass::gemm::GemmShape<64, 128, 32>,
+    cutlass::gemm::GemmShape<32, 64, 32>,
+    cutlass::gemm::GemmShape<16, 8, 8>,
     cutlass::epilogue::thread::LinearCombination<
-      ElementC,
+      float,
       1,
-      ElementAccumulator,
-      ElementAccumulator
+      float,
+      float
     >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<>,
-    3
-  >;
+    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<8>,
+    3,
+    1,
+    4,
+    false,
+    cutlass::arch::OpMultiplyAdd
+>;
 
-  EXPECT_TRUE(test::gemm::device::TestAllRankKUniversal<RankK>());
+  EXPECT_TRUE(test::gemm::device::TestAllTrmmUniversal<Trmm>());
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
-
 #endif // #if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_tf32n_f32t_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_tf32n_f32t_tensor_op_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_tf32t_f32t_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/syrk_tf32t_f32t_tensor_op_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -61,14 +61,17 @@
 namespace device {
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 template <typename Gemm, bool Relu = false>
 struct Testbed {
 
+  using ElementA = typename Gemm::ElementA;
+  using ElementB = typename Gemm::ElementB;
+  using ElementC = typename Gemm::ElementC;
   using ElementAccumulator = typename Gemm::ElementAccumulator;
   using ElementCompute = typename Gemm::GemmKernel::Epilogue::OutputOp::ElementCompute;
 
   /// Initialization
   typename Gemm::LayoutA::Stride stride_factor_A;
   typename Gemm::LayoutB::Stride stride_factor_B;
   typename Gemm::LayoutC::Stride stride_factor_C;
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_complex.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_complex.h`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -59,14 +59,17 @@
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 template <typename Gemm>
 struct TestbedComplex : public Testbed<Gemm> {
 
   using Base = Testbed<Gemm>;
+  using ElementA = typename Gemm::ElementA;
+  using ElementB = typename Gemm::ElementB;
+  using ElementC = typename Gemm::ElementC;
   using ElementAccumulator = typename Gemm::ElementAccumulator;
   using ElementCompute = typename Gemm::GemmKernel::Epilogue::OutputOp::ElementCompute;
 
 
   //
   // Methods
   //
@@ -127,15 +130,15 @@
     if (result != cudaSuccess) {
     	throw std::runtime_error("cudaGetDeviceProperties() failed");
     }
     
     if (properties.sharedMemPerBlockOptin < smem_size) {
     	return false;
     }
-    
+
     return true;
   }
 
   /// Executes one test
   bool run(
     cutlass::gemm::GemmCoord problem_size, 
     int split_k_slices = 1,
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_gemm_with_broadcast.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_gemm_with_broadcast.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -96,31 +96,34 @@
 
 template <
   typename Gemm, 
   typename ReferenceOp = GemmWithBroadcastReferenceOp<Gemm>
 >
 struct TestbedGemmWithBroadcast {
 
+  using ElementA = typename Gemm::ElementA;
+  using ElementB = typename Gemm::ElementB;
   using OutputOp = typename Gemm::GemmKernel::Epilogue::OutputOp;
   using ElementC = typename Gemm::ElementC;
   using ElementAccumulator = typename Gemm::ElementAccumulator;
-  using ElementCOmpute = typename OutputOp::ElementCompute;
+  using ElementCompute = typename OutputOp::ElementCompute;
+  using ElementVector = typename OutputOp::ElementVector;
   using ElementZ = typename OutputOp::ElementZ;
   using ElementT = typename OutputOp::ElementT;
 
   /// Initialization
   cutlass::Distribution::Kind init_A;
   cutlass::Distribution::Kind init_B;
   cutlass::Distribution::Kind init_C;
   uint64_t seed;
 
   cutlass::HostTensor<typename Gemm::ElementA, typename Gemm::LayoutA> tensor_A;          // Input A
   cutlass::HostTensor<typename Gemm::ElementB, typename Gemm::LayoutB> tensor_B;          // Input B
   cutlass::HostTensor<ElementC, typename Gemm::LayoutC> tensor_C;                         // Input C
-  cutlass::HostTensor<ElementC, typename Gemm::LayoutC> tensor_Broadcast;                 // Input Broadcast
+  cutlass::HostTensor<ElementVector, typename Gemm::LayoutC> tensor_Broadcast;            // Input Broadcast
 
   cutlass::HostTensor<ElementZ, typename Gemm::LayoutC> tensor_Z;
   cutlass::HostTensor<ElementT, typename Gemm::LayoutC> tensor_T;
 
   cutlass::HostTensor<ElementAccumulator, typename Gemm::LayoutC> tensor_C_ref;
   cutlass::HostTensor<ElementAccumulator, typename Gemm::LayoutC> tensor_Y_ref;
   cutlass::HostTensor<ElementZ, typename Gemm::LayoutC> tensor_Z_ref;
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_gemm_with_reduction.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_gemm_with_reduction.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -57,14 +57,15 @@
 namespace gemm {
 namespace device {
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 template <typename Gemm, typename BinaryOp>
 struct GemmWithReductionReference {
+
   using ElementAccumulator = typename Gemm::ElementAccumulator;
   using ElementCompute = typename Gemm::GemmKernel::Epilogue::ElementCompute;
   using ElementC = typename Gemm::ElementC;
   using ElementT = typename Gemm::GemmKernel::Epilogue::ElementTensor;
   //
   // Data members
   //
@@ -89,14 +90,17 @@
 
 template <
   typename Gemm,
   typename ReferenceOp
 >
 struct TestbedGemmWithReduction {
 
+  using ElementA = typename Gemm::ElementA;
+  using ElementB = typename Gemm::ElementB;
+  using ElementC = typename Gemm::ElementC;
   using ElementAccumulator = typename Gemm::ElementAccumulator;
   using ElementT = typename Gemm::GemmKernel::Epilogue::ElementTensor;
 
   /// Initialization
   cutlass::Distribution::Kind init_A;
   cutlass::Distribution::Kind init_B;
   cutlass::Distribution::Kind init_C;
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_grouped.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_grouped.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_grouped_rank_2k.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_grouped_rank_2k.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_grouped_rank_2k_scheduler.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_grouped_rank_2k_scheduler.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_grouped_scheduler.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_grouped_scheduler.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_interleaved.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_interleaved.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -53,14 +53,17 @@
 namespace device {
 
 ////////////////////////////////////////////////////////////////////////////////
 
 template <typename Gemm, int InterleavedK>
 struct InterleavedTestbed {
 
+  using ElementA = typename Gemm::ElementA;
+  using ElementB = typename Gemm::ElementB;
+  using ElementC = typename Gemm::ElementC;
   using ElementAccumulator = typename Gemm::ElementAccumulator;
   using ElementCompute = typename Gemm::GemmKernel::Epilogue::OutputOp::ElementCompute;
 
   /// Initialization
   cutlass::Distribution::Kind init_A;
   cutlass::Distribution::Kind init_B;
   cutlass::Distribution::Kind init_C;
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_planar_complex.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_planar_complex.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_rank2k_universal.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_rank2k_universal.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -60,14 +60,17 @@
 namespace device {
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 template <typename Rank2K>
 struct TestbedRank2KUniversal {
 
+  using ElementA = typename Rank2K::ElementA;
+  using ElementB = typename Rank2K::ElementB;
+  using ElementC = typename Rank2K::ElementC;
   using ElementAccumulator = typename Rank2K::ElementAccumulator;
   using ElementCompute = typename Rank2K::Rank2Kkernel::Epilogue::OutputOp::ElementCompute;
 
   /// Initialization
   cutlass::Distribution::Kind init_A;
   cutlass::Distribution::Kind init_B;
   cutlass::Distribution::Kind init_C;
@@ -297,15 +300,14 @@
     if (result != cudaSuccess) {
       throw std::runtime_error("cudaGetDeviceProperties() failed");
     }
 
     if (properties.sharedMemPerBlockOptin < smem_size) {
       return false;
     }
-
     return true;
   }
 
   /// Executes one test
   bool run(
     cutlass::gemm::GemmUniversalMode mode,
     cutlass::gemm::GemmCoord problem_size,
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_rank_k_universal.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_rank_k_universal.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -59,14 +59,16 @@
 namespace device {
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 template <typename RankK>
 struct TestbedRank2KUniversal {
 
+  using ElementA = typename RankK::ElementA;
+  using ElementC = typename RankK::ElementC;
   using ElementAccumulator = typename RankK::ElementAccumulator;
   using ElementCompute = typename RankK::RankKkernel::Epilogue::OutputOp::ElementCompute;
 
   /// Initialization
   cutlass::Distribution::Kind init_A;
   cutlass::Distribution::Kind init_C;
   uint64_t seed;
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_sanity.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_sanity.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_sparse.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_sparse.h`

 * *Files 3% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -60,14 +60,17 @@
 namespace device {
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 template <typename Gemm>
 struct SparseTestbed {
 
+  using ElementA = typename Gemm::ElementA;
+  using ElementB = typename Gemm::ElementB;
+  using ElementC = typename Gemm::ElementC;
   using ElementAccumulator = typename Gemm::ElementAccumulator;
   using ElementCompute = typename Gemm::GemmKernel::Epilogue::OutputOp::ElementCompute;
 
   static int const kSparse = Gemm::GemmKernel::kSparse;
   static int const kMetaSizeInBits = Gemm::GemmKernel::kMetaSizeInBits;
   static int const kMaxID2 = Gemm::GemmKernel::kMaxID2;
   static int const kElementsPerElementE = Gemm::GemmKernel::kElementsPerElementE;
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_splitk.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_splitk.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_symm_universal.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_symm_universal.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -60,14 +60,17 @@
 namespace device {
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 template <typename Symm>
 struct TestbedSymmUniversal {
 
+  using ElementA = typename Symm::ElementA;
+  using ElementB = typename Symm::ElementB;
+  using ElementC = typename Symm::ElementC;
   using ElementAccumulator = typename Symm::ElementAccumulator;
   using ElementCompute = typename Symm::SymmKernel::Epilogue::OutputOp::ElementCompute;
 
   /// Initialization
   cutlass::Distribution::Kind init_A;
   cutlass::Distribution::Kind init_B;
   cutlass::Distribution::Kind init_C;
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_trmm_universal.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_trmm_universal.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -62,14 +62,17 @@
 namespace device {
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 template <typename Trmm>
 struct TestbedTrmmUniversal {
 
+  using ElementA = typename Trmm::ElementA;
+  using ElementB = typename Trmm::ElementB;
+  using ElementC = typename Trmm::ElementC;
   using ElementAccumulator = typename Trmm::ElementAccumulator;
   using ElementCompute = typename Trmm::TrmmKernel::Epilogue::OutputOp::ElementCompute;
 
   /// Initialization
   cutlass::Distribution::Kind init_A;
   cutlass::Distribution::Kind init_B;
   cutlass::Distribution::Kind init_D;
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_universal.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_universal.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -57,14 +57,17 @@
 namespace device {
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 template <typename Gemm, bool Relu = false>
 struct TestbedUniversal {
 
+  using ElementA = typename Gemm::ElementA;
+  using ElementB = typename Gemm::ElementB;
+  using ElementC = typename Gemm::ElementC;
   using ElementAccumulator = typename Gemm::ElementAccumulator;
   using ElementCompute = typename Gemm::GemmKernel::Epilogue::OutputOp::ElementCompute;
 
   /// Initialization
   cutlass::Distribution::Kind init_A;
   cutlass::Distribution::Kind init_B;
   cutlass::Distribution::Kind init_C;
@@ -87,15 +90,15 @@
     uint64_t seed_ = 2080
   ):
     init_A(init_A_), init_B(init_B_), init_C(init_C_), seed(seed_) { }
 
   /// Helper to initialize a tensor view
   template <typename Element, typename Layout>
   bool initialize_tensor(
-    cutlass::TensorView<Element, Layout> view, 
+    cutlass::TensorView<Element, Layout> view,
     cutlass::Distribution::Kind dist_kind,
     uint64_t seed) {
 
     if (dist_kind == cutlass::Distribution::Uniform) {
 
       double scope_max, scope_min;
       int bits_input = cutlass::sizeof_bits<Element>::value;
@@ -113,28 +116,28 @@
       } else {
         scope_max = 8;
         scope_min = -8;
       }
 
       cutlass::reference::host::TensorFillRandomUniform(
         view, seed, scope_max, scope_min, 0);
-    } 
+    }
     else if (dist_kind == cutlass::Distribution::Identity) {
 
       cutlass::reference::host::TensorFillIdentity(view);
-    } 
+    }
     else if (dist_kind == cutlass::Distribution::Gaussian) {
 
       cutlass::reference::host::TensorFillRandomGaussian(view, seed, 0, 0.5);
     }
     else if (dist_kind == cutlass::Distribution::Sequential) {
 
       cutlass::reference::host::BlockFillSequential(
         view.data(), view.capacity());
-    } 
+    }
     else {
       // TODO: Implement the rest
       EXPECT_TRUE(false) << "Not implemented";
       return false;
     }
 
     return true;
@@ -169,24 +172,24 @@
     tensor_B.sync_device();
     tensor_C.sync_device();
     tensor_D.sync_device();
   }
 
   /// Compares computed reference with device reference and outputs to a file if incorrect
   bool compare_reference(
-    cutlass::gemm::GemmCoord problem_size, 
-    ElementCompute alpha, 
+    cutlass::gemm::GemmCoord problem_size,
+    ElementCompute alpha,
     ElementCompute beta) {
 
     tensor_D.sync_host();
 
     EXPECT_GT(cutlass::reference::host::TensorNorm(tensor_A.host_view()), 0);
     EXPECT_GT(cutlass::reference::host::TensorNorm(tensor_B.host_view()), 0);
     EXPECT_GT(cutlass::reference::host::TensorNorm(tensor_C.host_view()), 0);
-    
+
     EXPECT_GT(cutlass::reference::host::TensorNorm(tensor_D.host_view()), 0);
     EXPECT_GT(cutlass::reference::host::TensorNorm(reference_D.host_view()), 0);
 
     bool passed = cutlass::reference::host::TensorEquals(reference_D.host_view(), tensor_D.host_view());
 
     EXPECT_TRUE(passed) << " mismatched reference";
 
@@ -195,66 +198,66 @@
       /*
       std::stringstream fname;
 
       fname << "error_Gemm_device_"
         << problem_size.m() << "x"
         << problem_size.n() << "x"
         << problem_size.k() << "_"
-        << Gemm::ThreadblockShape::kM << "x"  
-        << Gemm::ThreadblockShape::kN << "x"  
+        << Gemm::ThreadblockShape::kM << "x"
+        << Gemm::ThreadblockShape::kN << "x"
         << Gemm::ThreadblockShape::kK << "_"
-        << Gemm::WarpShape::kM << "x"  
-        << Gemm::WarpShape::kN << "x"  
+        << Gemm::WarpShape::kM << "x"
+        << Gemm::WarpShape::kN << "x"
         << Gemm::WarpShape::kK << ".txt";
 
       std::ofstream file(fname.str());
       */
 
       std::ofstream file("testbed_universal_errors.txt");
 
       file
-        << "problem: " << problem_size 
+        << "problem: " << problem_size
         << ", alpha: " << alpha << ", beta: " << beta << "\n\n";
 
-      file 
+      file
         << "A =\n" << tensor_A.host_view()
         << "\nB =\n" << tensor_B.host_view()
         << "\nC =\n" << tensor_C.host_view()
         << "\n\nReference =\n" << reference_D.host_view()
         << "\nComputed =\n" << tensor_D.host_view();
     }
 
     return passed;
   }
 
   /// Verifies the result is a GEMM
   bool verify(
-    cutlass::gemm::GemmCoord problem_size, 
-    ElementCompute alpha, 
+    cutlass::gemm::GemmCoord problem_size,
+    ElementCompute alpha,
     ElementCompute beta) {
 
     //
     // Verify
     //
 
     cutlass::reference::host::GemmComplex<
         typename Gemm::ElementA, typename Gemm::LayoutA,
         typename Gemm::ElementB, typename Gemm::LayoutB,
-        typename Gemm::ElementC, typename Gemm::LayoutC, 
+        typename Gemm::ElementC, typename Gemm::LayoutC,
         ElementCompute, ElementAccumulator
     >(
       problem_size,
-      alpha, 
+      alpha,
       tensor_A.host_ref(),
       Gemm::kTransformA,
       tensor_B.host_ref(),
       Gemm::kTransformB,
-      beta, 
-      tensor_C.host_ref(), 
-      reference_D.host_ref(), 
+      beta,
+      tensor_C.host_ref(),
+      reference_D.host_ref(),
       ElementAccumulator(0)
     );
 
     if (Relu) {
       for (int i = 0; i < problem_size.m(); ++i) {
         for (int j = 0; j < problem_size.n(); ++j) {
            reference_D.at(cutlass::MatrixCoord(i, j)) =
@@ -382,28 +385,28 @@
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 template <typename Gemm, bool Relu = false>
 bool TestGemmUniversal(
   cutlass::gemm::GemmCoord const & problem_size,
   cutlass::gemm::GemmUniversalMode mode,
   int batch_count,
-  double alpha = 1.0, 
+  double alpha = 1.0,
   double beta = 2.0) {
 
   bool passed = true;
 
   TestbedUniversal<Gemm, Relu> testbed;
-  
+
   using ElementCompute = typename Gemm::EpilogueOutputOp::ElementCompute;
 
   passed = testbed.run(
     mode,
-    problem_size, 
+    problem_size,
     batch_count,
-    cutlass::from_real<ElementCompute>(alpha), 
+    cutlass::from_real<ElementCompute>(alpha),
     cutlass::from_real<ElementCompute>(beta)
   );
 
   return passed;
 }
 
 template <typename Gemm, bool Relu = false>
@@ -490,17 +493,17 @@
 
                 cutlass::gemm::GemmCoord problem_size(m, n, k);
 
                 TestbedUniversal<Gemm, Relu> testbed;
 
                 passed = testbed.run(
                   mode,
-                  problem_size, 
+                  problem_size,
                   batch_count,
-                  cutlass::from_real<ElementCompute>(alpha), 
+                  cutlass::from_real<ElementCompute>(alpha),
                   cutlass::from_real<ElementCompute>(beta)
                 );
 
                 if (!passed) {
                   return false;
                 }
               }
@@ -516,17 +519,17 @@
   for (int split_k_slices = 1; split_k_slices <= 3; ++split_k_slices) {
     TestbedUniversal<Gemm> testbed;
 
     cutlass::gemm::GemmCoord problem_size(72, 56, 8192);
 
     passed = testbed.run(
       cutlass::gemm::GemmUniversalMode::kGemm,
-      problem_size, 
+      problem_size,
       split_k_slices,
-      cutlass::from_real<ElementCompute>(1.0), 
+      cutlass::from_real<ElementCompute>(1.0),
       cutlass::from_real<ElementCompute>(2.0)
     );
 
     if (!passed) {
       break;
     }
   }
@@ -538,8 +541,7 @@
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 } // namespace device
 } // namespace gemm
 } // namespace test
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
-
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_utils.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/testbed_utils.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_cf32n_cf32n_cf32t_tensor_op_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_cf32n_cf32n_cf32t_tensor_op_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_cf32n_cf32n_cf32t_tensor_op_fast_f32_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_cf32n_cf32n_cf32t_tensor_op_fast_f32_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_cf64_cf64_cf64_tensor_op_f64_sm90.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_cf64_cf64_cf64_tensor_op_f64_sm90.cu`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -44,15 +44,15 @@
 #include "cutlass/util/reference/host/tensor_compare.h"
 #include "cutlass/util/reference/host/tensor_copy.h"
 #include "cutlass/util/reference/host/tensor_fill.h"
 #include "cutlass/util/tensor_view_io.h"
 
 #include "testbed_trmm_universal.h"
 
-#if defined(CUTLASS_ARCH_MMA_SM90_SUPPORTED)
+#if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 TEST(SM90_Device_Trmm_cf64n_cf64n_cf64t_ls_u_nu_tensor_op_f64_gaussian, 32x32x16_16x16x16) {
 
   using ElementOutput = cutlass::complex<double>;
   using ElementAccumulator = cutlass::complex<double>;
@@ -130,8 +130,8 @@
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllTrmmUniversal<Trmm>());
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-#endif // #if defined(CUTLASS_ARCH_MMA_SM90_SUPPORTED)
+#endif // #if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_cf64n_cf64n_cf64t_tensor_op_f64_gaussian_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_cf64n_cf64n_cf64t_tensor_op_f64_gaussian_sm80.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_cf64n_cf64n_cf64t_tensor_op_f64_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_cf64n_cf64n_cf64t_tensor_op_f64_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_f32n_f32t_f32t_tensor_op_fast_f32_ls_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_f32n_f32t_f32t_tensor_op_fast_f32_ls_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_f32n_f32t_f32t_tensor_op_fast_f32_rs_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_f32n_f32t_f32t_tensor_op_fast_f32_rs_sm80.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_f32t_f32n_f32n_tensor_op_fast_f32_ls_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_f32t_f32n_f32n_tensor_op_fast_f32_ls_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_f32t_f32n_f32t_tensor_op_fast_f32_ls_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_f32t_f32n_f32t_tensor_op_fast_f32_ls_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_f64_f64_f64_tensor_op_f64_sm90.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_f64_f64_f64_tensor_op_f64_sm90.cu`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -44,15 +44,15 @@
 #include "cutlass/util/reference/host/tensor_compare.h"
 #include "cutlass/util/reference/host/tensor_copy.h"
 #include "cutlass/util/reference/host/tensor_fill.h"
 #include "cutlass/util/tensor_view_io.h"
 
 #include "testbed_trmm_universal.h"
 
-#if defined(CUTLASS_ARCH_MMA_SM90_SUPPORTED)
+#if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 TEST(SM90_Device_Trmm_f64n_f64n_f64t_rs_l_nu_tensor_op_f64, 32x32x16_16x16x16) {
 
   using ElementOutput = double;
   using ElementAccumulator = double;
@@ -120,8 +120,8 @@
   >;
 
   EXPECT_TRUE(test::gemm::device::TestAllTrmmUniversal<Trmm>());
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-#endif // #if defined(CUTLASS_ARCH_MMA_SM90_SUPPORTED)
+#endif // #if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_f64n_f64n_f64t_tensor_op_f64_ls_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_f64n_f64n_f64t_tensor_op_f64_ls_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_f64n_f64n_f64t_tensor_op_f64_rs_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_f64n_f64n_f64t_tensor_op_f64_rs_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_f64n_f64t_f64t_tensor_op_f64_rs_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_f64n_f64t_f64t_tensor_op_f64_rs_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_f64t_f64t_f64n_tensor_op_f64_ls_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_f64t_f64t_f64n_tensor_op_f64_ls_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_f64t_f64t_f64n_tensor_op_f64_rs_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_f64t_f64t_f64n_tensor_op_f64_rs_sm80.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_tf32n_tf32t_f32t_tensor_op_f32_ls_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_tf32n_tf32t_f32t_tensor_op_f32_ls_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_tf32n_tf32t_f32t_tensor_op_f32_rs_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_sm70.cu`

 * *Files 25% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -25,228 +25,271 @@
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /*! \file
-    \brief Tests for device-wide TRMM interface
-
-  
+    \brief Unit tests for thread-level GEMM
 */
 
-#include <iostream>
-
 #include "../../common/cutlass_unit_test.h"
-#include "cutlass/blas3.h"
-#include "cutlass/gemm/device/trmm.h"
-#include "cutlass/util/host_tensor.h"
-#include "cutlass/util/reference/host/trmm.h"
-#include "cutlass/util/reference/host/tensor_compare.h"
-#include "cutlass/util/reference/host/tensor_copy.h"
-#include "cutlass/util/reference/host/tensor_fill.h"
-#include "cutlass/util/tensor_view_io.h"
 
-#include "testbed_trmm_universal.h"
+#include "cutlass/aligned_buffer.h"
+#include "cutlass/half.h"
 
-#if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
+#include "cutlass/gemm/warp/mma_tensor_op_sm70.h"
 
-////////////////////////////////////////////Test name//////////////////////////////////////////////////
-//                             
-// SM80_Device_Trmm_{ElementA}{LayoutA}_{ElementB}{LayoutB}_{ElementC}{LayoutC}_{SideMode}_{FillMode}\
-//    _{DiagType}_tensor_op_{ElementAccumulator}_align{AlignmentA}_align{AlignmentB}
-//
-///////////////////////////////////////////////////////////////////////////////////////////////////////
+#include "cutlass/core_io.h"
+#include "cutlass/util/host_tensor.h"
+#include "cutlass/util/tensor_view_io.h"
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+#include "cutlass/util/reference/host/tensor_fill.h"
+#include "cutlass/util/reference/host/tensor_compare.h"
+#include "cutlass/util/reference/host/gemm.h"
 
-TEST(SM80_Device_Trmm_tf32n_tf32t_f32t_rs_u_nu_tensor_op_f32_align1_align1, 64x128x32_32x64x32) {
+#include "testbed.h"
 
-using Trmm = cutlass::gemm::device::Trmm<
-    float, cutlass::layout::ColumnMajor,
-    cutlass::SideMode::kRight, cutlass::FillMode::kUpper, cutlass::DiagType::kNonUnit,
-    float, cutlass::layout::RowMajor,
-    float, cutlass::layout::RowMajor,
-    float,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<64, 128, 32>,
-    cutlass::gemm::GemmShape<32, 64, 32>,
-    cutlass::gemm::GemmShape<16, 8, 8>,
-    cutlass::epilogue::thread::LinearCombination<
-      float,
-      1,
-      float,
-      float
-    >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<8>,
-    3,
-    1,
-    1,
-    false,
-    cutlass::arch::OpMultiplyAdd
->;
+#if defined(CUTLASS_ARCH_MMA_SM70_SUPPORTED)
 
-  EXPECT_TRUE(test::gemm::device::TestAllTrmmUniversal<Trmm>());
-}
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Trmm_tf32n_tf32t_f32t_rs_u_nu_tensor_op_f32_align1_align1, 128x64x32_32x64x32) {
+TEST(SM70_warp_gemm_tensor_op_congruous, 128x128x16_64x64x16_16x16x4) {
+
+  using Shape = cutlass::gemm::GemmShape<64, 64, 16>;
+  using ElementA = cutlass::half_t;
+  using ElementB = cutlass::half_t;
+  using ElementC = cutlass::half_t;
+  using LayoutA = cutlass::layout::ColumnMajorVoltaTensorOpMultiplicandCongruous<cutlass::sizeof_bits<ElementA>::value>;
+  using LayoutB = cutlass::layout::RowMajorVoltaTensorOpMultiplicandBCongruous<cutlass::sizeof_bits<ElementB>::value>;
+
+  using Policy = cutlass::gemm::warp::MmaTensorOpPolicy<
+    cutlass::arch::Mma<
+      cutlass::gemm::GemmShape<16, 16, 4>,
+      32,
+      ElementA,
+      cutlass::layout::ColumnMajor,
+      ElementB,
+      cutlass::layout::RowMajor,
+      ElementC,
+      cutlass::layout::RowMajor,
+      cutlass::arch::OpMultiplyAdd
+    >,
+    cutlass::MatrixShape<1, 1>
+  >;
 
-using Trmm = cutlass::gemm::device::Trmm<
-    float, cutlass::layout::ColumnMajor,
-    cutlass::SideMode::kRight, cutlass::FillMode::kUpper, cutlass::DiagType::kNonUnit,
-    float, cutlass::layout::RowMajor,
-    float, cutlass::layout::RowMajor,
-    float,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<128, 64, 32>,
-    cutlass::gemm::GemmShape<32, 64, 32>,
-    cutlass::gemm::GemmShape<16, 8, 8>,
-    cutlass::epilogue::thread::LinearCombination<
-      float,
-      1,
-      float,
-      float
-    >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<8>,
-    3,
-    1,
-    1,
-    false,
-    cutlass::arch::OpMultiplyAdd
->;
+  using MmaTensorOp = cutlass::gemm::warp::MmaVoltaTensorOp<
+    Shape,
+    ElementA,
+    LayoutA,
+    ElementB,
+    LayoutB,
+    ElementC,
+    cutlass::layout::RowMajor,
+    Policy
+  >;
 
-  EXPECT_TRUE(test::gemm::device::TestAllTrmmUniversal<Trmm>());
+  test::gemm::warp::Testbed<MmaTensorOp, cutlass::gemm::GemmShape<128, 128, 16> >().run();
 }
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+TEST(SM70_warp_gemm_tensor_op_congruous, 128x64x4_64x64x4_16x16x4) {
 
-TEST(SM80_Device_Trmm_tf32n_tf32t_f32t_rs_l_nu_tensor_op_f32_align1_align1, 64x128x32_32x64x32) {
+  using Shape = cutlass::gemm::GemmShape<64, 64, 4>;
+  using ElementA = cutlass::half_t;
+  using ElementB = cutlass::half_t;
+  using ElementC = cutlass::half_t;
+  using LayoutA = cutlass::layout::ColumnMajorVoltaTensorOpMultiplicandCongruous<cutlass::sizeof_bits<ElementA>::value>;
+  using LayoutB = cutlass::layout::RowMajorVoltaTensorOpMultiplicandBCongruous<cutlass::sizeof_bits<ElementB>::value>;
+
+  using Policy = cutlass::gemm::warp::MmaTensorOpPolicy<
+    cutlass::arch::Mma<
+      cutlass::gemm::GemmShape<16, 16, 4>,
+      32,
+      ElementA,
+      cutlass::layout::ColumnMajor,
+      ElementB,
+      cutlass::layout::RowMajor,
+      ElementC,
+      cutlass::layout::RowMajor,
+      cutlass::arch::OpMultiplyAdd
+    >,
+    cutlass::MatrixShape<1, 1>
+  >;
 
-using Trmm = cutlass::gemm::device::Trmm<
-    float, cutlass::layout::ColumnMajor,
-    cutlass::SideMode::kRight, cutlass::FillMode::kLower, cutlass::DiagType::kNonUnit,
-    float, cutlass::layout::RowMajor,
-    float, cutlass::layout::RowMajor,
-    float,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<64, 128, 32>,
-    cutlass::gemm::GemmShape<32, 64, 32>,
-    cutlass::gemm::GemmShape<16, 8, 8>,
-    cutlass::epilogue::thread::LinearCombination<
-      float,
-      1,
-      float,
-      float
-    >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<8>,
-    3,
-    1,
-    1,
-    false,
-    cutlass::arch::OpMultiplyAdd
->;
+  using MmaTensorOp = cutlass::gemm::warp::MmaVoltaTensorOp<
+    Shape,
+    ElementA,
+    LayoutA,
+    ElementB,
+    LayoutB,
+    ElementC,
+    cutlass::layout::RowMajor,
+    Policy
+  >;
 
-  EXPECT_TRUE(test::gemm::device::TestAllTrmmUniversal<Trmm>());
+  test::gemm::warp::Testbed<MmaTensorOp, cutlass::gemm::GemmShape<128, 64, 4> >().run();
 }
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
-
+TEST(SM70_warp_gemm_tensor_op_congruous, 128x128x4_32x32x4_16x16x4) {
 
-TEST(SM80_Device_Trmm_tf32n_tf32t_f32t_rs_u_nu_tensor_op_f32_align1_align4, 64x128x32_32x64x32) {
+  using Shape = cutlass::gemm::GemmShape<32, 32, 4>;
+  using ElementA = cutlass::half_t;
+  using ElementB = cutlass::half_t;
+  using ElementC = cutlass::half_t;
+  using LayoutA = cutlass::layout::ColumnMajorVoltaTensorOpMultiplicandCongruous<cutlass::sizeof_bits<ElementA>::value>;
+  using LayoutB = cutlass::layout::RowMajorVoltaTensorOpMultiplicandBCongruous<cutlass::sizeof_bits<ElementB>::value>;
+
+  using Policy = cutlass::gemm::warp::MmaTensorOpPolicy<
+    cutlass::arch::Mma<
+      cutlass::gemm::GemmShape<16, 16, 4>,
+      32,
+      ElementA,
+      cutlass::layout::ColumnMajor,
+      ElementB,
+      cutlass::layout::RowMajor,
+      ElementC,
+      cutlass::layout::RowMajor,
+      cutlass::arch::OpMultiplyAdd
+    >,
+    cutlass::MatrixShape<1, 1>
+  >;
 
-using Trmm = cutlass::gemm::device::Trmm<
-    float, cutlass::layout::ColumnMajor,
-    cutlass::SideMode::kRight, cutlass::FillMode::kUpper, cutlass::DiagType::kNonUnit,
-    float, cutlass::layout::RowMajor,
-    float, cutlass::layout::RowMajor,
-    float,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<64, 128, 32>,
-    cutlass::gemm::GemmShape<32, 64, 32>,
-    cutlass::gemm::GemmShape<16, 8, 8>,
-    cutlass::epilogue::thread::LinearCombination<
-      float,
-      1,
-      float,
-      float
-    >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<8>,
-    3,
-    1,
-    4,
-    false,
-    cutlass::arch::OpMultiplyAdd
->;
+  using MmaTensorOp = cutlass::gemm::warp::MmaVoltaTensorOp<
+    Shape,
+    ElementA,
+    LayoutA,
+    ElementB,
+    LayoutB,
+    ElementC,
+    cutlass::layout::RowMajor,
+    Policy
+  >;
 
-  EXPECT_TRUE(test::gemm::device::TestAllTrmmUniversal<Trmm>());
+  test::gemm::warp::Testbed<MmaTensorOp, cutlass::gemm::GemmShape<128, 128, 4> >().run();
 }
-/////////////////////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Trmm_tf32n_tf32t_f32t_rs_u_nu_tensor_op_f32_align1_align4, 128x64x32_32x64x32) {
+TEST(SM70_warp_gemm_tensor_op_crosswise, 64x64x32_64x64x32_16x16x4) {
+  using Shape = cutlass::gemm::GemmShape<64, 64, 32>;
+  using ElementA = cutlass::half_t;
+  using ElementB = cutlass::half_t;
+  using ElementC = cutlass::half_t;
+  using LayoutA = cutlass::layout::RowMajorVoltaTensorOpMultiplicandCrosswise<
+      cutlass::sizeof_bits<ElementA>::value, 32>;
+  using LayoutB = cutlass::layout::ColumnMajorVoltaTensorOpMultiplicandCrosswise<
+      cutlass::sizeof_bits<ElementB>::value, 32>;
+
+  using Policy = cutlass::gemm::warp::MmaTensorOpPolicy<
+    cutlass::arch::Mma<
+      cutlass::gemm::GemmShape<16, 16, 4>,
+      32,
+      ElementA,
+      cutlass::layout::RowMajor,
+      ElementB,
+      cutlass::layout::ColumnMajor,
+      ElementC,
+      cutlass::layout::RowMajor,
+      cutlass::arch::OpMultiplyAdd
+    >,
+    cutlass::MatrixShape<1, 1>
+  >;
 
-using Trmm = cutlass::gemm::device::Trmm<
-    float, cutlass::layout::ColumnMajor,
-    cutlass::SideMode::kRight, cutlass::FillMode::kUpper, cutlass::DiagType::kNonUnit,
-    float, cutlass::layout::RowMajor,
-    float, cutlass::layout::RowMajor,
-    float,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<128, 64, 32>,
-    cutlass::gemm::GemmShape<32, 64, 32>,
-    cutlass::gemm::GemmShape<16, 8, 8>,
-    cutlass::epilogue::thread::LinearCombination<
-      float,
-      1,
-      float,
-      float
-    >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<8>,
-    3,
-    1,
-    4,
-    false,
-    cutlass::arch::OpMultiplyAdd
->;
+  using MmaTensorOp = cutlass::gemm::warp::MmaVoltaTensorOp<
+    Shape,
+    ElementA,
+    LayoutA,
+    ElementB,
+    LayoutB,
+    ElementC,
+    cutlass::layout::RowMajor,
+    Policy
+  >;
 
-  EXPECT_TRUE(test::gemm::device::TestAllTrmmUniversal<Trmm>());
+  test::gemm::warp::Testbed<MmaTensorOp, cutlass::gemm::GemmShape<64, 64, 32> >().run();
 }
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM80_Device_Trmm_tf32n_tf32t_f32t_rs_l_nu_tensor_op_f32_align1_align4, 64x128x32_32x64x32) {
+TEST(SM70_warp_gemm_volta_tensor_op_canonical_f32_row_col, 64x64x16_64x64x4_8x8x4) {
+  
+  using Shape = cutlass::gemm::GemmShape<64, 64, 4>;
+  using InstructionShape = cutlass::gemm::GemmShape<8, 8, 4>;
+  using ElementA = cutlass::half_t;
+  using ElementB = cutlass::half_t;
+  using ElementC = float;
+  using LayoutA = cutlass::layout::RowMajor;
+  using LayoutB = cutlass::layout::ColumnMajor;
+
+  using Policy = cutlass::gemm::warp::MmaTensorOpPolicy<
+    cutlass::arch::Mma<
+      cutlass::gemm::GemmShape<16, 16, 4>,
+      32,
+      ElementA,
+      cutlass::layout::RowMajor,
+      ElementB,
+      cutlass::layout::ColumnMajor,
+      ElementC,
+      cutlass::layout::RowMajor,
+      cutlass::arch::OpMultiplyAdd
+    >,
+    cutlass::MatrixShape<1, 1>
+  >;
 
-using Trmm = cutlass::gemm::device::Trmm<
-    float, cutlass::layout::ColumnMajor,
-    cutlass::SideMode::kRight, cutlass::FillMode::kLower, cutlass::DiagType::kNonUnit,
-    float, cutlass::layout::RowMajor,
-    float, cutlass::layout::RowMajor,
-    float,
-    cutlass::arch::OpClassTensorOp,
-    cutlass::arch::Sm80,
-    cutlass::gemm::GemmShape<64, 128, 32>,
-    cutlass::gemm::GemmShape<32, 64, 32>,
-    cutlass::gemm::GemmShape<16, 8, 8>,
-    cutlass::epilogue::thread::LinearCombination<
-      float,
-      1,
-      float,
-      float
-    >,
-    cutlass::gemm::threadblock::GemmIdentityThreadblockSwizzle<8>,
-    3,
-    1,
-    4,
-    false,
-    cutlass::arch::OpMultiplyAdd
->;
+  using MmaTensorOp = cutlass::gemm::warp::MmaVoltaTensorOp<
+    Shape,
+    ElementA,
+    LayoutA,
+    ElementB,
+    LayoutB,
+    ElementC,
+    cutlass::layout::RowMajor,
+    Policy
+  >;
+
+  test::gemm::warp::Testbed<MmaTensorOp,
+                            cutlass::gemm::GemmShape<64, 64, 16> >()
+      .run();
+}
 
-  EXPECT_TRUE(test::gemm::device::TestAllTrmmUniversal<Trmm>());
+TEST(SM70_warp_gemm_volta_tensor_op_canonical_f32_col_row, 64x64x16_64x64x4_8x8x4) {
+  
+  using Shape = cutlass::gemm::GemmShape<64, 64, 4>;
+  using InstructionShape = cutlass::gemm::GemmShape<8, 8, 4>;
+  using ElementA = cutlass::half_t;
+  using ElementB = cutlass::half_t;
+  using ElementC = float;
+  using LayoutA = cutlass::layout::ColumnMajor;
+  using LayoutB = cutlass::layout::RowMajor;
+
+  using Policy = cutlass::gemm::warp::MmaTensorOpPolicy<
+    cutlass::arch::Mma<
+      cutlass::gemm::GemmShape<16, 16, 4>,
+      32,
+      ElementA,
+      LayoutA,
+      ElementB,
+      LayoutB,
+      ElementC,
+      cutlass::layout::RowMajor,
+      cutlass::arch::OpMultiplyAdd
+    >,
+    cutlass::MatrixShape<1, 1>
+  >;
+
+  using MmaTensorOp = cutlass::gemm::warp::MmaVoltaTensorOp<
+    Shape,
+    ElementA,
+    LayoutA,
+    ElementB,
+    LayoutB,
+    ElementC,
+    cutlass::layout::RowMajor,
+    Policy
+  >;
+
+  test::gemm::warp::Testbed<MmaTensorOp,
+                            cutlass::gemm::GemmShape<64, 64, 16> >()
+      .run();
 }
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
-#endif // #if defined(CUTLASS_ARCH_MMA_SM80_SUPPORTED)
+
+#endif // CUTLASS_ARCH_MMA_SM70_SUPPORTED
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_tf32t_tf32n_f32n_tensor_op_f32_ls_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_tf32t_tf32n_f32n_tensor_op_f32_ls_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_tf32t_tf32n_f32t_tensor_op_f32_ls_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/device/trmm_tf32t_tf32n_f32t_tensor_op_f32_ls_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/kernel/batched_gemv.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/kernel/batched_gemv.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/kernel/testbed_gemv.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/kernel/testbed_gemv.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -57,15 +57,15 @@
         typename ThreadShape_,
         typename ElementAB_,
         typename ElementAccumulator_,
         typename ElementCD_,
         typename LayoutA_,
         typename LayoutB_,
         typename LayoutCD_,
-        int LDG_B = 1, // batch tile size
+        int THREAD_B = 1, // batch tile size
         bool DEBUG=false>
 void batched_gemv_kernel_test(cutlass::gemm::BatchedGemmCoord problem_size,
                               ElementCD_ alpha = ElementCD_(1),
                               ElementCD_ beta = ElementCD_(0),
                               bool perf_test = false,
                               int perf_test_iter = 1)
 {
@@ -150,15 +150,15 @@
     matrix_C_computed.sync_device();
 
     ThreadBlockSwizzle swizzle;
 
     cutlass::gemm::BatchedGemmCoord tiled_size{ThreadBlockShape::kM,
                                                 ThreadBlockShape::kN,
                                                 problem_size.k(), // no split-k
-                                                DEBUG ? 1 : LDG_B };
+                                                DEBUG ? 1 : THREAD_B };
 
     cutlass::gemm::BatchedGemmCoord tiled_shape = swizzle.get_tiled_shape(problem_size, tiled_size);
 
     #if 0 
     printf("tiled_size = %d %d %d %d\n", tiled_size.m(), tiled_size.n(), tiled_size.k(), tiled_size.batch());
     printf("tiled_shape = %d %d %d %d\n", tiled_shape.m(), tiled_shape.n(), tiled_shape.k(), tiled_shape.batch());
     #endif
@@ -330,29 +330,29 @@
         typename ThreadShape_,
         typename ElementAB_,
         typename ElementAccumulator_,
         typename ElementCD_,
         typename LayoutA_,
         typename LayoutB_,
         typename LayoutCD_,
-        int LDG_B = 1, // batch tile size
+        int THREAD_B = 1, // batch tile size
         bool DEBUG=false>
 void batched_gemv_kernel_perf_test(cutlass::gemm::BatchedGemmCoord problem_size,
                                    ElementCD_ alpha = ElementCD_(1),
                                    ElementCD_ beta = ElementCD_(0),
                                    int iter = 50)
 {
     batched_gemv_kernel_test<ThreadBlockShape_,
                              ThreadShape_,
                              ElementAB_,
                              ElementAccumulator_,
                              ElementCD_,
                              LayoutA_,
                              LayoutB_,
                              LayoutCD_,
-                             LDG_B,
+                             THREAD_B,
                              DEBUG>(problem_size, alpha, beta, true, iter);
 }
     
 } // namespace threadblock
 } // namespace kernel
 } // namespace test
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/thread/gemm_sm50.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/thread/gemm_sm50.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/thread/gemm_sm60.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/thread/gemm_sm60.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/thread/gemm_sm61.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/thread/gemm_sm61.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/thread/host/gemm_sm60_host.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/thread/host/gemm_sm60_host.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/thread/host/testbed_host.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/thread/host/testbed_host.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/thread/testbed.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/thread/testbed.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/batched_gemv.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/batched_gemv.cu`

 * *Files 16% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -103,28 +103,28 @@
 
 template<typename Shape_,
          typename ElementAB_,
          typename ElementC_,
          typename LayoutA_,
          typename LayoutB_,
          typename LayoutC_,
-         int LDG_N,
-         int LDG_K,
+         int THREAD_N,
+         int THREAD_K,
          int MAX_THREADS_PER_BLOCK=512,
          bool DEBUG=false>
 void batched_gemv_threadblock_test(cutlass::gemm::GemmCoord problem_size, int num_batch)
 {
   using Shape = Shape_;
   using ElementA = ElementAB_;
   using LayoutA = LayoutA_;
   using ElementB = ElementAB_;
   using LayoutB = LayoutB_;
   using ElementC = ElementC_;
   using LayoutC = LayoutC_;
-  using ThreadShape = cutlass::gemm::GemmShape<1, LDG_N, LDG_K>;
+  using ThreadShape = cutlass::gemm::GemmShape<1, THREAD_N, THREAD_K>;
 
   using Core = typename cutlass::gemm::threadblock::DefaultGemvCore<
     Shape,
     ThreadShape,
     ElementA,
     LayoutA,
     ElementB,
@@ -188,22 +188,22 @@
   }
 
   matrix_A.sync_device();
   matrix_B.sync_device();
   matrix_C_computed.sync_device();
 
   dim3 grid(1, 1);      // only 1 CTA is used
-  dim3 block(Shape::kN / LDG_N, num_batch, 1);
+  dim3 block(Shape::kN / THREAD_N, num_batch, 1);
 
   #if 0
   printf("block dim = %d x %d\n", block.x, block.y);
   #endif
 
   // Some sanity checks
-  EXPECT_TRUE( problem_size.n() % LDG_N == 0 );
+  EXPECT_TRUE( problem_size.n() % THREAD_N == 0 );
   EXPECT_TRUE( block.x*block.y <= MAX_THREADS_PER_BLOCK );
 
   test::gemm::threadblock::batched_gemv_threadblock_test_kernel<Mma><<< grid, block >>>(
     problem_size,
     matrix_A.capacity(),
     matrix_B.capacity(),
     matrix_C_computed.capacity(),
@@ -257,390 +257,390 @@
 // C: ColumnMajor
 
 TEST(SM50_batched_gemv_threadblock, 4x1x64x64_crc_fp32_fp32_2N_2K) {
   
   using namespace test::gemm::threadblock;
   cutlass::gemm::GemmCoord problem_size(1, 64, 64);
   const int num_batch = 4;
-  const int LDG_N = 2;
-  const int LDG_K = 2;
+  const int THREAD_N = 2;
+  const int THREAD_K = 2;
  
-  using Shape = cutlass::gemm::GemmShape<1, 64, LDG_K>;
+  using Shape = cutlass::gemm::GemmShape<1, 64, THREAD_K>;
   batched_gemv_threadblock_test<Shape, float, float, 
                                 cutlass::layout::ColumnMajor,
                                 cutlass::layout::RowMajor,
                                 cutlass::layout::ColumnMajor,
-                                LDG_N, LDG_K>(problem_size, num_batch);
+                                THREAD_N, THREAD_K>(problem_size, num_batch);
 }
 
 TEST(SM50_batched_gemv_threadblock, 5x1x128x128_crc_fp32_fp32_4N_4K) {
   using namespace test::gemm::threadblock;
   cutlass::gemm::GemmCoord problem_size(1, 128, 128);
   const int num_batch = 5;
-  const int LDG_N = 4;
-  const int LDG_K = 4;
+  const int THREAD_N = 4;
+  const int THREAD_K = 4;
 
-  using Shape = cutlass::gemm::GemmShape<1, 128, LDG_K>;
+  using Shape = cutlass::gemm::GemmShape<1, 128, THREAD_K>;
   batched_gemv_threadblock_test<Shape, float, float, 
                                 cutlass::layout::ColumnMajor,
                                 cutlass::layout::RowMajor,
                                 cutlass::layout::ColumnMajor,
-                                LDG_N, LDG_K>(problem_size, num_batch);
+                                THREAD_N, THREAD_K>(problem_size, num_batch);
 }
 
 TEST(SM50_batched_gemv_threadblock, 16x1x17x64_crc_fp32_fp32_1N_4K) {
   using namespace test::gemm::threadblock;
   cutlass::gemm::GemmCoord problem_size(1, 17, 64);
   const int num_batch = 16;
-  const int LDG_N = 1;
-  const int LDG_K = 4;
+  const int THREAD_N = 1;
+  const int THREAD_K = 4;
 
-  using Shape = cutlass::gemm::GemmShape<1, 32, LDG_K>;
+  using Shape = cutlass::gemm::GemmShape<1, 32, THREAD_K>;
   batched_gemv_threadblock_test<Shape,
                                 float, float, 
                                 cutlass::layout::ColumnMajor,
                                 cutlass::layout::RowMajor,
                                 cutlass::layout::ColumnMajor,
-                                LDG_N, LDG_K>(problem_size, num_batch);
+                                THREAD_N, THREAD_K>(problem_size, num_batch);
 }
 
 TEST(SM50_batched_gemv_threadblock, 4x1x64x64_crc_fp16_fp32_2N_2K) {
   using namespace test::gemm::threadblock;
   cutlass::gemm::GemmCoord problem_size(1, 64, 64);
   const int num_batch = 4;
-  const int LDG_N = 2;
-  const int LDG_K = 2;
+  const int THREAD_N = 2;
+  const int THREAD_K = 2;
   
-  using Shape = cutlass::gemm::GemmShape<1, 64, LDG_K>;
+  using Shape = cutlass::gemm::GemmShape<1, 64, THREAD_K>;
   batched_gemv_threadblock_test<Shape,
                                 cutlass::half_t, float, 
                                 cutlass::layout::ColumnMajor,
                                 cutlass::layout::RowMajor,
                                 cutlass::layout::ColumnMajor,
-                                LDG_N, LDG_K>(problem_size, num_batch);
+                                THREAD_N, THREAD_K>(problem_size, num_batch);
 }
 
 TEST(SM50_batched_gemv_threadblock, 4x1x64x64_crc_fp16_fp32_2N_8K) {
   using namespace test::gemm::threadblock;
   cutlass::gemm::GemmCoord problem_size(1, 64, 64);
   const int num_batch = 4;
-  const int LDG_N = 2;
-  const int LDG_K = 8;
+  const int THREAD_N = 2;
+  const int THREAD_K = 8;
  
-  using Shape = cutlass::gemm::GemmShape<1, 64, LDG_K>;
+  using Shape = cutlass::gemm::GemmShape<1, 64, THREAD_K>;
   batched_gemv_threadblock_test<Shape,
                                 cutlass::half_t, float, 
                                 cutlass::layout::ColumnMajor,
                                 cutlass::layout::RowMajor,
                                 cutlass::layout::ColumnMajor,
-                                LDG_N, LDG_K>(problem_size, num_batch);
+                                THREAD_N, THREAD_K>(problem_size, num_batch);
 }
 
 TEST(SM50_batched_gemv_threadblock, 16x1x17x64_crc_fp16_fp32_1N_4K) {
   using namespace test::gemm::threadblock;
   cutlass::gemm::GemmCoord problem_size(1, 17, 64);
   const int num_batch = 16;
-  const int LDG_N = 1;
-  const int LDG_K = 4;
+  const int THREAD_N = 1;
+  const int THREAD_K = 4;
 
-  using Shape = cutlass::gemm::GemmShape<1, 32, LDG_K>;
+  using Shape = cutlass::gemm::GemmShape<1, 32, THREAD_K>;
   batched_gemv_threadblock_test<Shape,
                                 cutlass::half_t, float, 
                                 cutlass::layout::ColumnMajor,
                                 cutlass::layout::RowMajor,
                                 cutlass::layout::ColumnMajor,
-                                LDG_N, LDG_K>(problem_size, num_batch);
+                                THREAD_N, THREAD_K>(problem_size, num_batch);
 }
 
 TEST(SM50_batched_gemv_threadblock, 4x1x64x64_crc_i8_i32_2N_4K) {
   using namespace test::gemm::threadblock;
   cutlass::gemm::GemmCoord problem_size(1, 64, 64);
   const int num_batch = 4;
-  const int LDG_N = 2;
-  const int LDG_K = 4;
+  const int THREAD_N = 2;
+  const int THREAD_K = 4;
 
-  using Shape = cutlass::gemm::GemmShape<1, 128, LDG_K>;
+  using Shape = cutlass::gemm::GemmShape<1, 128, THREAD_K>;
   batched_gemv_threadblock_test<Shape,
                                 int8_t, int32_t, 
                                 cutlass::layout::ColumnMajor,
                                 cutlass::layout::RowMajor,
                                 cutlass::layout::ColumnMajor,
-                                LDG_N, LDG_K>(problem_size, num_batch);
+                                THREAD_N, THREAD_K>(problem_size, num_batch);
 }
 
 TEST(SM50_batched_gemv_threadblock, 16x1x17x64_crc_i8_i32_1N_4K) {
   using namespace test::gemm::threadblock;
   cutlass::gemm::GemmCoord problem_size(1, 17, 64);
   const int num_batch = 16;
-  const int LDG_N = 1;
-  const int LDG_K = 4;
+  const int THREAD_N = 1;
+  const int THREAD_K = 4;
 
-  using Shape = cutlass::gemm::GemmShape<1, 32, LDG_K>;
+  using Shape = cutlass::gemm::GemmShape<1, 32, THREAD_K>;
   batched_gemv_threadblock_test<Shape,
                                 int8_t, int32_t, 
                                 cutlass::layout::ColumnMajor,
                                 cutlass::layout::RowMajor,
                                 cutlass::layout::ColumnMajor,
-                                LDG_N, LDG_K>(problem_size, num_batch);
+                                THREAD_N, THREAD_K>(problem_size, num_batch);
 }
 
 // A: RowMajor
 // B: ColumnMajor
 // C: RowMajor
 
 TEST(SM50_batched_gemv_threadblock, 4x1x64x64_rcr_fp32_fp32_2N_2K) {
   
   using namespace test::gemm::threadblock;
   cutlass::gemm::GemmCoord problem_size(1, 64, 64);
   const int num_batch = 4;
-  const int LDG_N = 2;
-  const int LDG_K = 2;
+  const int THREAD_N = 2;
+  const int THREAD_K = 2;
  
-  using Shape = cutlass::gemm::GemmShape<1, 64, LDG_K>;
+  using Shape = cutlass::gemm::GemmShape<1, 64, THREAD_K>;
   batched_gemv_threadblock_test<Shape, float, float, 
                                 cutlass::layout::RowMajor,
                                 cutlass::layout::ColumnMajor,
                                 cutlass::layout::RowMajor,
-                                LDG_N, LDG_K>(problem_size, num_batch);
+                                THREAD_N, THREAD_K>(problem_size, num_batch);
 }
 
 TEST(SM50_batched_gemv_threadblock, 5x1x128x128_rcr_fp32_fp32_4N_4K) {
   using namespace test::gemm::threadblock;
   cutlass::gemm::GemmCoord problem_size(1, 128, 128);
   const int num_batch = 5;
-  const int LDG_N = 4;
-  const int LDG_K = 4;
+  const int THREAD_N = 4;
+  const int THREAD_K = 4;
 
-  using Shape = cutlass::gemm::GemmShape<1, 128, LDG_K>;
+  using Shape = cutlass::gemm::GemmShape<1, 128, THREAD_K>;
   batched_gemv_threadblock_test<Shape, float, float, 
                                 cutlass::layout::RowMajor,
                                 cutlass::layout::ColumnMajor,
                                 cutlass::layout::RowMajor,
-                                LDG_N, LDG_K>(problem_size, num_batch);
+                                THREAD_N, THREAD_K>(problem_size, num_batch);
 }
 
 TEST(SM50_batched_gemv_threadblock, 16x1x17x64_rcr_fp32_fp32_1N_4K) {
   using namespace test::gemm::threadblock;
   cutlass::gemm::GemmCoord problem_size(1, 17, 64);
   const int num_batch = 16;
-  const int LDG_N = 1;
-  const int LDG_K = 4;
+  const int THREAD_N = 1;
+  const int THREAD_K = 4;
 
-  using Shape = cutlass::gemm::GemmShape<1, 32, LDG_K>;
+  using Shape = cutlass::gemm::GemmShape<1, 32, THREAD_K>;
   batched_gemv_threadblock_test<Shape,
                                 float, float, 
                                 cutlass::layout::RowMajor,
                                 cutlass::layout::ColumnMajor,
                                 cutlass::layout::RowMajor,
-                                LDG_N, LDG_K>(problem_size, num_batch);
+                                THREAD_N, THREAD_K>(problem_size, num_batch);
 }
 
 TEST(SM50_batched_gemv_threadblock, 4x1x64x64_rcr_fp16_fp32_2N_2K) {
   using namespace test::gemm::threadblock;
   cutlass::gemm::GemmCoord problem_size(1, 64, 64);
   const int num_batch = 4;
-  const int LDG_N = 2;
-  const int LDG_K = 2;
+  const int THREAD_N = 2;
+  const int THREAD_K = 2;
   
-  using Shape = cutlass::gemm::GemmShape<1, 64, LDG_K>;
+  using Shape = cutlass::gemm::GemmShape<1, 64, THREAD_K>;
   batched_gemv_threadblock_test<Shape,
                                 cutlass::half_t, float, 
                                 cutlass::layout::RowMajor,
                                 cutlass::layout::ColumnMajor,
                                 cutlass::layout::RowMajor,
-                                LDG_N, LDG_K>(problem_size, num_batch);
+                                THREAD_N, THREAD_K>(problem_size, num_batch);
 }
 
 TEST(SM50_batched_gemv_threadblock, 4x1x64x64_rcr_fp16_fp32_2N_8K) {
   using namespace test::gemm::threadblock;
   cutlass::gemm::GemmCoord problem_size(1, 64, 64);
   const int num_batch = 4;
-  const int LDG_N = 2;
-  const int LDG_K = 8;
+  const int THREAD_N = 2;
+  const int THREAD_K = 8;
  
-  using Shape = cutlass::gemm::GemmShape<1, 64, LDG_K>;
+  using Shape = cutlass::gemm::GemmShape<1, 64, THREAD_K>;
   batched_gemv_threadblock_test<Shape,
                                 cutlass::half_t, float, 
                                 cutlass::layout::RowMajor,
                                 cutlass::layout::ColumnMajor,
                                 cutlass::layout::RowMajor,
-                                LDG_N, LDG_K>(problem_size, num_batch);
+                                THREAD_N, THREAD_K>(problem_size, num_batch);
 }
 
 TEST(SM50_batched_gemv_threadblock, 16x1x17x64_rcr_fp16_fp32_1N_4K) {
   using namespace test::gemm::threadblock;
   cutlass::gemm::GemmCoord problem_size(1, 17, 64);
   const int num_batch = 16;
-  const int LDG_N = 1;
-  const int LDG_K = 4;
+  const int THREAD_N = 1;
+  const int THREAD_K = 4;
 
-  using Shape = cutlass::gemm::GemmShape<1, 32, LDG_K>;
+  using Shape = cutlass::gemm::GemmShape<1, 32, THREAD_K>;
   batched_gemv_threadblock_test<Shape,
                                 cutlass::half_t, float, 
                                 cutlass::layout::RowMajor,
                                 cutlass::layout::ColumnMajor,
                                 cutlass::layout::RowMajor,
-                                LDG_N, LDG_K>(problem_size, num_batch);
+                                THREAD_N, THREAD_K>(problem_size, num_batch);
 }
 
 TEST(SM50_batched_gemv_threadblock, 4x1x64x64_rcr_i8_i32_2N_4K) {
   using namespace test::gemm::threadblock;
   cutlass::gemm::GemmCoord problem_size(1, 64, 64);
   const int num_batch = 4;
-  const int LDG_N = 2;
-  const int LDG_K = 4;
+  const int THREAD_N = 2;
+  const int THREAD_K = 4;
 
-  using Shape = cutlass::gemm::GemmShape<1, 128, LDG_K>;
+  using Shape = cutlass::gemm::GemmShape<1, 128, THREAD_K>;
   batched_gemv_threadblock_test<Shape,
                                 int8_t, int32_t, 
                                 cutlass::layout::RowMajor,
                                 cutlass::layout::ColumnMajor,
                                 cutlass::layout::RowMajor,
-                                LDG_N, LDG_K>(problem_size, num_batch);
+                                THREAD_N, THREAD_K>(problem_size, num_batch);
 }
 
 TEST(SM50_batched_gemv_threadblock, 16x1x17x64_rcr_i8_i32_1N_4K) {
   using namespace test::gemm::threadblock;
   cutlass::gemm::GemmCoord problem_size(1, 17, 64);
   const int num_batch = 16;
-  const int LDG_N = 1;
-  const int LDG_K = 4;
+  const int THREAD_N = 1;
+  const int THREAD_K = 4;
 
-  using Shape = cutlass::gemm::GemmShape<1, 32, LDG_K>;
+  using Shape = cutlass::gemm::GemmShape<1, 32, THREAD_K>;
   batched_gemv_threadblock_test<Shape,
                                 int8_t, int32_t, 
                                 cutlass::layout::RowMajor,
                                 cutlass::layout::ColumnMajor,
                                 cutlass::layout::RowMajor,
-                                LDG_N, LDG_K>(problem_size, num_batch);
+                                THREAD_N, THREAD_K>(problem_size, num_batch);
 }
 
 // A: RowMajor
 // B: ColumnMajor
 // C: ColumnMajor
 
 TEST(SM50_batched_gemv_threadblock, 4x1x64x64_rcc_fp32_fp32_2N_2K) {
   
   using namespace test::gemm::threadblock;
   cutlass::gemm::GemmCoord problem_size(1, 64, 64);
   const int num_batch = 4;
-  const int LDG_N = 2;
-  const int LDG_K = 2;
+  const int THREAD_N = 2;
+  const int THREAD_K = 2;
  
-  using Shape = cutlass::gemm::GemmShape<1, 64, LDG_K>;
+  using Shape = cutlass::gemm::GemmShape<1, 64, THREAD_K>;
   batched_gemv_threadblock_test<Shape, float, float, 
                                 cutlass::layout::RowMajor,
                                 cutlass::layout::ColumnMajor,
                                 cutlass::layout::ColumnMajor,
-                                LDG_N, LDG_K>(problem_size, num_batch);
+                                THREAD_N, THREAD_K>(problem_size, num_batch);
 }
 
 TEST(SM50_batched_gemv_threadblock, 5x1x128x128_rcc_fp32_fp32_4N_4K) {
   using namespace test::gemm::threadblock;
   cutlass::gemm::GemmCoord problem_size(1, 128, 128);
   const int num_batch = 5;
-  const int LDG_N = 4;
-  const int LDG_K = 4;
+  const int THREAD_N = 4;
+  const int THREAD_K = 4;
 
-  using Shape = cutlass::gemm::GemmShape<1, 128, LDG_K>;
+  using Shape = cutlass::gemm::GemmShape<1, 128, THREAD_K>;
   batched_gemv_threadblock_test<Shape, float, float, 
                                 cutlass::layout::RowMajor,
                                 cutlass::layout::ColumnMajor,
                                 cutlass::layout::ColumnMajor,
-                                LDG_N, LDG_K>(problem_size, num_batch);
+                                THREAD_N, THREAD_K>(problem_size, num_batch);
 }
 
 TEST(SM50_batched_gemv_threadblock, 16x1x17x64_rcc_fp32_fp32_1N_4K) {
   using namespace test::gemm::threadblock;
   cutlass::gemm::GemmCoord problem_size(1, 17, 64);
   const int num_batch = 16;
-  const int LDG_N = 1;
-  const int LDG_K = 4;
+  const int THREAD_N = 1;
+  const int THREAD_K = 4;
 
-  using Shape = cutlass::gemm::GemmShape<1, 32, LDG_K>;
+  using Shape = cutlass::gemm::GemmShape<1, 32, THREAD_K>;
   batched_gemv_threadblock_test<Shape,
                                 float, float, 
                                 cutlass::layout::RowMajor,
                                 cutlass::layout::ColumnMajor,
                                 cutlass::layout::ColumnMajor,
-                                LDG_N, LDG_K>(problem_size, num_batch);
+                                THREAD_N, THREAD_K>(problem_size, num_batch);
 }
 
 TEST(SM50_batched_gemv_threadblock, 4x1x64x64_rcc_fp16_fp32_2N_2K) {
   using namespace test::gemm::threadblock;
   cutlass::gemm::GemmCoord problem_size(1, 64, 64);
   const int num_batch = 4;
-  const int LDG_N = 2;
-  const int LDG_K = 2;
+  const int THREAD_N = 2;
+  const int THREAD_K = 2;
   
-  using Shape = cutlass::gemm::GemmShape<1, 64, LDG_K>;
+  using Shape = cutlass::gemm::GemmShape<1, 64, THREAD_K>;
   batched_gemv_threadblock_test<Shape,
                                 cutlass::half_t, float, 
                                 cutlass::layout::RowMajor,
                                 cutlass::layout::ColumnMajor,
                                 cutlass::layout::ColumnMajor,
-                                LDG_N, LDG_K>(problem_size, num_batch);
+                                THREAD_N, THREAD_K>(problem_size, num_batch);
 }
 
 TEST(SM50_batched_gemv_threadblock, 4x1x64x64_rcc_fp16_fp32_2N_8K) {
   using namespace test::gemm::threadblock;
   cutlass::gemm::GemmCoord problem_size(1, 64, 64);
   const int num_batch = 4;
-  const int LDG_N = 2;
-  const int LDG_K = 8;
+  const int THREAD_N = 2;
+  const int THREAD_K = 8;
  
-  using Shape = cutlass::gemm::GemmShape<1, 64, LDG_K>;
+  using Shape = cutlass::gemm::GemmShape<1, 64, THREAD_K>;
   batched_gemv_threadblock_test<Shape,
                                 cutlass::half_t, float, 
                                 cutlass::layout::RowMajor,
                                 cutlass::layout::ColumnMajor,
                                 cutlass::layout::ColumnMajor,
-                                LDG_N, LDG_K>(problem_size, num_batch);
+                                THREAD_N, THREAD_K>(problem_size, num_batch);
 }
 
 TEST(SM50_batched_gemv_threadblock, 16x1x17x64_rcc_fp16_fp32_1N_4K) {
   using namespace test::gemm::threadblock;
   cutlass::gemm::GemmCoord problem_size(1, 17, 64);
   const int num_batch = 16;
-  const int LDG_N = 1;
-  const int LDG_K = 4;
+  const int THREAD_N = 1;
+  const int THREAD_K = 4;
 
-  using Shape = cutlass::gemm::GemmShape<1, 32, LDG_K>;
+  using Shape = cutlass::gemm::GemmShape<1, 32, THREAD_K>;
   batched_gemv_threadblock_test<Shape,
                                 cutlass::half_t, float, 
                                 cutlass::layout::RowMajor,
                                 cutlass::layout::ColumnMajor,
                                 cutlass::layout::ColumnMajor,
-                                LDG_N, LDG_K>(problem_size, num_batch);
+                                THREAD_N, THREAD_K>(problem_size, num_batch);
 }
 
 TEST(SM50_batched_gemv_threadblock, 4x1x64x64_rcc_i8_i32_2N_4K) {
   using namespace test::gemm::threadblock;
   cutlass::gemm::GemmCoord problem_size(1, 64, 64);
   const int num_batch = 4;
-  const int LDG_N = 2;
-  const int LDG_K = 4;
+  const int THREAD_N = 2;
+  const int THREAD_K = 4;
 
-  using Shape = cutlass::gemm::GemmShape<1, 128, LDG_K>;
+  using Shape = cutlass::gemm::GemmShape<1, 128, THREAD_K>;
   batched_gemv_threadblock_test<Shape,
                                 int8_t, int32_t, 
                                 cutlass::layout::RowMajor,
                                 cutlass::layout::ColumnMajor,
                                 cutlass::layout::ColumnMajor,
-                                LDG_N, LDG_K>(problem_size, num_batch);
+                                THREAD_N, THREAD_K>(problem_size, num_batch);
 }
 
 TEST(SM50_batched_gemv_threadblock, 16x1x17x64_rcc_i8_i32_1N_4K) {
   using namespace test::gemm::threadblock;
   cutlass::gemm::GemmCoord problem_size(1, 17, 64);
   const int num_batch = 16;
-  const int LDG_N = 1;
-  const int LDG_K = 4;
+  const int THREAD_N = 1;
+  const int THREAD_K = 4;
 
-  using Shape = cutlass::gemm::GemmShape<1, 32, LDG_K>;
+  using Shape = cutlass::gemm::GemmShape<1, 32, THREAD_K>;
   batched_gemv_threadblock_test<Shape,
                                 int8_t, int32_t, 
                                 cutlass::layout::RowMajor,
                                 cutlass::layout::ColumnMajor,
                                 cutlass::layout::ColumnMajor,
-                                LDG_N, LDG_K>(problem_size, num_batch);
+                                THREAD_N, THREAD_K>(problem_size, num_batch);
 }
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/epilogue_workspace.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/epilogue_workspace.cu`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_multistage.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_multistage.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_multistage_slicedk.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_multistage_slicedk.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_multistage_sparse.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_multistage_sparse.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_multistage_sparse_testbed.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_multistage_sparse_testbed.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -237,34 +237,28 @@
 
   /// Returns true if the CUDA device is sufficient to execute the kernel.
   bool sufficient() const {
     //
     // Determine SMEM requirements and waive if not satisfied
     //
 
-    int smem_size = int(sizeof(typename Mma::SharedStorage));
-
     cudaDeviceProp properties;
     int device_idx;
     cudaError_t result = cudaGetDevice(&device_idx);
 
     if (result != cudaSuccess) {
       throw std::runtime_error("cudaGetDevice() API call failed.");
     }
 
     result = cudaGetDeviceProperties(&properties, device_idx);
 
     if (result != cudaSuccess) {
       throw std::runtime_error("cudaGetDeviceProperties() failed");
     }
 
-    if (properties.sharedMemPerBlockOptin < smem_size) {
-      return false;
-    }
-
     return true;
   }
 
   /// Runs the test
   bool run(
       dim3 grid, dim3 block,
       cutlass::Distribution::Kind init_A = cutlass::Distribution::Uniform,
@@ -411,22 +405,28 @@
     reference_gemm(problem_size, ElementC(alpha),
                    matrix_A_uncompressed.host_view(), matrix_B.host_view(),
                    ElementC(beta), matrix_C_reference.host_view());
 
     bool passed = cutlass::reference::host::TensorEquals(
         matrix_C_computed.host_view(), matrix_C_reference.host_view());
 
-    EXPECT_TRUE(passed)
+    EXPECT_TRUE(passed);
+
+    if (!passed && CUTLASS_TEST_UNIT_ENABLE_WARNINGS) {
+
+      std::cout
+        << __FILE__ << ":" << __LINE__ << "  "
         << "A:\n" << matrix_A.host_view() << "\n"
         << "B:\n" << matrix_B.host_view() << "\n"
         << "E:\n" << matrix_E.host_view() << "\n"
         << "Reference:\n"
         << matrix_C_reference.host_view() << "\n"
         << "Computed:\n"
         << matrix_C_computed.host_view() << "\n";
+    }
 
     EXPECT_GT(cutlass::reference::host::TensorNorm(matrix_C_reference.host_view()), 0);
     EXPECT_GT(cutlass::reference::host::TensorNorm(matrix_C_computed.host_view()), 0);
 
     return passed;
   }
 };
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_multistage_testbed.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_multistage_testbed.h`

 * *Files 7% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -189,19 +189,48 @@
       : problem_size(m, n, k), alpha(alpha_), beta(beta_) {
     matrix_A.reset(cutlass::make_Coord(m, k));
     matrix_B.reset(cutlass::make_Coord(k, n));
     matrix_C_computed.reset(cutlass::make_Coord(m, n));
     matrix_C_reference.reset(cutlass::make_Coord(m, n), false);
   }
 
+  /// Returns true if the CUDA device is sufficient to execute the kernel.
+  bool sufficient() const {
+
+    //
+    // Determine SMEM requirements and waive if not satisfied
+    //
+
+    cudaDeviceProp properties;
+    int device_idx;
+    cudaError_t result = cudaGetDevice(&device_idx);
+
+    if (result != cudaSuccess) {
+      throw std::runtime_error("cudaGetDevice() API call failed.");
+    }
+
+    result = cudaGetDeviceProperties(&properties, device_idx);
+
+    if (result != cudaSuccess) {
+      throw std::runtime_error("cudaGetDeviceProperties() failed");
+    }
+
+    return true;
+  }
+
   /// Runs the test
   bool run(
       dim3 grid, dim3 block,
       cutlass::Distribution::Kind init_A = cutlass::Distribution::Uniform,
       cutlass::Distribution::Kind init_B = cutlass::Distribution::Uniform) {
+
+    if (!sufficient()) {
+      return true;
+    }
+
     //
     // initialize device memory
     //
 
     if (init_A == cutlass::Distribution::Uniform) {
 
       int scope_max = 8;
@@ -314,21 +343,26 @@
     reference_gemm(
         problem_size, ElementC(alpha), matrix_A.host_view(),
         matrix_B.host_view(), ElementC(beta), matrix_C_reference.host_view());
 
     bool passed = cutlass::reference::host::TensorEquals(
         matrix_C_computed.host_view(), matrix_C_reference.host_view());
 
-    EXPECT_TRUE(passed) 
+    EXPECT_TRUE(passed);
+
+    if (!passed && CUTLASS_TEST_UNIT_ENABLE_WARNINGS) {
+      std::cout
+        << __FILE__ << ":" << __LINE__ << "  "
         << "A:\n" << matrix_A.host_view() << "\n"
         << "B:\n" << matrix_B.host_view() << "\n"
         << "Reference:\n"
         << matrix_C_reference.host_view() << "\n"
         << "Computed:\n"
         << matrix_C_computed.host_view() << "\n";
+    }
 
     EXPECT_GT(cutlass::reference::host::TensorNorm(matrix_C_reference.host_view()), 0);
     EXPECT_GT(cutlass::reference::host::TensorNorm(matrix_C_computed.host_view()), 0);
 
     return passed;
   }
 };
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_multistage_testbed_slicedk.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_multistage_testbed_slicedk.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_pipelined_simt.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_pipelined_simt.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_pipelined_slicedk.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_pipelined_slicedk.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_pipelined_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_pipelined_sm70.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_pipelined_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_pipelined_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_pipelined_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_pipelined_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_pipelined_testbed.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_pipelined_testbed.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -213,19 +213,33 @@
       : problem_size(m, n, k), alpha(alpha_), beta(beta_) {
     matrix_A.reset(cutlass::make_Coord(m, k));
     matrix_B.reset(cutlass::make_Coord(k, n));
     matrix_C_computed.reset(cutlass::make_Coord(m, n));
     matrix_C_reference.reset(cutlass::make_Coord(m, n), false);
   }
 
+  bool sufficient() {
+    return true;
+  }
+
   /// Runs the test
   bool run(
       dim3 grid, dim3 block,
       cutlass::Distribution::Kind init_A = cutlass::Distribution::Uniform,
       cutlass::Distribution::Kind init_B = cutlass::Distribution::Uniform) {
+
+    // Waive test if insufficient CUDA device
+    if (!sufficient()) {
+      if (CUTLASS_TEST_UNIT_ENABLE_WARNINGS) {
+        std::cerr << "Test waived due to insufficient CUDA device." << std::endl;
+      }
+      return true;
+    }
+
+
     //
     // initialize device memory
     //
 
     if (init_A == cutlass::Distribution::Uniform) {
 
       int scope_max = 8;
@@ -296,15 +310,15 @@
 
     //
     // Check error code
     //
 
     cudaError_t result = cudaDeviceSynchronize();
     EXPECT_EQ(result, cudaSuccess)
-        << " kernel error: " << cudaGetErrorString(result);
+        << " kernel error: " << cudaGetErrorString(result) << " on device " << GetCudaDevice();
 
     matrix_C_computed.sync_host();
 
     cutlass::reference::host::Gemm<ElementA, LayoutA, ElementB, LayoutB,
                                    ElementC, LayoutC, ElementC, ElementC,
                                    typename MmaCore::Operator>
         reference_gemm;
@@ -312,15 +326,15 @@
     reference_gemm(
         problem_size, ElementC(alpha), matrix_A.host_view(),
         matrix_B.host_view(), ElementC(beta), matrix_C_reference.host_view());
 
     bool passed = cutlass::reference::host::TensorEquals(
         matrix_C_computed.host_view(), matrix_C_reference.host_view());
 
-    EXPECT_TRUE(passed);
+    EXPECT_TRUE(passed) << "Failed on device " << GetCudaDevice();
 
     if (!passed) {
       std::ofstream output("mma_pipelined_testbed_errors.txt");
 
       output
         << "A:\n" << matrix_A.host_view() << "\n"
         << "B:\n" << matrix_B.host_view() << "\n"
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_pipelined_testbed_slicedk.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_pipelined_testbed_slicedk.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_pipelined_wmma_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_pipelined_wmma_sm70.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_pipelined_wmma_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_pipelined_wmma_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_planar_complex_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_planar_complex_sm80.cu`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_singlestage_wmma_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_singlestage_wmma_sm70.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_singlestage_wmma_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/threadblock/mma_singlestage_wmma_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_complex_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_complex_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_complex_sm90.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_complex_sm90.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -46,15 +46,15 @@
 
 #include "cutlass/util/reference/host/tensor_fill.h"
 #include "cutlass/util/reference/host/tensor_compare.h"
 #include "cutlass/util/reference/host/gemm.h"
 
 #include "testbed.h"
 
-#if defined(CUTLASS_ARCH_MMA_SM90_SUPPORTED)
+#if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
 
 TEST(SM90_warp_gemm_complex_tensor_op_f64, 16x8x4_16x8x4_nt) {
 
   using Shape = cutlass::gemm::GemmShape<16, 8, 4>;
   using InstructionShape = cutlass::gemm::GemmShape<16, 8, 4>;
   
   using Element = cutlass::complex<double>;
@@ -327,8 +327,8 @@
     ElementC,
     cutlass::layout::RowMajor
   >::Type;
 
   test::gemm::warp::TestbedComplex<MmaTensorOp, Shape>().run();
 }
 
-#endif // if defined(CUTLASS_ARCH_MMA_SM90_SUPPORTED)
+#endif // if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_gaussian_complex_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_gaussian_complex_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_sm50.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_sm50.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_sm60.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_sm60.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_sm61.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_sm61.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_sm90.cu`

 * *Files 20% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -24,272 +24,183 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
-/*! \file
-    \brief Unit tests for thread-level GEMM
+/*! \file 
+
+    \brief Unit tests for thread-level GEMM with Hopper FP64
 */
 
 #include "../../common/cutlass_unit_test.h"
 
 #include "cutlass/aligned_buffer.h"
 #include "cutlass/half.h"
 
-#include "cutlass/gemm/warp/mma_tensor_op_sm70.h"
+#include "cutlass/gemm/warp/default_mma_tensor_op.h"
 
 #include "cutlass/core_io.h"
 #include "cutlass/util/host_tensor.h"
 #include "cutlass/util/tensor_view_io.h"
 
 #include "cutlass/util/reference/host/tensor_fill.h"
 #include "cutlass/util/reference/host/tensor_compare.h"
 #include "cutlass/util/reference/host/gemm.h"
 
 #include "testbed.h"
 
-#if defined(CUTLASS_ARCH_MMA_SM70_SUPPORTED)
+#if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
+
+TEST(SM90_warp_gemm_tensor_op_congruous_f64, 16x16x4_16x16x4_16x8x4) {
+  using Shape = cutlass::gemm::GemmShape<16, 16, 4>;
+  using InstructionShape = cutlass::gemm::GemmShape<16, 8, 4>;
+  using Element = double;
+  using ElementC = double;
+  using LayoutA = cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous64b;
+  using LayoutB = cutlass::layout::RowMajorTensorOpMultiplicandCongruous64b;
+
+  using MmaTensorOp = typename cutlass::gemm::warp::DefaultMmaTensorOp<
+      Shape, InstructionShape, Element, LayoutA, Element, LayoutB, ElementC,
+      cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>::Type;
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+  test::gemm::warp::Testbed<MmaTensorOp,
+                            cutlass::gemm::GemmShape<16, 16, 4> >()
+      .run();
+}
 
-TEST(SM70_warp_gemm_tensor_op_congruous, 128x128x16_64x64x16_16x16x4) {
+////////////////////////////////////////////////////////////////////////////////
 
-  using Shape = cutlass::gemm::GemmShape<64, 64, 16>;
-  using ElementA = cutlass::half_t;
-  using ElementB = cutlass::half_t;
-  using ElementC = cutlass::half_t;
-  using LayoutA = cutlass::layout::ColumnMajorVoltaTensorOpMultiplicandCongruous<cutlass::sizeof_bits<ElementA>::value>;
-  using LayoutB = cutlass::layout::RowMajorVoltaTensorOpMultiplicandBCongruous<cutlass::sizeof_bits<ElementB>::value>;
-
-  using Policy = cutlass::gemm::warp::MmaTensorOpPolicy<
-    cutlass::arch::Mma<
-      cutlass::gemm::GemmShape<16, 16, 4>,
-      32,
-      ElementA,
-      cutlass::layout::ColumnMajor,
-      ElementB,
-      cutlass::layout::RowMajor,
-      ElementC,
-      cutlass::layout::RowMajor,
-      cutlass::arch::OpMultiplyAdd
-    >,
-    cutlass::MatrixShape<1, 1>
-  >;
-
-  using MmaTensorOp = cutlass::gemm::warp::MmaVoltaTensorOp<
-    Shape,
-    ElementA,
-    LayoutA,
-    ElementB,
-    LayoutB,
-    ElementC,
-    cutlass::layout::RowMajor,
-    Policy
-  >;
+TEST(SM90_warp_gemm_tensor_op_congruous_f64, 32x16x4_32x16x4_16x8x4) {
+  using Shape = cutlass::gemm::GemmShape<32, 16, 4>;
+  using InstructionShape = cutlass::gemm::GemmShape<16, 8, 4>;
+  using Element = double;
+  using ElementC = double;
+  using LayoutA = cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous64b;
+  using LayoutB = cutlass::layout::RowMajorTensorOpMultiplicandCongruous64b;
+
+  using MmaTensorOp = typename cutlass::gemm::warp::DefaultMmaTensorOp<
+      Shape, InstructionShape, Element, LayoutA, Element, LayoutB, ElementC,
+      cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>::Type;
 
-  test::gemm::warp::Testbed<MmaTensorOp, cutlass::gemm::GemmShape<128, 128, 16> >().run();
+  test::gemm::warp::Testbed<MmaTensorOp,
+                            cutlass::gemm::GemmShape<32, 16, 4> >()
+      .run();
 }
 
-TEST(SM70_warp_gemm_tensor_op_congruous, 128x64x4_64x64x4_16x16x4) {
+////////////////////////////////////////////////////////////////////////////////
 
-  using Shape = cutlass::gemm::GemmShape<64, 64, 4>;
-  using ElementA = cutlass::half_t;
-  using ElementB = cutlass::half_t;
-  using ElementC = cutlass::half_t;
-  using LayoutA = cutlass::layout::ColumnMajorVoltaTensorOpMultiplicandCongruous<cutlass::sizeof_bits<ElementA>::value>;
-  using LayoutB = cutlass::layout::RowMajorVoltaTensorOpMultiplicandBCongruous<cutlass::sizeof_bits<ElementB>::value>;
-
-  using Policy = cutlass::gemm::warp::MmaTensorOpPolicy<
-    cutlass::arch::Mma<
-      cutlass::gemm::GemmShape<16, 16, 4>,
-      32,
-      ElementA,
-      cutlass::layout::ColumnMajor,
-      ElementB,
-      cutlass::layout::RowMajor,
-      ElementC,
-      cutlass::layout::RowMajor,
-      cutlass::arch::OpMultiplyAdd
-    >,
-    cutlass::MatrixShape<1, 1>
-  >;
-
-  using MmaTensorOp = cutlass::gemm::warp::MmaVoltaTensorOp<
-    Shape,
-    ElementA,
-    LayoutA,
-    ElementB,
-    LayoutB,
-    ElementC,
-    cutlass::layout::RowMajor,
-    Policy
-  >;
+TEST(SM90_warp_gemm_tensor_op_congruous_f64, 32x32x4_32x32x4_16x8x4) {
+  using Shape = cutlass::gemm::GemmShape<32, 32, 4>;
+  using InstructionShape = cutlass::gemm::GemmShape<16, 8, 4>;
+  using Element = double;
+  using ElementC = double;
+  using LayoutA = cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous64b;
+  using LayoutB = cutlass::layout::RowMajorTensorOpMultiplicandCongruous64b;
+
+  using MmaTensorOp = typename cutlass::gemm::warp::DefaultMmaTensorOp<
+      Shape, InstructionShape, Element, LayoutA, Element, LayoutB, ElementC,
+      cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>::Type;
 
-  test::gemm::warp::Testbed<MmaTensorOp, cutlass::gemm::GemmShape<128, 64, 4> >().run();
+  test::gemm::warp::Testbed<MmaTensorOp,
+                            cutlass::gemm::GemmShape<32, 32, 4> >()
+      .run();
 }
 
-TEST(SM70_warp_gemm_tensor_op_congruous, 128x128x4_32x32x4_16x16x4) {
+////////////////////////////////////////////////////////////////////////////////
 
-  using Shape = cutlass::gemm::GemmShape<32, 32, 4>;
-  using ElementA = cutlass::half_t;
-  using ElementB = cutlass::half_t;
-  using ElementC = cutlass::half_t;
-  using LayoutA = cutlass::layout::ColumnMajorVoltaTensorOpMultiplicandCongruous<cutlass::sizeof_bits<ElementA>::value>;
-  using LayoutB = cutlass::layout::RowMajorVoltaTensorOpMultiplicandBCongruous<cutlass::sizeof_bits<ElementB>::value>;
-
-  using Policy = cutlass::gemm::warp::MmaTensorOpPolicy<
-    cutlass::arch::Mma<
-      cutlass::gemm::GemmShape<16, 16, 4>,
-      32,
-      ElementA,
-      cutlass::layout::ColumnMajor,
-      ElementB,
-      cutlass::layout::RowMajor,
-      ElementC,
-      cutlass::layout::RowMajor,
-      cutlass::arch::OpMultiplyAdd
-    >,
-    cutlass::MatrixShape<1, 1>
-  >;
-
-  using MmaTensorOp = cutlass::gemm::warp::MmaVoltaTensorOp<
-    Shape,
-    ElementA,
-    LayoutA,
-    ElementB,
-    LayoutB,
-    ElementC,
-    cutlass::layout::RowMajor,
-    Policy
-  >;
+TEST(SM90_warp_gemm_tensor_op_congruous_f64, 32x64x4_32x64x4_16x8x4) {
+  using Shape = cutlass::gemm::GemmShape<32, 64, 4>;
+  using InstructionShape = cutlass::gemm::GemmShape<16, 8, 4>;
+  using Element = double;
+  using ElementC = double;
+  using LayoutA = cutlass::layout::ColumnMajorTensorOpMultiplicandCongruous64b;
+  using LayoutB = cutlass::layout::RowMajorTensorOpMultiplicandCongruous64b;
+
+  using MmaTensorOp = typename cutlass::gemm::warp::DefaultMmaTensorOp<
+      Shape, InstructionShape, Element, LayoutA, Element, LayoutB, ElementC,
+      cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>::Type;
 
-  test::gemm::warp::Testbed<MmaTensorOp, cutlass::gemm::GemmShape<128, 128, 4> >().run();
+  test::gemm::warp::Testbed<MmaTensorOp,
+                            cutlass::gemm::GemmShape<32, 64, 4> >()
+      .run();
 }
 
-TEST(SM70_warp_gemm_tensor_op_crosswise, 64x64x32_64x64x32_16x16x4) {
-  using Shape = cutlass::gemm::GemmShape<64, 64, 32>;
-  using ElementA = cutlass::half_t;
-  using ElementB = cutlass::half_t;
-  using ElementC = cutlass::half_t;
-  using LayoutA = cutlass::layout::RowMajorVoltaTensorOpMultiplicandCrosswise<
-      cutlass::sizeof_bits<ElementA>::value, 32>;
-  using LayoutB = cutlass::layout::ColumnMajorVoltaTensorOpMultiplicandCrosswise<
-      cutlass::sizeof_bits<ElementB>::value, 32>;
-
-  using Policy = cutlass::gemm::warp::MmaTensorOpPolicy<
-    cutlass::arch::Mma<
-      cutlass::gemm::GemmShape<16, 16, 4>,
-      32,
-      ElementA,
-      cutlass::layout::RowMajor,
-      ElementB,
-      cutlass::layout::ColumnMajor,
-      ElementC,
-      cutlass::layout::RowMajor,
-      cutlass::arch::OpMultiplyAdd
-    >,
-    cutlass::MatrixShape<1, 1>
-  >;
-
-  using MmaTensorOp = cutlass::gemm::warp::MmaVoltaTensorOp<
-    Shape,
-    ElementA,
-    LayoutA,
-    ElementB,
-    LayoutB,
-    ElementC,
-    cutlass::layout::RowMajor,
-    Policy
-  >;
+////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM90_warp_gemm_tensor_op_crosswise_f64, 16x16x16_16x16x16_16x8x4) {
+  using Shape = cutlass::gemm::GemmShape<16, 16, 16>;
+  using InstructionShape = cutlass::gemm::GemmShape<16, 8, 4>;
+  using Element = double;
+  using ElementC = double;
+  using LayoutA = cutlass::layout::RowMajorTensorOpMultiplicand64bCrosswise;
+  using LayoutB = cutlass::layout::ColumnMajorTensorOpMultiplicand64bCrosswise;
+
+  using MmaTensorOp = typename cutlass::gemm::warp::DefaultMmaTensorOp<
+      Shape, InstructionShape, Element, LayoutA, Element, LayoutB, ElementC,
+      cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>::Type;
 
-  test::gemm::warp::Testbed<MmaTensorOp, cutlass::gemm::GemmShape<64, 64, 32> >().run();
+  test::gemm::warp::Testbed<MmaTensorOp,
+                            cutlass::gemm::GemmShape<16, 16, 16> >()
+      .run();
 }
 
 ////////////////////////////////////////////////////////////////////////////////
 
-TEST(SM70_warp_gemm_volta_tensor_op_canonical_f32_row_col, 64x64x16_64x64x4_8x8x4) {
-  
-  using Shape = cutlass::gemm::GemmShape<64, 64, 4>;
-  using InstructionShape = cutlass::gemm::GemmShape<8, 8, 4>;
-  using ElementA = cutlass::half_t;
-  using ElementB = cutlass::half_t;
-  using ElementC = float;
-  using LayoutA = cutlass::layout::RowMajor;
-  using LayoutB = cutlass::layout::ColumnMajor;
-
-  using Policy = cutlass::gemm::warp::MmaTensorOpPolicy<
-    cutlass::arch::Mma<
-      cutlass::gemm::GemmShape<16, 16, 4>,
-      32,
-      ElementA,
-      cutlass::layout::RowMajor,
-      ElementB,
-      cutlass::layout::ColumnMajor,
-      ElementC,
-      cutlass::layout::RowMajor,
-      cutlass::arch::OpMultiplyAdd
-    >,
-    cutlass::MatrixShape<1, 1>
-  >;
-
-  using MmaTensorOp = cutlass::gemm::warp::MmaVoltaTensorOp<
-    Shape,
-    ElementA,
-    LayoutA,
-    ElementB,
-    LayoutB,
-    ElementC,
-    cutlass::layout::RowMajor,
-    Policy
-  >;
+TEST(SM90_warp_gemm_tensor_op_crosswise_f64, 32x32x16_32x32x16_16x8x4) {
+  using Shape = cutlass::gemm::GemmShape<32, 32, 16>;
+  using InstructionShape = cutlass::gemm::GemmShape<16, 8, 4>;
+  using Element = double;
+  using ElementC = double;
+  using LayoutA = cutlass::layout::RowMajorTensorOpMultiplicand64bCrosswise;
+  using LayoutB = cutlass::layout::ColumnMajorTensorOpMultiplicand64bCrosswise;
+
+  using MmaTensorOp = typename cutlass::gemm::warp::DefaultMmaTensorOp<
+      Shape, InstructionShape, Element, LayoutA, Element, LayoutB, ElementC,
+      cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>::Type;
 
   test::gemm::warp::Testbed<MmaTensorOp,
-                            cutlass::gemm::GemmShape<64, 64, 16> >()
+                            cutlass::gemm::GemmShape<32, 32, 16> >()
       .run();
 }
 
-TEST(SM70_warp_gemm_volta_tensor_op_canonical_f32_col_row, 64x64x16_64x64x4_8x8x4) {
-  
-  using Shape = cutlass::gemm::GemmShape<64, 64, 4>;
-  using InstructionShape = cutlass::gemm::GemmShape<8, 8, 4>;
-  using ElementA = cutlass::half_t;
-  using ElementB = cutlass::half_t;
-  using ElementC = float;
-  using LayoutA = cutlass::layout::ColumnMajor;
-  using LayoutB = cutlass::layout::RowMajor;
-
-  using Policy = cutlass::gemm::warp::MmaTensorOpPolicy<
-    cutlass::arch::Mma<
-      cutlass::gemm::GemmShape<16, 16, 4>,
-      32,
-      ElementA,
-      LayoutA,
-      ElementB,
-      LayoutB,
-      ElementC,
-      cutlass::layout::RowMajor,
-      cutlass::arch::OpMultiplyAdd
-    >,
-    cutlass::MatrixShape<1, 1>
-  >;
-
-  using MmaTensorOp = cutlass::gemm::warp::MmaVoltaTensorOp<
-    Shape,
-    ElementA,
-    LayoutA,
-    ElementB,
-    LayoutB,
-    ElementC,
-    cutlass::layout::RowMajor,
-    Policy
-  >;
+////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM90_warp_gemm_tensor_op_crosswise_f64, 64x32x16_64x32x16_16x8x4) {
+  using Shape = cutlass::gemm::GemmShape<64, 32, 16>;
+  using InstructionShape = cutlass::gemm::GemmShape<16, 8, 4>;
+  using Element = double;
+  using ElementC = double;
+  using LayoutA = cutlass::layout::RowMajorTensorOpMultiplicand64bCrosswise;
+  using LayoutB = cutlass::layout::ColumnMajorTensorOpMultiplicand64bCrosswise;
+
+  using MmaTensorOp = typename cutlass::gemm::warp::DefaultMmaTensorOp<
+      Shape, InstructionShape, Element, LayoutA, Element, LayoutB, ElementC,
+      cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>::Type;
 
   test::gemm::warp::Testbed<MmaTensorOp,
-                            cutlass::gemm::GemmShape<64, 64, 16> >()
+                            cutlass::gemm::GemmShape<64, 32, 16> >()
       .run();
 }
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+////////////////////////////////////////////////////////////////////////////////
+
+TEST(SM90_warp_gemm_tensor_op_crosswise_f64, 32x64x16_32x64x16_16x8x4) {
+  using Shape = cutlass::gemm::GemmShape<32, 64, 16>;
+  using InstructionShape = cutlass::gemm::GemmShape<16, 8, 4>;
+  using Element = double;
+  using ElementC = double;
+  using LayoutA = cutlass::layout::RowMajorTensorOpMultiplicand64bCrosswise;
+  using LayoutB = cutlass::layout::ColumnMajorTensorOpMultiplicand64bCrosswise;
+
+  using MmaTensorOp = typename cutlass::gemm::warp::DefaultMmaTensorOp<
+      Shape, InstructionShape, Element, LayoutA, Element, LayoutB, ElementC,
+      cutlass::layout::RowMajor, cutlass::arch::OpMultiplyAdd>::Type;
+
+  test::gemm::warp::Testbed<MmaTensorOp,
+                            cutlass::gemm::GemmShape<32, 64, 16> >()
+      .run();
+}
+////////////////////////////////////////////////////////////////////////////////
 
-#endif // CUTLASS_ARCH_MMA_SM70_SUPPORTED
+#endif // if defined(CUTLASS_ARCH_MMA_SM90_F64_MMA_ENABLED)
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_sparse_sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/warp/gemm_sparse_sm80.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/warp/testbed.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/warp/testbed.h`

 * *Files 3% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -187,18 +187,55 @@
     tensor_A.reset(cutlass::make_Coord(ThreadblockShape::kM, ThreadblockShape::kK));
     tensor_B.reset(cutlass::make_Coord(ThreadblockShape::kK, ThreadblockShape::kN));
     tensor_C.reset(cutlass::make_Coord(Shape::kM, Shape::kN));
     tensor_D_computed.reset(cutlass::make_Coord(Shape::kM, Shape::kN));
     tensor_D_reference.reset(cutlass::make_Coord(Shape::kM, Shape::kN), false);
   }
 
+  /// Returns true if the CUDA device is sufficient to execute the kernel.
+  bool sufficient() const {
+
+    cudaDeviceProp properties;
+    int device_idx;
+    cudaError_t result = cudaGetDevice(&device_idx);
+
+    if (result != cudaSuccess) {
+      throw std::runtime_error("cudaGetDevice() API call failed.");
+    }
+
+    result = cudaGetDeviceProperties(&properties, device_idx);
+
+    if (result != cudaSuccess) {
+      throw std::runtime_error("cudaGetDeviceProperties() failed");
+    }
+
+    if (properties.major == 9) {
+      // NVIDIA Hopper drops support for several data types
+      if (
+        cutlass::sizeof_bits<ElementA>::value < 8 ||
+        cutlass::sizeof_bits<ElementB>::value < 8 ||
+        cutlass::sizeof_bits<ElementC>::value < 8) {
+
+        return false;
+      }
+    }
+
+    return true;
+  }
+
+
   /// Runs the test
   bool run(
       cutlass::Distribution::Kind init_A = cutlass::Distribution::Uniform,
       cutlass::Distribution::Kind init_B = cutlass::Distribution::Uniform) {
+
+    if (!sufficient()) {
+      return true;
+    }
+
     //
     // initialize device memory
     //
 
     if (init_A == cutlass::Distribution::Uniform) {
       int scope_max = 8;
       int scope_min = -8;
@@ -397,18 +434,54 @@
     tensor_A.reset(cutlass::make_Coord(ThreadblockShape::kM, ThreadblockShape::kK));
     tensor_B.reset(cutlass::make_Coord(ThreadblockShape::kK, ThreadblockShape::kN));
     tensor_C.reset(cutlass::make_Coord(Shape::kM, Shape::kN));
     tensor_D_computed.reset(cutlass::make_Coord(Shape::kM, Shape::kN));
     tensor_D_reference.reset(cutlass::make_Coord(Shape::kM, Shape::kN), false);
   }
 
+  /// Returns true if the CUDA device is sufficient to execute the kernel.
+  bool sufficient() const {
+
+    cudaDeviceProp properties;
+    int device_idx;
+    cudaError_t result = cudaGetDevice(&device_idx);
+
+    if (result != cudaSuccess) {
+      throw std::runtime_error("cudaGetDevice() API call failed.");
+    }
+
+    result = cudaGetDeviceProperties(&properties, device_idx);
+
+    if (result != cudaSuccess) {
+      throw std::runtime_error("cudaGetDeviceProperties() failed");
+    }
+
+    if (properties.major == 9) {
+      // NVIDIA Hopper drops support for several data types
+      if (
+        cutlass::sizeof_bits<ElementA>::value < 8 ||
+        cutlass::sizeof_bits<ElementB>::value < 8 ||
+        cutlass::sizeof_bits<ElementC>::value < 8) {
+
+        return false;
+      }
+    }
+
+    return true;
+  }
+
   /// Runs the test
   bool run(
       cutlass::Distribution::Kind init_A = cutlass::Distribution::Uniform,
       cutlass::Distribution::Kind init_B = cutlass::Distribution::Uniform) {
+
+    if (!sufficient()) {
+      return true;
+    }
+
     //
     // initialize device memory
     //
 
     if (init_A == cutlass::Distribution::Uniform) {
       uint64_t seed = 7;
       cutlass::reference::host::TensorFillRandomUniform(tensor_A.host_view(),
@@ -672,18 +745,54 @@
     tensor_A.reset(cutlass::make_Coord(ThreadblockShape::kM, ThreadblockShape::kK));
     tensor_B.reset(cutlass::make_Coord(ThreadblockShape::kK, ThreadblockShape::kN));
     tensor_C.reset(cutlass::make_Coord(Shape::kM, Shape::kN));
     tensor_D_computed.reset(cutlass::make_Coord(Shape::kM, Shape::kN));
     tensor_D_reference.reset(cutlass::make_Coord(Shape::kM, Shape::kN), false);
   }
 
+  /// Returns true if the CUDA device is sufficient to execute the kernel.
+  bool sufficient() const {
+
+    cudaDeviceProp properties;
+    int device_idx;
+    cudaError_t result = cudaGetDevice(&device_idx);
+
+    if (result != cudaSuccess) {
+      throw std::runtime_error("cudaGetDevice() API call failed.");
+    }
+
+    result = cudaGetDeviceProperties(&properties, device_idx);
+
+    if (result != cudaSuccess) {
+      throw std::runtime_error("cudaGetDeviceProperties() failed");
+    }
+
+    if (properties.major == 9) {
+      // NVIDIA Hopper drops support for several data types
+      if (
+        cutlass::sizeof_bits<ElementA>::value < 8 ||
+        cutlass::sizeof_bits<ElementB>::value < 8 ||
+        cutlass::sizeof_bits<ElementC>::value < 8) {
+
+        return false;
+      }
+    }
+
+    return true;
+  }
+
   /// Runs the test
   bool run(
       cutlass::Distribution::Kind init_A = cutlass::Distribution::Uniform,
       cutlass::Distribution::Kind init_B = cutlass::Distribution::Uniform) {
+
+    if (!sufficient()) {
+      return true;
+    }
+
     //
     // initialize device memory
     //
 
     if (init_A == cutlass::Distribution::Uniform) {
       int scope_max = 8;
       int scope_min = -8;
@@ -874,18 +983,54 @@
     tensor_A.reset(cutlass::make_Coord(ThreadblockShape::kM, ThreadblockShape::kK));
     tensor_B.reset(cutlass::make_Coord(ThreadblockShape::kK, ThreadblockShape::kN));
     tensor_C.reset(cutlass::make_Coord(Shape::kM, Shape::kN));
     tensor_D_computed.reset(cutlass::make_Coord(Shape::kM, Shape::kN));
     tensor_D_reference.reset(cutlass::make_Coord(Shape::kM, Shape::kN), false);
   }
 
+  /// Returns true if the CUDA device is sufficient to execute the kernel.
+  bool sufficient() const {
+
+    cudaDeviceProp properties;
+    int device_idx;
+    cudaError_t result = cudaGetDevice(&device_idx);
+
+    if (result != cudaSuccess) {
+      throw std::runtime_error("cudaGetDevice() API call failed.");
+    }
+
+    result = cudaGetDeviceProperties(&properties, device_idx);
+
+    if (result != cudaSuccess) {
+      throw std::runtime_error("cudaGetDeviceProperties() failed");
+    }
+
+    if (properties.major == 9) {
+      // NVIDIA Hopper drops support for several data types
+      if (
+        cutlass::sizeof_bits<ElementA>::value < 8 ||
+        cutlass::sizeof_bits<ElementB>::value < 8 ||
+        cutlass::sizeof_bits<ElementC>::value < 8) {
+
+        return false;
+      }
+    }
+
+    return true;
+  }
+
   /// Runs the test
   bool run(
       cutlass::Distribution::Kind init_A = cutlass::Distribution::Uniform,
       cutlass::Distribution::Kind init_B = cutlass::Distribution::Uniform) {
+
+    if (!sufficient()) {
+      return true;
+    }
+
     //
     // initialize device memory
     //
 
     if (init_A == cutlass::Distribution::Uniform) {
       uint64_t seed = 7;
       cutlass::reference::host::TensorFillRandomUniform(tensor_A.host_view(),
@@ -1195,20 +1340,55 @@
     tensor_D_reference.reset(cutlass::make_Coord(Shape::kM, Shape::kN), false);
     tensor_E.reset(cutlass::make_Coord(
         Shape::kM, Shape::kK / Sparse / ElementsPerElementE));
     tensor_E_reordered.reset(cutlass::make_Coord(
         Shape::kM, Shape::kK / Sparse / ElementsPerElementE));
   }
 
+  /// Returns true if the CUDA device is sufficient to execute the kernel.
+  bool sufficient() const {
+
+    cudaDeviceProp properties;
+    int device_idx;
+    cudaError_t result = cudaGetDevice(&device_idx);
+
+    if (result != cudaSuccess) {
+      throw std::runtime_error("cudaGetDevice() API call failed.");
+    }
+
+    result = cudaGetDeviceProperties(&properties, device_idx);
+
+    if (result != cudaSuccess) {
+      throw std::runtime_error("cudaGetDeviceProperties() failed");
+    }
+
+    if (properties.major == 9) {
+      // NVIDIA Hopper drops support for several data types
+      if (
+        cutlass::sizeof_bits<ElementA>::value < 8 ||
+        cutlass::sizeof_bits<ElementB>::value < 8 ||
+        cutlass::sizeof_bits<ElementC>::value < 8) {
+
+        return false;
+      }
+    }
+
+    return true;
+  }
+
   /// Runs the test
   bool run(
       cutlass::Distribution::Kind init_A = cutlass::Distribution::Uniform,
       cutlass::Distribution::Kind init_B = cutlass::Distribution::Uniform,
       cutlass::Distribution::Kind init_E = cutlass::Distribution::Uniform) {
 
+    if (!sufficient()) {
+      return true;
+    }
+
     //
     // initialize device memory
     //
 
     if (init_A == cutlass::Distribution::Uniform) {
       int scope_max = 8;
       int scope_min = -8;
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/warp/wmma_sm70.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/warp/wmma_sm70.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/warp/wmma_sm72.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/warp/wmma_sm72.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/gemm/warp/wmma_sm75.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/gemm/warp/wmma_sm75.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/layout/matrix.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/layout/matrix.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/layout/tensor.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/layout/tensor.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/layout/tensor_nhwc.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/layout/tensor_nhwc.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/nvrtc/cutlass/nvrtc/environment.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/nvrtc/cutlass/nvrtc/environment.h`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/nvrtc/kernel/thread/testbed_kernel.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/nvrtc/kernel/thread/testbed_kernel.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/nvrtc/stdlib/stdint.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/nvrtc/stdlib/stdint.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/nvrtc/thread/gemm_nvrtc.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/nvrtc/thread/gemm_nvrtc.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/nvrtc/thread/testbed.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/nvrtc/thread/testbed.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/reduction/device/tensor_reduce_contiguous.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/reduction/device/tensor_reduce_contiguous.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/reduction/device/tensor_reduce_strided.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/reduction/device/tensor_reduce_strided.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/reduction/kernel/reduce_splitk.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/reduction/kernel/reduce_splitk.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/reduction/kernel/reduce_splitk_testbed.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/reduction/kernel/reduce_splitk_testbed.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/reduction/thread/reduction_thread.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/reduction/thread/reduction_thread.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/reduction/thread/testbed.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/reduction/thread/testbed.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/test_unit.cpp` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/test_unit.cpp`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/transform/threadblock/predicated_tile_iterator.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/transform/threadblock/predicated_tile_iterator.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/transform/threadblock/regular_tile_iterator_tensor_op.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/transform/threadblock/regular_tile_iterator_tensor_op.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/util/cutlass_test_levels.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/util/cutlass_test_levels.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/test/unit/util/tensor_reduce.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/test/unit/util/tensor_reduce.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/include/cutlass/library/arch_mappings.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/include/cutlass/library/arch_mappings.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/include/cutlass/library/handle.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/include/cutlass/library/handle.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -317,21 +317,21 @@
     int64_t ldb_imag,                         /// Leading dimension of imaginary part of B matrix
 
     void const * beta,                        /// Pointer to beta scalar
 
     NumericTypeID element_C,                  /// Data type of C and D matrix
 
     void const * const * ptr_C_real,          /// Pointer to array containing pointers to real part of C matrices
-    void const * const * ptr_C_imag,          /// Pointer to array containing poitners to imaginary part of C matrices
+    void const * const * ptr_C_imag,          /// Pointer to array containing pointers to imaginary part of C matrices
 
     int64_t ldc_real,                         /// Leading dimension of real part of C matrix
     int64_t ldc_imag,                         /// Leading dimension of imaginary part of C matrix
 
     void * const * ptr_D_real,                /// Pointer to array containing pointers to real part of D matrices
-    void * const * ptr_D_imag,                /// Pointer to array containing poitners to imaginary part of D matrices
+    void * const * ptr_D_imag,                /// Pointer to array containing pointers to imaginary part of D matrices
 
     int64_t ldd_real,                         /// Leading dimension of real part of D matrix
     int64_t ldd_imag                          /// Leading dimension of imaginary part of D matrix
   );
 
 };
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/include/cutlass/library/library.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/include/cutlass/library/library.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -350,32 +350,37 @@
 
   /// Minimum compute capability (e.g. 70, 75) of a device eligible to run the operation.
   int minimum_compute_capability;
 
   /// Minimum compute capability (e.g. 70, 75) of a device eligible to run the operation.
   int maximum_compute_capability;
 
+  /// Describes the shape of a cluster (in blocks)
+  cutlass::gemm::GemmCoord cluster_shape;
+
   //
   // Methods
   //
 
   TileDescription(
     cutlass::gemm::GemmCoord threadblock_shape = cutlass::gemm::GemmCoord(),
     int threadblock_stages = 0,
     cutlass::gemm::GemmCoord warp_count = cutlass::gemm::GemmCoord(),
     MathInstructionDescription math_instruction = MathInstructionDescription(),
     int minimum_compute_capability = 0,
-    int maximum_compute_capability = 0
+    int maximum_compute_capability = 0,
+    cutlass::gemm::GemmCoord cluster_shape = cutlass::gemm::GemmCoord(1,1,1)
   ):
     threadblock_shape(threadblock_shape), 
     threadblock_stages(threadblock_stages), 
     warp_count(warp_count),
     math_instruction(math_instruction),
     minimum_compute_capability(minimum_compute_capability),
-    maximum_compute_capability(maximum_compute_capability) { }
+    maximum_compute_capability(maximum_compute_capability),
+    cluster_shape(cluster_shape) { }
 
   // Equality operator
   inline
   bool operator==(TileDescription const& rhs) const{
     return (
       (threadblock_shape == rhs.threadblock_shape) &&
       (threadblock_stages == rhs.threadblock_stages) &&
@@ -509,15 +514,15 @@
     split_k_mode(split_k_mode),
     transform_A(transform_A),
     transform_B(transform_B) {} 
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
-/// Desciprion for structured sparse GEMMs.
+/// Description for structured sparse GEMMs.
 struct SparseGemmDescription : public GemmDescription {
 
   /// Description structure for structured sparse GEMM
   SparseGemmDescription(
     GemmKind gemm_kind = GemmKind::kGemm,
     TensorDescription const &A = TensorDescription(),
     TensorDescription const &B = TensorDescription(),
@@ -987,24 +992,33 @@
   int64_t lda;
   int64_t ldb;
   int64_t ldc;
   int64_t ldd;
 };
 
 struct GemmUniversalArguments {
+  // NOTE: these are replicated for 3.0 interfaces 
+  gemm::GemmCoord problem_size;
+  int batch_count;
 
   void const *A;
   void const *B;
   void const *C;
   void *D;
 
   void const *alpha;
   void const *beta;
   ScalarPointerMode pointer_mode;
 
+  // NOTE: these are replicated for 3.0 interfaces
+  int64_t lda;
+  int64_t ldb;
+  int64_t ldc;
+  int64_t ldd;
+
   int64_t batch_stride_A;
   int64_t batch_stride_B;
   int64_t batch_stride_C;
   int64_t batch_stride_D;
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
@@ -1142,15 +1156,15 @@
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 //
 // OperationKind: kSparseGemm
 //
 
-/// Computes GEMM assumine one of the inputs has 2:4 structured sparsity.
+/// Computes GEMM assuming one of the inputs has 2:4 structured sparsity.
 struct SparseGemmConfiguration {
 
   GemmUniversalMode mode;
   gemm::GemmCoord problem_size;
   int batch_count;                /// number of sparse matrix products in batch
 
   int64_t lda;                    /// leading dimension of A operand
@@ -1169,15 +1183,15 @@
 /// Arguments for sparse GEMMs
 struct SparseGemmArguments {
 
   void const *A;                    /// pointer to A matrix
   void const *B;                    /// pointer to B matrix
   void const *C;                    /// pointer to C matrix
   void *D;                          /// pointer to D matrix
-  void const *E;                    /// pointer to E matric (metadata)
+  void const *E;                    /// pointer to E matrix (metadata)
 
   void const *alpha;                /// pointer to alpha scalar
   void const *beta;                 /// pointer to beta scalar
   ScalarPointerMode pointer_mode;   /// enumerant indicating whether alpha/beta pointers are host
                                     ///   or device pointers.
 };
 
@@ -1447,15 +1461,15 @@
 
   /// pointer to reordered matrix B
   void const *reordered_B;
   
   /// pointer to implicit gemm matrix C
   void const *C;
 
-  /// pointer to implicit gemm desitination matrix D
+  /// pointer to implicit gemm destination matrix D
   void *D;
 
   /// Host or device pointer to alpha scalar
   void const *alpha;
 
   /// Host or device pointer to beta scalar
   void const *beta;
@@ -1469,24 +1483,24 @@
 
 /// Configuration for Reduction operations
 //
 // OperationKind: Reduction
 //
 struct ReductionConfiguration {
 
-  /// Redcution problem size
+  /// Reduction problem size
   MatrixCoord problem_size;
 
   /// Number of partitions to reduce
   int partitions;
 
-  /// Number of lements between each partition
+  /// Number of elements between each partition
   int64_t partition_stride;
 
-  /// leading dimension of 'w'orksace operand
+  /// leading dimension of 'w'orkspace operand
   int64_t ldw; 
 
   /// leading dimension of 's'ource operand
   int64_t lds;
 
   /// leading dimension of 'd'estination operand
   int64_t ldd;
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/include/cutlass/library/manifest.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/include/cutlass/library/manifest.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/include/cutlass/library/operation_table.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/include/cutlass/library/operation_table.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/include/cutlass/library/singleton.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/include/cutlass/library/singleton.h`

 * *Files 7% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/include/cutlass/library/util.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/include/cutlass/library/util.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/compiler.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/compiler.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/cutlass.cpp` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/cutlass.cpp`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -25,16 +25,17 @@
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /* \file
-   \brief binding cutlass C++ APIs to python
+   \brief binding CUTLASS C++ APIs to Python
 */
+
 #include <pybind11/pybind11.h>
 #include <pybind11/stl_bind.h>
 
 #include "builtin_types.h"
 #include "device_launch_parameters.h"
 #include "stddef.h"
 #include "cutlass/cutlass.h"
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/arch.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/arch.h`

 * *Files 3% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -47,13 +47,13 @@
 
 void bind_opcode(py::module &m) {
     py::enum_<cutlass::OpcodeClass>(m, "OpClass",
         R"pbdoc(classification of math operators)pbdoc")
         .value("Simt", cutlass::OpcodeClass::kSimt, 
             R"pbdoc(Tag classifying math operators as thread-level operations)pbdoc")
         .value("TensorOp", cutlass::OpcodeClass::kTensorOp, 
-            R"pbdoc(Tag classifing operators as Tensor Core operations)pbdoc")
+            R"pbdoc(Tag classifying operators as Tensor Core operations)pbdoc")
         .value("WmmaTensorOp", cutlass::OpcodeClass::kWmmaTensorOp, 
-            R"pbdoc(Tag classifing operators as WMMA Tensor Core operations)pbdoc")
+            R"pbdoc(Tag classifying operators as WMMA Tensor Core operations)pbdoc")
         .value("SparseTensorOp", cutlass::OpcodeClass::kSparseTensorOp, 
-            R"pbdoc(Tag classifing operators as sparseTensor Core operations)pbdoc");
+            R"pbdoc(Tag classifying operators as sparseTensor Core operations)pbdoc");
 }
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/conv/conv_problem_size.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/conv/conv_problem_size.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -38,15 +38,15 @@
 #include "cutlass/conv/conv2d_problem_size.h"
 
 namespace py = pybind11;
 
 void bind_conv_problem_size(py::module &m) {
     //
     // Conv2d Problem Size: 
-    // include/cutlass/conv/conv2d_problem_sizd.h
+    // include/cutlass/conv/conv2d_problem_size.h
     //
     py::class_<cutlass::conv::Conv2dProblemSize>(m, "Conv2dProblemSize")
          // constructors
         .def(py::init<int, int, int, int, int, int, int, int, int, int, int, int, int, int, int, cutlass::conv::Mode, int, int>())
         .def(py::init<cutlass::Tensor4DCoord, cutlass::Tensor4DCoord, cutlass::Tensor4DCoord, cutlass::MatrixCoord, cutlass::MatrixCoord, cutlass::conv::Mode, int, int>())
         // attribute accessors
         .def_readwrite("N", &cutlass::conv::Conv2dProblemSize::N)
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/conv/convolution.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/conv/convolution.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/conv/host.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/conv/host.h`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_generic.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_generic.h`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -26,22 +26,19 @@
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 
 /*! \file
-  
-  \brief A file contains the epilogue visitor with CTA row-wise broadcast
 
-  The epilogue rearranges the result of a matrix product through shared memory to match canonical
-  tensor layouts in global memory. Epilogues support conversion and reduction operations.
-                          
+  \brief A generic wrapper around an epilogue visitor operation
 */
 
+
 #pragma once
 
 #include "cutlass/cutlass.h"
 #include "cutlass/arch/memory.h"
 #include "cutlass/arch/memory_sm75.h"
 #include "cutlass/gemm/kernel/gemm_transpose_operands.h"
 #include "cutlass/gemm/kernel/default_gemm.h"
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/binary_ops.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/gemm/host.h`

 * *Files 17% similar despite different names*

```diff
@@ -1,84 +1,47 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
  *
  * 2. Redistributions in binary form must reproduce the above copyright notice,
  * this list of conditions and the following disclaimer in the documentation
  * and/or other materials provided with the distribution.
  *
  * 3. Neither the name of the copyright holder nor the names of its
  * contributors may be used to endorse or promote products derived from
- * this layernormware without specific prior written permission.
+ * this software without specific prior written permission.
  *
  * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
  * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
  * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
  * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
-
-/*! \file
-  
-  \brief A file contains the binary ops
+/* \file
+   \brief Bind gemm host helpers to python
 */
-
 #pragma once
-#include "cutlass/cutlass.h"
-
-/////////////////////////////////////////////////////////////////////////////////////////////////
-
-namespace cutlass {
-
-/////////////////////////////////////////////////////////////////////////////////////////////////
-
-
-/// Scalar multiplication
-template <typename T, int N>
-struct VectorAdd {
-
-    struct Arguments {
-        int tmp;
-
-        CUTLASS_HOST_DEVICE
-        Arguments():tmp(0){ }
-
-        CUTLASS_HOST_DEVICE
-        Arguments(int tmp): tmp(tmp) { }
-    };
-    
-    struct Params {
-
-        CUTLASS_HOST_DEVICE
-        Params(Arguments const &args) { }
-    };
-
-    CUTLASS_HOST_DEVICE
-    VectorAdd(
-        Params const &params
-    ) { }
-
-    CUTLASS_HOST_DEVICE
-    Array<T, N> operator()(Array<T, N> const &lhs, Array<T, N> const &rhs) const {
-        cutlass::plus<Array<T, N>> add_op;
-        return add_op(lhs, rhs);
-    }
+#include <pybind11/pybind11.h>
+#include <pybind11/stl_bind.h>
 
-};
+#include "cutlass/util/host_reorder.h"
+#include "cutlass/layout/tensor.h"
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+namespace py = pybind11;
 
-} // namespace cutlass
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+void bind_gemm_host_helper(py::module &m) {
+    m.def("reorder_column", &cutlass::reorder_column<32, int8_t, cutlass::layout::RowMajorInterleaved<32>>);
+    m.def("reorder_column", &cutlass::reorder_column<32, int8_t, cutlass::layout::ColumnMajorInterleaved<32>>);
+}
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/unary_ops.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/unary_ops.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_accumulator.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_accumulator.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_binary.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_binary.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -80,19 +80,18 @@
 
     /// Fragment type returned by this visitor
     using VisitAccessType = Array<ElementCompute, kElementsPerAccess>; 
 
     /// Fragment type of accumulator
     using AccumulatorAccessType = Array<ElementAccumulator, kElementsPerAccess>;
 
-    /// Combination Op TODO: generalize this
     using BinaryOp = BinaryOp_<ElementCompute, kElementsPerAccess>;
 
     static_assert(kElementsPerAccess==VisitAccessTypeA::kElements, "kElementsPerAccess mismatches with Visitor A");
-    static_assert(kElementsPerAccess==VisitAccessTypeB::kElements, "kElementsPerAccess misnatches with Visitor B");
+    static_assert(kElementsPerAccess==VisitAccessTypeB::kElements, "kElementsPerAccess mismatches with Visitor B");
 
     /// SMEM buffer class required in the epilogue visitor
     struct SharedStorage {
         typename VisitorA::SharedStorage storage_a;
         typename VisitorB::SharedStorage storage_b;
 
         CUTLASS_HOST_DEVICE
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_column_broadcast.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_column_broadcast.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_column_reduction.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_column_reduction.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -51,28 +51,27 @@
 ///
 template <
     typename ThreadblockShape_,             /// Threadblock shape
     typename ElementAccumulator_,           ///< Data type of the Accumulator
     typename ElementReduction_,             ///< Data type of the output reduction in device memory
     typename ElementReductionAccumulator_ , ///< Data type to accumulate reduction in smem and register
     typename OutputTileIterator_,           ///< Tile Iterator type
-    typename Visitor_                       ///< preceeding visitor op
+    typename Visitor_                       ///< preceding visitor op
 >
 class VisitorOpColumnReduction {
 public:
     using ElementAccumulator = ElementAccumulator_;
     using ElementReductionAccumulator = ElementReductionAccumulator_;
     using ElementReduction = ElementReduction_;
     using OutputTileIterator = OutputTileIterator_;
     using ThreadblockShape = ThreadblockShape_;
     using Visitor = Visitor_;
 
     static int const kElementsPerAccess = OutputTileIterator::kElementsPerAccess;
 
-    // TODO: generalize the reduction op
     using ReductionOp = cutlass::plus<Array<ElementReductionAccumulator, kElementsPerAccess>>;
     using ReductionOpScalar = cutlass::plus<ElementReductionAccumulator>;
     using ElementOutput = typename OutputTileIterator::Element;
 
     
 
     /// Fragment type returned from Visitor
@@ -80,15 +79,15 @@
     using ElementVisitor = typename VisitAccessTypeVisitor::Element;
 
     using VisitAccessType = VisitAccessTypeVisitor;
 
     /// Fragment type of accumulator
     using AccumulatorAccessType = Array<ElementAccumulator, kElementsPerAccess>;
 
-    /// Fragment type of redcution
+    /// Fragment type of reduction
     using ReductionAccumulatorAccessType = Array<ElementReductionAccumulator, kElementsPerAccess>;
 
     /// Thread map used by output tile iterators
     using ThreadMap = typename OutputTileIterator::ThreadMap;
     /// Used for the reduction
     struct ReductionDetail {
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_linear_combination.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_linear_combination.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -78,19 +78,19 @@
 
     /// Fragment type returned by this visitor
     using VisitAccessType = Array<ElementCompute, kElementsPerAccess>; 
 
     /// Fragment type of accumulator
     using AccumulatorAccessType = Array<ElementAccumulator, kElementsPerAccess>;
 
-    /// Combination Op TODO: generalize this
+    /// Combination Op
     using CombinationOp = cutlass::plus<VisitAccessType>;
 
     static_assert(kElementsPerAccess==VisitAccessTypeA::kElements, "kElementsPerAccess mismatches with Visitor A");
-    static_assert(kElementsPerAccess==VisitAccessTypeB::kElements, "kElementsPerAccess misnatches with Visitor B");
+    static_assert(kElementsPerAccess==VisitAccessTypeB::kElements, "kElementsPerAccess mismatches with Visitor B");
 
     /// SMEM buffer class required in the epilogue visitor
     struct SharedStorage {
         typename VisitorA::SharedStorage storage_a;
         typename VisitorB::SharedStorage storage_b;
 
         CUTLASS_HOST_DEVICE
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_row_broadcast.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_row_broadcast.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_row_reduction.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_row_reduction.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -52,42 +52,41 @@
 ///
 template <
     typename ThreadblockShape_,             /// Threadblock shape
     typename ElementAccumulator_,           ///< Data type of the Accumulator
     typename ElementReduction_,             ///< Data type of the output reduction in device memory
     typename ElementReductionAccumulator_ , ///< Data type to accumulate reduction in smem and register
     typename OutputTileIterator_,           ///< Tile Iterator type
-    typename Visitor_                       ///< preceeding visitor op
+    typename Visitor_                       ///< preceding visitor op
 >
 class VisitorOpRowReduction {
 public:
     using ElementAccumulator = ElementAccumulator_;
     using ElementReductionAccumulator = ElementReductionAccumulator_;
     using ElementReduction = ElementReduction_;
     using OutputTileIterator = OutputTileIterator_;
     using ThreadblockShape = ThreadblockShape_;
     using Visitor = Visitor_;
 
     static int const kElementsPerAccess = OutputTileIterator::kElementsPerAccess;
 
-    // TODO: generalize the reduction op
     using ReductionOp = cutlass::plus<Array<ElementReductionAccumulator, kElementsPerAccess>>;
     using ReductionOpScalar = cutlass::plus<ElementReductionAccumulator>;
     using ElementOutput = typename OutputTileIterator::Element;
 
     /// Fragment type returned from Visitor
     using VisitAccessTypeVisitor = typename Visitor::VisitAccessType;
     using ElementVisitor = typename VisitAccessTypeVisitor::Element;
 
     using VisitAccessType = VisitAccessTypeVisitor;
 
     /// Fragment type of accumulator
     using AccumulatorAccessType = Array<ElementAccumulator, kElementsPerAccess>;
 
-    /// Fragment type of redcution
+    /// Fragment type of reduction
     using ReductionAccumulatorAccessType = Array<ElementReductionAccumulator, kElementsPerAccess>;
 
     /// Thread map used by output tile iterators
     using ThreadMap = typename OutputTileIterator::ThreadMap;
     /// Used for the reduction
     struct ReductionDetail {
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_tensor_input.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_tensor_input.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_tensor_output.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_tensor_output.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_unary.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_op/visitor_op_unary.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -75,15 +75,15 @@
 
     /// Fragment type returned by this visitor
     using VisitAccessType = Array<ElementCompute, kElementsPerAccess>; 
 
     /// Fragment type of accumulator
     using AccumulatorAccessType = Array<ElementAccumulator, kElementsPerAccess>;
 
-    /// Combination Op TODO: generalize this
+    /// Combination Op
     using UnaryOp = UnaryOp_<ElementCompute, kElementsPerAccess>;
 
     static_assert(kElementsPerAccess==VisitAccessTypeVisitor::kElements, "kElementsPerAccess mismatches with Visitor");
 
     /// SMEM buffer class required in the epilogue visitor
     struct SharedStorage {
         typename Visitor::SharedStorage storage_visitor;
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_with_layernorm.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/epilogue/epilogue_visitor_with_layernorm.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -26,20 +26,19 @@
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 
 /*! \file
-    \brief A file contains all functioning classes needed by GemmLayernorm.
+    \brief Epilogue visitor type used for partial computation of a layernorm operation
 
     GemmLayernorm example =  GEMM0 with partial reduction fused in epilogue (EpilogueVisitorLayerNorm)
                           +  lightweight full reduction kernel (ApplyFinalReduction)
-                          +  GEMM1 with elemenwise operations fused in mainloop (GemmLayernormMainloopFusion)
-                          
+                          +  GEMM1 with elementwise operations fused in mainloop (GemmLayernormMainloopFusion)
 */
 
 #pragma once
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 #include "cutlass/cutlass.h"
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/gemm/gemm.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/gemm/gemm.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -48,15 +48,15 @@
     py::enum_<cutlass::gemm::GemmUniversalMode>(m, "Mode")
         .value("Gemm", cutlass::gemm::GemmUniversalMode::kGemm, "Ordinary GEMM & GEMM Split-K serial")
         .value("GemmSplitKParallel", cutlass::gemm::GemmUniversalMode::kGemmSplitKParallel, "GEMM Split-K parallel")
         .value("Batched", cutlass::gemm::GemmUniversalMode::kBatched, "Batched GEMM")
         .value("Array", cutlass::gemm::GemmUniversalMode::kArray)
         .value("Invalid", cutlass::gemm::GemmUniversalMode::kInvalid);
     
-    /// GemmCoord is a structure that specifies a location within the coordiate space of a GEMM problem
+    /// GemmCoord is a structure that specifies a location within the coordinate space of a GEMM problem
     py::class_<cutlass::gemm::GemmCoord>(m, "GemmCoord")
         .def(py::init<int, int, int>())
         .def("m", py::overload_cast<>(&cutlass::gemm::GemmCoord::m))
         .def("n", py::overload_cast<>(&cutlass::gemm::GemmCoord::n))
         .def("k", py::overload_cast<>(&cutlass::gemm::GemmCoord::k))
         // get tensor coords
         .def("mk",
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/gemm/gemm_universal_with_visitor.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/gemm/gemm_universal_with_visitor.h`

 * *Files 3% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -26,15 +26,15 @@
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 
 /*! \file
-    \brief 
+    \brief
 */
 
 #pragma once
 
 #include "cutlass/cutlass.h"
 #include "cutlass/fast_math.h"
 #include "cutlass/gemm/gemm.h"
@@ -135,16 +135,16 @@
     int const * ptr_gather_A_indices;
     int const * ptr_gather_B_indices;
     int const * ptr_scatter_D_indices;
 
     //
     // Methods
     //
-    
-    Arguments(): 
+
+    Arguments():
       ptr_A(nullptr), ptr_B(nullptr), ptr_C(nullptr), ptr_D(nullptr),
       ptr_gather_A_indices(nullptr),
       ptr_gather_B_indices(nullptr),
       ptr_scatter_D_indices(nullptr) {}
 
     /// constructs an arguments structure
     Arguments(
@@ -165,16 +165,16 @@
       typename LayoutC::Stride stride_c,
       typename LayoutC::Stride stride_d,
       int const *ptr_gather_A_indices = nullptr,
       int const *ptr_gather_B_indices = nullptr,
       int const *ptr_scatter_D_indices = nullptr
     ):
       UniversalArgumentsBase(mode, problem_size, batch_count, batch_stride_D),
-      epilogue_visitor(epilogue_visitor), 
-      ptr_A(ptr_A), ptr_B(ptr_B), ptr_C(ptr_C), ptr_D(ptr_D), 
+      epilogue_visitor(epilogue_visitor),
+      ptr_A(ptr_A), ptr_B(ptr_B), ptr_C(ptr_C), ptr_D(ptr_D),
       batch_stride_A(batch_stride_A), batch_stride_B(batch_stride_B), batch_stride_C(batch_stride_C),
       stride_a(stride_a), stride_b(stride_b), stride_c(stride_c), stride_d(stride_d),
       ptr_gather_A_indices(ptr_gather_A_indices), ptr_gather_B_indices(ptr_gather_B_indices),
       ptr_scatter_D_indices(ptr_scatter_D_indices) {
       lda = 0;
       ldb = 0;
       ldc = 0;
@@ -201,31 +201,31 @@
       typename LayoutC::Stride::LongIndex ldc,
       typename LayoutC::Stride::LongIndex ldd,
       int const *ptr_gather_A_indices = nullptr,
       int const *ptr_gather_B_indices = nullptr,
       int const *ptr_scatter_D_indices = nullptr
     ):
       UniversalArgumentsBase(mode, problem_size, batch_count, batch_stride_D),
-      epilogue_visitor(epilogue_visitor), 
-      ptr_A(ptr_A), ptr_B(ptr_B), ptr_C(ptr_C), ptr_D(ptr_D), 
+      epilogue_visitor(epilogue_visitor),
+      ptr_A(ptr_A), ptr_B(ptr_B), ptr_C(ptr_C), ptr_D(ptr_D),
       batch_stride_A(batch_stride_A), batch_stride_B(batch_stride_B), batch_stride_C(batch_stride_C),
       lda(lda), ldb(ldb), ldc(ldc), ldd(ldd),
       ptr_gather_A_indices(ptr_gather_A_indices), ptr_gather_B_indices(ptr_gather_B_indices),
       ptr_scatter_D_indices(ptr_scatter_D_indices) {
       stride_a = make_Coord(lda);
       stride_b = make_Coord(ldb);
       stride_c = make_Coord(ldc);
       stride_d = make_Coord(ldd);
       CUTLASS_TRACE_HOST("GemmUniversal::Arguments::Arguments() - problem_size: " << problem_size);
       }
 
     /// Returns arguments for the transposed problem
     Arguments transposed_problem() const {
       Arguments args(*this);
-      
+
       std::swap(args.problem_size.m(), args.problem_size.n());
       std::swap(args.ptr_A, args.ptr_B);
       std::swap(args.lda, args.ldb);
       std::swap(args.stride_a, args.stride_b);
       std::swap(args.batch_stride_A, args.batch_stride_B);
       std::swap(args.ptr_gather_A_indices, args.ptr_gather_B_indices);
 
@@ -252,15 +252,15 @@
       ElementB,
       ElementC>;
 
     typename Mma::IteratorA::Params params_A;
     typename Mma::IteratorB::Params params_B;
     typename EpilogueVisitor::OutputTileIterator::Params params_C;
     typename EpilogueVisitor::OutputTileIterator::Params params_D;
-    
+
     typename EpilogueVisitor::Params epilogue_visitor;
 
     void * ptr_A;
     void * ptr_B;
     void * ptr_C;
     void * ptr_D;
 
@@ -321,15 +321,15 @@
       ptr_scatter_D_indices = const_cast<int *>(args.ptr_scatter_D_indices);
 
       batch_stride_A = args.batch_stride_A;
       batch_stride_B = args.batch_stride_B;
       batch_stride_C = args.batch_stride_C;
 
       epilogue_visitor = args.epilogue_visitor;
-      
+
       semaphore = static_cast<int *>(workspace);
       CUTLASS_TRACE_HOST("GemmUniversal::Params::update()");
     }
   };
 
   /// Shared memory storage structure
   union SharedStorage {
@@ -341,15 +341,15 @@
 public:
 
   //
   // Methods
   //
 
   CUTLASS_DEVICE
-  GemmUniversalwithEpilogueVisitor() { } 
+  GemmUniversalwithEpilogueVisitor() { }
 
   /// Determines whether kernel satisfies alignment
   static Status can_implement(
     cutlass::gemm::GemmCoord const & problem_size) {
 
     CUTLASS_TRACE_HOST("GemmUniversalwithEpilogueVisitor::can_implement()");
 
@@ -451,20 +451,20 @@
 
     ElementA *ptr_A = static_cast<ElementA *>(params.ptr_A);
     ElementB *ptr_B = static_cast<ElementB *>(params.ptr_B);
 
     //
     // Fetch pointers based on mode.
     //
-    if (params.mode == GemmUniversalMode::kGemm || 
+    if (params.mode == GemmUniversalMode::kGemm ||
       params.mode == GemmUniversalMode::kGemmSplitKParallel) {
 
       if (threadblock_tile_offset.k() + 1 < params.grid_tiled_shape.k()) {
 
-        problem_size_k = (threadblock_tile_offset.k() + 1) * params.gemm_k_size; 
+        problem_size_k = (threadblock_tile_offset.k() + 1) * params.gemm_k_size;
       }
 
       offset_k = threadblock_tile_offset.k() * params.gemm_k_size;
     }
     else if (params.mode == GemmUniversalMode::kBatched) {
       ptr_A += threadblock_tile_offset.k() * params.batch_stride_A;
       ptr_B += threadblock_tile_offset.k() * params.batch_stride_B;
@@ -525,18 +525,18 @@
     accumulators.clear();
 
     // Compute threadblock-scoped matrix multiply-add
     int gemm_k_iterations = (problem_size_k - offset_k + Mma::Shape::kK - 1) / Mma::Shape::kK;
 
     // Compute threadblock-scoped matrix multiply-add
     mma(
-      gemm_k_iterations, 
-      accumulators, 
-      iterator_A, 
-      iterator_B, 
+      gemm_k_iterations,
+      accumulators,
+      iterator_A,
+      iterator_B,
       accumulators);
 
     //
     // Epilogue
     //
 
     // EpilogueOutputOp output_op(params.output_op);
@@ -551,95 +551,73 @@
     MatrixCoord threadblock_offset(
       threadblock_tile_offset.m() * Mma::Shape::kM,
       threadblock_tile_offset.n() * Mma::Shape::kN
     );
 
     int block_idx = threadblock_tile_offset.m() + threadblock_tile_offset.n() * params.grid_tiled_shape.m();
 
-    ElementC *ptr_C = static_cast<ElementC *>(params.ptr_C); 
+    ElementC *ptr_C = static_cast<ElementC *>(params.ptr_C);
     ElementC *ptr_D = static_cast<ElementC *>(params.ptr_D);
 
     //
     // Fetch pointers based on mode.
     //
-    
+
     // Construct the semaphore.
     Semaphore semaphore(params.semaphore + block_idx, thread_idx);
 
-    // if (params.mode == GemmUniversalMode::kGemm) {
-
-    //   // TODO: fix this order
-    //   // If performing a reduction via split-K, fetch the initial synchronization
-    //   if (params.grid_tiled_shape.k() > 1) {
-        
-    //     // Fetch the synchronization lock initially but do not block.
-    //     semaphore.fetch();
-
-    //     // Indicate which position in a serial reduction the output operator is currently updating
-    //     output_op.set_k_partition(threadblock_tile_offset.k(), params.grid_tiled_shape.k());
-    //   }
-    // }
-    
     // Tile iterator loading from source tensor.
 
     EpilogueVisitor epilogue_visitor(
         params.epilogue_visitor,
         shared_storage.visitor,
         threadblock_offset,
         threadblock_tile_offset,
         thread_idx,
         params.problem_size.mn()
     );
 
-    // if (params.mode == GemmUniversalMode::kGemmSplitKParallel) {
-    //   ptr_D += threadblock_tile_offset.k() * params.batch_stride_D;
-    // }
     if (params.mode == GemmUniversalMode::kBatched || params.mode == GemmUniversalMode::kArray) {
       epilogue_visitor.set_batch_index(threadblock_tile_offset.k());
     }
 
     Epilogue epilogue(
       shared_storage.epilogue,
       thread_idx,
       warp_idx,
       lane_idx);
 
     // Wait on the semaphore - this latency may have been covered by iterator construction
     if (params.mode == GemmUniversalMode::kGemm && params.grid_tiled_shape.k() > 1) {
-        
-      // For subsequent threadblocks, the source matrix is held in the 'D' tensor.
-      // TODO: ???
-      // if (threadblock_tile_offset.k()) {
-      //   iterator_C = iterator_D;
-      // }
 
+      // For subsequent threadblocks, the source matrix is held in the 'D' tensor.
       semaphore.wait(threadblock_tile_offset.k());
     }
 
 
     // Execute the epilogue operator to update the destination tensor.
-    epilogue(epilogue_visitor, accumulators); 
-    
+    epilogue(epilogue_visitor, accumulators);
+
     //
     // Release the semaphore
     //
 
-    if (params.mode == GemmUniversalMode::kGemm && params.grid_tiled_shape.k() > 1) { 
+    if (params.mode == GemmUniversalMode::kGemm && params.grid_tiled_shape.k() > 1) {
 
       int lock = 0;
       if (params.grid_tiled_shape.k() == threadblock_tile_offset.k() + 1) {
 
         // The final threadblock resets the semaphore for subsequent grids.
         lock = 0;
       }
       else {
         // Otherwise, the semaphore is incremented
         lock = threadblock_tile_offset.k() + 1;
       }
-      
+
       semaphore.release(lock);
     }
   }
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/gemm/host.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/performance_result.cu`

 * *Files 12% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -25,23 +25,37 @@
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /* \file
-   \brief Bind gemm host helpers to python
+   \brief
 */
+
 #pragma once
-#include <pybind11/pybind11.h>
-#include <pybind11/stl_bind.h>
 
-#include "cutlass/util/host_reorder.h"
-#include "cutlass/layout/tensor.h"
+#include <vector>
+
+#include "cutlass/cutlass.h"
+
+// CUTLASS Profiler includes
+#include "enumerated_types.h"
+#include "performance_result.h"
+
+// CUTLASS Library includes
+#include "cutlass/library/library.h"
+#include "cutlass/library/util.h"
+
+namespace cutlass {
+namespace profiler {
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
+
+
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
-namespace py = pybind11;
+} // namespace profiler
+} // namespace cutlass
 
+/////////////////////////////////////////////////////////////////////////////////////////////////
 
-void bind_gemm_host_helper(py::module &m) {
-    m.def("reorder_column", &cutlass::reorder_column<32, int8_t, cutlass::layout::RowMajorInterleaved<32>>);
-    m.def("reorder_column", &cutlass::reorder_column<32, int8_t, cutlass::layout::ColumnMajorInterleaved<32>>);
-}
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/layout/layout.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/layout/layout.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/layout/matrix.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/tensor_coord.h`

 * *Files 26% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -25,63 +25,54 @@
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
 /* \file
-   \brief Bind Matrix layouts to python
+   \brief Bind Tensor Coord to python
 */
 #pragma once
 #include <pybind11/pybind11.h>
 #include <pybind11/stl_bind.h>
 
-#include "cutlass/layout/matrix.h"
+#include "cutlass/tensor_coord.h"
 
 namespace py = pybind11;
 
-void bind_matrix_layout(py::module &m) {
+void bind_tensor_coord(py::module &m) {
     //
-    // Matrix layouts
-    // cutlass/layout/matrix.h
+    // Tensor Coords
+    // cutlass/include/cutlass/tensor_coord.h
     //
 
-    py::class_<cutlass::layout::RowMajor>(m, "RowMajor", R"pbdoc(
-        Mapping function for row-major matrices.
-    )pbdoc")
-        .def_static("packed", &cutlass::layout::RowMajor::packed, 
-            py::arg("extent"), 
-            R"pbdoc(Helper returns a layout to a tightly packed tensor)pbdoc")
-        .def("stride", [](const cutlass::layout::RowMajor & layout){
-            return layout.stride().at(0);
-        }, R"pbdoc(Returns the stride of the layout)pbdoc");
-
-    py::class_<cutlass::layout::ColumnMajor>(m, "ColumnMajor", R"pbdoc(
-        Mapping function for column-major matrices.
-    )pbdoc")
-        .def_static("packed", &cutlass::layout::ColumnMajor::packed, 
-            py::arg("extent"),
-            R"pbdoc(Helper returns a layout to a tightly packed tensor)pbdoc" )
-        .def("stride", [](const cutlass::layout::ColumnMajor & layout){
-            return layout.stride().at(0);
-        }, R"pbdoc(Returns the stride of the layout)pbdoc");
-
-    py::class_<cutlass::layout::RowMajorInterleaved<32>>(m, "RowMajorInterleaved32",
-        R"pbdoc(Mapping function for interleaved matrices. Matrix is structured 
-        as row-major arrangement of fixed-size columns 32)pbdoc")
-        .def_static("packed", &cutlass::layout::RowMajorInterleaved<32>::packed,
-            py::arg("extent"), 
-            R"pbdoc(Helper returns a layout to a tightly packed tensor)pbdoc")
-        .def("stride", [](const cutlass::layout::RowMajorInterleaved<32> & layout){
-            return layout.stride().at(0);
-        }, R"pbdoc(Returns the stride of the layout)pbdoc");
-
-    py::class_<cutlass::layout::ColumnMajorInterleaved<32>>(m, "ColumnMajorInterleaved32",
-        R"pbdoc(Mapping function for interleaved matrices. Matrix is structured 
-        as column-major arrangement of fixed-size rows 32)pbdoc")
-        .def_static("packed", &cutlass::layout::ColumnMajorInterleaved<32>::packed,
-            py::arg("extent"), 
-            R"pbdoc(Helper returns a layout to a tightly packed tensor)pbdoc")
-        .def("stride", [](const cutlass::layout::ColumnMajorInterleaved<32> & layout){
-            return layout.stride().at(0);
-        }, R"pbdoc(Returns the stride of the layout)pbdoc");
+    /// Defines a canonical 4D coordinate used by tensor operations.
+    py::class_<cutlass::Tensor4DCoord>(m, "Tensor4DCoord",
+        R"pbdoc(Defines a canonical 4D coordinate used by tensor operations)pbdoc")
+        .def(py::init<int, int, int, int>(),
+            py::arg("n"), py::arg("h"), py::arg("w"), py::arg("c"),
+            R"pbdoc(Helper to construct from N, H, W, and C)pbdoc")
+        .def("at", py::overload_cast<int>(&cutlass::Tensor4DCoord::at),
+            py::arg("dim"),
+            R"pbdoc(Gets the index of a given Coord element)pbdoc")
+        .def("size", [](const cutlass::Tensor4DCoord & coord) {
+            return coord.at(0) * coord.at(1) * coord.at(2) * coord.at(3);},
+            R"pbdoc(The size of the tensor coord)pbdoc");
+    
+    py::class_<cutlass::Coord<3>>(m, "Tensor3DCoord",
+        R"pbdoc(Defines a canonical 3D coordinate used by tensor operations)pbdoc")
+        .def("at", py::overload_cast<int>(&cutlass::Coord<3>::at),
+            py::arg("dim"),
+            R"pbdoc(Gets the index of a given Coord element)pbdoc");
+
+    // Matrix Size
+    py::class_<cutlass::MatrixCoord>(m, "MatrixCoord",
+        R"pbdoc(MatrixCoord wraps Coord<2, int> to provide a helper for accessing named dimensions. Classes
+        expecting a coordinate in the rank=2 index space of a matrix should use MatrixCoord.)pbdoc")
+        .def(py::init<int, int>(),
+            py::arg("row"), py::arg("column"), R"pbdoc(Helper to construct from a row and column)pbdoc")
+        .def("row", py::overload_cast<>(&cutlass::MatrixCoord::row),
+            R"pbdoc(Returns the row of the coordinate)pbdoc")
+        .def("column", py::overload_cast<>(&cutlass::MatrixCoord::column),
+            R"pbdoc(Returns the column of the coordinate)pbdoc");
+
 }
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/layout/tensor.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/layout/tensor.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/swizzling.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/swizzling.h`

 * *Files 5% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -79,21 +79,20 @@
                 &T::get_tiled_shape, py::const_
             ), py::arg("conv_operator"), py::arg("problem_size"), py::arg("tile_size"), py::arg("split_k_slices"),
             R"pbdoc(Returns the shape of the problem in units of logical tiles
             
             :param problem_size: Implicit gemm problem size conv_operator(NZPQK, NDHWC, KTRSC)
             :type problem_size: :class:`cutlass.gemm.GemmCoord`)
             )pbdoc")
-        // TODO: the returned dim3 is not usable in python
         .def("get_grid_shape", &T::get_grid_shape,
             py::arg("tiled_shape"), 
             R"pbdoc(Computes CUDA grid dimensions given a size in units of logical tiles)pbdoc")
         .def("tag", [](const T & swizzle){
             return demangle(typeid(T).name());
-        }, R"pbdoc(Returns the c++ name of the swizzling for code emittion)pbdoc");
+        }, R"pbdoc(Returns the c++ name of the swizzling for code emission)pbdoc");
 }
 
 template<typename T>
 void bind_swizzle(py::module & m, std::string name, std::string doc) {
     py::class_<T>(m, name.c_str(), doc.c_str())
         .def(py::init<>())
         .def("get_tiled_shape",
@@ -106,15 +105,15 @@
             :type problem_size: :class:`cutlass.gemm.GemmCoord`
             )pbdoc")
         .def("get_grid_shape", &T::get_grid_shape,
             py::arg("tiled_shape"), 
             R"pbdoc(Computes CUDA grid dimensions given a size in units of logical tiles)pbdoc")
         .def("tag", [](const T & swizzle){
             return demangle(typeid(T).name());
-        }, R"pbdoc(Returns the c++ name of the swizzling for code emittion)pbdoc");
+        }, R"pbdoc(Returns the c++ name of the swizzling for code emission)pbdoc");
 }
 
 template<typename T>
 void bind_dgrad_swizzle(py::module & m, std::string name) {
     py::class_<T>(m, name.c_str(),
         R"pbdoc(Threadblock swizzling function for strided dgrad convolution)pbdoc")
         .def(py::init<>())
@@ -129,15 +128,15 @@
             )pbdoc")
         .def("get_grid_shape", [](const T & swizzle, cutlass::gemm::GemmCoord tiled_shape) {
             return dim3(tiled_shape.m(), tiled_shape.n(), tiled_shape.k());
         }, py::arg("tiled_shape"), 
             R"pbdoc(Computes CUDA grid dimensions given a size in units of logical tiles)pbdoc")
         .def("tag", [](const T & swizzle){
             return demangle(typeid(T).name());
-        }, R"pbdoc(Returns the c++ name of the swizzling for code emittion)pbdoc");
+        }, R"pbdoc(Returns the c++ name of the swizzling for code emission)pbdoc");
 }
 
 void bind_threadblock_swizzle(py::module &m) {
 
     py::class_<dim3>(m, "dim3",
         R"pbdoc(A int3 type xyz contains three integers)pbdoc")
         .def(py::init<int, int, int>(),
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/tensor_ref_view.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/tensor_ref_view.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -16,15 +16,15 @@
  * contributors may be used to endorse or promote products derived from
  * this software without specific prior written permission.
  *
  * THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS"
  * AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE
  * IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE
  * DISCLAIMED. IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE
- * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSE<cutlass::TensorRef<QUENTIAL
+ * FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/types.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/types.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/library.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/library.h`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/test/conv/conv_problems.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/test/conv/conv_problems.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/test/conv/convolution.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/test/conv/convolution.h`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/test/conv/host.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/test/conv/host.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/test/gemm/gemm.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/test/gemm/gemm.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/test/gemm/host.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/test/gemm/host.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/conv2d_operation.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/conv2d_operation.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -354,15 +354,15 @@
   // to dump arguments passed on to cutlass operator for debugging
   void print_operator_args(OperatorArguments &operator_args) const {
     std::cout << "Conv2dOperation::OperatorArguments" << std::endl
               << "  problem_size:" << std::endl 
               << operator_args.problem_size << std::endl
               << "  split_k_mode: "
               << (operator_args.split_k_mode == cutlass::conv::SplitKMode::kSerial ? "serial" : "parallel") << std::endl
-              << "  epilouge (alpha, beta): "
+              << "  epilogue (alpha, beta): "
               << operator_args.output_op.alpha << ", " 
               << operator_args.output_op.beta << std::endl
               << "  ref_A (ptr, {stride}): " 
               << operator_args.ref_A.data() << ", {"
               << operator_args.ref_A.stride(0) << ", " 
               << operator_args.ref_A.stride(1) << ", " 
               << operator_args.ref_A.stride(2) << "}" << std::endl
@@ -606,15 +606,15 @@
   // to dump arguments passed on to cutlass operator for debugging
   void print_operator_args(OperatorArguments &operator_args) const {
     std::cout << "Conv2dOperation::OperatorArguments" << std::endl
               << "  problem_size:" << std::endl 
               << operator_args.problem_size << std::endl
               << "  split_k_mode: "
               << (operator_args.split_k_mode == cutlass::conv::SplitKMode::kSerial ? "serial" : "parallel") << std::endl
-              << "  epilouge (alpha, beta): "
+              << "  epilogue (alpha, beta): "
               << operator_args.output_op.alpha << ", " 
               << operator_args.output_op.beta << std::endl
               << "  ref_A (ptr, {stride}): " 
               << operator_args.ref_A.data() << ", {"
               << operator_args.ref_A.stride(0) << ", " 
               << operator_args.ref_A.stride(1) << ", " 
               << operator_args.ref_A.stride(2) << "}" << std::endl
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/conv3d_operation.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/conv3d_operation.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -345,15 +345,15 @@
   // to dump arguments passed on to cutlass operator for debugging
   void print_operator_args(OperatorArguments &operator_args) const {
     std::cout << "Conv3dOperation::OperatorArguments" << std::endl
               << "  problem_size: " 
               << operator_args.problem_size << std::endl
               << "  split_k_mode: "
               << (operator_args.split_k_mode == cutlass::conv::SplitKMode::kSerial ? "serial" : "parallel") << std::endl
-              << "  epilouge (alpha, beta): " 
+              << "  epilogue (alpha, beta): "
               << operator_args.output_op.alpha << ", " 
               << operator_args.output_op.beta << std::endl
               << "  ref_A (ptr, {stride}): " 
               << operator_args.ref_A.data() << ", {"
               << operator_args.ref_A.stride(0) << ", " 
               << operator_args.ref_A.stride(1) << ", " 
               << operator_args.ref_A.stride(2) << ", "
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/gemm_operation.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/gemm_operation.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/library_internal.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/library_internal.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/manifest.cpp` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/manifest.cpp`

 * *Files 5% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/operation_table.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/operation_table.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/rank_2k_operation.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/rank_2k_operation.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -343,15 +343,15 @@
 
   /// Call print_operator_args  from the Conv2dOperation::initialize()
   // to dump arguments passed on to cutlass operator for debugging
   void print_operator_args(OperatorArguments &operator_args) const {
     std::cout << "Rank2KOperation::OperatorArguments" << std::endl
               << "  problem_size:" << std::endl 
               << operator_args.problem_size << std::endl
-              << "  epilouge (alpha, beta): "
+              << "  epilogue (alpha, beta): "
               << operator_args.epilogue.alpha << ", " 
               << operator_args.epilogue.beta << std::endl
               << "  ref_A (ptr, {stride}): " 
               << operator_args.ptr_A << ", {"
               << operator_args.lda << "}" << std::endl
               << "  ref_B (ptr, {stride}): " 
               << operator_args.ptr_B << ", {"
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/rank_k_operation.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/rank_k_operation.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/reduction/init_reduction_operations.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/reduction/init_reduction_operations.cu`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/reduction/reduction_device.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/reduction/reduction_device.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/reduction/reduction_operation.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/reduction/reduction_operation.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -262,15 +262,15 @@
     std::cout << "Reduction::OperatorArguments" << std::endl
               << "  problem_size: " 
               << operator_args.problem_size << std::endl 
               << "  partitions: " 
               << operator_args.partitions << std::endl 
               << "  partition_stride: " 
               << operator_args.partition_stride << std::endl
-              << "  epilouge (alpha, beta): " 
+              << "  epilogue (alpha, beta): "
               << operator_args.output.alpha << ", " 
               << operator_args.output.beta << std::endl
               << "  workspace (ptr, stride): "
               << operator_args.workspace.data() << ", " 
               << operator_args.workspace.stride(0) << std::endl
               << "  source (ptr, stride): " 
               << operator_args.source.data() << ", "
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/reference/conv2d.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/reference/conv2d.cu`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/reference/conv3d.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/reference/conv3d.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/reference/conv_reference_operation.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/reference/conv_reference_operation.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -70,15 +70,15 @@
   typename ElementCompute_,
   typename ElementAccumulator_ = ElementCompute_,
   typename ConvertOp_ = NumericConverter<ElementC_, ElementCompute_>,
   typename InnerProductOp_ = multiply_add<ElementAccumulator_>
 >
 struct ConvReferenceDispatcher;
 
-/// Dispatcher for Conv2d (partially specialied for kConvDim == 2)
+/// Dispatcher for Conv2d (partially specialized for kConvDim == 2)
 template <
   Provider kProvider,
   conv::Operator kConvolutionalOperator,
   typename ElementA,
   typename LayoutA,
   typename ElementB,
   typename LayoutB,
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/reference/gemm.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/reference/gemm.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/reference/gemm_reference_operation.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/reference/gemm_reference_operation.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/reference/initialize_reference_operations.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/reference/initialize_reference_operations.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/singleton.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/singleton.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/symm_operation.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/symm_operation.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -349,15 +349,15 @@
 
   /// Call print_operator_args  from the Conv2dOperation::initialize()
   // to dump arguments passed on to cutlass operator for debugging
   void print_operator_args(OperatorArguments &operator_args) const {
     std::cout << "SymmOperation::OperatorArguments" << std::endl
               << "  problem_size:" << std::endl 
               << operator_args.problem_size << std::endl
-              << "  epilouge (alpha, beta): "
+              << "  epilogue (alpha, beta): "
               << operator_args.epilogue.alpha << ", " 
               << operator_args.epilogue.beta << std::endl
               << "  ref_A (ptr, {stride}): " 
               << operator_args.ptr_A << ", {"
               << operator_args.lda << "}" << std::endl
               << "  ref_B (ptr, {stride}): " 
               << operator_args.ptr_B << ", {"
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/trmm_operation.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/trmm_operation.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/library/src/util.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/library/src/util.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -424,15 +424,15 @@
 
 static struct {
   char const *text;
   char const *pretty;
   NumericTypeID enumerant;
 }
 NumericTypeID_enumerants[] = {
-  {"unknown", "<unkown>", NumericTypeID::kUnknown},
+  {"unknown", "<unknown>", NumericTypeID::kUnknown},
   {"void", "Void", NumericTypeID::kVoid},
   {"b1", "B1", NumericTypeID::kB1},
   {"u2", "U2", NumericTypeID::kU2},
   {"u4", "U4", NumericTypeID::kU4},
   {"u8", "U8", NumericTypeID::kU8},
   {"u16", "U16", NumericTypeID::kU16},
   {"u32", "U32", NumericTypeID::kU32},
@@ -461,15 +461,15 @@
   {"cu64", "CU64", NumericTypeID::kCU64},  
   {"cs2", "CS2", NumericTypeID::kCS2},
   {"cs4", "CS4", NumericTypeID::kCS4},
   {"cs8", "CS8", NumericTypeID::kCS8},
   {"cs16", "CS16", NumericTypeID::kCS16},
   {"cs32", "CS32", NumericTypeID::kCS32},
   {"cs64", "CS64", NumericTypeID::kCS64},
-  {"*", "<unkown/enumerate all>", NumericTypeID::kUnknown}
+  {"*", "<unknown/enumerate all>", NumericTypeID::kUnknown}
 };
 
 /// Converts a NumericTypeID enumerant to a string
 char const *to_string(NumericTypeID type, bool pretty) {
 
   for (auto const & possible : NumericTypeID_enumerants) {
     if (type == possible.enumerant) {
@@ -954,15 +954,15 @@
 
 static struct {
   char const *text;
   char const *pretty;
   ConvKind enumerant;
 }
 ConvKind_enumerants[] = {
-  {"unknown", "<unkown>", ConvKind::kUnknown},
+  {"unknown", "<unknown>", ConvKind::kUnknown},
   {"fprop", "<fprop>", ConvKind::kFprop},
   {"dgrad", "<dgrad>", ConvKind::kDgrad},
   {"wgrad", "<wgrad>", ConvKind::kWgrad},
 };
 
 /// Converts a ConvKind enumerant to a string
 char const *to_string(ConvKind type, bool pretty) {
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/conv2d_operation_profiler.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/conv2d_operation_profiler.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -266,15 +266,15 @@
 
   if (!arg_as_int(problem_.dilation_w, "dilation_w", problem_space, problem)) {
     // default value
     problem_.dilation_w = 1;
   }
 
   ////////////////////////  Convolution output dimensions p and q ////////////////////////
-  // Cutlass convolutions support arbitrary output sizes and not constriant by          //
+  // Cutlass convolutions support arbitrary output sizes and not constrained by         //
   // input, filter, padding, striding, dilation sizes.                                  //
   // cuDNN sets the output dimensions (p, q)  using following equations:                //
   //                                                                                    //
   // output = div_up(input + 2 * pad - ((filter - 1) * dilation + 1) + 1, stride)       //
   // where; div_up(a, b) : (a - 1)/b + 1                                                //
   //                                                                                    //
   // Thus, when output p and q dimensions are unspecified by the user                   //
@@ -498,23 +498,23 @@
 
   int64_t output_bytes = int64_t(library::sizeof_bits(operation_desc.output().element) / 8) * 
     conv_workspace_.configuration.problem_size.output_size();
 
   // Bytes of activation, filter, and output tensors
   result.bytes = problem_.bytes(operation_desc);
 
-  // Theoritical flops required for the computation
+  // Theoretical flops required for the computation
   result.flops = problem_.flops(operation_desc);
 
   // Measured runtime
   result.runtime = 0;
 
 }
 
-/// Initialize reduction problem dimenstions and library::Operation
+/// Initialize reduction problem dimensions and library::Operation
 bool Conv2dOperationProfiler::initialize_reduction_configuration_(
   Options const &options,  
   PerformanceReport &report,
   DeviceContext &device_context,
   library::Operation const *operation,
   ProblemSpace const &problem_space,
   ProblemSpace::Problem const &problem) {
@@ -531,15 +531,15 @@
   if (!cast_from_double(problem_.beta_zero, conv_desc.element_epilogue, 0)) {
    return false;
   }
 
   /// This chooses the appropriate stride element of the row-major C tensor.
   int const & tensor_c_stride_idx = (conv_kind == library::ConvKind::kWgrad ? 2 : 0);
 
-  /// intialize library::ReductionConfiguration
+  /// initialize library::ReductionConfiguration
   conv_workspace_.reduction_configuration.problem_size     = problem_.eq_gemm_size(conv_kind).mn();
   conv_workspace_.reduction_configuration.partitions       = int(problem_.split_k_slices);
   conv_workspace_.reduction_configuration.partition_stride = problem_.eq_gemm_size(conv_kind).mn().product();
   conv_workspace_.reduction_configuration.ldw =
       conv_workspace_.configuration.stride_c[tensor_c_stride_idx];
   conv_workspace_.reduction_configuration.lds =
       conv_workspace_.configuration.stride_c[tensor_c_stride_idx];
@@ -769,15 +769,15 @@
   
   if (conv_workspace_.configuration.split_k_mode == conv::SplitKMode::kParallel) {
     // update library::ConvArguments for parallel split-k reduction
     conv_workspace_.arguments.D = conv_workspace_.device_workspace.data();
     conv_workspace_.arguments.alpha = problem_.alpha_one.data();
     conv_workspace_.arguments.beta = problem_.beta_zero.data();
 
-    /// intialize library::ReductionArguments
+    /// initialize library::ReductionArguments
     conv_workspace_.reduction_arguments.workspace           = conv_workspace_.device_workspace.data();
     conv_workspace_.reduction_arguments.source              = conv_workspace_.C->data();
     conv_workspace_.reduction_arguments.destination         = conv_workspace_.Computed->data();
     conv_workspace_.reduction_arguments.alpha               = problem_.alpha.data();
     conv_workspace_.reduction_arguments.beta                = problem_.beta.data();
     conv_workspace_.reduction_arguments.pointer_mode        = library::ScalarPointerMode::kHost;
   }
@@ -957,15 +957,15 @@
       conv_desc.B.element,
       conv_desc.B.layout,
       conv_desc.C.element,
       conv_desc.C.layout,
       conv_desc.tile_description.math_instruction.element_accumulator, 
       conv_desc.element_epilogue);
 
-#if 0 // debug print to check which host refererence instance is selected
+#if 0 // debug print to check which host reference instance is selected
     std::cout << conv2d_key << "\n";
 #endif
 
     auto operators_it = Singleton::get().operation_table.conv2d_operations.find(conv2d_key);
 
     if(operators_it == Singleton::get().operation_table.conv2d_operations.end()) {
 
@@ -978,15 +978,15 @@
     auto cc_it = operators_it->second.find(preference_key);
     
     if(cc_it == operators_it->second.end()) {
       results_.back().verification_map[library::Provider::kReferenceHost] = Disposition::kNotRun;
       return true;
     }
 
-    // host refernce has only one instances in Conv2dOperationVectorMap
+    // host reference has only one instances in Conv2dOperationVectorMap
     library::Operation const *reference_op = cc_it->second[0];
 
     //
     // Copy input tensors A, B, and C from device to host buffers
     //
     conv_workspace_.host_tensor_a.resize(conv_workspace_.A->bytes());
     conv_workspace_.host_tensor_b.resize(conv_workspace_.B->bytes());
@@ -1005,15 +1005,15 @@
     conv_workspace_.arguments.D = conv_workspace_.host_tensor_c.data();
 
     conv_workspace_.arguments.alpha = problem_.alpha.data();
     conv_workspace_.arguments.beta = problem_.beta.data();
     conv_workspace_.arguments.pointer_mode = library::ScalarPointerMode::kHost;
 
     //
-    // Intialize host reference operation
+    // Initialize host reference operation
     //
     std::vector<uint8_t> host_workspace_reference_op;
 
     uint64_t workspace_size = reference_op->get_host_workspace_size(&conv_workspace_.configuration);
     host_workspace_reference_op.resize(workspace_size, 0);
 
     reference_op->initialize(
@@ -1110,19 +1110,19 @@
     
     if(cc_it == operators_it->second.end()) {
       results_.back().verification_map[library::Provider::kReferenceDevice] = Disposition::kNotRun;
 
       return true;
     }
 
-    // device refernce has only one instances in Conv2dOperationVectorMap
+    // device reference has only one instances in Conv2dOperationVectorMap
     library::Operation const *reference_op = cc_it->second[0];
   
     //
-    // Intialize device reference operation
+    // Initialize device reference operation
     //
     std::vector<uint8_t> host_workspace_reference_op;
 
     uint64_t workspace_size = reference_op->get_host_workspace_size(&conv_workspace_.configuration);
     host_workspace_reference_op.resize(workspace_size, 0);
 
     reference_op->initialize(
@@ -1201,15 +1201,15 @@
 
     if (conv_workspace_.configuration.split_k_mode == conv::SplitKMode::kParallel) {
       // update library::ConvArguments for parallel split-k reduction
       conv_workspace_.arguments.D = conv_workspace_.device_workspace.data();
       conv_workspace_.arguments.alpha = problem_.alpha_one.data();
       conv_workspace_.arguments.beta = problem_.beta_zero.data();
 
-      /// intialize library::ReductionArguments
+      /// initialize library::ReductionArguments
       conv_workspace_.reduction_arguments.workspace           = conv_workspace_.device_workspace.data();
       conv_workspace_.reduction_arguments.source              = conv_workspace_.C->data();
       conv_workspace_.reduction_arguments.destination         = conv_workspace_.Computed->data();
       conv_workspace_.reduction_arguments.alpha               = problem_.alpha.data();
       conv_workspace_.reduction_arguments.beta                = problem_.beta.data();
       conv_workspace_.reduction_arguments.pointer_mode        = library::ScalarPointerMode::kHost;
     }
@@ -1272,15 +1272,15 @@
     conv_arguments->C = conv_workspace_.C->batch_data(problem_idx);
     conv_arguments->D = conv_workspace_.Computed->batch_data(problem_idx);
     
     if (conv_workspace_.configuration.split_k_mode == conv::SplitKMode::kParallel) {
       // update library::ConvArguments for parallel split-k reduction
       conv_arguments->D = conv_workspace_.device_workspace.data();
 
-      /// intialize library::ReductionArguments
+      /// initialize library::ReductionArguments
       conv_workspace_.reduction_arguments.workspace           = conv_workspace_.device_workspace.data();
       conv_workspace_.reduction_arguments.source              = conv_workspace_.C->batch_data(problem_idx);
       conv_workspace_.reduction_arguments.destination         = conv_workspace_.Computed->batch_data(problem_idx);
     }
 
     // Run underlying conv2d operation
     status = underlying_operation->run(
@@ -1325,15 +1325,15 @@
     conv_arguments->C = conv_workspace_.C->batch_data(problem_idx);
     conv_arguments->D = conv_workspace_.Computed->batch_data(problem_idx);
 
     if (conv_workspace_.configuration.split_k_mode == conv::SplitKMode::kParallel) {
       // update library::ConvArguments for parallel split-k reduction
       conv_arguments->D = conv_workspace_.device_workspace.data();
 
-      /// intialize library::ReductionArguments
+      /// initialize library::ReductionArguments
       conv_workspace_.reduction_arguments.workspace           = conv_workspace_.device_workspace.data();
       conv_workspace_.reduction_arguments.source              = conv_workspace_.C->batch_data(problem_idx);
       conv_workspace_.reduction_arguments.destination         = conv_workspace_.Computed->batch_data(problem_idx);
     }
 
     // Run underlying conv2d operation
     status = underlying_operation->run(
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/conv2d_operation_profiler.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/conv2d_operation_profiler.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -185,37 +185,37 @@
         case library::ConvKind::kFprop:
         case library::ConvKind::kDgrad: 
         case library::ConvKind::kWgrad: return library::LayoutTypeID::kColumnMajor;
         default : throw std::runtime_error("Invalid Conv Operator (fprop, dgrad, wgrad)");
       }
     }
 
-    // Returns leading dimenstion for equivalent gemm matrix A
+    // Returns leading dimension for equivalent gemm matrix A
     int64_t eq_gemm_lda(library::ConvKind const &conv_kind) const {
 
       switch (conv_kind) {
         case library::ConvKind::kFprop: return eq_gemm_size(conv_kind).k();
         case library::ConvKind::kDgrad: return eq_gemm_size(conv_kind).k();
         case library::ConvKind::kWgrad: return eq_gemm_size(conv_kind).m();
         default : throw std::runtime_error("Invalid Conv Operator (fprop, dgrad, wgrad)");
       }
     }
 
-    // Returns leading dimenstion for equivalent gemm matrix B
+    // Returns leading dimension for equivalent gemm matrix B
     int64_t eq_gemm_ldb(library::ConvKind const &conv_kind) const {
 
       switch (conv_kind) {
         case library::ConvKind::kFprop: return eq_gemm_size(conv_kind).k();
         case library::ConvKind::kDgrad: return eq_gemm_size(conv_kind).n();
         case library::ConvKind::kWgrad: return eq_gemm_size(conv_kind).n();
         default : throw std::runtime_error("Invalid Conv Operator (fprop, dgrad, wgrad)");
       }
     }
 
-    // Returns leading dimenstion for equivalent gemm matrix C
+    // Returns leading dimension for equivalent gemm matrix C
     int64_t eq_gemm_ldc(library::ConvKind const &conv_kind) const {
 
       switch (conv_kind) {
         case library::ConvKind::kFprop: 
         case library::ConvKind::kDgrad: 
         case library::ConvKind::kWgrad: return eq_gemm_size(conv_kind).m();
         default : throw std::runtime_error("Invalid Conv Operator (fprop, dgrad, wgrad)");
@@ -432,15 +432,15 @@
     Options const &options,
     library::Operation const *operation,
     void *arguments,
     void *host_workspace,
     void *device_workspace);
  
  
-  /// Initialize reduction problem dimenstions and library::Operation
+  /// Initialize reduction problem dimensions and library::Operation
   bool initialize_reduction_configuration_(
     Options const &options,  
     PerformanceReport &report,
     DeviceContext &device_context,
     library::Operation const *operation,
     ProblemSpace const &problem_space,
     ProblemSpace::Problem const &problem);
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/conv3d_operation_profiler.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/conv3d_operation_profiler.cu`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -280,15 +280,15 @@
 
   if (!arg_as_int(problem_.dilation_w, "dilation_w", problem_space, problem)) {
     // default value
     problem_.dilation_w = 1;
   }
 
   ////////////////////////  Convolution output dimensions p and q ////////////////////////
-  // Cutlass convolutions support arbitrary output sizes and not constriant by          //
+  // Cutlass convolutions support arbitrary output sizes and not constrained by         //
   // input, filter, padding, striding, dilation sizes.                                  //
   // cuDNN sets the output dimensions (p, q)  using following equations:                //
   //                                                                                    //
   // output = div_up(input + 2 * pad - ((filter - 1) * dilation + 1) + 1, stride)       //
   // where; div_up(a, b) : (a - 1)/b + 1                                                //
   //                                                                                    //
   // Thus, when output p and q dimensions are unspecified by the user                   //
@@ -541,23 +541,23 @@
     std::string(library::to_string(problem_.eq_gemm_provider)));
 
   OperationProfiler::initialize_result_(result, operation_desc, problem_space);
 
   // Bytes of activation, filter, and output tensors
   result.bytes = problem_.bytes(operation_desc);
 
-  // Theoritical flops required for the computation
+  // Theoretical flops required for the computation
   result.flops = problem_.flops(operation_desc);
 
   // Measured runtime
   result.runtime = 0;
 
 }
 
-/// Initialize reduction problem dimenstions and library::Operation
+/// Initialize reduction problem dimensions and library::Operation
 bool Conv3dOperationProfiler::initialize_reduction_configuration_(
   Options const &options,  
   PerformanceReport &report,
   DeviceContext &device_context,
   library::Operation const *operation,
   ProblemSpace const &problem_space,
   ProblemSpace::Problem const &problem) {
@@ -574,15 +574,15 @@
   if (!cast_from_double(problem_.beta_zero, conv_desc.element_epilogue, 0)) {
    return false;
   }
 
   /// This chooses the appropriate stride element of the row-major C tensor.
   int const & tensor_c_stride_idx = (conv_kind == library::ConvKind::kWgrad ? 3 : 0);
 
-  /// intialize library::ReductionConfiguration
+  /// initialize library::ReductionConfiguration
   conv_workspace_.reduction_configuration.problem_size     = problem_.eq_gemm_size(conv_kind).mn();
   conv_workspace_.reduction_configuration.partitions       = int(problem_.split_k_slices);
   conv_workspace_.reduction_configuration.partition_stride = problem_.eq_gemm_size(conv_kind).mn().product();
   conv_workspace_.reduction_configuration.ldw              = conv_workspace_.configuration.layout_c(conv_kind).stride()[tensor_c_stride_idx];
   conv_workspace_.reduction_configuration.lds              = conv_workspace_.configuration.layout_c(conv_kind).stride()[tensor_c_stride_idx];
   conv_workspace_.reduction_configuration.ldd              = conv_workspace_.configuration.layout_c(conv_kind).stride()[tensor_c_stride_idx];
 
@@ -943,15 +943,15 @@
     conv_desc.B.element,
     conv_desc.B.layout,
     conv_desc.C.element,
     conv_desc.C.layout,
     conv_desc.tile_description.math_instruction.element_accumulator, 
     conv_desc.element_epilogue);
 
-#if 0 // debug print to check which host refererence instance is selected
+#if 0 // debug print to check which host reference instance is selected
     std::cout << conv_key << "\n";
 #endif
 
   auto operators_it = Singleton::get().operation_table.conv3d_operations.find(conv_key);
 
   if(operators_it == Singleton::get().operation_table.conv3d_operations.end()) {
 
@@ -964,15 +964,15 @@
   auto cc_it = operators_it->second.find(preference_key);
   
   if(cc_it == operators_it->second.end()) {
     results_.back().verification_map[library::Provider::kReferenceHost] = Disposition::kNotRun;
     return true;
   }
 
-  // host refernce has only one instances in ConvOperationVectorMap
+  // host reference has only one instances in ConvOperationVectorMap
   library::Operation const *reference_op = cc_it->second[0];
 
   //
   // Copy input tensors A, B, and C from device to host buffers
   //
   conv_workspace_.host_tensor_a.resize(conv_workspace_.A->bytes());
   conv_workspace_.host_tensor_b.resize(conv_workspace_.B->bytes());
@@ -989,15 +989,15 @@
   conv_workspace_.arguments.C = conv_workspace_.host_tensor_c.data();
   conv_workspace_.arguments.D = conv_workspace_.host_tensor_c.data();
   conv_workspace_.arguments.alpha = problem_.alpha.data();
   conv_workspace_.arguments.beta = problem_.beta.data();
   conv_workspace_.arguments.pointer_mode = library::ScalarPointerMode::kHost;
 
   //
-  // Intialize host reference operation
+  // Initialize host reference operation
   //
   std::vector<uint8_t> host_workspace_reference_op;
 
   uint64_t workspace_size = reference_op->get_host_workspace_size(&conv_workspace_.configuration);
   host_workspace_reference_op.resize(workspace_size, 0);
 
   reference_op->initialize(
@@ -1105,15 +1105,15 @@
 
   if (conv_workspace_.configuration.split_k_mode == conv::SplitKMode::kParallel) {
     // update library::ConvArguments for parallel split-k reduction
     conv_workspace_.arguments.D = conv_workspace_.device_workspace.data();
     conv_workspace_.arguments.alpha = problem_.alpha_one.data();
     conv_workspace_.arguments.beta = problem_.beta_zero.data();
 
-    /// intialize library::ReductionArguments
+    /// initialize library::ReductionArguments
     conv_workspace_.reduction_arguments.workspace           = conv_workspace_.device_workspace.data();
     conv_workspace_.reduction_arguments.source              = conv_workspace_.C->batch_data(problem_idx);
     conv_workspace_.reduction_arguments.destination         = conv_workspace_.Computed->batch_data(problem_idx);
     conv_workspace_.reduction_arguments.alpha               = problem_.alpha.data();
     conv_workspace_.reduction_arguments.beta                = problem_.beta.data();
     conv_workspace_.reduction_arguments.pointer_mode        = library::ScalarPointerMode::kHost;
   }
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/conv3d_operation_profiler.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/conv3d_operation_profiler.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -101,15 +101,15 @@
 
     /// Total number of bytes loaded
     int64_t bytes(library::ConvDescription const &operation_desc) const;
 
     /// Total number of flops computed
     int64_t flops(library::ConvDescription const &operation_desc) const;
 
-    /// Infers output size from theinput size, padding, stride, and dilation
+    /// Infers output size from the input size, padding, stride, and dilation
     void set_default_output_size() {
       z = ((d + pad_d - t * dilation_d) / stride_d) + 1;
       p = ((h + pad_h - r * dilation_h) / stride_h) + 1;
       q = ((w + pad_w - s * dilation_w) / stride_w) + 1;
     }
 
     // Returns equivalent gemm problem size for convolution
@@ -186,37 +186,37 @@
         case library::ConvKind::kFprop:
         case library::ConvKind::kDgrad: 
         case library::ConvKind::kWgrad: return library::LayoutTypeID::kColumnMajor;
         default : throw std::runtime_error("Invalid Conv Operator (fprop, dgrad, wgrad)");
       }
     }
 
-    // Returns leading dimenstion for equivalent gemm matrix A
+    // Returns leading dimension for equivalent gemm matrix A
     int64_t eq_gemm_lda(library::ConvKind const &conv_kind) const {
 
       switch (conv_kind) {
         case library::ConvKind::kFprop: return eq_gemm_size(conv_kind).k();
         case library::ConvKind::kDgrad: return eq_gemm_size(conv_kind).k();
         case library::ConvKind::kWgrad: return eq_gemm_size(conv_kind).m();
         default : throw std::runtime_error("Invalid Conv Operator (fprop, dgrad, wgrad)");
       }
     }
 
-    // Returns leading dimenstion for equivalent gemm matrix B
+    // Returns leading dimension for equivalent gemm matrix B
     int64_t eq_gemm_ldb(library::ConvKind const &conv_kind) const {
 
       switch (conv_kind) {
         case library::ConvKind::kFprop: return eq_gemm_size(conv_kind).k();
         case library::ConvKind::kDgrad: return eq_gemm_size(conv_kind).n();
         case library::ConvKind::kWgrad: return eq_gemm_size(conv_kind).n();
         default : throw std::runtime_error("Invalid Conv Operator (fprop, dgrad, wgrad)");
       }
     }
 
-    // Returns leading dimenstion for equivalent gemm matrix C
+    // Returns leading dimension for equivalent gemm matrix C
     int64_t eq_gemm_ldc(library::ConvKind const &conv_kind) const {
 
       switch (conv_kind) {
         case library::ConvKind::kFprop: 
         case library::ConvKind::kDgrad: 
         case library::ConvKind::kWgrad: return eq_gemm_size(conv_kind).m();
         default : throw std::runtime_error("Invalid Conv Operator (fprop, dgrad, wgrad)");
@@ -385,15 +385,15 @@
     double &runtime,
     Options const &options,
     library::Operation const *operation,
     void *arguments,
     void *host_workspace,
     void *device_workspace);
   
-  /// Initialize reduction problem dimenstions and library::Operation
+  /// Initialize reduction problem dimensions and library::Operation
   bool initialize_reduction_configuration_(
     Options const &options,  
     PerformanceReport &report,
     DeviceContext &device_context,
     library::Operation const *operation,
     ProblemSpace const &problem_space,
     ProblemSpace::Problem const &problem);
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/cublas_helpers.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/cublas_helpers.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -53,15 +53,15 @@
     case CUBLAS_STATUS_NOT_SUPPORTED:
       return Status::kErrorNotSupported;
     default: break;
   }
   return Status::kErrorInternal;
 }
 
-/// Converts a cuBLASS status to cutlass::profiler::Disposition
+/// Converts a cuBLAS status to cutlass::profiler::Disposition
 Disposition get_cutlass_disposition(cublasStatus_t cublas_status) {
 
   if (cublas_status == CUBLAS_STATUS_INVALID_VALUE) {
     return Disposition::kInvalidProblem;
   }
   else if (cublas_status == CUBLAS_STATUS_NOT_SUPPORTED) {
     return Disposition::kNotSupported;
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/cublas_helpers.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/cublas_helpers.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -50,15 +50,15 @@
 namespace profiler {
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 /// Converts a cuBLAS status to cutlass::Status
 Status get_cutlass_status(cublasStatus_t cublas);
 
-/// Converts a cuBLASS status to cutlass::profiler::Disposition
+/// Converts a cuBLAS status to cutlass::profiler::Disposition
 Disposition get_cutlass_disposition(cublasStatus_t cublas_status);
 
 /// Maps a CUTLASS tensor layout to a cuBLAS transpose operation
 bool get_cublas_transpose_operation(
   cublasOperation_t &operation,
   library::LayoutTypeID layout,
   library::ComplexTransform transform = library::ComplexTransform::kNone);
@@ -83,15 +83,15 @@
 Status cublas_satisfies(library::TrmmDescription const &desc);
 
 /// Returns a status if cuBLAS can satisfy a particular SYMM/HEMM description
 Status cublas_satisfies(library::SymmDescription const &desc);
 
 /// This is a helper class to create cublasHandle_t automatically on CublasCreate object creation and 
 /// to destroy cublasHandle_t on CublasCreate object destruction. 
-/// Additionaly, it provides implicit cast from CublasCreate's object to cublasHandle_t's object
+/// Additionally, it provides implicit cast from CublasCreate's object to cublasHandle_t's object
 class CublasCreate {
 private:
 	cublasHandle_t handle;
 	cublasStatus_t status;
 
 public:
 	CublasCreate() {
@@ -192,15 +192,15 @@
 
   //
   // Data members
   //
   library::GemmUniversalConfiguration configuration;
   library::GemmUniversalArguments arguments;
 
-  // cublass-specific data structures to fill cublas API call arguments
+  // cublas-specific data structures to fill cublas API call arguments
   cublasOperation_t trans_A;
   cublasOperation_t trans_B;
   cudaDataType_t data_type_A;
   cudaDataType_t data_type_B;
   cudaDataType_t data_type_C;
   cudaDataType_t compute_data_type;
 
@@ -233,15 +233,15 @@
 
   //
   // Data members
   //
   library::RankKConfiguration configuration;
   library::RankKArguments arguments;
 
-  // cublass-specific data structures to fill cublas API call arguments
+  // cublas-specific data structures to fill cublas API call arguments
   cublasOperation_t trans_A;
   cublasFillMode_t uplo;
   cudaDataType_t data_type_A;
   cudaDataType_t data_type_C;
   cudaDataType_t compute_data_type;
 
 #if (__CUDACC_VER_MAJOR__ >= 11)
@@ -273,15 +273,15 @@
 
   //
   // Data members
   //
   library::TrmmConfiguration configuration;
   library::TrmmArguments arguments;
 
-  // cublass-specific data structures to fill cublas API call arguments
+  // cublas-specific data structures to fill cublas API call arguments
   cublasOperation_t trans_A;
   cublasSideMode_t side;
   cublasFillMode_t uplo;
   cublasDiagType_t diag;
   cudaDataType_t data_type_A;
   cudaDataType_t data_type_B;
   cudaDataType_t data_type_D;
@@ -314,15 +314,15 @@
 
   //
   // Data members
   //
   library::SymmConfiguration configuration;
   library::SymmArguments arguments;
 
-  // cublass-specific data structures to fill cublas API call arguments
+  // cublas-specific data structures to fill cublas API call arguments
   cublasSideMode_t side;
   cublasFillMode_t uplo;
   cudaDataType_t data_type_A;
   cudaDataType_t data_type_B;
   cudaDataType_t data_type_C;
   cudaDataType_t compute_data_type;
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/cudnn_helpers.cpp` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/cudnn_helpers.cpp`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -64,15 +64,15 @@
   }
   else if (cudnn_status == CUDNN_STATUS_NOT_SUPPORTED) {
     return Disposition::kNotSupported;
   }
   return Disposition::kFailed;
 }
 
-/// Checks cudnnStatus_t converts to cutlas status and returns if Status::kSuccess o.w. throws exception
+/// Checks cudnnStatus_t converts to cutlass status and returns if Status::kSuccess o.w. throws exception
 Status checkCudnnErr(cudnnStatus_t cudnn_status) {
   Status cutlass_status = get_cutlass_status(cudnn_status);
   if(cutlass_status != Status::kSuccess) {
     throw std::runtime_error("checkCudnnErr failed");
   }
   return cutlass_status;
 }
@@ -239,15 +239,15 @@
   auto const &math_instruction = desc.tile_description.math_instruction;
 
   if(a_tensor.element != b_tensor.element) {
     return Status::kErrorInvalidDataType;
   }
 
   ////////////////////////  Convolution output dimensions p and q ///////////////////////
-  // Cutlass convolutions support arbitrary output dimensions and not constriant by    //
+  // Cutlass convolutions support arbitrary output dimensions and not constrained by   //
   // input, filter, padding, striding, dilation sizes.                                 //
   // cuDNN sets the output dimensions (p, q) using following equations:                //
   //                                                                                   //
   // output = div_up(input + 2 * pad - ((filter - 1) * dilation + 1) + 1, stride)      //
   // where; div_up(a, b) : (a - 1)/b + 1                                               //
   //                                                                                   //
   // Before launching cudnn verification or profiling check that output p and q        //
@@ -369,15 +369,15 @@
   auto const &math_instruction = desc.tile_description.math_instruction;
 
   if(a_tensor.element != b_tensor.element) {
     return Status::kErrorInvalidDataType;
   }
 
   ////////////////////////  Convolution output dimensions p and q ///////////////////////
-  // Cutlass convolutions support arbitrary output dimensions and not constriant by    //
+  // Cutlass convolutions support arbitrary output dimensions and not constrained by   //
   // input, filter, padding, striding, dilation sizes.                                 //
   // cuDNN sets the output dimensions (p, q) using following equations:                //
   //                                                                                   //
   // output = div_up(input + 2 * pad - ((filter - 1) * dilation + 1) + 1, stride)      //
   // where; div_up(a, b) : (a - 1)/b + 1                                               //
   //                                                                                   //
   // Before launching cudnn verification or profiling check that output p and q        //
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/cudnn_helpers.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/cudnn_helpers.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -51,15 +51,15 @@
 /////////////////////////////////////////////////////////////////////////////////////////////////
 /// Converts a cuDNN status to cutlass::Status
 Status get_cutlass_status(cudnnStatus_t cudnn_status);
 
 /// Converts a cuDNN status to cutlass::profiler::Disposition
 Disposition get_cutlass_disposition(cudnnStatus_t cudnn_status);
 
-/// Checks cudnnStatus_t converts to cutlas status and returns if Status::kSuccess o.w. throws exception
+/// Checks cudnnStatus_t converts to cutlass status and returns if Status::kSuccess o.w. throws exception
 Status checkCudnnErr(cudnnStatus_t cudnn_status);
 
 /// Maps a CUTLASS conv mode to a cuDNN conv mode enumeration
 bool get_cudnn_conv_mode(cudnnConvolutionMode_t &cudnn_conv_mode, conv::Mode conv_mode);
 
 /// Maps a CUTLASS layout type to a cuDNN data type enumeration
 bool get_cudnn_layout(cudnnTensorFormat_t &cudnn_layout, library::LayoutTypeID layout);
@@ -78,15 +78,15 @@
 
 /// Cudnn compute type seems to be hardcoded to float (To handle a possible cudnn issue)
 float cast_cudnn_compute_type_to_float(library::NumericTypeID type, void const * src);
 
 
 /// This is a helper class to create cudnnHandle_t automatically on CudnnCreate object creation and 
 /// to destroy cudnnHandle_t on CudnnCreate object destruction. 
-/// Additionaly, it provides implicit cast from CudnnCreate's object to cudnnHandle_t's object
+/// Additionally, it provides implicit cast from CudnnCreate's object to cudnnHandle_t's object
 class CudnnCreate {
 private:
 	cudnnHandle_t handle;
 	cudnnStatus_t status;
 
 public:
 	CudnnCreate() {
@@ -158,15 +158,15 @@
 
   Status status;
   
   //
   // Methods
   //
 
-  // TODO: unify ctor cudnnConvDispatcher for conv2d and conv3d by unifying Conv2dConfigration
+  // TODO: unify ctor cudnnConvDispatcher for conv2d and conv3d by unifying Conv2dConfiguration
   
   // ctor for conv2d 
   cudnnConvDispatcher( 
     library::ConvDescription const &op_desc,
     library::Conv2dConfiguration configuration,
     library::ConvArguments arguments_,
     cudnnHandle_t handle
@@ -492,15 +492,15 @@
         )); break;
 
     }
 
     workspace = cutlass::device_memory::allocation<char>(workspace_size_in_bytes);
   }
 
-  /// Executes Conv2d operater from cudnn library
+  /// Executes Conv2d operator from cudnn library
   cudnnStatus_t operator()(cudnnHandle_t handle) {
 
     switch (conv_kind) {
       case library::ConvKind::kFprop:
         return cudnnConvolutionForward(
           handle,
           &alpha,
@@ -548,15 +548,15 @@
           filter_desc,
           arguments.D
         );
       default : throw std::runtime_error("Invalid Conv Operator (fprop, dgrad, wgrad)");
     }
   }
 
-  // Returns Actviation Tensor
+  // Returns Activation Tensor
   void const * activation() const {
     switch(conv_kind) {
       case library::ConvKind::kFprop : return arguments.A;
       case library::ConvKind::kDgrad : return arguments.C;
       case library::ConvKind::kWgrad : return arguments.B;
       default : throw std::runtime_error("Invalid Conv Operator (fprop, dgrad, wgrad)");
     }
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/cutlass_profiler.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/cutlass_profiler.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/cutlass_profiler.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/cutlass_profiler.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/debug.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/debug.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -35,15 +35,15 @@
 #pragma once
 
 #include <iostream>
 
 //#define report(x) { std::cout << "\033[31m" << __FILE__ << ":" << __LINE__ << "  " << x << "\033[0m" << std::endl; }
 //#define report(x) {}
 
-// Enable/Disble Profiler debug prints
+// Enable/Disable Profiler debug prints
 //#define DEBUG_PROFILER 
 
 //RED    31m   // profiler prints debug messages in red
 //YELLOW 33m   // ir prints debug messages in yellow
 
 #ifndef DEBUG_PROFILER
 #define debugprof(...)
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/device_allocation.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/device_allocation.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -438,20 +438,20 @@
 }
 
 /// Gets the number of adjacent tensors in memory
 int DeviceAllocation::batch_count() const {
   return batch_count_;
 }
 
-/// Gets the stride (in units of elements) beteween items
+/// Gets the stride (in units of elements) between items
 int64_t DeviceAllocation::batch_stride() const {
   return batch_stride_;
 }
 
-/// Gets the stride (in units of bytes) beteween items
+/// Gets the stride (in units of bytes) between items
 int64_t DeviceAllocation::batch_stride_bytes() const {
   return bytes(type_, batch_stride_);
 }
 
 size_t DeviceAllocation::capacity() const {
   return capacity_;
 }
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/device_allocation.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/device_allocation.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -172,18 +172,18 @@
 
   /// Gets the extent vector
   std::vector<int> const & extent() const;
 
   /// Gets the number of adjacent tensors in memory
   int batch_count() const;
 
-  /// Gets the stride (in units of elements) beteween items
+  /// Gets the stride (in units of elements) between items
   int64_t batch_stride() const;
 
-  /// Gets the stride (in units of bytes) beteween items
+  /// Gets the stride (in units of bytes) between items
   int64_t batch_stride_bytes() const;
 
   /// Capacity of allocation in number of elements
   size_t capacity() const;
   
   /// Capacity of allocation in bytes
   size_t bytes() const;
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/device_context.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/device_context.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/device_context.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/device_context.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/enumerated_types.cpp` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/enumerated_types.cpp`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/enumerated_types.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/enumerated_types.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/gemm_operation_profiler.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/gemm_operation_profiler.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -104,15 +104,15 @@
 
     << "Schmoo over accumulator types:\n"
     << "  $ cutlass_profiler --operation=Gemm --accumulator-type=f16,f32\n\n"
 
     << "Run when A is f16 with column-major and B is any datatype with row-major (For column major, use column, col, or n. For row major use, row or t):\n"
     << "  $ cutlass_profiler --operation=Gemm --A=f16:column --B=*:row\n\n"
 
-    << "Profile a particular problem size with split K and paralell reduction:\n"
+    << "Profile a particular problem size with split K and parallel reduction:\n"
     << "  $ cutlass_profiler --operation=Gemm --split_k_mode=parallel --split_k_slices=2 --m=1024 --n=1024 --k=128\n\n"
 
     << "Using various input value distribution:\n"
     << "  $ cutlass_profiler --operation=Gemm --dist=uniform,min:0,max:3\n"
     << "  $ cutlass_profiler --operation=Gemm --dist=gaussian,mean:0,stddev:3\n"
     << "  $ cutlass_profiler --operation=Gemm --dist=sequential,start:0,delta:1\n\n"
 
@@ -164,15 +164,15 @@
   
   if (!arg_as_int(this->k, "k", problem_space, problem)) {
     // default value
     this->k = 1024;
   }
 
   if (!arg_as_SplitKModeID(this->split_k_mode, "split_k_mode", problem_space, problem)) {
-    // defualt value
+    // default value
     this->split_k_mode = library::SplitKMode::kSerial;
   }
   
   this->mode = library::GemmUniversalMode::kGemm;
   if(this->split_k_mode == library::SplitKMode::kParallel) {
     this->mode = library::GemmUniversalMode::kGemmSplitKParallel;
   }
@@ -401,15 +401,15 @@
 
   result.bytes = problem_.bytes(operation_desc);
   result.flops = problem_.flops(operation_desc);
   result.runtime = 0;
 
 }
 
-/// Initialize redution problem dimentions and library::Operation
+/// Initialize reduction problem dimensions and library::Operation
 bool GemmOperationProfiler::initialize_reduction_configuration_(
   library::Operation const *operation,
   ProblemSpace::Problem const &problem) {
   library::GemmDescription const &gemm_desc =
     static_cast<library::GemmDescription const&>(operation->description());
 
   if (!cast_from_double(problem_.alpha_one, gemm_desc.element_epilogue, 1)) {
@@ -430,15 +430,15 @@
 
   // find reduction operation
   library::ReductionFunctionalKey reduction_key(
     library::Provider::kCUTLASS,
     gemm_desc.tile_description.math_instruction.element_accumulator,    // element workspace
     gemm_desc.tile_description.math_instruction.element_accumulator,    // element accumulator
     gemm_desc.C.element,                                                // element output
-    gemm_desc.element_epilogue                                          // element coumpute
+    gemm_desc.element_epilogue                                          // element compute
   );
 
   auto reduction_it = library::Singleton::get().operation_table.reduction_operations.find(reduction_key);
  
   if (reduction_it == library::Singleton::get().operation_table.reduction_operations.end()) {
     return false;
   }
@@ -533,14 +533,21 @@
       {int(problem_.m), int(problem_.n)},
       {int(problem_.ldc)},
       problem_.batch_count * gemm_workspace_.problem_count
     );
 
     gemm_workspace_.Reference->copy_from_device(gemm_workspace_.C->data());
 
+    // NOTE: the leading non-batch strides are duplicated here for 3.0 API kernels
+    gemm_workspace_.arguments.problem_size = {int(problem_.m), int(problem_.n), int(problem_.k)};
+    gemm_workspace_.arguments.batch_count = problem_.batch_count;
+    gemm_workspace_.arguments.lda = problem_.lda;
+    gemm_workspace_.arguments.ldb = problem_.ldb;
+    gemm_workspace_.arguments.ldc = problem_.ldc;
+    gemm_workspace_.arguments.ldd = problem_.ldc;
     gemm_workspace_.arguments.batch_stride_A = gemm_workspace_.A->batch_stride();
     gemm_workspace_.arguments.batch_stride_B = gemm_workspace_.B->batch_stride();
     gemm_workspace_.arguments.batch_stride_C = gemm_workspace_.C->batch_stride();
     gemm_workspace_.arguments.batch_stride_D = gemm_workspace_.Computed->batch_stride();
   }
 
   //
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/gemm_operation_profiler.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/gemm_operation_profiler.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/gpu_timer.cpp` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/gpu_timer.cpp`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -90,15 +90,15 @@
     result = cudaDeviceSynchronize();
     if (result != cudaSuccess) {
       throw std::runtime_error("Failed to synchronize with CUDA device.");
     }
   }
 }
 
-/// Returns the duration in miliseconds
+/// Returns the duration in milliseconds
 double GpuTimer::duration(int iterations) const {
 
   float avg_ms;
 
   cudaError_t result = cudaEventElapsedTime(&avg_ms, events[0], events[1]);
   if (result != cudaSuccess) {
     throw std::runtime_error("Failed to query elapsed time from CUDA events.");
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/gpu_timer.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/gpu_timer.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -58,15 +58,15 @@
 
   /// Records a stop event in the stream
   void stop(cudaStream_t stream = nullptr);
 
   /// Records a stop event in the stream and synchronizes on the stream
   void stop_and_wait(cudaStream_t stream = nullptr);
 
-  /// Returns the duration in miliseconds
+  /// Returns the duration in milliseconds
   double duration(int iterations = 1) const;
 };
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
 } // namespace profiler
 } // namespace cutlass
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/main.cpp` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/main.cpp`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/operation_profiler.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/operation_profiler.cu`

 * *Files 15% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -71,14 +71,17 @@
 
   ArgumentDescriptionVector tile_description_arguments{
     {ArgumentTypeID::kEnumerated, {"op_class", "opcode-class"}, "Class of math instruction (simt, tensorop, wmmatensorop, wmma)"},
     {ArgumentTypeID::kEnumerated, {"accum", "accumulator-type"}, "Math instruction accumulator data type"},
     {ArgumentTypeID::kInteger, {"cta_m", "threadblock-shape::m"}, "Threadblock shape in the M dimension"},
     {ArgumentTypeID::kInteger, {"cta_n", "threadblock-shape::n"}, "Threadblock shape in the N dimension"},
     {ArgumentTypeID::kInteger, {"cta_k", "threadblock-shape::k"}, "Threadblock shape in the K dimension"},
+    {ArgumentTypeID::kInteger, {"cluster_m", "cluster-shape::m"}, "Cluster shape in the M dimension"},
+    {ArgumentTypeID::kInteger, {"cluster_n", "cluster-shape::n"}, "Cluster shape in the N dimension"},
+    {ArgumentTypeID::kInteger, {"cluster_k", "cluster-shape::k"}, "Cluster shape in the K dimension"},
     {ArgumentTypeID::kInteger, {"stages", "threadblock-stages"}, "Number of stages of threadblock-scoped matrix multiply"},
     {ArgumentTypeID::kInteger, {"warps_m", "warp-count::m"}, "Number of warps within threadblock along the M dimension"},
     {ArgumentTypeID::kInteger, {"warps_n", "warp-count::n"}, "Number of warps within threadblock along the N dimension"},
     {ArgumentTypeID::kInteger, {"warps_k", "warp-count::k"}, "Number of warps within threadblock along the K dimension"},
     {ArgumentTypeID::kInteger, {"inst_m", "instruction-shape::m"}, "Math instruction shape in the M dimension"},
     {ArgumentTypeID::kInteger, {"inst_n", "instruction-shape::n"}, "Math instruction shape in the N dimension"},
     {ArgumentTypeID::kInteger, {"inst_k", "instruction-shape::k"}, "Math instruction shape in the K dimension"},
@@ -194,14 +197,32 @@
 
   if (arg_as_int(int_value, "cta_k", problem_space, problem)) {
     if (int64_t(op_desc.tile_description.threadblock_shape.k()) != int_value) {
       return false;
     }
   }
 
+  if (arg_as_int(int_value, "cluster_m", problem_space, problem)) {
+    if (int64_t(op_desc.tile_description.cluster_shape.m()) != int_value) {
+      return false;
+    }
+  }
+
+  if (arg_as_int(int_value, "cluster_n", problem_space, problem)) {
+    if (int64_t(op_desc.tile_description.cluster_shape.n()) != int_value) {
+      return false;
+    }
+  }
+
+  if (arg_as_int(int_value, "cluster_k", problem_space, problem)) {
+    if (int64_t(op_desc.tile_description.cluster_shape.k()) != int_value) {
+      return false;
+    }
+  }
+
   if (arg_as_int(int_value, "stages", problem_space, problem)) {
     if (int64_t(op_desc.tile_description.threadblock_stages) != int_value) {
       return false;
     }
   }
 
   if (arg_as_int(int_value, "warps_m", problem_space, problem)) {
@@ -592,14 +613,17 @@
 
   set_argument(result, "accum", problem_space,
     library::to_string(operation_desc.tile_description.math_instruction.element_accumulator));
 
   set_argument(result, "cta_m", problem_space, operation_desc.tile_description.threadblock_shape.m());
   set_argument(result, "cta_n", problem_space, operation_desc.tile_description.threadblock_shape.n());
   set_argument(result, "cta_k", problem_space, operation_desc.tile_description.threadblock_shape.k());
+  set_argument(result, "cluster_m", problem_space, operation_desc.tile_description.cluster_shape.m());
+  set_argument(result, "cluster_n", problem_space, operation_desc.tile_description.cluster_shape.n());
+  set_argument(result, "cluster_k", problem_space, operation_desc.tile_description.cluster_shape.k());
   set_argument(result, "stages", problem_space, operation_desc.tile_description.threadblock_stages);
   set_argument(result, "warps_m", problem_space, operation_desc.tile_description.warp_count.m());
   set_argument(result, "warps_n", problem_space, operation_desc.tile_description.warp_count.n());
   set_argument(result, "warps_k", problem_space, operation_desc.tile_description.warp_count.k());
   set_argument(result, "inst_m", problem_space, operation_desc.tile_description.math_instruction.instruction_shape.m());
   set_argument(result, "inst_n", problem_space, operation_desc.tile_description.math_instruction.instruction_shape.n());
   set_argument(result, "inst_k", problem_space, operation_desc.tile_description.math_instruction.instruction_shape.k());
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/operation_profiler.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/operation_profiler.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -77,15 +77,15 @@
 
   /// Arguments parsed from command line
   ArgumentDescriptionVector arguments_;
 
   /// List of providers used to verify and compare each result
   ProviderVector verification_providers_;
 
-  /// Model performance result initailized by the operation profiler with workload statistics
+  /// Model performance result initialized by the operation profiler with workload statistics
   /// and reasonable default state.
   PerformanceResult model_result_;
 
   /// Performance result vector constructed by profiling the operation
   PerformanceResultVector results_;
 
 public:
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/options.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/options.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -185,15 +185,15 @@
     std::string str;
     cmdline.get_cmd_line_argument("initialization-provider", str);
     provider = library::from_string<library::Provider>(str);
     if (provider == library::Provider::kInvalid) {
       enabled = false;
     }
     else if (provider != library::Provider::kReferenceHost && provider != library::Provider::kReferenceDevice) {
-      throw std::runtime_error("Unsupported intialization provider specified."); 
+      throw std::runtime_error("Unsupported initialization provider specified.");
     }
   }
   else {
     provider = library::Provider::kReferenceDevice;
   }
 
   cmdline.get_cmd_line_argument("seed", seed, 2019);
@@ -201,15 +201,15 @@
   if (cmdline.check_cmd_line_flag("dist")) {
     // user has set the data distribution (fix data distribution once set)
     fix_data_distribution = true;
     // set user provided data distribution
     get_distribution(cmdline, "dist", data_distribution);
   }
   else {
-    // profiler choosen data distribution (allowed to change based on numeric types)
+    // profiler chosen data distribution (allowed to change based on numeric types)
     fix_data_distribution = false;
     // set uniform data distribution with range [-4, 4] 
     data_distribution.set_uniform(-4, 4, 0);
   }
   
 
 }
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/options.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/options.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -227,15 +227,15 @@
     /// Path to a file containing junit xml results
     std::string junit_output_path;
 
     /// Sequence of tags to attach to each result
     std::vector<std::pair<std::string, std::string>> pivot_tags;
 
     /// If true, reports status of all kernels including those that were
-    /// not run for the given argumetns
+    /// not run for the given arguments
     bool report_not_run;
 
     /// Prints human-readable text to stdout. If false, nothing is written to stdout
     bool verbose;
 
     /// Sort results by (currently by flops-per-byte)
     bool sort_results;
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/performance_report.cpp` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/performance_report.cpp`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/performance_report.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/performance_report.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/performance_result.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/examples/45_dual_gemm/dual_gemm_common.h`

 * *Files 12% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -24,38 +24,29 @@
  * DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR
  * SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUPTION) HOWEVER
  * CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY,
  * OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE
  * OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
  *
  **************************************************************************************************/
-/* \file
-   \brief
+/*! \file
+    \brief Defines common types used for all DualGemm operators.
 */
-
 #pragma once
 
-#include <vector>
-
-#include "cutlass/cutlass.h"
-
-// CUTLASS Profiler includes
-#include "enumerated_types.h"
-#include "performance_result.h"
-
-// CUTLASS Library includes
-#include "cutlass/library/library.h"
-#include "cutlass/library/util.h"
-
 namespace cutlass {
-namespace profiler {
+namespace gemm {
 
 /////////////////////////////////////////////////////////////////////////////////////////////////
 
+enum class DualGemmMode {
+  kGemm,
+  kBatched,
+  kInvalid
+};
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
+////////////////////////////////////////////////////////////////////////////////////////////////////
 
-} // namespace profiler
+} // namespace gemm
 } // namespace cutlass
 
-/////////////////////////////////////////////////////////////////////////////////////////////////
-
+////////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/performance_result.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/performance_result.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/problem_space.cpp` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/problem_space.cpp`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/problem_space.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/problem_space.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -280,15 +280,15 @@
     virtual std::unique_ptr<KernelArgument::Value> at() const;
   };
 
   //
   // Data members
   //
 
-  /// Set of posible values
+  /// Set of possible values
   ValueCollection values;
 
   //
   // Methods
   //
 
   /// Default ctor
@@ -536,15 +536,15 @@
     virtual std::unique_ptr<KernelArgument::Value> at() const;
   };
 
   //
   // Data members
   //
 
-  /// Set of posible values
+  /// Set of possible values
   RangeCollection ranges;
 
   //
   // Methods
   //
 
   /// Default ctor
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/rank_2k_operation_profiler.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/rank_2k_operation_profiler.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/rank_2k_operation_profiler.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/rank_2k_operation_profiler.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/rank_k_operation_profiler.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/rank_k_operation_profiler.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/rank_k_operation_profiler.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/rank_k_operation_profiler.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/reduction_operation_profiler.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/reduction_operation_profiler.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/sparse_gemm_operation_profiler.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/sparse_gemm_operation_profiler.cu`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/sparse_gemm_operation_profiler.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/sparse_gemm_operation_profiler.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/symm_operation_profiler.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/symm_operation_profiler.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/symm_operation_profiler.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/symm_operation_profiler.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/trmm_operation_profiler.cu` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/trmm_operation_profiler.cu`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/profiler/src/trmm_operation_profiler.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/profiler/src/trmm_operation_profiler.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/command_line.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/command_line.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /******************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -184,15 +184,15 @@
       // Clear any default values
       vals.clear();
 
       // Recover from multi-value string
       for (int i = 0; i < keys.size(); ++i) {
         if (keys[i] == string(arg_name)) {
           string val_string(values[i]);
-          seperate_string(val_string, vals, sep);
+          separate_string(val_string, vals, sep);
         }
       }
     }
   }
 
   /**
    * Returns the values specified for a given commandline parameter
@@ -221,15 +221,15 @@
     std::vector<std::string> ranges;
     get_cmd_line_arguments(arg_name, ranges, delim);
 
     for (std::vector<std::string>::const_iterator range = ranges.begin();
       range != ranges.end(); ++range) {
 
       std::vector<std::string> range_vals;
-      seperate_string(*range, range_vals, sep);
+      separate_string(*range, range_vals, sep);
       vals.push_back(range_vals);
     }
   }
 
   /**
    * The number of pairs parsed
    */
@@ -279,15 +279,15 @@
     tokenize(token_pairs, str, delim, sep);
     for (token_iterator tok = token_pairs.begin(); tok != token_pairs.end(); ++tok) {
       tokens.push_back(tok->first);
     }
   }
 
   template <typename value_t>
-  static void seperate_string(std::string const& str,
+  static void separate_string(std::string const& str,
                               std::vector<value_t>& vals,
                               char sep = ',') {
     std::istringstream str_stream(str);
     std::string::size_type old_pos = 0;
     std::string::size_type new_pos = 0;
 
     // Iterate <sep>-delimited values
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/debug.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/debug.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/device_dump.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/device_dump.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/device_groupnorm.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/device_groupnorm.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /******************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -310,15 +310,15 @@
             }
             output_TVec_ptr[offset_in_group] = output_tmp_vec;
         }
     }
 }
 
 //ref_input & ref_output should be [N, H, W, C]
-//ref_gamma & ref_beta shoud be [1, 1, 1, C]
+//ref_gamma & ref_beta should be [1, 1, 1, C]
 template <typename T>
 void groupnorm(cutlass::Tensor4DCoord input_size,
                const int num_groups,
                const float eps,
                TensorRef<T, layout::TensorNHWC> ref_output,
                TensorRef<T, layout::TensorNHWC> ref_input,
                TensorRef<T, layout::TensorNHWC> ref_gamma,
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/device_layernorm.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/device_layernorm.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /******************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -452,15 +452,15 @@
   const T* beta = ref_beta.data();
   dim3 grid(m);
   dim3 block((n + 31)/32*32);
   if (block.x > 1024){
     block.x = 1024;
   }
   // TODO : There should be better configs for different cases, we only use several samples to show how to use here
-  // TODO : using registers to store values locally can reduce the ldgs from global memory and speedup the kernels.
+  // TODO : using registers to store values locally can reduce the loads from global memory and speedup the kernels.
   if ((n % 4 == 0) && (n >= 128) && (n <= 4096)) {
     block.x = (n/4 + 31)/32*32;
     if (std::is_same<T, float>::value) {
       layernorm_twoPassAlgo_stored_locally_e4<float4, float, 1><<<grid, block, 0, stream>>>(
         (float4*)output,
         (const float4*)input,
         (const float4*)gamma,
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/device_memory.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/device_memory.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /******************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/device_nchw_to_nhwc.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/device_nchw_to_nhwc.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /******************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/device_nhwc_padding.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/device_nhwc_padding.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /******************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -105,17 +105,17 @@
   __shared__ Tio shm[192];
   const int tidx = blockIdx.x * 192 + threadIdx.x;  
   const int threadidx = threadIdx.x; 
 
   shm[threadIdx.x] = tidx >= max_input_element ? zero_io : input[tidx];  
   __syncthreads();
   
-  const int ouput_offset = blockIdx.x * 256;
-  const int lower_bound = max_output_element < ouput_offset + 256 ? max_output_element : ouput_offset + 256;
-  for (int i = ouput_offset + threadidx, j = threadidx ; i < lower_bound ; i+=192, j+=192)
+  const int output_offset = blockIdx.x * 256;
+  const int lower_bound = max_output_element < output_offset + 256 ? max_output_element : output_offset + 256;
+  for (int i = output_offset + threadidx, j = threadidx ; i < lower_bound ; i+=192, j+=192)
   {
     const Telement* shm_element = (const Telement*)shm + j*3*element_in_Tio/4;
     Telement array[element_in_Tio];
     CUTLASS_PRAGMA_UNROLL
     for (int k = 0 ; k < element_in_Tio ; k++)
       array[k] = ((k+1)%4 == 0) ? zero_element : shm_element[(k > 3) ? (k - 1) : k];
     output[i] = *((const Tio *)array);
@@ -136,17 +136,17 @@
   __shared__ Tio shm[192];
   const int tidx = blockIdx.x * 192 + threadIdx.x;  
   const int threadidx = threadIdx.x; 
 
   shm[threadIdx.x] = tidx >= max_input_element ? zero_io : input[tidx];  
   __syncthreads();
   
-  const int ouput_offset = blockIdx.x * 512;
-  const int lower_bound = max_output_element < ouput_offset + 512 ? max_output_element : ouput_offset + 512;
-  for (int i = ouput_offset + threadidx, j = threadidx ; i < lower_bound ; i+=192, j+=192)
+  const int output_offset = blockIdx.x * 512;
+  const int lower_bound = max_output_element < output_offset + 512 ? max_output_element : output_offset + 512;
+  for (int i = output_offset + threadidx, j = threadidx ; i < lower_bound ; i+=192, j+=192)
   {
     const Telement* shm_element = (const Telement*)shm + (element_in_Tio == 4 ? j/2 : j)*3;
     Telement array[element_in_Tio];
     //float
     if (element_in_Tio == 4){
       CUTLASS_PRAGMA_UNROLL
       for (int k = 0 ; k < element_in_Tio ; k++)
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/device_nhwc_pooling.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/device_nhwc_pooling.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /******************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/device_nhwc_to_nchw.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/device_nhwc_to_nchw.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /******************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/device_utils.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/device_utils.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/distribution.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/distribution.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/exceptions.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/exceptions.h`

 * *Files 4% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /******************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/host_reorder.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/host_reorder.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/host_tensor.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/host_tensor.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/host_tensor_planar_complex.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/host_tensor_planar_complex.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/host_uncompress.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/host_uncompress.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/index_sequence.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/index_sequence.h`

 * *Files 5% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/detail/inner_product.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/detail/inner_product.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/detail/linear_to_coordinate.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/detail/linear_to_coordinate.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/convolution.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/convolution.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/gemm.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/gemm.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -244,15 +244,15 @@
                  NumericConverterClamp<ElementC, ScalarType>>(
         problem_size, alpha, tensor_a, tensor_b, beta, tensor_c, tensor_d, initial_accum);
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
-/// Parital specialization for XOR-popc
+/// Partial specialization for XOR-popc
 template <typename ElementA, typename LayoutA, typename ElementB,
           typename LayoutB, typename ElementC, typename LayoutC,
           typename ScalarType, typename AccumulatorType>
 struct Gemm<ElementA, LayoutA, ElementB, LayoutB, ElementC, LayoutC, ScalarType,
             AccumulatorType, arch::OpXorPopc> {
 
   void operator()(gemm::GemmCoord problem_size, ScalarType alpha,
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/gemm_complex.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/gemm_complex.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/gemm_planar_complex.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/gemm_planar_complex.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/kernel/gemm.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/kernel/gemm.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/kernel/tensor_elementwise.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/kernel/tensor_elementwise.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/kernel/tensor_foreach.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/kernel/tensor_foreach.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -68,15 +68,15 @@
   }
 };
 
 /// Helper to perform for-each operation
 template <typename Func, int Rank>
 struct TensorForEachHelper<Func, Rank, 0> {
 
-  /// Constructor for fastest chaning rank
+  /// Constructor for fastest changing rank
   __inline__ __device__
   TensorForEachHelper(Func &func, Coord<Rank> const &size, Coord<Rank> &coord, int64_t index) {
 
     coord[Rank - 1] = index;
 
     if (coord < size) {
       func(coord);
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/rank_2k_complex.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/rank_2k_complex.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/tensor_compare.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/tensor_compare.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/tensor_fill.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/tensor_fill.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -1304,15 +1304,15 @@
   Element val = Element(0)) {               ///< value to uniformly fill it with
 
   TensorFillDiagonal(view, val, val);
 }
 
 ///////////////////////////////////////////////////////////////////////////////////////////////////
 
-/// Fills a tensor's digonal with 1 and 0 everywhere else.
+/// Fills a tensor's diagonal with 1 and 0 everywhere else.
 template <
   typename Element,               ///< Element type
   typename Layout>                ///< Layout function
 void TensorFillIdentity(
   TensorView<Element, Layout> view) {               ///< destination tensor
 
   TensorFillDiagonal(view, Element(1), Element(0));
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/tensor_foreach.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/tensor_foreach.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -129,8 +129,8 @@
   }
 };
 
 ///////////////////////////////////////////////////////////////////////////////////////////////////
 
 } // namespace device
 } // namespace reference
-} // namesace cutlass
+} // namespace cutlass
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/tensor_reduce.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/tensor_reduce.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/tensor_relu.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/tensor_relu.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/thread/gemm.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/device/thread/gemm.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/convolution.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/convolution.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/error_metrics.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/error_metrics.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/gemm.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/gemm.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -331,15 +331,15 @@
                  NumericConverterClamp<ElementC, ScalarType>>(
         problem_size, alpha, tensor_a, tensor_b, beta, tensor_c, tensor_d, initial_accum);
   }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
-/// Parital specialization for XOR-popc
+/// Partial specialization for XOR-popc
 template <typename ElementA, typename LayoutA, typename ElementB,
           typename LayoutB, typename ElementC, typename LayoutC,
           typename ScalarType, typename ComputeType>
 struct Gemm<ElementA, LayoutA, ElementB, LayoutB, ElementC, LayoutC, ScalarType,
             ComputeType, arch::OpXorPopc> {
 
   void operator()(gemm::GemmCoord problem_size, ScalarType alpha,
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/gemm_complex.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/gemm_complex.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -38,14 +38,15 @@
 #include "cutlass/complex.h"
 #include "cutlass/numeric_types.h"
 #include "cutlass/functional.h"
 #include "cutlass/numeric_conversion.h"
 #include "cutlass/matrix_coord.h"
 
 #include "cutlass/tensor_view.h"
+
 #include "cutlass/gemm/gemm.h"
 
 namespace cutlass {
 namespace reference {
 namespace host {
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/gemm_planar_complex.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/gemm_planar_complex.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/rank_2k.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/rank_2k.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/rank_2k_complex.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/rank_2k_complex.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/rank_k_complex.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/rank_k_complex.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/symm.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/symm.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/symm_complex.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/symm_complex.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/tensor_compare.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/tensor_compare.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/tensor_copy.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/tensor_copy.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/tensor_elementwise.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/tensor_elementwise.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/tensor_fill.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/tensor_fill.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -988,15 +988,15 @@
     func
   );
 }
 
 ///////////////////////////////////////////////////////////////////////////////////////////////////
 ///////////////////////////////////////////////////////////////////////////////////////////////////
 
-/// Helper to fill a tensor's digonal with 1 and 0 everywhere else.
+/// Helper to fill a tensor's diagonal with 1 and 0 everywhere else.
 template <
   typename Element,               ///< Element type
   typename Layout>                ///< Layout function
 void TensorFillIdentity(
   TensorView<Element, Layout> dst) {               ///< destination tensor
 
   TensorFillDiagonal(dst, Element(1), Element(0));
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/tensor_foreach.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/tensor_foreach.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
@@ -65,15 +65,15 @@
 /// Helper to perform for-each operation
 template <typename Func, int Rank>
 struct TensorForEachHelper<Func, Rank, 0> {
 
   /// Index of the active rank
   static int const kActiveRank = Rank - 1;
 
-  /// Constructor for fastest chaning rank
+  /// Constructor for fastest changing rank
   TensorForEachHelper(
     Func &func,
     Coord<Rank> const &extent,
     Coord<Rank> &coord) {
 
     for (int i = 0; i < extent.at(kActiveRank); ++i) {
       coord[kActiveRank] = i;
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/tensor_norm.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/tensor_norm.h`

 * *Files 1% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/tensor_reduce.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/tensor_reduce.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/trmm.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/trmm.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/trmm_complex.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/trmm_complex.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/tensor_view_io.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/tensor_view_io.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/type_traits.h` & `flash_attn-1.0.0/csrc/flash_attn/cutlass/tools/util/include/cutlass/util/type_traits.h`

 * *Files 0% similar despite different names*

```diff
@@ -1,9 +1,9 @@
 /***************************************************************************************************
- * Copyright (c) 2017 - 2022 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
+ * Copyright (c) 2017 - 2023 NVIDIA CORPORATION & AFFILIATES. All rights reserved.
  * SPDX-License-Identifier: BSD-3-Clause
  *
  * Redistribution and use in source and binary forms, with or without
  * modification, are permitted provided that the following conditions are met:
  *
  * 1. Redistributions of source code must retain the above copyright notice, this
  * list of conditions and the following disclaimer.
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/fmha_api.cpp` & `flash_attn-1.0.0/csrc/flash_attn/fmha_api.cpp`

 * *Files 2% similar despite different names*

```diff
@@ -203,21 +203,22 @@
         const int num_splits,
         c10::optional<at::Generator> gen_) {
 
     auto dprops = at::cuda::getCurrentDeviceProperties();
     bool is_sm75 = dprops->major == 7 && dprops->minor == 5;
     bool is_sm80 = dprops->major == 8 && dprops->minor == 0;
     bool is_sm8x = dprops->major == 8 && dprops->minor >= 0;
-    TORCH_CHECK(is_sm8x || is_sm75);
+    bool is_sm90 = dprops->major == 9 && dprops->minor == 0;
+    TORCH_CHECK(is_sm90 || is_sm8x || is_sm75);
     auto stream = at::cuda::getCurrentCUDAStream().stream();
     bool is_dropout = p_dropout > 0.0;
     Launch_params<FMHA_fprop_params> launch_params(dprops, stream, is_dropout, return_softmax);
 
     auto q_dtype = q.dtype();
-    TORCH_CHECK(q_dtype == torch::kFloat16 || (is_sm8x && q_dtype == torch::kBFloat16));
+    TORCH_CHECK(q_dtype == torch::kFloat16 || ((is_sm8x || is_sm90) && q_dtype == torch::kBFloat16));
     TORCH_CHECK(k.dtype() == q_dtype);
     TORCH_CHECK(v.dtype() == q_dtype);
     TORCH_CHECK(out.dtype() == q_dtype);
     TORCH_CHECK(cu_seqlens_q.dtype() == torch::kInt32);
     TORCH_CHECK(cu_seqlens_k.dtype() == torch::kInt32);
 
     TORCH_CHECK(q.is_cuda());
@@ -305,15 +306,14 @@
                      is_causal,
                      num_splits);
 
     // number of times random will be generated per thread, to offset philox counter in thc random
     // state
     // We use a custom RNG that increases the offset by batch_size * nheads * 32.
     int64_t counter_offset = launch_params.params.b * launch_params.params.h * 32;
-    at::PhiloxCudaState rng_engine_inputs;
 
     if( is_dropout ) {
         // See Note [Acquire lock when using random generators]
         std::lock_guard<std::mutex> lock(gen->mutex_);
         launch_params.params.philox_args = gen->philox_cuda_state(counter_offset);
     }
 
@@ -355,22 +355,23 @@
         const int num_splits,
         c10::optional<at::Generator> gen_
 ) {
     auto dprops = at::cuda::getCurrentDeviceProperties();
     bool is_sm75 = dprops->major == 7 && dprops->minor == 5;
     bool is_sm80 = dprops->major == 8 && dprops->minor == 0;
     bool is_sm8x = dprops->major == 8 && dprops->minor >= 0;
-    TORCH_CHECK(is_sm8x || is_sm75);
+    bool is_sm90 = dprops->major == 9 && dprops->minor == 0;
+    TORCH_CHECK(is_sm90 || is_sm8x || is_sm75);
     auto launch = &run_fmha_bwd;
 
     bool is_dropout = p_dropout > 0.0;
     auto stream = at::cuda::getCurrentCUDAStream().stream();
 
     auto q_dtype = q.dtype();
-    TORCH_CHECK(q_dtype == torch::kFloat16 || (is_sm8x && q_dtype == torch::kBFloat16));
+    TORCH_CHECK(q_dtype == torch::kFloat16 || ((is_sm8x || is_sm90) && q_dtype == torch::kBFloat16));
     TORCH_CHECK(k.dtype() == q_dtype);
     TORCH_CHECK(v.dtype() == q_dtype);
     TORCH_CHECK(out.dtype() == q_dtype);
     TORCH_CHECK(dout.dtype() == q_dtype);
     TORCH_CHECK(dq.dtype() == q_dtype);
     TORCH_CHECK(dk.dtype() == q_dtype);
     TORCH_CHECK(dv.dtype() == q_dtype);
@@ -403,15 +404,15 @@
     const int total_q = sizes[TOTAL_DIM];
     const int num_heads = sizes[H_DIM];
     const int head_size = sizes[D_DIM];
     const int total_k = k.size(TOTAL_DIM);
     TORCH_CHECK(batch_size > 0);
     TORCH_CHECK((head_size % 8 == 0) && (head_size <= 128));
     if (head_size > 64) {  // TODO: eventually we should support SM86 and SM70 with d=128 as well
-        TORCH_CHECK(is_sm80);
+        TORCH_CHECK(is_sm80 || is_sm90);
     }
 
     CHECK_SHAPE(q, total_q, num_heads, head_size);
     CHECK_SHAPE(k, total_k, num_heads, head_size);
     CHECK_SHAPE(v, total_k, num_heads, head_size);
     CHECK_SHAPE(out, total_q, num_heads, head_size);
     CHECK_SHAPE(dout, total_q, num_heads, head_size);
@@ -515,15 +516,18 @@
               const float p_dropout,
               const float softmax_scale,
               const bool is_causal,
               const bool return_softmax,
               c10::optional<at::Generator> gen_) {
 
     auto dprops = at::cuda::getCurrentDeviceProperties();
-    TORCH_CHECK(dprops->major == 8 && dprops->minor >= 0);
+    bool is_sm80 = dprops->major == 8 && dprops->minor == 0;
+    bool is_sm8x = dprops->major == 8 && dprops->minor >= 0;
+    bool is_sm90 = dprops->major == 9 && dprops->minor == 0;
+    TORCH_CHECK(is_sm8x || is_sm90);
     auto stream = at::cuda::getCurrentCUDAStream().stream();
     bool is_dropout = p_dropout > 0.0;
     Launch_params<FMHA_fprop_params> launch_params(dprops, stream, is_dropout, return_softmax);
 
     TORCH_CHECK(q.dtype() == torch::kFloat16);
     TORCH_CHECK(k.dtype() == torch::kFloat16);
     TORCH_CHECK(v.dtype() == torch::kFloat16);
@@ -608,15 +612,14 @@
                      /*num_splits=*/1);
     launch_params.params.blockmask = static_cast<int *>(blockmask.data_ptr());
 
     run_fmha_block_fp16_sm80(launch_params, /*configure=*/ true);
     // number of times random will be generated per thread, to offset philox counter in thc random
     // state
     int64_t counter_offset = launch_params.elts_per_thread;
-    at::PhiloxCudaState rng_engine_inputs;
 
     if( is_dropout ) {
         // See Note [Acquire lock when using random generators]
         std::lock_guard<std::mutex> lock(gen->mutex_);
         launch_params.params.philox_args = gen->philox_cuda_state(counter_offset);
     }
 
@@ -646,15 +649,16 @@
               const float softmax_scale,
               const bool is_causal,
               c10::optional<at::Generator> gen_
 ) {
     auto dprops = at::cuda::getCurrentDeviceProperties();
     bool is_sm80 = dprops->major == 8 && dprops->minor == 0;
     bool is_sm8x = dprops->major == 8 && dprops->minor >= 0;
-    TORCH_CHECK(dprops->major == 8 && dprops->minor >= 0);
+    bool is_sm90 = dprops->major == 9 && dprops->minor == 0;
+    TORCH_CHECK(is_sm8x || is_sm90);
     auto launch = &run_fmha_block_dgrad_fp16_sm80;
 
     bool is_dropout = p_dropout > 0.0;
     auto stream = at::cuda::getCurrentCUDAStream().stream();
 
     TORCH_CHECK(q.dtype() == torch::kFloat16);
     TORCH_CHECK(k.dtype() == torch::kFloat16);
@@ -696,15 +700,15 @@
     const int total_q = sizes[TOTAL_DIM];
     const int num_heads = sizes[H_DIM];
     const int head_size = sizes[D_DIM];
     const int total_k = k.size(TOTAL_DIM);
     TORCH_CHECK(batch_size > 0);
     TORCH_CHECK(head_size == 16 || head_size == 32 || head_size == 64 || head_size == 128);
     if (head_size == 128) {  // TODO: eventually we should support SM86 and SM70 with d=128 as well
-        TORCH_CHECK(is_sm80);
+        TORCH_CHECK(is_sm80 || is_sm90);
     }
 
     CHECK_SHAPE(q, total_q, num_heads, head_size);
     CHECK_SHAPE(k, total_k, num_heads, head_size);
     CHECK_SHAPE(v, total_k, num_heads, head_size);
     CHECK_SHAPE(out, total_q, num_heads, head_size);
     CHECK_SHAPE(dout, total_q, num_heads, head_size);
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/src/fmha/gemm.h` & `flash_attn-1.0.0/csrc/flash_attn/src/fmha/gemm.h`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/flash_attn/src/fmha/gmem_tile.h` & `flash_attn-1.0.0/csrc/flash_attn/src/fmha/gmem_tile.h`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/flash_attn/src/fmha/kernel_traits.h` & `flash_attn-1.0.0/csrc/flash_attn/src/fmha/kernel_traits.h`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/flash_attn/src/fmha/mask.h` & `flash_attn-1.0.0/csrc/flash_attn/src/fmha/mask.h`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/flash_attn/src/fmha/smem_tile.h` & `flash_attn-1.0.0/csrc/flash_attn/src/fmha/smem_tile.h`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/flash_attn/src/fmha/softmax.h` & `flash_attn-1.0.0/csrc/flash_attn/src/fmha/softmax.h`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/flash_attn/src/fmha/utils.h` & `flash_attn-1.0.0/csrc/flash_attn/src/fmha/utils.h`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/flash_attn/src/fmha.h` & `flash_attn-1.0.0/csrc/flash_attn/src/fmha.h`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/flash_attn/src/fmha_block_dgrad_fp16_kernel_loop.sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/src/fmha_block_dgrad_fp16_kernel_loop.sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/flash_attn/src/fmha_block_dgrad_kernel_1xN_loop.h` & `flash_attn-1.0.0/csrc/flash_attn/src/fmha_block_dgrad_kernel_1xN_loop.h`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/flash_attn/src/fmha_block_fprop_fp16_kernel.sm80.cu` & `flash_attn-1.0.0/csrc/flash_attn/src/fmha_block_fprop_fp16_kernel.sm80.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/flash_attn/src/fmha_block_fprop_kernel_1xN.h` & `flash_attn-1.0.0/csrc/flash_attn/src/fmha_block_fprop_kernel_1xN.h`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/flash_attn/src/fmha_blockmask.h` & `flash_attn-1.0.0/csrc/flash_attn/src/fmha_blockmask.h`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/flash_attn/src/fmha_bwd_hdim32.cu` & `flash_attn-1.0.0/csrc/flash_attn/src/fmha_bwd_hdim32.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/flash_attn/src/fmha_bwd_hdim64.cu` & `flash_attn-1.0.0/csrc/flash_attn/src/fmha_bwd_hdim64.cu`

 * *Files 8% similar despite different names*

```diff
@@ -7,18 +7,18 @@
 void run_fmha_bwd_hdim64(FMHA_dgrad_params &params, cudaStream_t stream, const bool configure) {
     FP16_SWITCH(params.is_bf16, ([&] {
         auto dprops = at::cuda::getCurrentDeviceProperties();
         if (params.seqlen_k == 128) {
             using Kernel_traits = FMHA_kernel_traits<128, 64, 16, 1, 8, 0x08u, elem_type>;
             run_fmha_bwd_loop<Kernel_traits>(params, stream, configure);
         } else if (params.seqlen_k >= 256) {
-            if (dprops->major == 8 && dprops->minor == 0) {
+            if ((dprops->major == 8 && dprops->minor == 0) || (dprops->major == 9 && dprops->minor == 0)) {
                 // Don't share smem for K & V, and don't keep V in registers
                 // This speeds things up by 2-3% by avoiding register spills, but it
-                // uses more shared memory, which is fine on A100 but not other GPUs.
+                // uses more shared memory, which is fine on A100 and H100 but not other GPUs.
                 // For other GPUs, we keep V in registers.
                 using Kernel_traits = FMHA_kernel_traits<256, 64, 16, 1, 8, 0x100u, elem_type>;
                 run_fmha_bwd_loop<Kernel_traits>(params, stream, configure);
             } else if (dprops->major == 8 && dprops->minor > 0) {
                 using Kernel_traits = FMHA_kernel_traits<256, 64, 16, 1, 8, 0x08u, elem_type>;
                 run_fmha_bwd_loop<Kernel_traits>(params, stream, configure);
             } else if (dprops->major == 7 && dprops->minor == 5) {
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/src/fmha_bwd_launch_template.h` & `flash_attn-1.0.0/csrc/flash_attn/src/fmha_bwd_launch_template.h`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/flash_attn/src/fmha_dgrad_kernel_1xN_loop.h` & `flash_attn-1.0.0/csrc/flash_attn/src/fmha_dgrad_kernel_1xN_loop.h`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/flash_attn/src/fmha_fprop_hdim32.cu` & `flash_attn-1.0.0/csrc/flash_attn/src/fmha_fwd_hdim32.cu`

 * *Files 6% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 // Copyright (c) 2022, Tri Dao.
 
-// Splitting the different head dimentions to different files to speed up compilation.
+// Splitting the different head dimensions to different files to speed up compilation.
 
-#include "fmha_fprop_launch_template.h"
+#include "fmha_fwd_launch_template.h"
 
 void run_fmha_fwd_hdim32(Launch_params<FMHA_fprop_params> &launch_params) {
-    FP16_SWITCH(launch_params.params.is_bf16, [&] {
+    FP16_SWITCH(launch_params.params.is_bf16, ([&] {
         if (launch_params.params.seqlen_k == 128) {
             using Kernel_traits = FMHA_kernel_traits<128, 32, 16, 1, 4, 0x08u, elem_type>;
-            run_fmha_loop<Kernel_traits>(launch_params);
+            run_fmha_fwd_loop<Kernel_traits>(launch_params);
         } else if (launch_params.params.seqlen_k >= 256) {
             using Kernel_traits = FMHA_kernel_traits<256, 32, 16, 1, 4, 0x08u, elem_type>;
-            run_fmha_loop<Kernel_traits>(launch_params);
+            run_fmha_fwd_loop<Kernel_traits>(launch_params);
         }
-    });
+    }));
 }
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/src/fmha_fprop_hdim64.cu` & `flash_attn-1.0.0/csrc/flash_attn/src/fmha_fwd_hdim64.cu`

 * *Files 7% similar despite different names*

```diff
@@ -1,17 +1,17 @@
 // Copyright (c) 2022, Tri Dao.
 
-// Splitting the different head dimentions to different files to speed up compilation.
+// Splitting the different head dimensions to different files to speed up compilation.
 
-#include "fmha_fprop_launch_template.h"
+#include "fmha_fwd_launch_template.h"
 
 void run_fmha_fwd_hdim64(Launch_params<FMHA_fprop_params> &launch_params) {
-    FP16_SWITCH(launch_params.params.is_bf16, [&] {
+    FP16_SWITCH(launch_params.params.is_bf16, ([&] {
         if (launch_params.params.seqlen_k == 128) {
             using Kernel_traits = FMHA_kernel_traits<128, 64, 16, 1, 4, 0x08u, elem_type>;
-            run_fmha_loop<Kernel_traits>(launch_params);
+            run_fmha_fwd_loop<Kernel_traits>(launch_params);
         } else if (launch_params.params.seqlen_k >= 256) {
             using Kernel_traits = FMHA_kernel_traits<256, 64, 16, 1, 4, 0x08u, elem_type>;
-            run_fmha_loop<Kernel_traits>(launch_params);
+            run_fmha_fwd_loop<Kernel_traits>(launch_params);
         }
-    });
+    }));
 }
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/src/fmha_fprop_kernel_1xN.h` & `flash_attn-1.0.0/csrc/flash_attn/src/fmha_fprop_kernel_1xN.h`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/flash_attn/src/fmha_fprop_launch_template.h` & `flash_attn-1.0.0/csrc/flash_attn/src/fmha_fwd_launch_template.h`

 * *Files 4% similar despite different names*

```diff
@@ -4,15 +4,14 @@
 
 #include <vector>
 
 #include <cuda_fp16.h>
 #include <cuda_bf16.h>
 
 #include "static_switch.h"
-#include "fp16_switch.h"
 #include "fmha.h"
 #include "fmha_fprop_kernel_1xN.h"
 
 // Find the number of splits that maximizes the occupancy. For example, if we have
 // batch * n_heads = 48 and we have 108 SMs, having 2 splits (efficiency = 0.89) is
 // better than having 3 splits (efficiency = 0.67). However, we also don't want too many
 // splits as that would incur more HBM reads/writes.
@@ -36,39 +35,39 @@
             return num_splits;
         }
     }
     return 1;
 }
 
 template<typename Kernel_traits, bool Is_dropout, bool Is_causal, bool Return_softmax>
-__global__ void fmha_fprop_loop_kernel(FMHA_fprop_params params) {
+__global__ void fmha_fwd_loop_kernel(FMHA_fprop_params params) {
     fmha::device_1xN_loop<Kernel_traits, Is_dropout, Is_causal, Return_softmax>(params);
 }
 
 template<typename Kernel_traits>
-void run_fmha_loop(Launch_params<FMHA_fprop_params> &launch_params) {
+void run_fmha_fwd_loop(Launch_params<FMHA_fprop_params> &launch_params) {
     constexpr int blocksize_c = Kernel_traits::Cta_tile_p::N;
     const int loop_steps = (launch_params.params.seqlen_k + blocksize_c - 1) / blocksize_c;
 
     constexpr int smem_size_softmax_lse = Kernel_traits::Smem_dp_sum::BYTES_PER_TILE;
     // Don't need smem_size_softmax_lse if we're not looping
     const int smem_size = fmha::get_dynamic_smem_size<Kernel_traits>()
         + (loop_steps > 1 ? smem_size_softmax_lse : 0);
 
     // Work-around for gcc 7. It doesn't like nested BOOL_SWITCH.
     // https://github.com/kokkos/kokkos-kernels/issues/349
     // https://github.com/HazyResearch/flash-attention/issues/21
-    BOOL_SWITCH(launch_params.is_dropout, IsDropoutConst, [&] {
+    BOOL_SWITCH(launch_params.is_dropout, IsDropoutConst, ([&] {
         auto kernel = launch_params.params.is_causal
             ? (launch_params.return_softmax
-               ? &fmha_fprop_loop_kernel<Kernel_traits, IsDropoutConst, true, true>
-               : &fmha_fprop_loop_kernel<Kernel_traits, IsDropoutConst, true, false>)
+               ? &fmha_fwd_loop_kernel<Kernel_traits, IsDropoutConst, true, true>
+               : &fmha_fwd_loop_kernel<Kernel_traits, IsDropoutConst, true, false>)
             : (launch_params.return_softmax
-               ? &fmha_fprop_loop_kernel<Kernel_traits, IsDropoutConst, false, true>
-               : &fmha_fprop_loop_kernel<Kernel_traits, IsDropoutConst, false, false>);
+               ? &fmha_fwd_loop_kernel<Kernel_traits, IsDropoutConst, false, true>
+               : &fmha_fwd_loop_kernel<Kernel_traits, IsDropoutConst, false, false>);
         if( smem_size >= 48 * 1024 ) {
             FMHA_CHECK_CUDA(cudaFuncSetAttribute(
                 kernel, cudaFuncAttributeMaxDynamicSharedMemorySize, smem_size));
         }
         // Automatically set num_splits to maximize occupancy
         if (launch_params.params.num_splits <= 0) {
             int ctas_per_sm;
@@ -84,9 +83,9 @@
             );
         }
         // printf("smem_size = %d\n", smem_size);
         dim3 grid(launch_params.params.b, launch_params.params.h, launch_params.params.num_splits);
         kernel<<<grid, Kernel_traits::THREADS, smem_size, launch_params.stream>>>(
             launch_params.params);
         FMHA_CHECK_CUDA(cudaPeekAtLastError());
-    });
+    }));
 }
```

### Comparing `flash_attn-0.2.8/csrc/flash_attn/src/fmha_kernel.h` & `flash_attn-1.0.0/csrc/flash_attn/src/fmha_kernel.h`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/flash_attn/src/fmha_utils.h` & `flash_attn-1.0.0/csrc/flash_attn/src/fmha_utils.h`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/flash_attn/src/philox.cuh` & `flash_attn-1.0.0/csrc/flash_attn/src/philox.cuh`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/flash_attn/src/static_switch.h` & `flash_attn-1.0.0/csrc/flash_attn/src/static_switch.h`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/flash_gen/decoder_masked_multihead_attention.cu` & `flash_attn-1.0.0/csrc/flash_gen/decoder_masked_multihead_attention.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/flash_gen/decoder_masked_multihead_attention.h` & `flash_attn-1.0.0/csrc/ft_attention/decoder_masked_multihead_attention.h`

 * *Files 4% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+// Downloaded from from FasterTransformer v5.2.1
+// https://github.com/NVIDIA/FasterTransformer/blob/release/v5.2.1_tag/src/fastertransformer/kernels/decoder_masked_multihead_attention.h
 /*
  * Copyright (c) 2020-2022, NVIDIA CORPORATION.  All rights reserved.
  *
  * Licensed under the Apache License, Version 2.0 (the "License");
  * you may not use this file except in compliance with the License.
  * You may obtain a copy of the License at
  *
@@ -78,14 +80,16 @@
     // The number of heads (H).
     int num_heads = 0;
     // The hidden dimension per head (Dh).
     int hidden_size_per_head = 0;
     // The per-head latent space reserved for rotary embeddings.
     int  rotary_embedding_dim = 0;
     bool neox_rotary_style    = false;
+    // The maximum length of input sentences.
+    int max_input_length = 0;
     // The current timestep. TODO(bhsueh) Check that do we only this param in cross attention?
     int timestep = 0;
     // The current timestep of each sentences (support different timestep for different sentences)
 
     // The 1.f / sqrt(Dh). Computed on the host.
     float inv_sqrt_dh = 0.0f;
 
@@ -94,14 +98,24 @@
 
     const bool* masked_tokens            = nullptr;
     const int*  prefix_prompt_lengths    = nullptr;
     int         max_prefix_prompt_length = 0;
 
     const T* relative_attention_bias        = nullptr;
     int      relative_attention_bias_stride = 0;
+    // The slope per head of linear position bias to attention score (H).
+    const T* linear_bias_slopes = nullptr;
+
+    const T*   ia3_key_weights   = nullptr;
+    const T*   ia3_value_weights = nullptr;
+    const int* ia3_tasks         = nullptr;
+
+    const float* qkv_scale_out       = nullptr;
+    const float* attention_out_scale = nullptr;
+    int          int8_mode           = 0;
 };
 
 template<typename T, bool CROSS_ATTENTION>
 struct Multihead_attention_params: public Multihead_attention_params_base<T> {
     // output cross attentions
     float* cross_attention_out        = nullptr;
     int    max_decoder_seq_len        = 0;
```

### Comparing `flash_attn-0.2.8/csrc/flash_gen/decoder_masked_multihead_attention_utils.h` & `flash_attn-1.0.0/csrc/ft_attention/decoder_masked_multihead_attention_utils.h`

 * *Files 2% similar despite different names*

```diff
@@ -1,7 +1,9 @@
+// Downloaded from from FasterTransformer v5.2.1
+// https://github.com/NVIDIA/FasterTransformer/blob/release/v5.2.1_tag/src/fastertransformer/kernels/decoder_masked_multihead_attention_utils.h
 /*
  * Copyright (c) 2020-2022, NVIDIA CORPORATION.  All rights reserved.
  *
  * Licensed under the Apache License, Version 2.0 (the "License");
  * you may not use this file except in compliance with the License.
  * You may obtain a copy of the License at
  *
@@ -12,16 +14,16 @@
  * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
  * See the License for the specific language governing permissions and
  * limitations under the License.
  */
 
 #pragma once
 
-#include "bfloat16_fallback_kenrels.cuh"
 #include "cuda_bf16_wrapper.h"
+#include "cuda_bf16_fallbacks.cuh"
 #include <stdint.h>
 
 using namespace fastertransformer;
 
 namespace mmha {
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
@@ -56,14 +58,101 @@
     __nv_bfloat162 z;
     __nv_bfloat162 w;
 };
 #endif
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
+template<typename T>
+struct num_elems;
+template<>
+struct num_elems<float> {
+    static constexpr int value = 1;
+};
+template<>
+struct num_elems<float2> {
+    static constexpr int value = 2;
+};
+template<>
+struct num_elems<float4> {
+    static constexpr int value = 4;
+};
+template<>
+struct num_elems<Float4_> {
+    static constexpr int value = 4;
+};
+template<>
+struct num_elems<Float8_> {
+    static constexpr int value = 8;
+};
+
+template<>
+struct num_elems<uint32_t> {
+    static constexpr int value = 2;
+};
+template<>
+struct num_elems<uint2> {
+    static constexpr int value = 4;
+};
+template<>
+struct num_elems<uint4> {
+    static constexpr int value = 8;
+};
+
+#ifdef ENABLE_BF16
+template<>
+struct num_elems<__nv_bfloat162> {
+    static constexpr int value = 2;
+};
+template<>
+struct num_elems<bf16_4_t> {
+    static constexpr int value = 4;
+};
+template<>
+struct num_elems<bf16_8_t> {
+    static constexpr int value = 8;
+};
+#endif
+
+////////////////////////////////////////////////////////////////////////////////////////////////////
+
+template<typename T, int N>
+struct packed_type;
+template<typename T>
+struct packed_type<T, 1> {
+    using type = T;
+};
+template<>
+struct packed_type<int8_t, 2> {
+    using type = int16_t;
+};
+template<>
+struct packed_type<int8_t, 4> {
+    using type = int32_t;
+};
+template<>
+struct packed_type<int8_t, 8> {
+    using type = int64_t;
+};
+
+template<>
+struct packed_type<float, 2> {
+    using type = float2;
+};
+template<>
+struct packed_type<float, 4> {
+    using type = float4;
+};
+template<>
+struct packed_type<float, 8> {
+    using type = Float8_;
+};
+
+////////////////////////////////////////////////////////////////////////////////////////////////////
+
 inline __device__ float add(float a, float b)
 {
     return a + b;
 }
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
@@ -637,15 +726,18 @@
     fd.w = fma(s, b.w, fc.w);
     return fd;
 }
 #endif  // ENABLE_BF16
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 template<typename Acc, typename A, typename B>
-inline __device__ Acc mul(A a, B b);
+inline __device__ Acc mul(A a, B b)
+{
+    return a * b;
+}
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 template<>
 inline __device__ float mul<float, float>(float a, float b)
 {
     return a * b;
@@ -698,14 +790,27 @@
     c.w = a * b.w;
     return c;
 }
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 template<>
+inline __device__ Float8_ mul(float a, Float8_ b)
+{
+    Float8_ c;
+    c.x = make_float2(a * b.x.x, a * b.x.y);
+    c.y = make_float2(a * b.y.x, a * b.y.y);
+    c.z = make_float2(a * b.z.x, a * b.z.y);
+    c.w = make_float2(a * b.w.x, a * b.w.y);
+    return c;
+}
+
+////////////////////////////////////////////////////////////////////////////////////////////////////
+
+template<>
 inline __device__ uint16_t mul(uint16_t a, uint16_t b)
 {
     uint16_t c;
     asm volatile("mul.f16 %0, %1, %2;\n" : "=h"(c) : "h"(a), "h"(b));
     return c;
 }
 
@@ -786,14 +891,22 @@
     float fb = half_to_float(b);
     return fa * fb;
 }
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 template<>
+inline __device__ float mul(uint16_t a, float b)
+{
+    return half_to_float(a) * b;
+}
+
+////////////////////////////////////////////////////////////////////////////////////////////////////
+
+template<>
 inline __device__ float2 mul(uint32_t a, uint32_t b)
 {
     float2 fa = half2_to_float2(a);
     float2 fb = half2_to_float2(b);
     return mul<float2, float2, float2>(fa, fb);
 }
 
@@ -943,14 +1056,22 @@
     float fb = (float)b;
     return fa * fb;
 }
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 template<>
+inline __device__ float mul(__nv_bfloat16 a, float b)
+{
+    return __bfloat162float(a) * b;
+}
+
+////////////////////////////////////////////////////////////////////////////////////////////////////
+
+template<>
 inline __device__ float2 mul(__nv_bfloat162 a, __nv_bfloat162 b)
 {
     float2 fa = bf1622float2(a);
     float2 fb = bf1622float2(b);
     return mul<float2, float2, float2>(fa, fb);
 }
 
@@ -1544,30 +1665,14 @@
 
 template<>
 __device__ __inline__ void write_smem_transpose(const float& vec, float* smem, int transpose_idx, int smem_pitch)
 {
     return;
 }
 
-#ifdef ENABLE_BF16
-template<>
-__device__ __inline__ void
-write_smem_transpose(const bf16_4_t& vec, __nv_bfloat16* smem, int transpose_idx, int smem_pitch)
-{
-    return;
-}
-
-template<>
-__device__ __inline__ void
-write_smem_transpose(const bf16_8_t& vec, __nv_bfloat16* smem, int transpose_idx, int smem_pitch)
-{
-    return;
-}
-#endif
-
 template<>
 __device__ __inline__ void write_smem_transpose(const uint4& vec, uint16_t* smem, int transpose_idx, int smem_pitch)
 {
     union {
         uint64_t u64;
         uint16_t u16[4];
     } tmp_1, tmp_2;
@@ -1651,14 +1756,28 @@
 template<>
 __device__ __inline__ void
 write_smem_transpose(const __nv_bfloat162& vec, __nv_bfloat16* smem, int transpose_idx, int smem_pitch)
 {
     smem[transpose_idx]              = vec.x;
     smem[smem_pitch + transpose_idx] = vec.y;
 }
+
+template<>
+__device__ __inline__ void
+write_smem_transpose(const bf16_4_t& vec, __nv_bfloat16* smem, int transpose_idx, int smem_pitch)
+{
+    write_smem_transpose(reinterpret_cast<const uint2&>(vec), reinterpret_cast<uint16_t*>(smem), transpose_idx, smem_pitch);
+}
+
+template<>
+__device__ __inline__ void
+write_smem_transpose(const bf16_8_t& vec, __nv_bfloat16* smem, int transpose_idx, int smem_pitch)
+{
+    write_smem_transpose(reinterpret_cast<const uint4&>(vec), reinterpret_cast<uint16_t*>(smem), transpose_idx, smem_pitch);
+}
 #endif
 
 template<>
 __device__ __inline__ void write_smem_transpose(const float2& vec, float* smem, int transpose_idx, int smem_pitch)
 {
     smem[transpose_idx]              = vec.x;
     smem[smem_pitch + transpose_idx] = vec.y;
```

### Comparing `flash_attn-0.2.8/csrc/ft_attention/bfloat16_fallback.cuh` & `flash_attn-1.0.0/csrc/ft_attention/cuda_bf16_fallbacks.cuh`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/ft_attention/cuda_bf16_wrapper.h` & `flash_attn-1.0.0/csrc/ft_attention/cuda_bf16_wrapper.h`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/ft_attention/decoder_masked_multihead_attention.cu` & `flash_attn-1.0.0/csrc/ft_attention/decoder_masked_multihead_attention.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/ft_attention/ft_attention.cpp` & `flash_attn-1.0.0/csrc/ft_attention/ft_attention.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/fused_dense_lib/fused_dense.cpp` & `flash_attn-1.0.0/csrc/fused_dense_lib/fused_dense.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/fused_dense_lib/fused_dense_cuda.cu` & `flash_attn-1.0.0/csrc/fused_dense_lib/fused_dense_cuda.cu`

 * *Files 0% similar despite different names*

```diff
@@ -118,15 +118,17 @@
   float beta = 0.0;
   cudaDataType_t abcType = std::is_same<Dtype, at::Half>::value ? CUDA_R_16F : CUDA_R_16BF;
 
   cublasLtHandle_t ltHandle =
     reinterpret_cast<cublasLtHandle_t>(at::cuda::getCurrentCUDABlasHandle());
   // See https://github.com/pytorch/pytorch/issues/73328 for reasoning behind
   // setting this to 1M.
-  size_t workspaceSize = 1024 * 1024;
+  // However, Apex sets it to 4M and TransformerEngine sets to 32M for Hopper and 4M for other GPUs
+  // https://github.com/NVIDIA/TransformerEngine/blob/a0f0065498bbcfc1da78cf9e8b166f5381613fbc/transformer_engine/pytorch/module.py#L91
+  size_t workspaceSize = 1024 * 1024 * (at::cuda::getCurrentDeviceProperties()->major >= 9 ? 32 : 4);
   void* workspace = at::empty(
     {static_cast<int64_t>(workspaceSize)},
     at::device({at::kCUDA, at::cuda::current_device()}).dtype(at::kByte)).data_ptr();
 
   cublasStatus_t status = CUBLAS_STATUS_SUCCESS;
 
   cublasLtMatmulDescOpaque_t operationDesc = {};
@@ -292,15 +294,16 @@
   float beta = 0.0;
   cudaDataType_t abcType = std::is_same<Dtype, at::Half>::value ? CUDA_R_16F : CUDA_R_16BF;
 
   cublasLtHandle_t ltHandle =
     reinterpret_cast<cublasLtHandle_t>(at::cuda::getCurrentCUDABlasHandle());
   // See https://github.com/pytorch/pytorch/issues/73328 for reasoning behind
   // setting this to 1M.
-  size_t workspaceSize = 1024 * 1024;
+  // However, Apex sets it to 4M and TransformerEngine sets to 32M for Hopper and 4M for other GPUs
+  size_t workspaceSize = 1024 * 1024 * (at::cuda::getCurrentDeviceProperties()->major >= 9 ? 32 : 4);
   void* workspace = at::empty(
     {static_cast<int64_t>(workspaceSize)},
     at::device({at::kCUDA, at::cuda::current_device()}).dtype(at::kByte)).data_ptr();
 
   cublasStatus_t status = CUBLAS_STATUS_SUCCESS;
 
   cublasLtMatmulDescOpaque_t operationDesc = {};
@@ -445,15 +448,16 @@
   float beta = 0.0;
   cudaDataType_t abcType = std::is_same<Dtype, at::Half>::value ? CUDA_R_16F : CUDA_R_16BF;
 
   cublasLtHandle_t ltHandle =
     reinterpret_cast<cublasLtHandle_t>(at::cuda::getCurrentCUDABlasHandle());
   // See https://github.com/pytorch/pytorch/issues/73328 for reasoning behind
   // setting this to 1M.
-  size_t workspaceSize = 1024 * 1024;
+  // However, Apex sets it to 4M and TransformerEngine sets to 32M for Hopper and 4M for other GPUs
+  size_t workspaceSize = 1024 * 1024 * (at::cuda::getCurrentDeviceProperties()->major >= 9 ? 32 : 4);
   void* workspace = at::empty(
     {static_cast<int64_t>(workspaceSize)},
     at::device({at::kCUDA, at::cuda::current_device()}).dtype(at::kByte)).data_ptr();
 
   cublasStatus_t status = CUBLAS_STATUS_SUCCESS;
 
   cublasLtMatmulDescOpaque_t operationDesc = {};
```

### Comparing `flash_attn-0.2.8/csrc/fused_softmax/fused_softmax.cpp` & `flash_attn-1.0.0/csrc/fused_softmax/fused_softmax.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/fused_softmax/scaled_masked_softmax.h` & `flash_attn-1.0.0/csrc/fused_softmax/scaled_masked_softmax.h`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/fused_softmax/scaled_masked_softmax_cuda.cu` & `flash_attn-1.0.0/csrc/fused_softmax/scaled_masked_softmax_cuda.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/fused_softmax/scaled_upper_triang_masked_softmax.h` & `flash_attn-1.0.0/csrc/fused_softmax/scaled_upper_triang_masked_softmax.h`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/fused_softmax/scaled_upper_triang_masked_softmax_cuda.cu` & `flash_attn-1.0.0/csrc/fused_softmax/scaled_upper_triang_masked_softmax_cuda.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/fused_softmax/type_shim.h` & `flash_attn-1.0.0/csrc/fused_softmax/type_shim.h`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/layer_norm/ln.h` & `flash_attn-1.0.0/csrc/layer_norm/ln.h`

 * *Files 14% similar despite different names*

```diff
@@ -10,15 +10,15 @@
 #include <ATen/cuda/CUDAGeneratorImpl.h>
 #endif
 
 namespace layer_norm {
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
-template<typename Params> 
+template<typename Params>
 struct LaunchParams{
 
     size_t elts_per_thread;
     size_t workspace_bytes;
     size_t barrier_size;
 
     cudaDeviceProp * props;
@@ -36,14 +36,15 @@
         : ctas_per_col(0)
         , rows(0)
         , cols(0)
         , x(nullptr)
         , mu(nullptr)
         , rs(nullptr)
         , gamma(nullptr)
+        , gamma1(nullptr)
         , rowscale(nullptr)
         , colscale(nullptr)
         , dropout_keep_p(1.f)
         , dropout_scale(1.f)
         , is_rms_norm(false)
         , workspace(nullptr)
         , barrier(nullptr)
@@ -55,20 +56,23 @@
 
     // Input is interpreted as matrix. We normalize across columns.
     int rows;
     int cols;
 
     // Common data pointers.
     void *x0;
+    void *x1;
     void *residual;
     void *x;
     void *dmask;
+    void *dmask1;
     void *mu;
     void *rs;
     void *gamma;
+    void *gamma1;
     void *rowscale;
     void *colscale;
     void *x0_subset;
     void *z_subset;
 
     float inverse_cols;
 
@@ -88,76 +92,92 @@
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 struct FwdParams : public ParamsBase {
     FwdParams()
         : ParamsBase()
         , z(nullptr)
+        , z1(nullptr)
         , beta(nullptr)
+        , beta1(nullptr)
         , epsilon(0.f)
     {
     }
 
     // Output of LN FWD.
     void *z;
+    void *z1;
     void *beta;
+    void *beta1;
     float epsilon;
 
     // Random state.
     at::PhiloxCudaState philox_args;
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 struct BwdParams : public ParamsBase {
     BwdParams()
         : ParamsBase()
         , dz(nullptr)
+        , dz1(nullptr)
         , dx(nullptr)
         , dbeta_part(nullptr)
         , dgamma_part(nullptr)
+        , dbeta1_part(nullptr)
+        , dgamma1_part(nullptr)
         , dcolscale_part(nullptr)
         , dx0(nullptr)
+        , dx1(nullptr)
         , dresidual(nullptr)
         , dbeta(nullptr)
         , dgamma(nullptr)
+        , dbeta1(nullptr)
+        , dgamma1(nullptr)
         , dcolscale(nullptr)
     {
     }
 
     // Input: gradient wrt. LN FWD output.
     void *dz;
+    void *dz1;
     // Input: gradient wrt residual.
     void *dx;
 
     // Workspace for Wgrad pre-reduction.
     void *dbeta_part;
     void *dgamma_part;
+    void *dbeta1_part;
+    void *dgamma1_part;
     void *dcolscale_part;
 
     // Output: Dgrad.
     void *dx0;
+    void *dx1;
     void *dresidual;
     // Output: Wgrad.
     void *dbeta;
     void *dgamma;
+    void *dbeta1;
+    void *dgamma1;
     void *dcolscale;
 
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 using FwdFunction = std::function<void(LaunchParams<FwdParams>&, const bool)>;
 using BwdFunction = std::function<void(LaunchParams<BwdParams>&, const bool)>;
 using FunctionKey = uint64_t;
 using FwdRegistry = std::unordered_map<FunctionKey, FwdFunction>;
 using BwdRegistry = std::unordered_map<FunctionKey, BwdFunction>;
 
-extern FwdRegistry FWD_FUNCS;
-extern BwdRegistry BWD_FUNCS;
+extern FwdRegistry FWD_FUNCS, PARALLEL_FWD_FUNCS;
+extern BwdRegistry BWD_FUNCS, PARALLEL_BWD_FUNCS;
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 using fp32 = float;
 using fp16 = half;
 using bf16 = nv_bfloat16;
 
@@ -234,8 +254,28 @@
         uint64_t key = Types2Key<W,I,R,O,C>::get(HIDDEN_SIZE);
         BWD_FUNCS.insert({ key, f });
     }
 };
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
+template<typename W, typename I, typename R, typename O, typename C, uint64_t HIDDEN_SIZE>
+struct FwdParallelRegistrar{
+    FwdParallelRegistrar(FwdFunction f){
+        uint64_t key = Types2Key<W,I,R,O,C>::get(HIDDEN_SIZE);
+        PARALLEL_FWD_FUNCS.insert({ key, f });
+    }
+};
+
+////////////////////////////////////////////////////////////////////////////////////////////////////
+
+template<typename W, typename I, typename R, typename O, typename C, uint64_t HIDDEN_SIZE>
+struct BwdParallelRegistrar{
+    BwdParallelRegistrar(BwdFunction f){
+        uint64_t key = Types2Key<W,I,R,O,C>::get(HIDDEN_SIZE);
+        PARALLEL_BWD_FUNCS.insert({ key, f });
+    }
+};
+
+////////////////////////////////////////////////////////////////////////////////////////////////////
+
 }  // namespace layer_norm
```

### Comparing `flash_attn-0.2.8/csrc/layer_norm/ln_api.cpp` & `flash_attn-1.0.0/csrc/layer_norm/ln_api.cpp`

 * *Files 24% similar despite different names*

```diff
@@ -24,16 +24,16 @@
 
 */
 
 namespace layer_norm {
 
 // Create registries and provide runtime versions of config hash functions.
 
-FwdRegistry FWD_FUNCS;
-BwdRegistry BWD_FUNCS;
+FwdRegistry FWD_FUNCS, PARALLEL_FWD_FUNCS;
+BwdRegistry BWD_FUNCS, PARALLEL_BWD_FUNCS;
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 uint32_t get_type_id(torch::Dtype dtype){
     if( dtype == torch::kFloat16 ) {
         return TypeId<fp16>::Value;
     } else if( dtype == torch::kBFloat16 ) {
@@ -76,14 +76,36 @@
     } else {
         TORCH_CHECK(false, "BWD: Unsupported hidden_size or types: ", hidden_size, wtype, itype, rtype, otype, ctype);
     }
 }
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
+layer_norm::FwdFunction & get_parallel_fwd_launcher(torch::Dtype wtype, torch::Dtype itype, torch::Dtype rtype, torch::Dtype otype, torch::Dtype ctype, uint32_t hidden_size) {
+    auto iter = layer_norm::PARALLEL_FWD_FUNCS.find(layer_norm::get_key(wtype, itype, rtype, otype, ctype, hidden_size));
+    if( iter != layer_norm::PARALLEL_FWD_FUNCS.end() ) {
+        return iter->second;
+    } else {
+        TORCH_CHECK(false, "FWD: Unsupported hidden_size or types: ", hidden_size, wtype, itype, rtype, otype, ctype);
+    }
+}
+
+////////////////////////////////////////////////////////////////////////////////////////////////////
+
+layer_norm::BwdFunction & get_parallel_bwd_launcher(torch::Dtype wtype, torch::Dtype itype, torch::Dtype rtype, torch::Dtype otype, torch::Dtype ctype, uint32_t hidden_size) {
+    auto iter = layer_norm::PARALLEL_BWD_FUNCS.find(layer_norm::get_key(wtype, itype, rtype, otype, ctype, hidden_size));
+    if( iter != layer_norm::PARALLEL_BWD_FUNCS.end() ) {
+        return iter->second;
+    } else {
+        TORCH_CHECK(false, "BWD: Unsupported hidden_size or types: ", hidden_size, wtype, itype, rtype, otype, ctype);
+    }
+}
+
+////////////////////////////////////////////////////////////////////////////////////////////////////
+
 std::vector<at::Tensor> dropout_add_ln_fwd(const at::Tensor &x0,      // Input: BxSxhidden_size
                                            c10::optional<const at::Tensor> &residual_,  // Residual: BxSxhidden_size
                                            const at::Tensor &gamma,   // hidden_size
                                            c10::optional<const at::Tensor> &beta_,   // hidden_size
                                            c10::optional<const at::Tensor> &rowscale_,      // BxS
                                            c10::optional<const at::Tensor> &colscale_,      // hidden_size
                                            c10::optional<const at::Tensor> &x0_subset_,      // BxS
@@ -101,79 +123,78 @@
         ? residual_.value().scalar_type()
         : (residual_in_fp32 ? torch::kFloat32 : x0.scalar_type());
     auto wtype = gamma.scalar_type();
     auto otype = itype;
     auto ctype = torch::kFloat32;
     auto mtype = torch::kUInt8;
 
-    TORCH_CHECK(x0.is_cuda())
-    TORCH_CHECK(gamma.is_cuda())
+    TORCH_CHECK(x0.is_cuda());
+    TORCH_CHECK(gamma.is_cuda());
 
     TORCH_CHECK(x0.is_contiguous());
     // c10::IntArrayRef does not own the storage, so we need to construct a vector.
     // Otherwise just constructing IntArrayRef({blah}) will cause unintialized memory because
     // blah is then deallocated.
     std::vector<int64_t> sizes_vec {!x0_subset_.has_value() ? x0.size(0) : x0_subset_.value().size(0), x0.size(1)};
     auto sizes = c10::IntArrayRef(sizes_vec);
     TORCH_CHECK(x0.dim() == 2);
     TORCH_CHECK(sizes.size() == 2);
 
     const int rows = sizes[0];
     const int cols = sizes[1];
     auto hidden_size = gamma.numel();
+    TORCH_CHECK(hidden_size == cols);
 
     if (beta_.has_value()) {
         auto beta = beta_.value();
         TORCH_CHECK(beta.dtype() == wtype);
-        TORCH_CHECK(beta.is_cuda())
+        TORCH_CHECK(beta.is_cuda());
         TORCH_CHECK(beta.is_contiguous());
-        TORCH_CHECK(gamma.sizes() == beta.sizes());
+        TORCH_CHECK(beta.sizes() == gamma.sizes());
     }
 
     if (residual_.has_value()) {
         auto residual = residual_.value();
-        TORCH_CHECK(residual.is_cuda())
+        TORCH_CHECK(residual.is_cuda());
         TORCH_CHECK(residual.is_contiguous());
         TORCH_CHECK(residual.sizes() == sizes);
     }
 
     if (rowscale_.has_value()) {
         auto rowscale = rowscale_.value();
-        TORCH_CHECK(rowscale.is_cuda())
+        TORCH_CHECK(rowscale.is_cuda());
         TORCH_CHECK(rowscale.is_contiguous());
         TORCH_CHECK(rowscale.sizes() == c10::IntArrayRef{rows});
         TORCH_CHECK(rowscale.dtype() == itype);
     }
 
     if (colscale_.has_value()) {
         auto colscale = colscale_.value();
-        TORCH_CHECK(colscale.is_cuda())
+        TORCH_CHECK(colscale.is_cuda());
         TORCH_CHECK(colscale.is_contiguous());
         TORCH_CHECK(colscale.sizes() == c10::IntArrayRef{cols});
         TORCH_CHECK(colscale.dtype() == wtype);
     }
 
     if (x0_subset_.has_value()) {
         auto x0_subset = x0_subset_.value();
-        TORCH_CHECK(x0_subset.is_cuda())
+        TORCH_CHECK(x0_subset.is_cuda());
         TORCH_CHECK(x0_subset.is_contiguous());
         TORCH_CHECK(x0_subset.sizes() == c10::IntArrayRef{rows});
         TORCH_CHECK(x0_subset.dtype() == torch::kInt32);
 
         TORCH_CHECK(z_subset_.has_value());
         auto z_subset = z_subset_.value();
         TORCH_CHECK(z_subset.is_cuda());
         TORCH_CHECK(z_subset.is_contiguous());
         TORCH_CHECK(z_subset.sizes() == c10::IntArrayRef{rows});
         TORCH_CHECK(z_subset.dtype() == torch::kInt32);
     }
 
-    TORCH_CHECK(hidden_size == cols);
-    TORCH_CHECK((hidden_size % 8 == 0) && (hidden_size <= 6144));
-
+    TORCH_CHECK((hidden_size % 8 == 0) && (hidden_size <= 8192));
     TORCH_CHECK(epsilon >= 0.f);
 
     // Otherwise the kernel will be launched from cuda:0 device
     // Cast to char to avoid compiler warning about narrowing
     at::cuda::CUDAGuard device_guard{(char)x0.get_device()};
 
     auto opts = x0.options();
@@ -302,78 +323,78 @@
 
     auto sizes = x.sizes();
     TORCH_CHECK(sizes.size() == 2);
     auto rows = sizes[0];
     auto cols = sizes[1];
     TORCH_CHECK(dz.dim() == 2);
     TORCH_CHECK(dz.size(1) == cols);
+    auto hidden_size = gamma.numel();
+    TORCH_CHECK(hidden_size == cols);
 
     // c10::IntArrayRef does not own the storage, so we need to construct a vector.
     // Otherwise just constructing IntArrayRef({blah}) will cause unintialized memory because
     // blah is then deallocated.
     std::vector<int64_t> x0_sizes_vec {!x0_subset_.has_value() ? rows : x0_numrows, cols};
     auto x0_sizes = c10::IntArrayRef(x0_sizes_vec);
 
     if (dx_.has_value()) {
         auto dx = dx_.value();
         TORCH_CHECK(dx.dtype() == rtype);
-        TORCH_CHECK(dx.is_cuda())
+        TORCH_CHECK(dx.is_cuda());
         TORCH_CHECK(dx.is_contiguous());
         TORCH_CHECK(dx.sizes() == sizes);
     }
 
     if (dmask_.has_value()) {
         auto dmask = dmask_.value();
         TORCH_CHECK(dmask.dtype() == mtype);
         TORCH_CHECK(dmask.is_cuda());
         TORCH_CHECK(dmask.is_contiguous());
         TORCH_CHECK(dmask.sizes() == x0_sizes);
     }
 
     if (rowscale_.has_value()) {
         auto rowscale = rowscale_.value();
-        TORCH_CHECK(rowscale.is_cuda())
+        TORCH_CHECK(rowscale.is_cuda());
         TORCH_CHECK(rowscale.is_contiguous());
         TORCH_CHECK(rowscale.sizes() == c10::IntArrayRef{rows});
         TORCH_CHECK(rowscale.dtype() == itype);
     }
 
     if (colscale_.has_value()) {
         auto colscale = colscale_.value();
-        TORCH_CHECK(colscale.is_cuda())
+        TORCH_CHECK(colscale.is_cuda());
         TORCH_CHECK(colscale.is_contiguous());
         TORCH_CHECK(colscale.sizes() == c10::IntArrayRef{cols});
         TORCH_CHECK(colscale.dtype() == wtype);
 
         TORCH_CHECK(x0_.has_value());
         auto x0 = x0_.value();
-        TORCH_CHECK(x0.is_cuda())
+        TORCH_CHECK(x0.is_cuda());
         TORCH_CHECK(x0.is_contiguous());
         TORCH_CHECK(x0.sizes() == x0_sizes);
         TORCH_CHECK(x0.dtype() == itype);
     }
 
     if (x0_subset_.has_value()) {
         auto x0_subset = x0_subset_.value();
-        TORCH_CHECK(x0_subset.is_cuda())
+        TORCH_CHECK(x0_subset.is_cuda());
         TORCH_CHECK(x0_subset.is_contiguous());
         TORCH_CHECK(x0_subset.sizes() == c10::IntArrayRef{rows});
         TORCH_CHECK(x0_subset.dtype() == torch::kInt32);
 
         TORCH_CHECK(z_subset_.has_value());
         auto z_subset = z_subset_.value();
         TORCH_CHECK(z_subset.is_cuda());
         TORCH_CHECK(z_subset.is_contiguous());
         TORCH_CHECK(z_subset.sizes() == c10::IntArrayRef{rows});
         TORCH_CHECK(z_subset.dtype() == torch::kInt32);
     }
 
-    auto hidden_size = gamma.numel();
-    TORCH_CHECK(hidden_size == cols);
-    TORCH_CHECK((hidden_size % 8 == 0) && (hidden_size <= 6144));
+    TORCH_CHECK((hidden_size % 8 == 0) && (hidden_size <= 8192));
 
     TORCH_CHECK(mu.numel() == rows);
     TORCH_CHECK(mu.sizes() == rsigma.sizes());
 
     TORCH_CHECK(gamma.numel() == cols);
 
     // Otherwise the kernel will be launched from cuda:0 device
@@ -453,22 +474,377 @@
     std::vector<at::Tensor> result = { dx0, dresidual, dgamma, dbeta, dgamma_part, dbeta_part };
     if (colscale_.has_value()) {
         result.push_back(dcolscale);
         result.push_back(dcolscale_part);
     }
     return result;
 }
+
+////////////////////////////////////////////////////////////////////////////////////////////////////
+
+std::vector<at::Tensor> dropout_add_ln_parallel_residual_fwd(
+    const at::Tensor &x0,      // Input: BxSxhidden_size
+    c10::optional<const at::Tensor> &x1_,      // Input: BxSxhidden_size
+    c10::optional<const at::Tensor> &residual_,  // Residual: BxSxhidden_size
+    const at::Tensor &gamma0,   // hidden_size
+    c10::optional<const at::Tensor> &beta0_,   // hidden_size
+    c10::optional<const at::Tensor> &gamma1_,   // hidden_size
+    c10::optional<const at::Tensor> &beta1_,   // hidden_size
+    const float dropout_p,
+    const float epsilon,
+    c10::optional<at::Generator> gen_,
+    bool residual_in_fp32=false,
+    bool is_rms_norm=false
+) {
+    auto itype = x0.scalar_type();
+    auto rtype = residual_.has_value()
+        ? residual_.value().scalar_type()
+        : (residual_in_fp32 ? torch::kFloat32 : x0.scalar_type());
+    auto wtype = gamma0.scalar_type();
+    auto otype = itype;
+    auto ctype = torch::kFloat32;
+    auto mtype = torch::kUInt8;
+
+    TORCH_CHECK(x0.is_cuda());
+    TORCH_CHECK(gamma0.is_cuda());
+
+    TORCH_CHECK(x0.is_contiguous());
+    const auto sizes = x0.sizes();
+    TORCH_CHECK(x0.dim() == 2);
+
+    const int rows = sizes[0];
+    const int cols = sizes[1];
+    auto hidden_size = gamma0.numel();
+    TORCH_CHECK(hidden_size == cols);
+
+    if (x1_.has_value()) {
+        auto x1 = x1_.value();
+        TORCH_CHECK(x1.is_cuda());
+        TORCH_CHECK(x1.is_contiguous());
+        TORCH_CHECK(x1.sizes() == sizes);
+    }
+
+    if (residual_.has_value()) {
+        auto residual = residual_.value();
+        TORCH_CHECK(residual.is_cuda());
+        TORCH_CHECK(residual.is_contiguous());
+        TORCH_CHECK(residual.sizes() == sizes);
+    }
+
+    if (beta0_.has_value()) {
+        auto beta0 = beta0_.value();
+        TORCH_CHECK(beta0.dtype() == wtype);
+        TORCH_CHECK(beta0.is_cuda());
+        TORCH_CHECK(beta0.is_contiguous());
+        TORCH_CHECK(beta0.sizes() == gamma0.sizes());
+    }
+
+    if (gamma1_.has_value()) {
+        auto gamma1 = gamma1_.value();
+        TORCH_CHECK(gamma1.dtype() == wtype);
+        TORCH_CHECK(gamma1.is_cuda());
+        TORCH_CHECK(gamma1.is_contiguous());
+        TORCH_CHECK(gamma1.sizes() == gamma0.sizes());
+    }
+
+    if (beta1_.has_value()) {
+        auto beta1 = beta1_.value();
+        TORCH_CHECK(beta1.dtype() == wtype);
+        TORCH_CHECK(beta1.is_cuda());
+        TORCH_CHECK(beta1.is_contiguous());
+        TORCH_CHECK(beta1.sizes() == gamma0.sizes());
+    }
+
+    TORCH_CHECK((hidden_size % 8 == 0) && (hidden_size <= 8192));
+    TORCH_CHECK(epsilon >= 0.f);
+
+    // Otherwise the kernel will be launched from cuda:0 device
+    // Cast to char to avoid compiler warning about narrowing
+    at::cuda::CUDAGuard device_guard{(char)x0.get_device()};
+
+    auto opts = x0.options();
+
+    bool save_x = residual_.has_value() || x1_.has_value() || (dropout_p > 0.f) || (itype != rtype);
+    at::Tensor x;
+    if (save_x) { x = torch::empty(sizes, opts.dtype(rtype)); }
+    at::Tensor dmask0, dmask1;
+    if (dropout_p > 0.f) {
+        dmask0 = torch::empty(x0.sizes(), opts.dtype(mtype));
+        if (x1_.has_value()) { dmask1 = torch::empty(x0.sizes(), opts.dtype(mtype)); }
+    };
+    auto z0 = torch::empty(sizes, opts.dtype(otype));
+    at::Tensor z1;
+    if (gamma1_.has_value()) { z1 = torch::empty(sizes, opts.dtype(otype)); }
+
+    auto mu = torch::empty({ rows }, opts.dtype(ctype));
+    auto rsigma = torch::empty({ rows }, opts.dtype(ctype));
+
+    layer_norm::LaunchParams<layer_norm::FwdParams> launch_params;
+
+    launch_params.props = at::cuda::getCurrentDeviceProperties();
+    launch_params.stream = at::cuda::getCurrentCUDAStream().stream();
+    TORCH_CHECK(dropout_p < 1.f);
+    launch_params.params.dropout_keep_p = 1.f - dropout_p;
+    launch_params.params.residual = residual_.has_value() ? residual_.value().data_ptr() : nullptr;
+
+    auto gen = at::get_generator_or_default<at::CUDAGeneratorImpl>(
+        gen_, at::cuda::detail::getDefaultCUDAGenerator());
+
+    auto round_multiple = [](int x, int m) { return (x + m - 1) / m * m; };
+    const int multiple = hidden_size <= 1536 ? 256 : (hidden_size <= 3072 ? 512 : 1024);
+    // Request the kernel launcher.
+    auto launcher = get_parallel_fwd_launcher(wtype, itype, rtype, otype, ctype, round_multiple(hidden_size, multiple));
+
+    // Query the kernel-specific launch parameters.
+    launcher(launch_params, true);
+
+    at::Tensor workspace, barrier;
+
+    // Set the kernel runtime parameters.
+    layer_norm::FwdParams &params = launch_params.params;
+    params.rows = rows;
+    params.cols = cols;
+    params.x0 = x0.data_ptr();
+    params.x1 = x1_.has_value() ? x1_.value().data_ptr() : nullptr;
+    params.x = save_x ? x.data_ptr() : nullptr;
+    params.dmask = dropout_p > 0.f ? dmask0.data_ptr() : nullptr;
+    params.dmask1 = (dropout_p > 0.f && x1_.has_value()) ? dmask1.data_ptr() : nullptr;
+    params.mu = mu.data_ptr();
+    params.rs = rsigma.data_ptr();
+    params.gamma = gamma0.data_ptr();
+    params.gamma1 = gamma1_.has_value() ? gamma1_.value().data_ptr() : nullptr;
+    params.beta = beta0_.has_value() ? beta0_.value().data_ptr() : nullptr;
+    params.beta1 = beta1_.has_value() ? beta1_.value().data_ptr() : nullptr;
+    params.z = z0.data_ptr();
+    params.z1 = gamma1_.has_value() ? z1.data_ptr() : nullptr;
+    params.epsilon = epsilon;
+    params.dropout_scale = 1.f / (1.f - dropout_p);
+    params.inverse_cols = 1.f / float(params.cols);
+    params.is_rms_norm = is_rms_norm;
+
+    if (dropout_p > 0.f) {
+        // number of times random will be generated per thread, to offset philox counter in thc random
+        // state
+        int64_t counter_offset = 2 * launch_params.elts_per_thread;
+
+        // See Note [Acquire lock when using random generators]
+        {
+            std::lock_guard<std::mutex> lock(gen->mutex_);
+            params.philox_args = gen->philox_cuda_state(counter_offset);
+        }
+    }
+
+    if( launch_params.barrier_size > 0 ) {
+        auto options = x0.options();
+        barrier = torch::zeros(launch_params.barrier_size, options.dtype(torch::kInt32));
+        workspace = torch::empty(launch_params.workspace_bytes, options.dtype(torch::kChar));
+        params.workspace = workspace.data_ptr();
+        params.barrier = barrier.data_ptr<int>();
+    }
+
+    // Launch the kernel.
+    launcher(launch_params, false);
+
+    return { z0, z1, x, dmask0, dmask1, mu, rsigma };
+}
+
+////////////////////////////////////////////////////////////////////////////////////////////////////
+
+std::vector<at::Tensor> dropout_add_ln_parallel_residual_bwd(
+    const at::Tensor &dz0,     // BxSxhidden_size
+    c10::optional<const at::Tensor> &dz1_,     // BxSxhidden_size
+    c10::optional<const at::Tensor> &dx_,     // BxSxhidden_size
+    const at::Tensor &x,      // BxSxhidden_size
+    c10::optional<const at::Tensor> &dmask0_,  // BxSxhidden_size
+    c10::optional<const at::Tensor> &dmask1_,  // BxSxhidden_size
+    const at::Tensor &mu,     // BxS, FP32!
+    const at::Tensor &rsigma, // BxS, FP32!
+    const at::Tensor &gamma0,   // hidden_size
+    c10::optional<const at::Tensor> &gamma1_,   // hidden_size
+    const float dropout_p,
+    const bool has_x1,
+    const bool has_residual,
+    bool is_rms_norm=false
+) {
+
+    auto itype = dz0.scalar_type();
+    auto rtype = x.scalar_type();
+    auto wtype = gamma0.scalar_type();
+    auto otype = itype;
+    auto ctype = torch::kFloat32;
+    auto mtype = torch::kUInt8;
+
+    if (dropout_p > 0.f) { TORCH_CHECK(dmask0_.has_value()); }
+
+    TORCH_CHECK(dz0.dtype() == otype);
+    TORCH_CHECK(dz0.dtype() == otype);
+    TORCH_CHECK(mu.dtype() == ctype);
+    TORCH_CHECK(rsigma.dtype() == ctype);
+
+    TORCH_CHECK(x.is_cuda());
+    TORCH_CHECK(dz0.is_cuda());
+    TORCH_CHECK(mu.is_cuda());
+    TORCH_CHECK(rsigma.is_cuda());
+    TORCH_CHECK(gamma0.is_cuda());
+
+    TORCH_CHECK(x.is_contiguous());
+    TORCH_CHECK(dz0.is_contiguous());
+
+    auto sizes = x.sizes();
+    TORCH_CHECK(sizes.size() == 2);
+    auto rows = sizes[0];
+    auto cols = sizes[1];
+    TORCH_CHECK(dz0.dim() == 2);
+    TORCH_CHECK(dz0.size(1) == cols);
+    auto hidden_size = gamma0.numel();
+    TORCH_CHECK(hidden_size == cols);
+
+    if (dz1_.has_value()) {
+        auto dz1 = dz1_.value();
+        TORCH_CHECK(dz1.dtype() == otype);
+        TORCH_CHECK(dz1.is_cuda());
+        TORCH_CHECK(dz1.is_contiguous());
+        TORCH_CHECK(dz1.sizes() == sizes);
+
+        TORCH_CHECK(gamma1_.has_value());
+        auto gamma1 = gamma1_.value();
+        TORCH_CHECK(gamma1.dtype() == wtype);
+        TORCH_CHECK(gamma1.is_cuda());
+        TORCH_CHECK(gamma1.is_contiguous());
+        TORCH_CHECK(gamma1.sizes() == gamma0.sizes());
+    }
+
+    if (dx_.has_value()) {
+        auto dx = dx_.value();
+        TORCH_CHECK(dx.dtype() == rtype);
+        TORCH_CHECK(dx.is_cuda());
+        TORCH_CHECK(dx.is_contiguous());
+        TORCH_CHECK(dx.sizes() == sizes);
+    }
+
+    if (dmask0_.has_value()) {
+        auto dmask0 = dmask0_.value();
+        TORCH_CHECK(dmask0.dtype() == mtype);
+        TORCH_CHECK(dmask0.is_cuda());
+        TORCH_CHECK(dmask0.is_contiguous());
+        TORCH_CHECK(dmask0.sizes() == sizes);
+
+        if (has_x1) {
+            TORCH_CHECK(dmask1_.has_value());
+            auto dmask1 = dmask1_.value();
+            TORCH_CHECK(dmask1.dtype() == mtype);
+            TORCH_CHECK(dmask1.is_cuda());
+            TORCH_CHECK(dmask1.is_contiguous());
+            TORCH_CHECK(dmask1.sizes() == sizes);
+        }
+    }
+
+    TORCH_CHECK((hidden_size % 8 == 0) && (hidden_size <= 8192));
+
+    TORCH_CHECK(mu.numel() == rows);
+    TORCH_CHECK(mu.sizes() == rsigma.sizes());
+
+    // Otherwise the kernel will be launched from cuda:0 device
+    // Cast to char to avoid compiler warning about narrowing
+    at::cuda::CUDAGuard device_guard{(char)dz0.get_device()};
+
+    auto opts = x.options();
+
+    auto dx0 = torch::empty(sizes, opts.dtype(itype));
+    at::Tensor dx1;
+    if (has_x1) { dx1 = torch::empty(sizes, opts.dtype(itype)); }
+    at::Tensor dresidual;
+    if (has_residual) { dresidual = torch::empty_like(x, opts.dtype(rtype)); }
+    auto dgamma0 = torch::empty_like(gamma0);
+    auto dbeta0 = torch::empty_like(gamma0);
+    at::Tensor dgamma1, dbeta1;
+    if (gamma1_.has_value()) {
+        dgamma1 = torch::empty_like(gamma0);
+        dbeta1 = torch::empty_like(gamma0);
+    }
+
+    layer_norm::LaunchParams<layer_norm::BwdParams> launch_params;
+    launch_params.stream = at::cuda::getCurrentCUDAStream().stream();
+    launch_params.props = at::cuda::getCurrentDeviceProperties();
+    TORCH_CHECK(dropout_p < 1.f);
+    launch_params.params.dropout_keep_p = 1.f - dropout_p;
+    launch_params.params.dresidual = has_residual ? dresidual.data_ptr() : nullptr;
+
+    auto round_multiple = [](int x, int m) { return (x + m - 1) / m * m; };
+    const int multiple = hidden_size <= 1536 ? 256 : (hidden_size <= 3072 ? 512 : 1024);
+    auto launcher = get_parallel_bwd_launcher(wtype, itype, rtype, otype, ctype, round_multiple(hidden_size, multiple));
+
+    launcher(launch_params, true);
+
+    auto dgamma0_part = torch::zeros({ launch_params.params.ctas_per_col, hidden_size }, opts.dtype(ctype));
+    auto dbeta0_part = torch::zeros({ launch_params.params.ctas_per_col, hidden_size }, opts.dtype(ctype));
+    at::Tensor dgamma1_part, dbeta1_part;
+    if (gamma1_.has_value()) {
+        dgamma1_part = torch::zeros_like(dgamma0_part);
+        dbeta1_part = torch::zeros_like(dbeta0_part);
+    }
+    at::Tensor workspace, barrier;
+
+    layer_norm::BwdParams &params = launch_params.params;
+    params.rows = rows;
+    params.cols = cols;
+    params.x = x.data_ptr();
+    params.dmask = dropout_p > 0.f ? dmask0_.value().data_ptr() : nullptr;
+    params.dmask1 = (dropout_p > 0.f && has_x1) ? dmask1_.value().data_ptr() : nullptr;
+    params.mu = mu.data_ptr();
+    params.rs = rsigma.data_ptr();
+    params.gamma = gamma0.data_ptr();
+    params.gamma1 = gamma1_.has_value() ? gamma1_.value().data_ptr() : nullptr;
+    params.dz = dz0.data_ptr();
+    params.dz1 = dz1_.has_value() ? dz1_.value().data_ptr() : nullptr;
+    params.dx = dx_.has_value() ? dx_.value().data_ptr() : nullptr;
+    params.dx0 = dx0.data_ptr();
+    params.dx1 = has_x1 ? dx1.data_ptr() : nullptr;
+    params.dbeta = dbeta0.data_ptr();
+    params.dgamma = dgamma0.data_ptr();
+    params.dbeta1 = gamma1_.has_value() ? dbeta1.data_ptr() : nullptr;
+    params.dgamma1 = gamma1_.has_value() ? dgamma1.data_ptr() : nullptr;
+    params.dbeta_part = dbeta0_part.data_ptr();
+    params.dgamma_part = dgamma0_part.data_ptr();
+    params.dbeta1_part = gamma1_.has_value() ? dbeta1_part.data_ptr() : nullptr;
+    params.dgamma1_part = gamma1_.has_value() ? dgamma1_part.data_ptr() : nullptr;
+    params.dropout_scale = 1.f / (1.f - dropout_p);
+    params.inverse_cols = 1.f / float(params.cols);
+    params.is_rms_norm = is_rms_norm;
+
+    if( launch_params.barrier_size > 0 ) {
+        // TODO Any way to avoid this?
+        barrier = torch::zeros(launch_params.barrier_size, opts.dtype(torch::kInt32));
+        workspace = torch::empty(launch_params.workspace_bytes, opts.dtype(torch::kChar));
+        params.workspace = workspace.data_ptr();
+        params.barrier = barrier.data_ptr<int>();
+    }
+
+    launcher(launch_params, false);
+
+    std::vector<at::Tensor> result = { dx0, dx1, dresidual, dgamma0, dbeta0, dgamma1, dbeta1, dgamma0_part, dbeta0_part, dgamma1_part, dbeta1_part };
+    return result;
+}
+
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 PYBIND11_MODULE(TORCH_EXTENSION_NAME, m) {
-  m.doc() = "CUDA DropoutAddLayerNorm";
-  m.def("dropout_add_ln_fwd", &dropout_add_ln_fwd, "Run Dropout + Add + LayerNorm forward kernel",
-        py::arg("x0"), py::arg("residual"), py::arg("gamma"), py::arg("beta"),
-        py::arg("rowscale_"), py::arg("colscale_"), py::arg("x0_subset_"), py::arg("z_subset_"),
-        py::arg("dropout_p"), py::arg("epsilon"), py::arg("rowscale_const"), py::arg("z_numrows"),
-        py::arg("gen_"), py::arg("residual_in_fp32")=false, py::arg("is_rms_norm")=false);
-  m.def("dropout_add_ln_bwd", &dropout_add_ln_bwd, "Run Dropout + Add + LayerNorm backward kernel",
-        py::arg("dz"), py::arg("dx_"), py::arg("x"), py::arg("x0_"), py::arg("dmask_"), py::arg("mu"),
-        py::arg("rsigma"), py::arg("gamma"), py::arg("rowscale_"), py::arg("colscale_"),
-        py::arg("x0_subset_"), py::arg("z_subset_"), py::arg("dropout_p"), py::arg("rowscale_const"),
-        py::arg("x0_numrows"), py::arg("has_residual"), py::arg("is_rms_norm")=false);
+    m.doc() = "CUDA DropoutAddLayerNorm";
+    m.def("dropout_add_ln_fwd", &dropout_add_ln_fwd, "Run Dropout + Add + LayerNorm forward kernel",
+          py::arg("x0"), py::arg("residual"), py::arg("gamma"), py::arg("beta_"),
+          py::arg("rowscale_"), py::arg("colscale_"), py::arg("x0_subset_"), py::arg("z_subset_"),
+          py::arg("dropout_p"), py::arg("epsilon"), py::arg("rowscale_const"), py::arg("z_numrows"),
+          py::arg("gen_"), py::arg("residual_in_fp32")=false, py::arg("is_rms_norm")=false);
+    m.def("dropout_add_ln_bwd", &dropout_add_ln_bwd, "Run Dropout + Add + LayerNorm backward kernel",
+          py::arg("dz"), py::arg("dx_"), py::arg("x"), py::arg("x0_"), py::arg("dmask_"), py::arg("mu"),
+          py::arg("rsigma"), py::arg("gamma"), py::arg("rowscale_"), py::arg("colscale_"),
+          py::arg("x0_subset_"), py::arg("z_subset_"), py::arg("dropout_p"), py::arg("rowscale_const"),
+          py::arg("x0_numrows"), py::arg("has_residual"), py::arg("is_rms_norm")=false);
+    m.def("dropout_add_ln_parallel_residual_fwd", &dropout_add_ln_parallel_residual_fwd, "Run Dropout + Add + LayerNorm parallel residual forward kernel",
+          py::arg("x0"), py::arg("x1_"), py::arg("residual"), py::arg("gamma0"), py::arg("beta0_"),
+          py::arg("gamma1_"), py::arg("beta1_"), py::arg("dropout_p"), py::arg("epsilon"),
+          py::arg("gen_"), py::arg("residual_in_fp32")=false, py::arg("is_rms_norm")=false);
+    m.def("dropout_add_ln_parallel_residual_bwd", &dropout_add_ln_parallel_residual_bwd, "Run Dropout + Add + LayerNorm parallel residual backward kernel",
+          py::arg("dz0"), py::arg("dz1_"), py::arg("dx_"), py::arg("x"), py::arg("dmask0_"),
+          py::arg("dmask1_"), py::arg("mu"), py::arg("rsigma"), py::arg("gamma0"), py::arg("gamma1_"),
+          py::arg("dropout_p"), py::arg("has_x1"), py::arg("has_residual"), py::arg("is_rms_norm")=false);
 }
```

### Comparing `flash_attn-0.2.8/csrc/layer_norm/ln_bwd_1024.cu` & `flash_attn-1.0.0/csrc/layer_norm/ln_bwd_1024.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/layer_norm/ln_bwd_1280.cu` & `flash_attn-1.0.0/csrc/layer_norm/ln_bwd_1280.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/layer_norm/ln_bwd_1536.cu` & `flash_attn-1.0.0/csrc/layer_norm/ln_bwd_1536.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/layer_norm/ln_bwd_2048.cu` & `flash_attn-1.0.0/csrc/layer_norm/ln_bwd_2048.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/layer_norm/ln_bwd_256.cu` & `flash_attn-1.0.0/csrc/layer_norm/ln_bwd_256.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/layer_norm/ln_bwd_2560.cu` & `flash_attn-1.0.0/csrc/layer_norm/ln_bwd_2560.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/layer_norm/ln_bwd_3072.cu` & `flash_attn-1.0.0/csrc/layer_norm/ln_bwd_3072.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/layer_norm/ln_bwd_4096.cu` & `flash_attn-1.0.0/csrc/layer_norm/ln_bwd_4096.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/layer_norm/ln_bwd_512.cu` & `flash_attn-1.0.0/csrc/layer_norm/ln_bwd_512.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/layer_norm/ln_bwd_5120.cu` & `flash_attn-1.0.0/csrc/layer_norm/ln_bwd_5120.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/layer_norm/ln_bwd_6144.cu` & `flash_attn-1.0.0/csrc/layer_norm/ln_bwd_6144.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/layer_norm/ln_bwd_768.cu` & `flash_attn-1.0.0/csrc/layer_norm/ln_bwd_768.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/layer_norm/ln_bwd_kernels.cuh` & `flash_attn-1.0.0/csrc/layer_norm/ln_bwd_kernels.cuh`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/layer_norm/ln_bwd_semi_cuda_kernel.cu` & `flash_attn-1.0.0/csrc/layer_norm/ln_bwd_semi_cuda_kernel_old.cu`

 * *Files 0% similar despite different names*

```diff
@@ -31,15 +31,15 @@
                                         HIDDEN_SIZE,
                                         CTAS_PER_ROW,
                                         WARPS_M,
                                         WARPS_N,
                                         BYTES_PER_LDG_MAIN
                                         >;
     bool is_dropout = launch_params.params.dropout_keep_p < 1.f;
-    bool has_residual = launch_params.params.dx1 != nullptr;
+    bool has_residual = launch_params.params.dresidual != nullptr;
     BOOL_SWITCH(prenorm, PrenormConst, [&] {
         BOOL_SWITCH(is_dropout, IsDropoutConst, [&] {
             BOOL_SWITCH(has_residual, HasResidualConst, [&] {
                 auto kernel = &ln_bwd_kernel<Kernel_traits, PrenormConst, IsDropoutConst, HasResidualConst>;
                 if( configure_params ) {
                     int ctas_per_sm;
                     CHECK_CUDA(cudaOccupancyMaxActiveBlocksPerMultiprocessor(
```

### Comparing `flash_attn-0.2.8/csrc/layer_norm/ln_fwd_1024.cu` & `flash_attn-1.0.0/csrc/layer_norm/ln_fwd_1024.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/layer_norm/ln_fwd_128.cu` & `flash_attn-1.0.0/csrc/layer_norm/ln_fwd_128.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/layer_norm/ln_fwd_1280.cu` & `flash_attn-1.0.0/csrc/layer_norm/ln_fwd_1280.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/layer_norm/ln_fwd_1536.cu` & `flash_attn-1.0.0/csrc/layer_norm/ln_fwd_1536.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/layer_norm/ln_fwd_2048.cu` & `flash_attn-1.0.0/csrc/layer_norm/ln_fwd_2048.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/layer_norm/ln_fwd_256.cu` & `flash_attn-1.0.0/csrc/layer_norm/ln_fwd_256.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/layer_norm/ln_fwd_2560.cu` & `flash_attn-1.0.0/csrc/layer_norm/ln_fwd_2560.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/layer_norm/ln_fwd_3072.cu` & `flash_attn-1.0.0/csrc/layer_norm/ln_fwd_3072.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/layer_norm/ln_fwd_384.cu` & `flash_attn-1.0.0/csrc/layer_norm/ln_fwd_384.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/layer_norm/ln_fwd_4096.cu` & `flash_attn-1.0.0/csrc/layer_norm/ln_fwd_4096.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/layer_norm/ln_fwd_512.cu` & `flash_attn-1.0.0/csrc/layer_norm/ln_fwd_512.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/layer_norm/ln_fwd_5120.cu` & `flash_attn-1.0.0/csrc/layer_norm/ln_fwd_5120.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/layer_norm/ln_fwd_6144.cu` & `flash_attn-1.0.0/csrc/layer_norm/ln_fwd_6144.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/layer_norm/ln_fwd_768.cu` & `flash_attn-1.0.0/csrc/layer_norm/ln_fwd_768.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/layer_norm/ln_fwd_cuda_kernel.cu` & `flash_attn-1.0.0/csrc/layer_norm/ln_fwd_cuda_kernel_old.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/layer_norm/ln_fwd_kernels.cuh` & `flash_attn-1.0.0/csrc/layer_norm/ln_fwd_kernels.cuh`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/layer_norm/ln_kernel_traits.h` & `flash_attn-1.0.0/csrc/layer_norm/ln_kernel_traits.h`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/layer_norm/ln_utils.cuh` & `flash_attn-1.0.0/csrc/layer_norm/ln_utils.cuh`

 * *Files 6% similar despite different names*

```diff
@@ -60,14 +60,47 @@
                 BYTES_PER_LDG_FINALIZE>(launch_params, configure_params);                                                                       \
     }                                                                                                                                           \
     static BwdRegistrar<WTYPE, ITYPE, RTYPE, OTYPE, CTYPE, HIDDEN_SIZE> reg_##HIDDEN_SIZE##_##WTYPE##_##ITYPE##_##RTYPE##_##OTYPE##_##CTYPE(    \
         ln_bwd_##HIDDEN_SIZE##_##WTYPE##_##ITYPE##_##RTYPE##_##OTYPE##_##CTYPE)
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
+#define REGISTER_PARALLEL_FWD_LAUNCHER(HIDDEN_SIZE, WTYPE, ITYPE, RTYPE, OTYPE, CTYPE, CTAS_PER_ROW, WARPS_M, WARPS_N, BYTES_PER_LDG)                \
+    void ln_parallel_residual_fwd_##HIDDEN_SIZE##_##WTYPE##_##ITYPE##_##RTYPE##_##OTYPE##_##CTYPE(LaunchParams<FwdParams> &launch_params,            \
+                                                                                const bool configure_params) {                                       \
+        launch_parallel_residual_<WTYPE, ITYPE, RTYPE, OTYPE, CTYPE, uint32_t, HIDDEN_SIZE, CTAS_PER_ROW, WARPS_M, WARPS_N, BYTES_PER_LDG>(          \
+            launch_params, configure_params);                                                                                                        \
+    }                                                                                                                                                \
+    static FwdParallelRegistrar<WTYPE, ITYPE, RTYPE, OTYPE, CTYPE, HIDDEN_SIZE> reg_##HIDDEN_SIZE##_##WTYPE##_##ITYPE##_##RTYPE##_##OTYPE##_##CTYPE( \
+        ln_parallel_residual_fwd_##HIDDEN_SIZE##_##WTYPE##_##ITYPE##_##RTYPE##_##OTYPE##_##CTYPE)
+
+////////////////////////////////////////////////////////////////////////////////////////////////////
+
+#define REGISTER_PARALLEL_BWD_LAUNCHER(                                                                                                              \
+    HIDDEN_SIZE, WTYPE, ITYPE, RTYPE, OTYPE, CTYPE, CTAS_PER_ROW, WARPS_M, WARPS_N, BYTES_PER_LDG, BYTES_PER_LDG_FINALIZE)                           \
+    void ln_parallel_residual_bwd_##HIDDEN_SIZE##_##WTYPE##_##ITYPE##_##RTYPE##_##OTYPE##_##CTYPE(LaunchParams<BwdParams> &launch_params,            \
+                                                                                const bool configure_params) {                                       \
+        launch_parallel_residual_<WTYPE,                                                                                                             \
+                ITYPE,                                                                                                                               \
+                RTYPE,                                                                                                                               \
+                OTYPE,                                                                                                                               \
+                CTYPE,                                                                                                                               \
+                uint32_t,                                                                                                                            \
+                HIDDEN_SIZE,                                                                                                                         \
+                CTAS_PER_ROW,                                                                                                                        \
+                WARPS_M,                                                                                                                             \
+                WARPS_N,                                                                                                                             \
+                BYTES_PER_LDG,                                                                                                                       \
+                BYTES_PER_LDG_FINALIZE>(launch_params, configure_params);                                                                            \
+    }                                                                                                                                                \
+    static BwdParallelRegistrar<WTYPE, ITYPE, RTYPE, OTYPE, CTYPE, HIDDEN_SIZE> reg_##HIDDEN_SIZE##_##WTYPE##_##ITYPE##_##RTYPE##_##OTYPE##_##CTYPE( \
+        ln_parallel_residual_bwd_##HIDDEN_SIZE##_##WTYPE##_##ITYPE##_##RTYPE##_##OTYPE##_##CTYPE)
+
+////////////////////////////////////////////////////////////////////////////////////////////////////
+
 inline __device__ float2 operator+(const float2 & a, const float2 & b){
     return {a.x + b.x, a.y + b.y};
 }
 
 ////////////////////////////////////////////////////////////////////////////////////////////////////
 
 inline __device__ void operator+=(float2 & a, const float2 & b){
```

### Comparing `flash_attn-0.2.8/csrc/layer_norm/static_switch.h` & `flash_attn-1.0.0/csrc/layer_norm/static_switch.h`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/rotary/rotary.cpp` & `flash_attn-1.0.0/csrc/rotary/rotary.cpp`

 * *Files 9% similar despite different names*

```diff
@@ -1,7 +1,11 @@
+/******************************************************************************
+ * Copyright (c) 2023, Tri Dao.
+ ******************************************************************************/
+
 #include <torch/extension.h>
 #include <c10/cuda/CUDAGuard.h>
 
 #define CHECK_DEVICE(x) TORCH_CHECK(x.device().type() == torch::kCUDA, #x " must be on CUDA")
 #define CHECK_SHAPE(x, ...) TORCH_CHECK(x.sizes() == torch::IntArrayRef({__VA_ARGS__}), #x " must have shape (" #__VA_ARGS__ ")")
 
 void apply_rotary_cuda(const torch::Tensor x1, const torch::Tensor x2,
```

### Comparing `flash_attn-0.2.8/csrc/rotary/rotary_cuda.cu` & `flash_attn-1.0.0/csrc/rotary/rotary_cuda.cu`

 * *Files 15% similar despite different names*

```diff
@@ -1,7 +1,11 @@
+/******************************************************************************
+ * Copyright (c) 2023, Tri Dao.
+ ******************************************************************************/
+
 #include <torch/python.h>
 #include <ATen/native/TensorIterator.h>
 #include <ATen/native/cuda/Loops.cuh>
 
 void apply_rotary_cuda(const torch::Tensor x1, const torch::Tensor x2,
                        const torch::Tensor cos, const torch::Tensor sin,
                        torch::Tensor out1, torch::Tensor out2,
```

### Comparing `flash_attn-0.2.8/csrc/xentropy/interface.cpp` & `flash_attn-1.0.0/csrc/xentropy/interface.cpp`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/csrc/xentropy/xentropy_kernel.cu` & `flash_attn-1.0.0/csrc/xentropy/xentropy_kernel.cu`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/flash_attn/attention_kernl.py` & `flash_attn-1.0.0/flash_attn/attention_kernl.py`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/flash_attn/bert_padding.py` & `flash_attn-1.0.0/flash_attn/bert_padding.py`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/flash_attn/flash_attention.py` & `flash_attn-1.0.0/flash_attn/flash_attention.py`

 * *Files 7% similar despite different names*

```diff
@@ -14,15 +14,15 @@
     ---------
         softmax_scale: The temperature to use for the softmax attention.
                       (default: 1/sqrt(d_keys) where d_keys is computed at
                       runtime)
         attention_dropout: The dropout rate to apply to the attention
                            (default: 0.0)
     """
-    def __init__(self, softmax_scale=None, attention_dropout=0.0, device=None, dtype=None):
+    def __init__(self, softmax_scale=None, attention_dropout=0.0):
         super().__init__()
         self.softmax_scale = softmax_scale
         self.dropout_p = attention_dropout
 
     def forward(self, qkv, key_padding_mask=None, causal=False, cu_seqlens=None,
                 max_s=None, need_weights=False):
         """Implements the multihead softmax attention.
@@ -70,28 +70,28 @@
 
         return output, None
 
 
 class FlashMHA(nn.Module):
 
     def __init__(self, embed_dim, num_heads, bias=True, batch_first=True, attention_dropout=0.0,
-                 causal=False, device=None, dtype=None, **kwargs) -> None:
+                 causal=False, device=None, dtype=None) -> None:
         assert batch_first
         factory_kwargs = {'device': device, 'dtype': dtype}
         super().__init__()
         self.embed_dim = embed_dim
         self.causal = causal
 
         self.num_heads = num_heads
         assert self.embed_dim % num_heads == 0, "self.kdim must be divisible by num_heads"
         self.head_dim = self.embed_dim // num_heads
         assert self.head_dim % 8 == 0 and self.head_dim <= 128, "Only support head_dim <= 128 and divisible by 8"
 
         self.Wqkv = nn.Linear(embed_dim, 3 * embed_dim, bias=bias, **factory_kwargs)
-        self.inner_attn = FlashAttention(attention_dropout=attention_dropout, **factory_kwargs)
+        self.inner_attn = FlashAttention(attention_dropout=attention_dropout)
         self.out_proj = nn.Linear(embed_dim, embed_dim, bias=bias, **factory_kwargs)
 
     def forward(self, x, key_padding_mask=None, need_weights=False):
         """x: (batch, seqlen, hidden_dim) (where hidden_dim = num heads * head dim)
         key_padding_mask: bool tensor of shape (batch, seqlen)
         """
         qkv = self.Wqkv(x)
```

### Comparing `flash_attn-0.2.8/flash_attn/flash_attn_interface.py` & `flash_attn-1.0.0/flash_attn/flash_attn_interface.py`

 * *Files 8% similar despite different names*

```diff
@@ -46,129 +46,136 @@
     #     breakpoint()
     return dq, dk, dv, softmax_d
 
 
 class FlashAttnQKVPackedFunc(torch.autograd.Function):
 
     @staticmethod
-    def forward(ctx, qkv, cu_seqlens, max_seqlen, dropout_p, softmax_scale, causal, return_softmax):
+    def forward(ctx, qkv, cu_seqlens, max_seqlen, dropout_p, softmax_scale, causal,
+                return_softmax, deterministic):
         # Save rng_state because the backward pass will regenerate the dropout mask
         rng_state = torch.cuda.get_rng_state() if dropout_p > 0 else None
         if softmax_scale is None:
             softmax_scale = qkv.shape[-1] ** (-0.5)
         out, softmax_lse, S_dmask = _flash_attn_forward(
             qkv[:, 0], qkv[:, 1], qkv[:, 2], torch.empty_like(qkv[:, 0]), cu_seqlens, cu_seqlens,
             max_seqlen, max_seqlen, dropout_p, softmax_scale, causal=causal,
             return_softmax=return_softmax
         )
         ctx.save_for_backward(qkv, out, softmax_lse, cu_seqlens, rng_state)
         ctx.dropout_p = dropout_p
         ctx.max_seqlen = max_seqlen
         ctx.softmax_scale = softmax_scale
         ctx.causal = causal
+        ctx.deterministic = deterministic
         return out if not return_softmax else (out, softmax_lse, S_dmask)
 
     @staticmethod
     def backward(ctx, dout, *args):
         qkv, out, softmax_lse, cu_seqlens, rng_state = ctx.saved_tensors
         if rng_state is not None:
             cur_rng_state = torch.cuda.get_rng_state()
             torch.cuda.set_rng_state(rng_state)
         dqkv = torch.empty_like(qkv)
         _flash_attn_backward(
             dout, qkv[:, 0], qkv[:, 1], qkv[:, 2], out, softmax_lse,
             dqkv[:, 0], dqkv[:, 1], dqkv[:, 2], cu_seqlens, cu_seqlens,
-            ctx.max_seqlen, ctx.max_seqlen, ctx.dropout_p, ctx.softmax_scale, ctx.causal
+            ctx.max_seqlen, ctx.max_seqlen, ctx.dropout_p, ctx.softmax_scale, ctx.causal,
+            num_splits=1 if ctx.deterministic else 0,
         )
         if rng_state is not None:
             torch.cuda.set_rng_state(cur_rng_state)
-        return dqkv, None, None, None, None, None, None
+        return dqkv, None, None, None, None, None, None, None
 
 
 class FlashAttnKVPackedFunc(torch.autograd.Function):
 
     @staticmethod
     def forward(ctx, q, kv, cu_seqlens_q, cu_seqlens_k, max_seqlen_q, max_seqlen_k, dropout_p,
-                softmax_scale, causal, return_softmax):
+                softmax_scale, causal, return_softmax, deterministic):
         # Save rng_state because the backward pass will regenerate the dropout mask
         rng_state = torch.cuda.get_rng_state() if dropout_p > 0 else None
         if softmax_scale is None:
             softmax_scale = q.shape[-1] ** (-0.5)
         out, softmax_lse, S_dmask = _flash_attn_forward(
             q, kv[:, 0], kv[:, 1], torch.empty_like(q), cu_seqlens_q, cu_seqlens_k, max_seqlen_q,
             max_seqlen_k, dropout_p, softmax_scale, causal=causal, return_softmax=return_softmax
         )
         ctx.save_for_backward(q, kv, out, softmax_lse, cu_seqlens_q, cu_seqlens_k, rng_state)
         ctx.dropout_p = dropout_p
         ctx.max_seqlen_q = max_seqlen_q
         ctx.max_seqlen_k = max_seqlen_k
         ctx.softmax_scale = softmax_scale
         ctx.causal = causal
+        ctx.deterministic = deterministic
         return out if not return_softmax else (out, softmax_lse, S_dmask)
 
     @staticmethod
     def backward(ctx, dout, *args):
         q, kv, out, softmax_lse, cu_seqlens_q, cu_seqlens_k, rng_state = ctx.saved_tensors
         if rng_state is not None:
             cur_rng_state = torch.cuda.get_rng_state()
             torch.cuda.set_rng_state(rng_state)
         dq = torch.empty_like(q)
         dkv = torch.empty_like(kv)
         _flash_attn_backward(
             dout, q, kv[:, 0], kv[:, 1], out, softmax_lse,
             dq, dkv[:, 0], dkv[:, 1], cu_seqlens_q, cu_seqlens_k,
-            ctx.max_seqlen_q, ctx.max_seqlen_k, ctx.dropout_p, ctx.softmax_scale, ctx.causal
+            ctx.max_seqlen_q, ctx.max_seqlen_k, ctx.dropout_p, ctx.softmax_scale, ctx.causal,
+            num_splits=1 if ctx.deterministic else 0,
         )
         if rng_state is not None:
             torch.cuda.set_rng_state(cur_rng_state)
-        return dq, dkv, None, None, None, None, None, None, None, None
+        return dq, dkv, None, None, None, None, None, None, None, None, None
 
 
 class FlashAttnFunc(torch.autograd.Function):
 
     @staticmethod
     def forward(ctx, q, k, v, cu_seqlens_q, cu_seqlens_k, max_seqlen_q, max_seqlen_k, dropout_p,
-                softmax_scale, causal, return_softmax):
+                softmax_scale, causal, return_softmax, deterministic):
         # Save rng_state because the backward pass will regenerate the dropout mask
         rng_state = torch.cuda.get_rng_state() if dropout_p > 0 else None
         if softmax_scale is None:
             softmax_scale = q.shape[-1] ** (-0.5)
         out, softmax_lse, S_dmask = _flash_attn_forward(
             q, k, v, torch.empty_like(q), cu_seqlens_q, cu_seqlens_k, max_seqlen_q, max_seqlen_k,
             dropout_p, softmax_scale, causal=causal, return_softmax=return_softmax
         )
         ctx.save_for_backward(q, k, v, out, softmax_lse, cu_seqlens_q, cu_seqlens_k, rng_state)
         ctx.dropout_p = dropout_p
         ctx.max_seqlen_q = max_seqlen_q
         ctx.max_seqlen_k = max_seqlen_k
         ctx.softmax_scale = softmax_scale
         ctx.causal = causal
+        ctx.deterministic = deterministic
         return out if not return_softmax else (out, softmax_lse, S_dmask)
 
     @staticmethod
     def backward(ctx, dout, *args):
         q, k, v, out, softmax_lse, cu_seqlens_q, cu_seqlens_k, rng_state = ctx.saved_tensors
         if rng_state is not None:
             cur_rng_state = torch.cuda.get_rng_state()
             torch.cuda.set_rng_state(rng_state)
         dq, dk, dv = torch.empty_like(q), torch.empty_like(k), torch.empty_like(v)
         _flash_attn_backward(
             dout, q, k, v, out, softmax_lse, dq, dk, dv, cu_seqlens_q, cu_seqlens_k,
-            ctx.max_seqlen_q, ctx.max_seqlen_k, ctx.dropout_p, ctx.softmax_scale, ctx.causal
+            ctx.max_seqlen_q, ctx.max_seqlen_k, ctx.dropout_p, ctx.softmax_scale, ctx.causal,
+            num_splits=1 if ctx.deterministic else 0,
         )
         if rng_state is not None:
             torch.cuda.set_rng_state(cur_rng_state)
-        return dq, dk, dv, None, None, None, None, None, None, None, None
+        return dq, dk, dv, None, None, None, None, None, None, None, None, None
 
 
 class FlashAttnQKVPackedSplitFunc(torch.autograd.Function):
 
     @staticmethod
     def forward(ctx, qkv, cu_seqlens, max_seqlen0, max_seqlen1, batch_size0, dropout_p,
-                softmax_scale, causal, return_softmax):
+                softmax_scale, causal, return_softmax, deterministic):
         # Save rng_state because the backward pass will regenerate the dropout mask
         if dropout_p > 0:
             rng_state0 = torch.cuda.get_rng_state()
             generator1 = torch.Generator(device='cuda')
             rng_state1 = generator1.get_state()
         else:
             rng_state0, generator1, rng_state1 = None, None, None
@@ -192,14 +199,15 @@
                               rng_state0, rng_state1)
         ctx.dropout_p = dropout_p
         ctx.max_seqlen0 = max_seqlen0
         ctx.max_seqlen1 = max_seqlen1
         ctx.batch_size0 = batch_size0
         ctx.softmax_scale = softmax_scale
         ctx.causal = causal
+        ctx.deterministic = deterministic
         if not return_softmax:
             return out
         else:
             max_seqlen_q = max(softmax_lse0.shape[2], softmax_lse1.shape[2])
             max_seqlen_k = max(S_dmask0.shape[3], S_dmask1.shape[3])
             softmax_lse = torch.cat([F.pad(softmax_lse0, (0, max_seqlen_q - softmax_lse0.shape[2])),
                                      F.pad(softmax_lse1, (0, max_seqlen_q - softmax_lse1.shape[2]))],
@@ -219,61 +227,63 @@
         else:
             generator1 = None
         dqkv = torch.empty_like(qkv)
         _flash_attn_backward(
             dout, qkv[:, 0], qkv[:, 1], qkv[:, 2], out, softmax_lse0,
             dqkv[:, 0], dqkv[:, 1], dqkv[:, 2], cu_seqlens[:batch_size0 + 1],
             cu_seqlens[:batch_size0 + 1], ctx.max_seqlen0, ctx.max_seqlen0, ctx.dropout_p,
-            ctx.softmax_scale, ctx.causal
+            ctx.softmax_scale, ctx.causal, num_splits=1 if ctx.deterministic else 0,
         )
         s = torch.cuda.Stream()
         with torch.cuda.stream(s):
             _flash_attn_backward(
                 dout, qkv[:, 0], qkv[:, 1], qkv[:, 2], out, softmax_lse1,
                 dqkv[:, 0], dqkv[:, 1], dqkv[:, 2], cu_seqlens[batch_size0:],
                 cu_seqlens[batch_size0:], ctx.max_seqlen1, ctx.max_seqlen1, ctx.dropout_p,
-                ctx.softmax_scale, ctx.causal, generator=generator1
+                ctx.softmax_scale, ctx.causal, generator=generator1,
+                num_splits=1 if ctx.deterministic else 0,
             )
         torch.cuda.current_stream().wait_stream(s)
         if rng_state0 is not None:
             torch.cuda.set_rng_state(cur_rng_state)
-        return dqkv, None, None, None, None, None, None, None, None
+        return dqkv, None, None, None, None, None, None, None, None, None
 
 
 def flash_attn_unpadded_qkvpacked_func(qkv, cu_seqlens, max_seqlen, dropout_p, softmax_scale=None,
-                                       causal=False, return_attn_probs=False):
+                                       causal=False, return_attn_probs=False, deterministic=False):
     """dropout_p should be set to 0.0 during evaluation
     Arguments:
         qkv: (total, 3, nheads, headdim), where total = total number of tokens in the batch.
         cu_seqlens: (batch_size + 1,), dtype torch.int32. The cumulative sequence lengths
            of the sequences in the batch, used to index into qkv.
         max_seqlen: int. Maximum sequence length in the batch.
         dropout_p: float. Dropout probability.
         softmax_scale: float. The scaling of QK^T before applying softmax.
             Default to 1 / sqrt(headdim).
         causal: bool. Whether to apply causal attention mask (e.g., for auto-regressive modeling).
         return_attn_probs: bool. Whether to return the attention probabilities. This option is for
            testing only. The returned probabilities are not guaranteed to be correct
            (they might not have the right scaling).
+        deterministic: bool. Whether or not to ensure deterministic execution.
     Return:
         out: (total, nheads, headdim).
         softmax_lse [optional, if return_attn_probs=True]: (batch_size, nheads, seqlen). The
             logsumexp of each row of the matrix QK^T * scaling (e.g., log of the softmax
             normalization factor).
         S_dmask [optional, if return_attn_probs=True]: (batch_size, nheads, seqlen, seqlen).
             The output of softmax (possibly with different scaling). It also encodes the dropout
             pattern (negative means that location was dropped, nonnegative means it was kept).
     """
     return FlashAttnQKVPackedFunc.apply(qkv, cu_seqlens, max_seqlen, dropout_p, softmax_scale,
-                                        causal, return_attn_probs)
+                                        causal, return_attn_probs, deterministic)
 
 
 def flash_attn_unpadded_kvpacked_func(q, kv, cu_seqlens_q, cu_seqlens_k, max_seqlen_q, max_seqlen_k,
                                       dropout_p, softmax_scale=None, causal=False,
-                                      return_attn_probs=False):
+                                      return_attn_probs=False, deterministic=False):
     """dropout_p should be set to 0.0 during evaluation
     Arguments:
         q: (total_q, nheads, headdim), where total_q = total number of query tokens in the batch.
         kv: (total_k, 2, nheads, headdim), where total_k = total number of key tokens in the batch.
         cu_seqlens_q: (batch_size + 1,), dtype torch.int32. The cumulative sequence lengths
            of the sequences in the batch, used to index into q.
         cu_seqlens_k: (batch_size + 1,), dtype torch.int32. The cumulative sequence lengths
@@ -283,30 +293,32 @@
         dropout_p: float. Dropout probability.
         softmax_scale: float. The scaling of QK^T before applying softmax.
             Default to 1 / sqrt(headdim).
         causal: bool. Whether to apply causal attention mask (e.g., for auto-regressive modeling).
         return_attn_probs: bool. Whether to return the attention probabilities. This option is for
            testing only. The returned probabilities are not guaranteed to be correct
            (they might not have the right scaling).
+        deterministic: bool. Whether or not to ensure deterministic execution.
     Return:
         out: (total, nheads, headdim).
         softmax_lse [optional, if return_attn_probs=True]: (batch_size, nheads, seqlen). The
             logsumexp of each row of the matrix QK^T * scaling (e.g., log of the softmax
             normalization factor).
         S_dmask [optional, if return_attn_probs=True]: (batch_size, nheads, seqlen, seqlen).
             The output of softmax (possibly with different scaling). It also encodes the dropout
             pattern (negative means that location was dropped, nonnegative means it was kept).
     """
     return FlashAttnKVPackedFunc.apply(q, kv, cu_seqlens_q, cu_seqlens_k,
                                        max_seqlen_q, max_seqlen_k, dropout_p, softmax_scale, causal,
-                                       return_attn_probs)
+                                       return_attn_probs, deterministic)
 
 
 def flash_attn_unpadded_func(q, k, v, cu_seqlens_q, cu_seqlens_k, max_seqlen_q, max_seqlen_k,
-                             dropout_p, softmax_scale=None, causal=False, return_attn_probs=False):
+                             dropout_p, softmax_scale=None, causal=False, return_attn_probs=False,
+                             deterministic=False):
     """dropout_p should be set to 0.0 during evaluation
     Arguments:
         q: (total_q, nheads, headdim), where total_q = total number of query tokens in the batch.
         k: (total_k, nheads, headdim), where total_k = total number of key tokens in the batch.
         v: (total_k, nheads, headdim), where total_k = total number of key tokens in the batch.
         cu_seqlens_q: (batch_size + 1,), dtype torch.int32. The cumulative sequence lengths
            of the sequences in the batch, used to index into q.
@@ -317,30 +329,31 @@
         dropout_p: float. Dropout probability.
         softmax_scale: float. The scaling of QK^T before applying softmax.
             Default to 1 / sqrt(headdim).
         causal: bool. Whether to apply causal attention mask (e.g., for auto-regressive modeling).
         return_attn_probs: bool. Whether to return the attention probabilities. This option is for
            testing only. The returned probabilities are not guaranteed to be correct
            (they might not have the right scaling).
+        deterministic: bool. Whether or not to ensure deterministic execution.
     Return:
         out: (total, nheads, headdim).
         softmax_lse [optional, if return_attn_probs=True]: (batch_size, nheads, seqlen). The
             logsumexp of each row of the matrix QK^T * scaling (e.g., log of the softmax
             normalization factor).
         S_dmask [optional, if return_attn_probs=True]: (batch_size, nheads, seqlen, seqlen).
             The output of softmax (possibly with different scaling). It also encodes the dropout
             pattern (negative means that location was dropped, nonnegative means it was kept).
     """
     return FlashAttnFunc.apply(q, k, v, cu_seqlens_q, cu_seqlens_k, max_seqlen_q, max_seqlen_k,
-                               dropout_p, softmax_scale, causal, return_attn_probs)
+                               dropout_p, softmax_scale, causal, return_attn_probs, deterministic)
 
 
 def flash_attn_unpadded_qkvpacked_split_func(
         qkv, cu_seqlens, max_seqlen0, max_seqlen1, batch_size0, dropout_p, softmax_scale=None,
-        causal=False, return_attn_probs=False):
+        causal=False, return_attn_probs=False, deterministic=False):
     """
     Split attention into 2 kernels running on 2 separate streams for performance reason:
     e.g., if the batch has some sequences of length <= 128 and some > 128, it might be faster to
     have one kernel dealing with seqlen <= 128 and one kernel for seqlen > 128.
 
     dropout_p should be set to 0.0 during evaluation.
 
@@ -354,25 +367,27 @@
         dropout_p: float. Dropout probability.
         softmax_scale: float. The scaling of QK^T before applying softmax.
             Default to 1 / sqrt(headdim).
         causal: bool. Whether to apply causal attention mask (e.g., for auto-regressive modeling).
         return_attn_probs: bool. Whether to return the attention probabilities. This option is for
            testing only. The returned probabilities are not guaranteed to be correct
            (they might not have the right scaling).
+        deterministic: bool. Whether or not to ensure deterministic execution.
     Return:
         out: (total, nheads, headdim).
         softmax_lse [optional, if return_attn_probs=True]: (batch_size, nheads, seqlen). The
             logsumexp of each row of the matrix QK^T * scaling (e.g., log of the softmax
             normalization factor).
         S_dmask [optional, if return_attn_probs=True]: (batch_size, nheads, seqlen, seqlen).
             The output of softmax (possibly with different scaling). It also encodes the dropout
             pattern (negative means that location was dropped, nonnegative means it was kept).
     """
     return FlashAttnQKVPackedSplitFunc.apply(qkv, cu_seqlens, max_seqlen0, max_seqlen1, batch_size0,
-                                             dropout_p, softmax_scale, causal, return_attn_probs)
+                                             dropout_p, softmax_scale, causal, return_attn_probs,
+                                             deterministic)
 
 
 def flash_attn_func(qkv, cu_seqlens, dropout_p, max_s, softmax_scale=None, causal=False,
                      return_attn_probs=False):
     """For backward-compatibility only, will remove soon.
     dropout_p should be set to 0.0 during evaluation
     """
```

### Comparing `flash_attn-0.2.8/flash_attn/flash_attn_triton.py` & `flash_attn-1.0.0/flash_attn/flash_attn_triton_tmp.py`

 * *Files 0% similar despite different names*

```diff
@@ -1,34 +1,30 @@
 """
 *Experimental* implementation of FlashAttention in Triton.
-
 We use the FlashAttention implementation from Phil Tillet a starting point.
 https://github.com/openai/triton/blob/master/python/tutorials/06-fused-attention.py
-
 Changes:
 - Implement both causal and non-causal attention.
 - Implement both self-attention and cross-attention.
 - Support arbitrary seqlens (not just multiples of 128), for both forward and backward.
 - Support all head dimensions up to 128 (not just 16, 32, 64, 128), for both forward and backward.
 - Support attention bias.
 - Speed up the forward pass a bit, and only store the LSE instead of m and l.
 - Make the backward for d=128 much faster by reducing register spilling.
 - Optionally parallelize the backward pass across seqlen_k, to deal with the case of
 small batch size * nheads.
-
 Caution:
 - This is an *experimental* implementation. The forward pass should be quite robust but
 I'm not 100% sure that the backward pass doesn't have race conditions (due to the Triton compiler).
 - This implementation has only been tested on A100.
 - If you plan to use headdim other than 64 and 128, you should test for race conditions
 (due to the Triton compiler), as done in tests/test_flash_attn.py
 "test_flash_attn_triton_race_condition". I've tested and fixed many race conditions
 for different head dimensions (40, 48, 64, 128, 80, 88, 96), but I'm still not 100% confident
 that there are none left for other head dimensions.
-
 Differences between this Triton version and the CUDA version:
 - Triton version doesn't support dropout.
 - Triton forward is generally faster than CUDA forward, while Triton backward is
 generally slower than CUDA backward. Overall Triton forward + backward is slightly slower
 than CUDA forward + backward.
 - Triton version doesn't support different sequence lengths in a batch (i.e., RaggedTensor/NestedTensor).
 - Triton version supports attention bias, while CUDA version doesn't.
@@ -732,15 +728,16 @@
         ctx.save_for_backward(qkv, o, lse, bias)
         ctx.causal = causal
         return o
 
     @staticmethod
     def backward(ctx, do):
         qkv, o, lse, bias = ctx.saved_tensors
-        assert not ctx.needs_input_grad[1], 'FlashAttention does not support bias gradient yet'
+        if len(ctx.needs_input_grad) >= 2:
+            assert not ctx.needs_input_grad[1], 'FlashAttention does not support bias gradient yet'
         # Triton's autotune causes the Tensor._version to change, and so Pytorch autograd
         # does a memcpy. To avoid this we run in inference_mode, which doesn't track the version.
         with torch.inference_mode():
             dqkv = torch.empty_like(qkv)
             _flash_attn_backward(do, qkv[:, :, 0], qkv[:, :, 1], qkv[:, :, 2], o, lse,
                                  dqkv[:, :, 0], dqkv[:, :, 1], dqkv[:, :, 2],
                                  bias=bias, causal=ctx.causal, softmax_scale=ctx.softmax_scale)
```

### Comparing `flash_attn-0.2.8/flash_attn/flash_attn_triton_og.py` & `flash_attn-1.0.0/flash_attn/flash_attn_triton_og.py`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/flash_attn/flash_attn_triton_single_query.py` & `flash_attn-1.0.0/flash_attn/flash_attn_triton_single_query.py`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/flash_attn/flash_attn_triton_tmp.py` & `flash_attn-1.0.0/flash_attn/flash_attn_triton_varlen.py`

 * *Files 7% similar despite different names*

```diff
@@ -1,20 +1,15 @@
-"""
-Based on the FlashAttention implementation from Phil Tillet.
-https://github.com/openai/triton/blob/master/python/tutorials/06-fused-attention.py
+# [2022-10-23] Downloaded from https://github.com/openai/triton/blob/master/python/tutorials/06-fused-attention.py
 
-Changes:
-- Support both causal and non-causal attention.
-- Support arbitrary seqlens (not just multiples of 128) in the forward pass.
-- Speed up the forward pass a bit (and only store the LSE instead of m and l).
-- Make the backward for d=128 much faster by reducing register spilling.
-- Add the option to parallelize the backward pass across seqlen_k, to deal with the case of
-small batch size * nheads.
 """
-
+Fused Attention
+===============
+This is a Triton implementation of the Flash Attention algorithm
+(see: Dao et al., https://arxiv.org/pdf/2205.14135v2.pdf; Rabe and Staats https://arxiv.org/pdf/2112.05682v2.pdf)
+"""
 import math
 
 import torch
 
 from einops import rearrange
 
 import triton
@@ -27,27 +22,27 @@
         triton.Config({"BLOCK_M": 64, "BLOCK_N": 64}, num_warps=4, num_stages=1),
     ],
     key=['CACHE_KEY_SEQLEN_Q', 'CACHE_KEY_SEQLEN_K', 'IS_CAUSAL', 'BLOCK_HEADDIM']
 )
 @triton.heuristics(
     {
         "EVEN_M": lambda args: args["seqlen_q"] % args["BLOCK_M"] == 0,
-        "EVEN_N": lambda args: args["seqlen_k"] % args["BLOCK_N"] == 0,
+        "EVEN_N": lambda args: args["seqlen_k"] % (args["BLOCK_N"]) == 0,
     }
 )
 @triton.jit
 def _fwd_kernel(
     Q, K, V, Out,
     Lse, TMP,  # NOTE: TMP is a scratchpad buffer to workaround a compiler bug
     softmax_scale,
     stride_qb, stride_qh, stride_qm,
     stride_kb, stride_kh, stride_kn,
     stride_vb, stride_vh, stride_vn,
     stride_ob, stride_oh, stride_om,
-    nheads, seqlen_q, seqlen_k, seqlen_q_rounded,
+    nheads, seqlen_q, seqlen_k,
     CACHE_KEY_SEQLEN_Q, CACHE_KEY_SEQLEN_K,
     IS_CAUSAL: tl.constexpr,
     BLOCK_HEADDIM: tl.constexpr,
     EVEN_M: tl.constexpr, EVEN_N: tl.constexpr,
     BLOCK_M: tl.constexpr, BLOCK_N: tl.constexpr,
 ):
     start_m = tl.program_id(0)
@@ -65,37 +60,45 @@
     # Adding parenthesis around indexing might use int32 math instead of int64 math?
     # https://github.com/openai/triton/issues/741
     # I'm seeing a tiny bit of difference (5-7us)
     q_ptrs = Q + off_b * stride_qb + off_h * stride_qh + (offs_m[:, None] * stride_qm + offs_d[None, :])
     k_ptrs = K + off_b * stride_kb + off_h * stride_kh + (offs_n[:, None] * stride_kn + offs_d[None, :])
     v_ptrs = V + off_b * stride_vb + off_h * stride_vh + (offs_n[:, None] * stride_vn + offs_d[None, :])
     # initialize pointer to m and l
-    t_ptrs = TMP + off_hb * seqlen_q_rounded + offs_m
+    t_ptrs = TMP + off_hb * seqlen_q + offs_m
     lse_i = tl.zeros([BLOCK_M], dtype=tl.float32) - float("inf")
     m_i = tl.zeros([BLOCK_M], dtype=tl.float32) - float("inf")
     acc_o = tl.zeros([BLOCK_M, BLOCK_HEADDIM], dtype=tl.float32)
     # load q: it will stay in SRAM throughout
-    # [2022-10-30] TD: Idk why but in the case of EVEN_M=True and EVEN_N=False, if we just call
-    # tl.load(q_ptrs), we get the wrong output! Could be a bug in the compiler?
-    if EVEN_M & EVEN_N:
+    if EVEN_M:
         q = tl.load(q_ptrs)
     else:
         q = tl.load(q_ptrs, mask=offs_m[:, None] < seqlen_q, other=0.0)
     # loop over k, v and update accumulator
-    end_n = seqlen_k if not IS_CAUSAL else tl.minimum((start_m + 1) * BLOCK_M, seqlen_k)
+    end_n = seqlen_k if not IS_CAUSAL else (start_m + 1) * BLOCK_M
     for start_n in range(0, end_n, BLOCK_N):
         start_n = tl.multiple_of(start_n, BLOCK_N)
         # -- compute qk ----
         if EVEN_N:
             k = tl.load(k_ptrs + start_n * stride_kn)
         else:
             k = tl.load(k_ptrs + start_n * stride_kn, mask=(start_n + offs_n)[:, None] < seqlen_k,
                         other=0.0)
         qk = tl.zeros([BLOCK_M, BLOCK_N], dtype=tl.float32)
         qk += tl.dot(q, k, trans_b=True)
+        # qk *= softmax_scale
+        # if EVEN_N:
+        #     if IS_CAUSAL:
+        #         qk += tl.where(offs_m[:, None] >= (start_n + offs_n)[None, :], 0, float("-inf"))
+        # else:  # Need to mask out otherwise the softmax is wrong
+        #     if not IS_CAUSAL:
+        #         qk += tl.where((start_n + offs_n)[None, :] < seqlen_k, 0, float("-inf"))
+        #     else:
+        #         qk += tl.where((offs_m[:, None] >= (start_n + offs_n)[None, :])
+        #                        & ((start_n + offs_n)[None, :] < seqlen_k), 0, float("-inf"))
         if not EVEN_N:
             qk += tl.where((start_n + offs_n)[None, :] < seqlen_k, 0, float("-inf"))
         if IS_CAUSAL:
             qk += tl.where(offs_m[:, None] >= (start_n + offs_n)[None, :], 0, float("-inf"))
         m_ij = tl.maximum(tl.max(qk, 1) * softmax_scale, lse_i)
         # Slightly faster to multiply the softmax_scale here since the compiler can then
         # fuse the mult and add into an fma instruction.
@@ -129,15 +132,15 @@
     tl.store(t_ptrs, o_scale)
     o_scale = tl.load(t_ptrs)
     acc_o = acc_o * o_scale[:, None]
     # rematerialize offsets to save registers
     start_m = tl.program_id(0)
     offs_m = start_m * BLOCK_M + tl.arange(0, BLOCK_M)
     # write back l and m
-    lse_ptrs = Lse + off_hb * seqlen_q_rounded + offs_m
+    lse_ptrs = Lse + off_hb * seqlen_q + offs_m
     tl.store(lse_ptrs, lse_i)
     # initialize pointers to output
     offs_n = tl.arange(0, BLOCK_HEADDIM)
     out_ptrs = Out + off_b * stride_ob + off_h * stride_oh + (offs_m[:, None] * stride_om + offs_n[None, :])
     if EVEN_M:
         tl.store(out_ptrs, acc_o)
     else:
@@ -182,15 +185,15 @@
 @triton.jit
 def _bwd_kernel_one_col_block(
     start_n,
     Q, K, V, softmax_scale,
     DO, DQ, DK, DV,
     LSE, D,
     stride_qm, stride_kn, stride_vn, stride_dom, stride_dqm, stride_dkn, stride_dvn,
-    seqlen_q, seqlen_k,
+    seqlen_q, seqlen_k, seqlen_do, seqlen_dq,
     ATOMIC_ADD: tl.constexpr,
     IS_CAUSAL: tl.constexpr,
     BLOCK_HEADDIM: tl.constexpr,
     EVEN_M: tl.constexpr, EVEN_N: tl.constexpr,
     BLOCK_M: tl.constexpr, BLOCK_N: tl.constexpr,
 ):
     # We need to make sure begin_m is a multiple of BLOCK_M (not BLOCK_N)
@@ -206,67 +209,99 @@
     v_ptrs = V + (offs_n[:, None] * stride_vn + offs_k[None, :])
     do_ptrs = DO + (offs_qm[:, None] * stride_dom + offs_k[None, :])
     dq_ptrs = DQ + (offs_qm[:, None] * stride_dqm + offs_k[None, :])
     # initialize dv amd dk
     dv = tl.zeros([BLOCK_N, BLOCK_HEADDIM], dtype=tl.float32)
     dk = tl.zeros([BLOCK_N, BLOCK_HEADDIM], dtype=tl.float32)
     # k and v stay in SRAM throughout
-    # if EVEN_N:
-    if False:
+    if EVEN_N:
         k = tl.load(k_ptrs)
         v = tl.load(v_ptrs)
     else:
         k = tl.load(k_ptrs, mask=offs_n[:, None] < seqlen_k, other=0.0)
         v = tl.load(v_ptrs, mask=offs_n[:, None] < seqlen_k, other=0.0)
     # loop over rows
     num_block_m = tl.cdiv(seqlen_q, BLOCK_M)
     for start_m in range(begin_m, num_block_m * BLOCK_M, BLOCK_M):
         start_m = tl.multiple_of(start_m, BLOCK_M)
         offs_m_curr = start_m + offs_m
         # load q, k, v, do on-chip
-        q = tl.load(q_ptrs)
+        # if True:
+        if True:
+            q = tl.load(q_ptrs)
+        else:
+            q = tl.load(q_ptrs, mask=offs_m_curr[:, None] < seqlen_q, other=0.0)
         # recompute p = softmax(qk, dim=-1).T
         qk = tl.dot(q, k, trans_b=True)
-        # if not EVEN_N:
+        if EVEN_N:
+            if IS_CAUSAL:
+                qk = tl.where(offs_m_curr[:, None] >= (offs_n[None, :]), qk, float("-inf"))
+        else:    # Need to mask out otherwise the softmax is wrong
+            if not IS_CAUSAL:
+                qk += tl.where(offs_n[None, :] < seqlen_k, 0, float("-inf"))
+            else:
+                qk = tl.where((offs_m_curr[:, None] >= (offs_n[None, :]))
+                              & (offs_n[None, :] < seqlen_k), qk, float("-inf"))
+        # if EVEN_M:
         if True:
-            qk = tl.where(offs_n[None, :] < seqlen_k, qk, float("-inf"))
-        if IS_CAUSAL:
-            qk = tl.where(offs_m_curr[:, None] >= (offs_n[None, :]), qk, float("-inf"))
-        lse_i = tl.load(LSE + offs_m_curr)
+            lse_i = tl.load(LSE + offs_m_curr)
+        else:
+            lse_i = tl.load(LSE + offs_m_curr, mask=offs_m_curr < seqlen_q, other=float('inf'))
         p = tl.exp(qk * softmax_scale - lse_i[:, None])
         # compute dv
-        do = tl.load(do_ptrs)
+        # if EVEN_M:
+        if True:
+            do = tl.load(do_ptrs)
+        else:
+            # do = tl.load(do_ptrs, mask=offs_m_curr[:, None] < seqlen_q, other=0.0)
+            do = tl.load(do_ptrs, mask=offs_m_curr[:, None] < seqlen_do, other=0.0)
         dv += tl.dot(p.to(do.dtype), do, trans_a=True)
         # compute dp = dot(v, do)
         dp = tl.dot(do, v, trans_b=True)
         # compute ds = p * (dp - delta[:, None])
         # Putting the subtraction after the dp matmul (instead of before) is slightly faster
         Di = tl.load(D + offs_m_curr)
         # Converting ds to q.dtype here reduces register pressure and makes it much faster
         # for BLOCK_HEADDIM=128
         ds = (p * (dp - Di[:, None]) * softmax_scale).to(q.dtype)
         # compute dk = dot(ds.T, q)
         dk += tl.dot(ds, q, trans_a=True)
         # compute dq
         if not ATOMIC_ADD:
-            dq = tl.load(dq_ptrs, eviction_policy="evict_last")
+            # if EVEN_M:
+            if True:
+                dq = tl.load(dq_ptrs, eviction_policy="evict_last")
+            else:
+                # dq = tl.load(dq_ptrs, mask=offs_m_curr[:, None] < seqlen_q, other=0.0,
+                dq = tl.load(dq_ptrs, mask=offs_m_curr[:, None] < seqlen_dq, other=0.0,
+                             eviction_policy="evict_last")
             dq += tl.dot(ds, k)
-            tl.store(dq_ptrs, dq, eviction_policy="evict_last")
+            # if EVEN_M:
+            if True:
+                tl.store(dq_ptrs, dq, eviction_policy="evict_last")
+            else:
+                # tl.store(dq_ptrs, dq, mask=offs_m_curr[:, None] < seqlen_q,
+                tl.store(dq_ptrs, dq, mask=offs_m_curr[:, None] < seqlen_dq,
+                         eviction_policy="evict_last")
         else:  # If we're parallelizing across the seqlen_k dimension
             dq = tl.dot(ds, k)
-            tl.atomic_add(dq_ptrs, dq)
+            # if EVEN_M:
+            if True:
+                tl.atomic_add(dq_ptrs, dq)
+            else:
+                # tl.atomic_add(dq_ptrs, dq, mask=offs_m_curr[:, None] < seqlen_q)
+                tl.atomic_add(dq_ptrs, dq, mask=offs_m_curr[:, None] < seqlen_dq)
         # increment pointers
         dq_ptrs += BLOCK_M * stride_dqm
         q_ptrs += BLOCK_M * stride_qm
         do_ptrs += BLOCK_M * stride_dom
     # write-back
     dv_ptrs = DV + (offs_n[:, None] * stride_dvn + offs_k[None, :])
     dk_ptrs = DK + (offs_n[:, None] * stride_dkn + offs_k[None, :])
-    # if EVEN_N:
-    if False:
+    if EVEN_N:
         tl.store(dv_ptrs, dv)
         tl.store(dk_ptrs, dk)
     else:
         tl.store(dv_ptrs, dv, mask=offs_n[:, None] < seqlen_k)
         tl.store(dk_ptrs, dk, mask=offs_n[:, None] < seqlen_k)
 
 
@@ -277,15 +312,14 @@
     # return fn
     return lambda nargs: nargs[name].zero_()
 
 @triton.autotune(
     configs=[
         triton.Config({"BLOCK_M": 128, "BLOCK_N": 128, "SEQUENCE_PARALLEL": False}, num_warps=8, num_stages=1, pre_hook=init_to_zero('DQ')),
         # triton.Config({"BLOCK_M": 128, "BLOCK_N": 128, "SEQUENCE_PARALLEL": True}, num_warps=8, num_stages=1, pre_hook=init_to_zero('DQ')),
-        # # Kernel is buggy (give wrong result) if we set BLOCK_m=128, BLOCK_n=64, num_warps=*4*
         # triton.Config({"BLOCK_M": 128, "BLOCK_N": 64, "SEQUENCE_PARALLEL": False}, num_warps=8, num_stages=1, pre_hook=init_to_zero('DQ')),
         # triton.Config({"BLOCK_M": 128, "BLOCK_N": 64, "SEQUENCE_PARALLEL": True}, num_warps=8, num_stages=1, pre_hook=init_to_zero('DQ')),
         # triton.Config({"BLOCK_M": 64, "BLOCK_N": 64, "SEQUENCE_PARALLEL": False}, num_warps=4, num_stages=1, pre_hook=init_to_zero('DQ')),
         # triton.Config({"BLOCK_M": 64, "BLOCK_N": 64, "SEQUENCE_PARALLEL": True}, num_warps=4, num_stages=1, pre_hook=init_to_zero('DQ')),
         # triton.Config({"BLOCK_M": 128, "BLOCK_N": 128, "SEQUENCE_PARALLEL": False}, num_warps=8, num_stages=1),
         # triton.Config({"BLOCK_M": 128, "BLOCK_N": 128, "SEQUENCE_PARALLEL": True}, num_warps=8, num_stages=1),
         # triton.Config({"BLOCK_M": 128, "BLOCK_N": 64, "SEQUENCE_PARALLEL": False}, num_warps=4, num_stages=1),
@@ -311,15 +345,15 @@
     stride_qb, stride_qh, stride_qm,
     stride_kb, stride_kh, stride_kn,
     stride_vb, stride_vh, stride_vn,
     stride_dob, stride_doh, stride_dom,
     stride_dqb, stride_dqh, stride_dqm,
     stride_dkb, stride_dkh, stride_dkn,
     stride_dvb, stride_dvh, stride_dvn,
-    nheads, seqlen_q, seqlen_k, seqlen_q_rounded,
+    nheads, seqlen_q, seqlen_k, seqlen_q_rounded, seqlen_do, seqlen_dq,
     CACHE_KEY_SEQLEN_Q, CACHE_KEY_SEQLEN_K,
     IS_CAUSAL: tl.constexpr,
     BLOCK_HEADDIM: tl.constexpr,
     SEQUENCE_PARALLEL: tl.constexpr,
     EVEN_M: tl.constexpr, EVEN_N: tl.constexpr,
     BLOCK_M: tl.constexpr, BLOCK_N: tl.constexpr,
 ):
@@ -335,37 +369,38 @@
     DK += off_b * stride_dkb + off_h * stride_dkh
     DV += off_b * stride_dvb + off_h * stride_dvh
     # pointer to row-wise quantities in value-like data
     D += off_hb * seqlen_q_rounded
     LSE += off_hb * seqlen_q_rounded
     if not SEQUENCE_PARALLEL:
         num_block_n = tl.cdiv(seqlen_k, BLOCK_N)
+        # num_block_n = 1
         for start_n in range(0, num_block_n):
             _bwd_kernel_one_col_block(
                 start_n,
                 Q, K, V, softmax_scale,
                 DO, DQ, DK, DV,
                 LSE, D,
                 stride_qm, stride_kn, stride_vn, stride_dom, stride_dqm, stride_dkn, stride_dvn,
-                seqlen_q, seqlen_k,
+                seqlen_q, seqlen_k, seqlen_do, seqlen_dq,
                 ATOMIC_ADD=False,
                 IS_CAUSAL=IS_CAUSAL,
                 BLOCK_HEADDIM=BLOCK_HEADDIM,
                 EVEN_M=EVEN_M, EVEN_N=EVEN_N,
                 BLOCK_M=BLOCK_M, BLOCK_N=BLOCK_N
             )
     else:
         start_n = tl.program_id(0)
         _bwd_kernel_one_col_block(
             start_n,
             Q, K, V, softmax_scale,
             DO, DQ, DK, DV,
             LSE, D,
             stride_qm, stride_kn, stride_vn, stride_dom, stride_dqm, stride_dkn, stride_dvn,
-            seqlen_q, seqlen_k,
+            seqlen_q, seqlen_k, seqlen_do, seqlen_dq,
             ATOMIC_ADD=True,
             IS_CAUSAL=IS_CAUSAL,
             BLOCK_HEADDIM=BLOCK_HEADDIM,
             EVEN_M=EVEN_M, EVEN_N=EVEN_N,
             BLOCK_M=BLOCK_M, BLOCK_N=BLOCK_N
         )
 
@@ -395,46 +430,54 @@
         q, k, v, o,
         lse, tmp,
         softmax_scale,
         q.stride(0), q.stride(2), q.stride(1),
         k.stride(0), k.stride(2), k.stride(1),
         v.stride(0), v.stride(2), v.stride(1),
         o.stride(0), o.stride(2), o.stride(1),
-        nheads, seqlen_q, seqlen_k, seqlen_q_rounded,
+        nheads, seqlen_q, seqlen_k,
         seqlen_q // 32,  seqlen_k // 32, # key for triton cache (limit number of compilations)
         # Can't use kwargs here because triton autotune expects key to be args, not kwargs
         # IS_CAUSAL=causal, BLOCK_HEADDIM=d,
         causal, d,
         # BLOCK_M=BLOCK, BLOCK_N=BLOCK,
         # num_warps=num_warps,
         # num_stages=1,
     )
     return o, lse, softmax_scale  # softmax_scale could have been updated
 
 
 def _flash_attn_backward(do, q, k, v, o, lse, dq, dk, dv, causal=False, softmax_scale=None):
     # Make sure that the last dimension is contiguous
+    seqlen_q = q.shape[1]
+    seqlen_q_rounded = math.ceil(seqlen_q / 128) * 128
+    attn = torch.softmax(torch.einsum('bthd,bshd->bhts', q * softmax_scale, k), dim=-1)
+    # do = torch.nn.functional.pad(do, (0, 0, 0, 0, 0, seqlen_q_rounded - seqlen_q))
+    # o = torch.nn.functional.pad(o, (0, 0, 0, 0, 0, seqlen_q_rounded - seqlen_q))
+    q = torch.nn.functional.pad(q, (0, 0, 0, 0, 0, seqlen_q_rounded - seqlen_q))
+    attn_new = torch.softmax(torch.einsum('bthd,bshd->bhts', q * softmax_scale, k), dim=-1)
     if do.stride(-1) != 1:
         do = do.contiguous()
     batch, seqlen_q, nheads, d = q.shape
     _, seqlen_k, _, _ = k.shape
-    assert seqlen_q % 128 == 0, 'Backward pass currently only support seqlen that are multiples of 128'
-    assert seqlen_k % 128 == 0, 'Backward pass currently only support seqlen that are multiples of 128'
     seqlen_q_rounded = math.ceil(seqlen_q / 128) * 128
     assert lse.shape == (batch, nheads, seqlen_q_rounded)
     # dq_accum = torch.zeros_like(q, dtype=torch.float32)
-    dq_accum = torch.empty_like(q, dtype=torch.float32)
+    # dq_accum = torch.empty_like(q, dtype=torch.float32)
+    # dq_accum = torch.empty(batch, seqlen_q_rounded, nheads, d, device=q.device, dtype=torch.float32)
+    dq_accum = torch.empty(batch, do.shape[1], nheads, d, device=q.device, dtype=torch.float32)
     delta = torch.empty_like(lse)
     # delta = torch.zeros_like(lse)
     grid = lambda META: (triton.cdiv(seqlen_q, META["BLOCK_M"]), batch * nheads)
     _bwd_preprocess_do_o_dot[grid](
         o, do, delta,
         o.stride(0), o.stride(2), o.stride(1),
         do.stride(0), do.stride(2), do.stride(1),
-        nheads, seqlen_q, seqlen_q_rounded,
+        # nheads, seqlen_q, seqlen_q_rounded,
+        nheads, o.shape[1], seqlen_q_rounded,
         BLOCK_M=128, BLOCK_HEADDIM=d,
     )
 
     # TODO: There are 2 Memcpy DtoD when I use the autotuner.
     # BLOCK_M = 128
     # BLOCK_N = 64
     # num_warps = 4
@@ -448,95 +491,33 @@
         q.stride(0), q.stride(2), q.stride(1),
         k.stride(0), k.stride(2), k.stride(1),
         v.stride(0), v.stride(2), v.stride(1),
         do.stride(0), do.stride(2), do.stride(1),
         dq_accum.stride(0), dq_accum.stride(2), dq_accum.stride(1),
         dk.stride(0), dk.stride(2), dk.stride(1),
         dv.stride(0), dv.stride(2), dv.stride(1),
-        nheads, seqlen_q, seqlen_k, seqlen_q_rounded,
+        nheads, seqlen_q, seqlen_k, seqlen_q_rounded, do.shape[1], dq.shape[1],
         seqlen_q // 32,  seqlen_k // 32, # key for triton cache (limit number of compilations)
         # Can't use kwargs here because triton autotune expects key to be args, not kwargs
         # IS_CAUSAL=causal, BLOCK_HEADDIM=d,
         causal, d,
         # SEQUENCE_PARALLEL=False,
         # BLOCK_M=BLOCK_M, BLOCK_N=BLOCK_N,
         # num_warps=num_warps,
         # num_stages=1,
     )
-    dq.copy_(dq_accum)
-
-
-class FlashAttnQKVPackedFunc(torch.autograd.Function):
-
-    @staticmethod
-    def forward(ctx, qkv, causal=False, softmax_scale=None):
-        """
-            qkv: (batch, seqlen, 3, nheads, headdim)
-        """
-        # Make sure that the last dimension is contiguous
-        if qkv.stride(-1) != 1:
-            qkv = qkv.contiguous()
-        o, lse, ctx.softmax_scale = _flash_attn_forward(
-            qkv[:, :, 0], qkv[:, :, 1], qkv[:, :, 2], causal=causal, softmax_scale=softmax_scale
-        )
-        ctx.save_for_backward(qkv, o, lse)
-        ctx.causal = causal
-        return o
-
-    @staticmethod
-    def backward(ctx, do):
-        qkv, o, lse = ctx.saved_tensors
-        dqkv = torch.empty_like(qkv)
-        _flash_attn_backward(do, qkv[:, :, 0], qkv[:, :, 1], qkv[:, :, 2], o, lse,
-                             dqkv[:, :, 0], dqkv[:, :, 1], dqkv[:, :, 2],
-                             causal=ctx.causal, softmax_scale=ctx.softmax_scale)
-        return dqkv, None, None
-
-
-flash_attn_qkvpacked_func = FlashAttnQKVPackedFunc.apply
-
-
-class FlashAttnKVPackedFunc(torch.autograd.Function):
-
-    @staticmethod
-    def forward(ctx, q, kv, causal=False, softmax_scale=None):
-        """
-            q: (batch, seqlen, nheads, headdim)
-            kv: (batch, seqlen, 2, nheads, headdim)
-        """
-        # Make sure that the last dimension is contiguous
-        q, kv = [x if x.stride(-1) == 1 else x.contiguous() for x in [q, kv]]
-        o, lse, ctx.softmax_scale = _flash_attn_forward(
-            q, kv[:, :, 0], kv[:, :, 1], causal=causal, softmax_scale=softmax_scale
-        )
-        ctx.save_for_backward(q, kv, o, lse)
-        ctx.causal = causal
-        return o
-
-    @staticmethod
-    def backward(ctx, do):
-        q, kv, o, lse = ctx.saved_tensors
-        dq = torch.empty_like(q)
-        dkv = torch.empty_like(kv)
-        _flash_attn_backward(do, q, qkv[:, :, 0], qkv[:, :, 1], o, lse,
-                             dq, dkv[:, :, 0], dkv[:, :, 1],
-                             causal=ctx.causal, softmax_scale=ctx.softmax_scale)
-        return dq, dkv, None, None
-
-
-flash_attn_kvpacked_func = FlashAttnKVPackedFunc.apply
+    # dq.copy_(dq_accum)
+    # dq.copy_(dq_accum[:, :seqlen_q])
+    dq.copy_(dq_accum[:, :dq.shape[1]])
 
 
-class FlashAttnFunc(torch.autograd.Function):
+class _attention(torch.autograd.Function):
 
     @staticmethod
     def forward(ctx, q, k, v, causal=False, softmax_scale=None):
-        """
-            q, k, v: (batch_size, seqlen, nheads, headdim)
-        """
         # Make sure that the last dimension is contiguous
         q, k, v = [x if x.stride(-1) == 1 else x.contiguous() for x in [q, k, v]]
         o, lse, ctx.softmax_scale = _flash_attn_forward(q, k, v, causal=causal,
                                                         softmax_scale=softmax_scale)
         ctx.save_for_backward(q, k, v, o, lse)
         ctx.causal = causal
         return o
@@ -548,8 +529,8 @@
         dk = torch.empty_like(k)
         dv = torch.empty_like(v)
         _flash_attn_backward(do, q, k, v, o, lse, dq, dk, dv,
                              causal=ctx.causal, softmax_scale=ctx.softmax_scale)
         return dq, dk, dv, None, None
 
 
-flash_attn_func = FlashAttnFunc.apply
+attention = _attention.apply
```

### Comparing `flash_attn-0.2.8/flash_attn/flash_blocksparse_attention.py` & `flash_attn-1.0.0/flash_attn/flash_blocksparse_attention.py`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/flash_attn/flash_blocksparse_attn_interface.py` & `flash_attn-1.0.0/flash_attn/flash_blocksparse_attn_interface.py`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/flash_attn/fused_softmax.py` & `flash_attn-1.0.0/flash_attn/fused_softmax.py`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/flash_attn/layers/patch_embed.py` & `flash_attn-1.0.0/flash_attn/layers/patch_embed.py`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/flash_attn/layers/rotary.py` & `flash_attn-1.0.0/flash_attn/layers/rotary.py`

 * *Files 18% similar despite different names*

```diff
@@ -1,126 +1,155 @@
-# Inspired by https://github.com/facebookresearch/xformers/blob/main/xformers/components/positional_embedding/rotary.py
+# Copyright (c) 2023, Tri Dao.
 
 from typing import Tuple
 import math
 
 import torch
 
 from einops import rearrange, repeat
 
 import rotary_emb
 
 
-def rotate_half(x):
-    x1, x2 = x.chunk(2, dim=-1)
-    return torch.cat((-x2, x1), dim=-1)
+def rotate_half(x, interleaved=False):
+    if not interleaved:
+        x1, x2 = x.chunk(2, dim=-1)
+        return torch.cat((-x2, x1), dim=-1)
+    else:
+        x1, x2 = x[..., ::2], x[..., 1::2]
+        return rearrange(torch.stack((-x2, x1), dim=-1), '... d two -> ... (d two)', two=2)
 
 
-def apply_rotary_emb_torch(x, cos, sin):
+def apply_rotary_emb_torch(x, cos, sin, interleaved=False):
     """
     x: (batch_size, seqlen, nheads, headdim)
     cos, sin: (seqlen, rotary_dim / 2)
     """
-    rotary_dim = cos.shape[-1] * 2
-    assert rotary_dim <= x.shape[-1]
+    ro_dim = cos.shape[-1] * 2
+    assert ro_dim <= x.shape[-1]
     cos = repeat(cos, 's d -> s 1 (2 d)')
     sin = repeat(sin, 's d -> s 1 (2 d)')
-    return torch.cat([x[..., :rotary_dim] * cos + rotate_half(x[..., :rotary_dim]) * sin,
-                      x[..., rotary_dim:]], dim=-1)
+    return torch.cat([x[..., :ro_dim] * cos + rotate_half(x[..., :ro_dim], interleaved) * sin,
+                      x[..., ro_dim:]], dim=-1)
 
 
 class ApplyRotaryEmb(torch.autograd.Function):
 
     @staticmethod
-    def forward(ctx, x, cos, sin, inplace=False):
+    def forward(ctx, x, cos, sin, interleaved=False, inplace=False):
         """
             x: (batch_size, seqlen, nheads, headdim)
             cos, sin: (seqlen, rotary_dim / 2)
+            interleaved: if True, rotate pairs of even and odd dimensions (GPT-J style) instead
+                of 1st half and 2nd half (GPT-NeoX style).
         rotary_dim must be <= headdim
         Apply rotary embedding to the first rotary_dim of x.
         """
         batch, seqlen, nheads, headdim = x.shape
         rotary_seqlen, rotary_dim = cos.shape
         rotary_dim *= 2
         assert rotary_dim <= headdim
         assert seqlen <= rotary_seqlen
         assert sin.shape == (rotary_seqlen, rotary_dim // 2)
-        x1, x2 = x[..., :rotary_dim].chunk(2, dim=-1)
+        x_ro = x[..., :rotary_dim]
+        x1, x2 = x_ro.chunk(2, dim=-1) if not interleaved else (x_ro[..., ::2], x_ro[..., 1::2])
         out = torch.empty_like(x) if not inplace else x
-        o1, o2 = out[..., :rotary_dim].chunk(2, dim=-1) if not inplace else (x1, x2)
+        out_ro = out[..., :rotary_dim]
+        if inplace:
+            o1, o2 = x1, x2
+        else:
+            o1, o2 = (out_ro.chunk(2, dim=-1) if not interleaved
+                      else (out_ro[..., ::2], out_ro[..., 1::2]))
         rotary_emb.apply_rotary(x1, x2, rearrange(cos[:seqlen], 's d -> s 1 d'),
                                 rearrange(sin[:seqlen], 's d -> s 1 d'), o1, o2, False)
         if not inplace and rotary_dim < headdim:
             out[..., rotary_dim:].copy_(x[..., rotary_dim:])
         ctx.save_for_backward(cos, sin)
+        ctx.interleaved = interleaved
         ctx.inplace = inplace
         return out if not inplace else x
 
     @staticmethod
     def backward(ctx, do):
         cos, sin = ctx.saved_tensors
         _, seqlen, _, headdim = do.shape
         rotary_dim = cos.shape[-1]
         rotary_dim *= 2
         inplace = ctx.inplace
-        do1, do2 = do[..., :rotary_dim].chunk(2, dim=-1)
+        do_ro = do[..., :rotary_dim]
+        do1, do2 = (do_ro.chunk(2, dim=-1) if not ctx.interleaved
+                    else (do_ro[..., ::2], do_ro[..., 1::2]))
         dx = torch.empty_like(do) if not inplace else do
-        dx1, dx2 = dx[..., :rotary_dim].chunk(2, dim=-1) if not inplace else (do1, do2)
+        if inplace:
+            dx1, dx2 = do1, do2
+        else:
+            dx_ro = dx[..., :rotary_dim]
+            dx1, dx2 = (dx_ro.chunk(2, dim=-1) if not ctx.interleaved
+                        else (dx_ro[..., ::2], dx_ro[..., 1::2]))
         rotary_emb.apply_rotary(do1, do2, rearrange(cos[:seqlen], 's d -> s 1 d'),
                                 rearrange(sin[:seqlen], 's d -> s 1 d'), dx1, dx2, True)
         if not inplace and rotary_dim < headdim:
             dx[..., rotary_dim:].copy_(do[..., rotary_dim:])
-        return dx, None, None, None
+        return dx, None, None, None, None
 
 
 apply_rotary_emb_func = ApplyRotaryEmb.apply
 
 
 class ApplyRotaryEmbQKV_(torch.autograd.Function):
 
     @staticmethod
-    def forward(ctx, qkv, cos, sin, cos_k=None, sin_k=None):
+    def forward(ctx, qkv, cos, sin, cos_k=None, sin_k=None, interleaved=False):
         """
             qkv: (batch_size, seqlen, 3, nheads, headdim)
             cos, sin: (seqlen, rotary_dim / 2)
             cos_k, sin_k: (seqlen, rotary_dim / 2), optional
+            interleaved: if True, rotate pairs of even and odd dimensions (GPT-J style) instead of
+                1st half and 2nd half (GPT-NeoX style).
         rotary_dim must be <= headdim
         Apply rotary embedding *inplace* to the first rotary_dim of q and k.
         """
         batch, seqlen, three, nheads, headdim = qkv.shape
         assert three == 3
         rotary_seqlen, rotary_dim = cos.shape
         rotary_dim *= 2
         assert rotary_dim <= headdim
         assert seqlen <= rotary_seqlen
         cos_k = cos if cos_k is None else cos_k
         sin_k = sin if sin_k is None else sin_k
         assert sin.shape == cos_k.shape == sin_k.shape == (rotary_seqlen, rotary_dim // 2)
-        q1, q2 = qkv[:, :, 0, :, :rotary_dim].chunk(2, dim=-1)
+        q_ro = qkv[:, :, 0, :, :rotary_dim]
+        q1, q2 = q_ro.chunk(2, dim=-1) if not interleaved else (q_ro[..., ::2], q_ro[..., 1::2])
         rotary_emb.apply_rotary(q1, q2, rearrange(cos[:seqlen], 's d -> s 1 d'),
                                 rearrange(sin[:seqlen], 's d -> s 1 d'), q1, q2, False)
-        k1, k2 = qkv[:, :, 1, :, :rotary_dim].chunk(2, dim=-1)
+        k_ro = qkv[:, :, 1, :, :rotary_dim]
+        k1, k2 = k_ro.chunk(2, dim=-1) if not interleaved else (k_ro[..., ::2], k_ro[..., 1::2])
         rotary_emb.apply_rotary(k1, k2, rearrange(cos_k[:seqlen], 's d -> s 1 d'),
                                 rearrange(sin_k[:seqlen], 's d -> s 1 d'), k1, k2, False)
         ctx.save_for_backward(cos, sin, cos_k, sin_k)
+        ctx.interleaved = interleaved
         return qkv
 
     @staticmethod
     def backward(ctx, dqkv):
         cos, sin, cos_k, sin_k = ctx.saved_tensors
         _, seqlen, _, _, headdim = dqkv.shape
         rotary_dim = cos.shape[-1]
         rotary_dim *= 2
-        dq1, dq2 = dqkv[:, :, 0, :, :rotary_dim].chunk(2, dim=-1)
+        dq_ro = dqkv[:, :, 0, :, :rotary_dim]
+        dq1, dq2 = (dq_ro.chunk(2, dim=-1) if not ctx.interleaved
+                    else (dq_ro[..., ::2], dq_ro[..., 1::2]))
         rotary_emb.apply_rotary(dq1, dq2, rearrange(cos[:seqlen], 's d -> s 1 d'),
                                 rearrange(sin[:seqlen], 's d -> s 1 d'), dq1, dq2, True)
-        dk1, dk2 = dqkv[:, :, 1, :, :rotary_dim].chunk(2, dim=-1)
+        dk_ro = dqkv[:, :, 1, :, :rotary_dim]
+        dk1, dk2 = (dk_ro.chunk(2, dim=-1) if not ctx.interleaved
+                    else (dk_ro[..., ::2], dk_ro[..., 1::2]))
         rotary_emb.apply_rotary(dk1, dk2, rearrange(cos_k[:seqlen], 's d -> s 1 d'),
                                 rearrange(sin_k[:seqlen], 's d -> s 1 d'), dk1, dk2, True)
-        return dqkv, None, None, None, None
+        return dqkv, None, None, None, None, None
 
 
 apply_rotary_emb_qkv_ = ApplyRotaryEmbQKV_.apply
 
 
 class RotaryEmbedding(torch.nn.Module):
     """
@@ -131,30 +160,33 @@
     Other implementations are available in the Rotary Transformer repo_ and in
     GPT-NeoX_, GPT-NeoX was an inspiration
 
     .. _RoFormer: https://arxiv.org/abs/2104.09864
     .. _repo: https://github.com/ZhuiyiTechnology/roformer
     .. _GPT-NeoX: https://github.com/EleutherAI/gpt-neox
 
-    If scale_base > 0, this implements XPos (Sun et al., https://arxiv.org/abs/2212.10554).
+    If scale_base is not None, this implements XPos (Sun et al., https://arxiv.org/abs/2212.10554).
     A recommended value for scale_base is 512: https://github.com/HazyResearch/flash-attention/issues/96
     Reference: https://github.com/sunyt32/torchscale/blob/main/torchscale/component/xpos_relative_position.py
     """
 
-    def __init__(self, dim: int, base=10000, scale_base=0, device=None):
+    def __init__(self, dim: int, base=10000, interleaved=False, scale_base=None, device=None):
         """
+            interleaved: if True, rotate pairs of even and odd dimensions (GPT-J style) instead
+                of 1st half and 2nd half (GPT-NeoX style).
         """
         super().__init__()
         # Generate and save the inverse frequency buffer (non trainable)
         inv_freq = 1.0 / (base ** (torch.arange(0, dim, 2, device=device,
                                                 dtype=torch.float32) / dim))
         self.register_buffer("inv_freq", inv_freq)
+        self.interleaved = interleaved
         self.scale_base = scale_base
         scale = ((torch.arange(0, dim, 2, device=device, dtype=torch.float32) + 0.4 * dim)
-                 / (1.4 * dim) if scale_base > 0 else None)
+                 / (1.4 * dim) if scale_base is not None else None)
         self.register_buffer("scale", scale)
 
         self._seq_len_cached = 0
         self._cos_cached = None
         self._sin_cached = None
         self._cos_k_cached = None
         self._sin_k_cached = None
@@ -183,20 +215,23 @@
                 self._cos_cached = (torch.cos(freqs) * scale).to(x.dtype)
                 self._sin_cached = (torch.sin(freqs) * scale).to(x.dtype)
                 self._cos_k_cached = (torch.cos(freqs) / scale).to(x.dtype)
                 self._sin_k_cached = (torch.sin(freqs) / scale).to(x.dtype)
 
     def forward(self, qkv: torch.Tensor, seqlen_offset: int = 0) -> Tuple[torch.Tensor, torch.Tensor]:
         """
+        qkv: (batch, seqlen, 3, nheads, headdim)
         seqlen_offset: can be used in generation where the qkv being passed in is only the last
         token in the batch.
         """
         self._update_cos_sin_cache(qkv, seqlen_offset)
         if self.scale is None:
             return apply_rotary_emb_qkv_(
-                qkv, self._cos_cached[seqlen_offset:], self._sin_cached[seqlen_offset:]
+                qkv, self._cos_cached[seqlen_offset:], self._sin_cached[seqlen_offset:],
+                None, None, self.interleaved
             )
         else:
             return apply_rotary_emb_qkv_(
                 qkv, self._cos_cached[seqlen_offset:], self._sin_cached[seqlen_offset:],
-                self._cos_k_cached[seqlen_offset:], self._sin_k_cached[seqlen_offset:]
+                self._cos_k_cached[seqlen_offset:], self._sin_k_cached[seqlen_offset:],
+                self.interleaved
             )
```

### Comparing `flash_attn-0.2.8/flash_attn/losses/cross_entropy.py` & `flash_attn-1.0.0/flash_attn/losses/cross_entropy.py`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/flash_attn/losses/cross_entropy_apex.py` & `flash_attn-1.0.0/flash_attn/losses/cross_entropy_apex.py`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/flash_attn/losses/cross_entropy_parallel.py` & `flash_attn-1.0.0/flash_attn/losses/cross_entropy_parallel.py`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/flash_attn/models/bert.py` & `flash_attn-1.0.0/flash_attn/models/bert.py`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/flash_attn/models/gpt.py` & `flash_attn-1.0.0/flash_attn/models/gpt.py`

 * *Files 18% similar despite different names*

```diff
@@ -14,35 +14,43 @@
 
 from transformers import GPT2Config
 
 from einops import rearrange
 
 from flash_attn.modules.mha import MHA, ParallelMHA
 from flash_attn.modules.mlp import Mlp, FusedMLP, ParallelFusedMLP
-from flash_attn.modules.block import Block
+from flash_attn.modules.block import Block, ParallelBlock
 from flash_attn.modules.embedding import GPT2Embeddings, ParallelGPT2Embeddings
 from flash_attn.utils.distributed import sync_shared_params, all_gather_raw
 from flash_attn.utils.pretrained import state_dict_from_pretrained
 from flash_attn.utils.generation import GenerationMixin
-from flash_attn.models.opt import remap_state_dict_opt
+from flash_attn.models.opt import remap_state_dict_hf_opt
+from flash_attn.models.gptj import remap_state_dict_hf_gptj
+from flash_attn.models.gpt_neox import remap_state_dict_hf_gpt_neox
 
 try:
     from flash_attn.ops.fused_dense import ColumnParallelLinear
 except ImportError:
     ColumnParallelLinear = None
 
 try:
     from flash_attn.ops.layer_norm import dropout_add_layer_norm
 except ImportError:
     dropout_add_layer_norm = None
 
 try:
-    from flash_attn.ops.triton.mlp import FusedDenseSqreluDense
+    from flash_attn.ops.layer_norm import dropout_add_layer_norm_parallel_residual
+except ImportError:
+    dropout_add_layer_norm_parallel_residual = None
+
+try:
+    from flash_attn.ops.triton.mlp import FusedDenseSqreluDense, sqrelu_fwd
 except ImportError:
     FusedDenseSqreluDense = None
+    sqrelu_fwd = None
 
 
 logger = logging.getLogger(__name__)
 
 
 def create_mixer_cls(config, layer_idx=None, process_group=None, device=None, dtype=None):
     factory_kwargs = {'device': device, 'dtype': dtype}
@@ -50,29 +58,35 @@
     softmax_scale = 1.0 if not config.scale_attn_weights else head_dim ** (-0.5)
     if config.scale_attn_by_inverse_layer_idx:
         assert layer_idx is not None
         softmax_scale /= float(layer_idx + 1)
     dwconv = getattr(config, 'attn_dwconv', False)
     if dwconv:
         assert process_group is None, 'TensorParallel MHA does not support dwconv yet'
+    qkv_proj_bias = getattr(config, 'qkv_proj_bias', True)
+    out_proj_bias = getattr(config, 'out_proj_bias', True)
     rotary_emb_dim = int(getattr(config, 'rotary_emb_fraction', 0.0) * head_dim)
-    rotary_emb_scale_base = getattr(config, 'rotary_emb_scale_base', 0)
+    rotary_emb_scale_base = getattr(config, 'rotary_emb_scale_base', None)
+    rotary_emb_interleaved = getattr(config, 'rotary_emb_interleaved', False)
     use_flash_attn = getattr(config, 'use_flash_attn', False)
     fused_bias_fc = getattr(config, 'fused_bias_fc', False)
     if not fused_bias_fc:
         assert process_group is None, 'TensorParallel MHA requires fused_bias_fc'
     mha_cls = MHA if process_group is None else ParallelMHA
     serial_kwargs = ({'fused_bias_fc': fused_bias_fc, 'dwconv': dwconv}
                      if process_group is None else {})
     parallel_kwargs = ({'process_group': process_group,
                         'sequence_parallel': getattr(config, 'sequence_parallel', True)}
                        if process_group is not None else {})
-    mixer_cls = partial(mha_cls, num_heads=config.num_attention_heads, dropout=config.attn_pdrop,
+    mixer_cls = partial(mha_cls, num_heads=config.num_attention_heads,
+                        qkv_proj_bias=qkv_proj_bias, out_proj_bias=out_proj_bias,
+                        dropout=config.attn_pdrop,
                         softmax_scale=softmax_scale, causal=True, layer_idx=layer_idx,
                         rotary_emb_dim=rotary_emb_dim, rotary_emb_scale_base=rotary_emb_scale_base,
+                        rotary_emb_interleaved=rotary_emb_interleaved,
                         use_flash_attn=use_flash_attn,
                         **serial_kwargs, **parallel_kwargs, **factory_kwargs)
     return mixer_cls
 
 
 def create_mlp_cls(config, layer_idx=None, process_group=None, device=None, dtype=None):
     factory_kwargs = {'device': device, 'dtype': dtype}
@@ -84,16 +98,20 @@
     if fused_dense_sqrelu_dense:
         assert config.activation_function == 'sqrelu', ('fused_dense_sqrelu_dense only '
                                                'supports approximate activation_function sqrelu')
     assert not (fused_dense_sqrelu_dense and fused_mlp)
     if process_group is not None:
         assert fused_mlp, 'Tensor Parallel is only implemented for FusedMLP'
     if not fused_mlp and not fused_dense_sqrelu_dense:
+        assert config.activation_function in ['gelu_new', 'gelu_fast', 'gelu_approx', 'relu', 'sqrelu']
         if config.activation_function == 'relu':
             activation = partial(F.relu, inplace=True)
+        elif config.activation_function == 'sqrelu':
+            assert sqrelu_fwd is not None, 'sqrelu_fwd is not implemented'
+            activation = sqrelu_fwd
         else:
             approximate = ('tanh' if config.activation_function
                            in ['gelu_new', 'gelu_fast', 'gelu_approx'] else 'none')
             activation=partial(F.gelu, approximate=approximate)
         mlp_cls = partial(Mlp, hidden_features=inner_dim, activation=activation, **factory_kwargs)
     else:
         mlp_checkpoint_lvl = getattr(config, 'mlp_checkpoint_lvl', 0)
@@ -128,20 +146,35 @@
     mixer_cls = create_mixer_cls(config, layer_idx, process_group=process_group, **factory_kwargs)
     mlp_cls = create_mlp_cls(config, layer_idx, process_group=process_group, **factory_kwargs)
     norm_cls = partial(nn.LayerNorm, eps=config.layer_norm_epsilon, **factory_kwargs)
     # TD [2022-07-30]: Force residual in fp32, seems to make fp16 training more stable
     residual_in_fp32 = getattr(config, 'residual_in_fp32', False)
     resid_dropout1 = config.resid_pdrop if layer_idx is None or layer_idx > 0 else config.embd_pdrop
     prenorm = getattr(config, 'prenorm', True)
-    block = Block(config.hidden_size, mixer_cls, mlp_cls, norm_cls=norm_cls,
-                  prenorm=prenorm, resid_dropout1=resid_dropout1, resid_dropout2=config.resid_pdrop,
-                  fused_dropout_add_ln=getattr(config, 'fused_dropout_add_ln', False),
-                  residual_in_fp32=residual_in_fp32,
-                  sequence_parallel=sequence_parallel and process_group is not None,
-                  mark_shared_params=process_group is not None)
+    parallel_block = getattr(config, 'parallel_block', False)
+    if not parallel_block:
+        block = Block(
+            config.hidden_size, mixer_cls, mlp_cls, norm_cls=norm_cls,
+            prenorm=prenorm, resid_dropout1=resid_dropout1, resid_dropout2=config.resid_pdrop,
+            fused_dropout_add_ln=getattr(config, 'fused_dropout_add_ln', False),
+            residual_in_fp32=residual_in_fp32,
+            sequence_parallel=sequence_parallel and process_group is not None,
+            mark_shared_params=process_group is not None
+        )
+    else:
+        assert prenorm
+        block = ParallelBlock(
+            config.hidden_size, mixer_cls, mlp_cls, norm_cls=norm_cls,
+            resid_dropout1=resid_dropout1, resid_dropout2=config.resid_pdrop,
+            tied_norm=getattr(config, 'parallel_block_tied_norm', False),
+            fused_dropout_add_ln=getattr(config, 'fused_dropout_add_ln', False),
+            residual_in_fp32=residual_in_fp32,
+            sequence_parallel=sequence_parallel and process_group is not None,
+            mark_shared_params=process_group is not None
+        )
     block.layer_idx = layer_idx
     return block
 
 
 class GPTPreTrainedModel(nn.Module):
     """ An abstract class to handle weights initialization and
         a simple interface for dowloading and loading pretrained models.
@@ -162,27 +195,32 @@
                         world_size=1, rank=0, **kwargs):
         """
         Instantiate a GPTPreTrainedModel from a pre-trained model file or a pytorch state dict.
         Download and cache the pre-trained model file if needed.
         """
         # Instantiate model.
         model = cls(config, *args, device=device, dtype=dtype, **kwargs)
-        # If we're going to shard the model, then don't load fp32 weights to GPU.
+        # Load state_dict in cpu because we already initialized the model in GPU, and we don't
+        # want extra stuff taking up more GPU memory
         state_dict = state_dict_from_pretrained(
-            model_name, device=device if world_size == 1 else None, dtype=dtype
+            model_name, device='cpu', dtype=dtype
         )
         if model_name.startswith('gpt2'):
-            state_dict = remap_state_dict_gpt2(state_dict, config)
+            state_dict = remap_state_dict_hf_gpt2(state_dict, config)
         elif model_name.startswith('facebook/opt'):
-            state_dict = remap_state_dict_opt(state_dict, config)
+            state_dict = remap_state_dict_hf_opt(state_dict, config)
+        elif model_name.startswith('EleutherAI/gpt-j-'):
+            state_dict = remap_state_dict_hf_gptj(state_dict, config)
+            strict = False  # We have rotary_emb.inf_freq buffers not in the GPT-J checkpoint
+        elif model_name.startswith('EleutherAI/gpt-neox-'):
+            state_dict = remap_state_dict_hf_gpt_neox(state_dict, config)
         else:
             raise NotImplementedError(f'Model {model_name} not supported')
         if world_size > 1:
             state_dict = shard_state_dict_tp(state_dict, config, world_size, rank)
-            state_dict = {k: v.to(device=device) for k, v in state_dict.items()}
         load_return = model.load_state_dict(state_dict, strict=strict)
         logger.info(load_return)
         return model
 
 
 # https://github.com/huggingface/transformers/blob/c28d04e9e252a1a099944e325685f14d242ecdcd/src/transformers/models/gpt2/modeling_gpt2.py#L454
 def _init_weights(module, n_layer, initializer_range=0.02, rescale_prenorm_residual=True):
@@ -219,14 +257,16 @@
         vocab_size = (math.ceil(config.vocab_size / pad_vocab_size_multiple)
                       * pad_vocab_size_multiple)
         # TD [2022-07-30]: Force residual in fp32, seems to make fp16 training more stable
         self.residual_in_fp32 = getattr(config, 'residual_in_fp32', False)
         # These 2 options are for OPT-350m
         self.prenorm = getattr(config, 'prenorm', True)
         word_embed_proj_dim = getattr(config, 'word_embed_proj_dim', None)
+        # For GPT-J, GPT-NeoX
+        self.parallel_block = getattr(config, 'parallel_block', False)
 
         if process_group is None:
             self.embeddings = GPT2Embeddings(
                 config.hidden_size, vocab_size, config.max_position_embeddings,
                 word_embed_proj_dim=word_embed_proj_dim, **factory_kwargs
             )
         else:
@@ -243,16 +283,18 @@
         # nn.Dropout probabilities are changed.
         # This is for performance reason: we can fuse dropout + add + layer_norm.
         self.layers = nn.ModuleList([create_block(config, layer_idx=i, process_group=process_group,
                                                   **factory_kwargs)
                                      for i in range(config.num_hidden_layers)])
 
         self.fused_dropout_add_ln = getattr(config, 'fused_dropout_add_ln', False)
-        if self.fused_dropout_add_ln and dropout_add_layer_norm is None:
-            raise ImportError('dropout_add_layer_norm is not installed')
+        if self.fused_dropout_add_ln:
+            if ((not self.parallel_block and dropout_add_layer_norm is None)
+                or (self.parallel_block and dropout_add_layer_norm_parallel_residual is None)):
+                raise ImportError('dropout_layer_norm is not installed')
         if self.prenorm:
             self.drop_f = nn.Dropout(config.resid_pdrop)
             self.ln_f = nn.LayerNorm(config.hidden_size, eps=config.layer_norm_epsilon,
                                     **factory_kwargs)
         if process_group is not None:
             for p in self.ln_f.parameters():
                 # Mark the norm parameters as "shared_params" so that we sync their values at init.
@@ -272,72 +314,95 @@
     def forward(self, input_ids, position_ids=None, inference_params=None):
         # If using Tensor Parallel with sequence parallel, we combine the batch and the seqlen
         # dimensions so that we can split on it easily, in case of small batch size.
         # Only the attention layers need to know the seqlen.
         embedding_kwargs = ({'combine_batch_seqlen_dim': True}
                             if self.process_group is not None and self.sequence_parallel else {})
         hidden_states = self.embeddings(input_ids, position_ids=position_ids, **embedding_kwargs)
+        if self.parallel_block:
+            hidden_states2 = None
         residual = None
         mixer_kwargs = ({'seqlen': input_ids.shape[1]}
                         if self.process_group is not None and self.sequence_parallel else {})
         if inference_params is not None:
             mixer_kwargs['inference_params'] = inference_params
         for layer in self.layers:
             if self.prenorm:
-                hidden_states, residual = layer(hidden_states, residual, mixer_kwargs=mixer_kwargs)
+                if not self.parallel_block:
+                    hidden_states, residual = layer(hidden_states, residual,
+                                                    mixer_kwargs=mixer_kwargs)
+                else:
+                    hidden_states, hidden_states2, residual = layer(
+                        hidden_states, hidden_states2, residual, mixer_kwargs=mixer_kwargs
+                    )
             else:
                 hidden_states = layer(hidden_states, mixer_kwargs=mixer_kwargs)
         if self.prenorm:
             if not self.fused_dropout_add_ln:
                 dropped = self.drop_f(hidden_states)
-                residual = (dropped + residual) if residual is not None else dropped
+                if not self.parallel_block:
+                    residual = (dropped + residual) if residual is not None else dropped
+                else:
+                    dropped2 = self.drop_f(hidden_states2)
+                    residual = ((residual + dropped + dropped2)
+                                if residual is not None else dropped + dropped2)
                 hidden_states = self.ln_f(residual.to(dtype=self.ln_f.weight.dtype))
             else:
                 # Set prenorm=False here since we don't need the residual
-                hidden_states = dropout_add_layer_norm(
-                    hidden_states, residual, self.ln_f.weight, self.ln_f.bias,
-                    self.drop_f.p if self.training else 0.0, self.ln_f.eps, prenorm=False,
-                    residual_in_fp32=self.residual_in_fp32
-                )
+                if not self.parallel_block:
+                    hidden_states = dropout_add_layer_norm(
+                        hidden_states, residual, self.ln_f.weight, self.ln_f.bias,
+                        self.drop_f.p if self.training else 0.0, self.ln_f.eps, prenorm=False,
+                        residual_in_fp32=self.residual_in_fp32
+                    )
+                else:
+                    hidden_states, _ = dropout_add_layer_norm_parallel_residual(
+                        hidden_states, hidden_states2, residual, self.ln_f.weight, self.ln_f.bias,
+                        None, None, self.drop_f.p if self.training else 0.0, self.ln_f.eps,
+                        prenorm=False, residual_in_fp32=self.residual_in_fp32
+                    )
         return hidden_states
 
 
 class GPTLMHeadModel(GPTPreTrainedModel, GenerationMixin):
 
     def __init__(self, config: GPT2Config, process_group=None, device=None, dtype=None):
         factory_kwargs = {'device': device, 'dtype': dtype}
         super().__init__(config)
         self.process_group = process_group
         self.transformer = GPTModel(config, process_group=process_group, **factory_kwargs)
+        self.tie_word_embeddings = getattr(config, 'tie_word_embeddings', True)
+        lm_head_bias = getattr(config, 'lm_head_bias', False)
         pad_vocab_size_multiple = getattr(config, 'pad_vocab_size_multiple', 1)
         vocab_size = (math.ceil(config.vocab_size / pad_vocab_size_multiple)
                       * pad_vocab_size_multiple)
         # This option is for OPT-350m
         word_embed_proj_dim = getattr(config, 'word_embed_proj_dim', None)
         embed_dim = config.n_embd if word_embed_proj_dim is None else word_embed_proj_dim
         if word_embed_proj_dim is not None:
             self.project_out = nn.Linear(config.n_embd, embed_dim, bias=False, **factory_kwargs)
         else:
             self.project_out = None
         if process_group is None:
-            self.lm_head = nn.Linear(embed_dim, vocab_size, bias=False, **factory_kwargs)
+            self.lm_head = nn.Linear(embed_dim, vocab_size, bias=lm_head_bias, **factory_kwargs)
         else:
             if ColumnParallelLinear is None:
                 raise ImportError('fused_dense_lib is not installed')
             self.lm_head = ColumnParallelLinear(
-                embed_dim, vocab_size, process_group, bias=False,
+                embed_dim, vocab_size, process_group, bias=lm_head_bias,
                 sequence_parallel=getattr(config, 'sequence_parallel', True), **factory_kwargs
             )
         # Initialize weights and apply final processing
         self.apply(partial(_init_weights, n_layer=config.num_hidden_layers,
                            initializer_range=config.initializer_range))
         self.tie_weights()
 
     def tie_weights(self):
-        self.lm_head.weight = self.transformer.embeddings.word_embeddings.weight
+        if self.tie_word_embeddings:
+            self.lm_head.weight = self.transformer.embeddings.word_embeddings.weight
         if self.process_group is not None:
             sync_shared_params(self, self.process_group)
 
     def forward(self, input_ids, position_ids=None, inference_params=None):
         """
             inference_params: for generation. Adapted from Megatron-LM (and Apex)
             https://github.com/NVIDIA/apex/blob/3ff1a10f72ec07067c4e44759442329804ac5162/apex/transformer/testing/standalone_transformer_lm.py#L470
@@ -377,15 +442,103 @@
             ln_weight = state_dict.pop('transformer.ln_0.weight')
             ln_bias = state_dict.pop('transformer.ln_0.bias')
             state_dict[f'transformer.layers.0.norm1.weight'] = ln_weight
             state_dict[f'transformer.layers.0.norm1.bias'] = ln_bias
         return super().load_state_dict(state_dict, strict=strict)
 
 
-def remap_state_dict_gpt2(state_dict, config):
+def shard_state_dict_tp(state_dict, config, world_size, rank):
+    """Convert the state_dict of a standard GPT model to the state_dict of a GPT model
+    with tensor parallel.
+    """
+    pad_vocab_size_multiple = getattr(config, 'pad_vocab_size_multiple', 1)
+    vocab_size = (math.ceil(config.vocab_size / pad_vocab_size_multiple) * pad_vocab_size_multiple)
+    assert vocab_size % world_size == 0
+    assert config.hidden_size % world_size == 0
+    inner_dim = config.n_inner if config.n_inner is not None else 4 * config.hidden_size
+    assert inner_dim % world_size == 0
+
+    def shard_first_dim(state_dict, key):
+        x = state_dict[key]
+        dim = x.shape[0] // world_size
+        state_dict[key] = x[rank * dim:(rank + 1) * dim]
+
+    def shard_last_dim(state_dict, key):
+        x = state_dict[key]
+        dim = x.shape[-1] // world_size
+        state_dict[key] = x[..., rank * dim:(rank + 1) * dim]
+
+    def shard_qkv_headdim(state_dict, key):
+        x = rearrange(state_dict[key], '(three d) ... -> three d ...', three=3)
+        dim = x.shape[1] // world_size
+        state_dict[key] = rearrange(x[:, rank * dim:(rank + 1) * dim],
+                                    'three d ... -> (three d) ...')
+
+    shard_first_dim(state_dict, 'transformer.embeddings.word_embeddings.weight')
+    if 'lm_head.weight' in state_dict:
+        shard_first_dim(state_dict, 'lm_head.weight')
+    if 'transformer.embeddings.position_embeddings.weight' in state_dict:
+        shard_last_dim(state_dict, 'transformer.embeddings.position_embeddings.weight')
+    for i in range(config.num_hidden_layers):
+        shard_qkv_headdim(state_dict, f'transformer.layers.{i}.mixer.Wqkv.weight')
+        shard_qkv_headdim(state_dict, f'transformer.layers.{i}.mixer.Wqkv.bias')
+        shard_last_dim(state_dict, f'transformer.layers.{i}.mixer.out_proj.weight')
+        if rank != 0:
+            state_dict.pop(f'transformer.layers.{i}.mixer.out_proj.bias')
+        shard_first_dim(state_dict, f'transformer.layers.{i}.mlp.fc1.weight')
+        shard_first_dim(state_dict, f'transformer.layers.{i}.mlp.fc1.bias')
+        shard_last_dim(state_dict, f'transformer.layers.{i}.mlp.fc2.weight')
+        if rank != 0:
+            state_dict.pop(f'transformer.layers.{i}.mlp.fc2.bias')
+    return state_dict
+
+
+def combine_state_dicts_tp(state_dicts, config):
+    """Convert the state_dict of a standard GPT model to the state_dict of a GPT model
+    with tensor parallel.
+    """
+    world_size = len(state_dicts)
+    keys = state_dicts[0].keys()
+    pad_vocab_size_multiple = getattr(config, 'pad_vocab_size_multiple', 1)
+    vocab_size = (math.ceil(config.vocab_size / pad_vocab_size_multiple) * pad_vocab_size_multiple)
+    assert vocab_size % world_size == 0
+    assert config.hidden_size % world_size == 0
+    inner_dim = config.n_inner if config.n_inner is not None else 4 * config.hidden_size
+    assert inner_dim % world_size == 0
+
+    # The word embeddings from Megatron are weird, for each shard only the first
+    # vocab_size // world_size coordinates are nonzero.
+    def combine_word_embeddings(state_dicts, state_dict, key):
+        assert all(s[key].shape[0] == vocab_size for s in state_dicts)
+        state_dict[key] = torch.cat([s[key][:vocab_size // world_size] for s in state_dicts], dim=0)
+
+    def combine_dim(state_dicts, state_dict, key, dim=-1):
+        state_dict[key] = torch.cat([s[key] for s in state_dicts], dim=dim)
+
+    def combine_qkv_headdim(state_dicts, state_dict, key):
+        xs = [rearrange(s[key], '(three d) ... -> three d ...', three=3) for s in state_dicts]
+        state_dict[key] = rearrange(torch.cat(xs, dim=1), 'three d ... -> (three d) ...')
+
+    state_dict = state_dicts[0].copy()  # don't modify state_dict[0] inplace
+    combine_word_embeddings(state_dicts, state_dict, 'transformer.embeddings.word_embeddings.weight')
+    if 'lm_head.weight' in state_dict:
+        combine_word_embeddings(state_dicts, state_dict, 'lm_head.weight')
+    if 'transformer.embeddings.position_embeddings.weight' in state_dict:
+        combine_dim(state_dicts, state_dict, 'transformer.embeddings.position_embeddings.weight', -1)
+    for i in range(config.num_hidden_layers):
+        combine_qkv_headdim(state_dicts, state_dict, f'transformer.layers.{i}.mixer.Wqkv.weight')
+        combine_qkv_headdim(state_dicts, state_dict, f'transformer.layers.{i}.mixer.Wqkv.bias')
+        combine_dim(state_dicts, state_dict, f'transformer.layers.{i}.mixer.out_proj.weight', -1)
+        combine_dim(state_dicts, state_dict, f'transformer.layers.{i}.mlp.fc1.weight', 0)
+        combine_dim(state_dicts, state_dict, f'transformer.layers.{i}.mlp.fc1.bias', 0)
+        combine_dim(state_dicts, state_dict, f'transformer.layers.{i}.mlp.fc2.weight', -1)
+    return state_dict
+
+
+def remap_state_dict_hf_gpt2(state_dict, config):
     # Word embedding and position embedding
     def key_mapping_pos_emb(key):
         return re.sub(r'^wpe.', 'transformer.embeddings.position_embeddings.', key)
     state_dict = OrderedDict((key_mapping_pos_emb(k), v) for k, v in state_dict.items())
     word_embeddings = state_dict.pop('wte.weight')
     # It's possible that vocab_size is padded to be a multiple of 8, for example.
     pad_vocab_size_multiple = getattr(config, 'pad_vocab_size_multiple', 1)
@@ -426,51 +579,71 @@
         key = re.sub(r'^h.(\d+).attn.c_proj.bias', r'transformer.layers.\1.mixer.out_proj.bias', key)
         return key
     state_dict = OrderedDict((key_mapping_attn(k), v) for k, v in state_dict.items())
 
     return state_dict
 
 
-def shard_state_dict_tp(state_dict, config, world_size, rank):
-    """Convert the state_dict of a standard GPT model to the state_dict of a GPT model
-    with tensor parallel.
-    """
+def remap_state_dict_megatron(state_dict, config):
+    def key_mapping_transformer(key):
+        key = re.sub(r'^language_model.encoder.', 'transformer.', key)
+        key = re.sub(r'^language_model.', 'transformer.', key)
+        return key
+    state_dict = OrderedDict((key_mapping_transformer(k), v) for k, v in state_dict.items())
+    # Word embedding and position embedding
+    def key_mapping_pos_emb(key):
+        return re.sub(r'^wpe.', 'transformer.embeddings.position_embeddings.', key)
+    state_dict = OrderedDict((key_mapping_pos_emb(k), v) for k, v in state_dict.items())
+    word_embeddings = state_dict.pop('transformer.embedding.word_embeddings.weight')
+    # It's possible that vocab_size is padded to be a multiple of 8, for example.
     pad_vocab_size_multiple = getattr(config, 'pad_vocab_size_multiple', 1)
     vocab_size = (math.ceil(config.vocab_size / pad_vocab_size_multiple) * pad_vocab_size_multiple)
-    assert vocab_size % world_size == 0
-    assert config.hidden_size % world_size == 0
-    inner_dim = config.n_inner if config.n_inner is not None else 4 * config.hidden_size
-    assert inner_dim % world_size == 0
+    state_dict['transformer.embeddings.word_embeddings.weight'] = F.pad(
+        word_embeddings, (0, 0, 0, vocab_size - word_embeddings.shape[0])
+    )
+    state_dict['lm_head.weight'] = state_dict['transformer.embeddings.word_embeddings.weight']
 
-    def shard_first_dim(state_dict, key):
-        x = state_dict[key]
-        dim = x.shape[0] // world_size
-        state_dict[key] = x[rank * dim:(rank + 1) * dim]
+    # LayerNorm
+    def key_mapping_ln(key):
+        key = re.sub(r'^transformer.final_layernorm.(weight|bias)', r'transformer.ln_f.\1', key)
+        key = re.sub(r'^transformer.layers.(\d+).input_layernorm.(weight|bias)',
+                     r'transformer.layers.\1.norm1.\2', key)
+        key = re.sub(r'^transformer.layers.(\d+).post_attention_layernorm.(weight|bias)',
+                     r'transformer.layers.\1.norm2.\2', key)
+        return key
+    state_dict = OrderedDict((key_mapping_ln(k), v) for k, v in state_dict.items())
 
-    def shard_last_dim(state_dict, key):
-        x = state_dict[key]
-        dim = x.shape[-1] // world_size
-        state_dict[key] = x[..., rank * dim:(rank + 1) * dim]
+    # MLP
+    def key_mapping_mlp(key):
+        key = re.sub(r'^transformer.layers.(\d+).mlp.dense_h_to_4h.(weight|bias)',
+                     r'transformer.layers.\1.mlp.fc1.\2', key)
+        key = re.sub(r'^transformer.layers.(\d+).mlp.dense_4h_to_h.(weight|bias)',
+                     r'transformer.layers.\1.mlp.fc2.\2', key)
+        return key
+    state_dict = OrderedDict((key_mapping_mlp(k), v) for k, v in state_dict.items())
 
-    def shard_qkv_headdim(state_dict, key):
-        x = rearrange(state_dict[key], '(three d) ... -> three d ...', three=3)
-        dim = x.shape[1] // world_size
-        state_dict[key] = rearrange(x[:, rank * dim:(rank + 1) * dim],
-                                    'three d ... -> (three d) ...')
+    # Attention
+    def key_mapping_attn(key):
+        key = re.sub(r'^transformer.layers.(\d+).self_attention.rotary_emb.inv_freq',
+                     r'transformer.layers.\1.mixer.rotary_emb.inv_freq', key)
+        key = re.sub(r'^transformer.layers.(\d+).self_attention.query_key_value.(weight|bias)',
+                     r'transformer.layers.\1.mixer.Wqkv.\2', key)
+        key = re.sub(r'^transformer.layers.(\d+).self_attention.dense.(weight|bias)',
+                     r'transformer.layers.\1.mixer.out_proj.\2', key)
+        return key
+    state_dict = OrderedDict((key_mapping_attn(k), v) for k, v in state_dict.items())
+    # Megatron stores Wqkv as ((nheads 3 headdim), hidden_dim)
+    # while we store Wqkv as ((3 nheads headdim), hidden_dim)
+    headdim = config.hidden_size // config.num_attention_heads
+    for d in range(config.num_hidden_layers):
+        Wqkv = state_dict.pop(f'transformer.layers.{d}.mixer.Wqkv.weight')
+        state_dict[f'transformer.layers.{d}.mixer.Wqkv.weight'] = rearrange(
+            Wqkv, '(nheads three headdim) ... -> (three nheads headdim) ...',
+            three=3, headdim=headdim
+        )
+        bqkv = state_dict.pop(f'transformer.layers.{d}.mixer.Wqkv.bias')
+        state_dict[f'transformer.layers.{d}.mixer.Wqkv.bias'] = rearrange(
+            bqkv, '(nheads three headdim) -> (three nheads headdim)',
+            three=3, headdim=headdim
+        )
 
-    shard_first_dim(state_dict, 'transformer.embeddings.word_embeddings.weight')
-    if 'lm_head.weight' in state_dict:
-        shard_first_dim(state_dict, 'lm_head.weight')
-    if 'transformer.embeddings.position_embeddings.weight' in state_dict:
-        shard_last_dim(state_dict, 'transformer.embeddings.position_embeddings.weight')
-    for i in range(config.num_hidden_layers):
-        shard_qkv_headdim(state_dict, f'transformer.layers.{i}.mixer.Wqkv.weight')
-        shard_qkv_headdim(state_dict, f'transformer.layers.{i}.mixer.Wqkv.bias')
-        shard_last_dim(state_dict, f'transformer.layers.{i}.mixer.out_proj.weight')
-        if rank != 0:
-            state_dict.pop(f'transformer.layers.{i}.mixer.out_proj.bias')
-        shard_first_dim(state_dict, f'transformer.layers.{i}.mlp.fc1.weight')
-        shard_first_dim(state_dict, f'transformer.layers.{i}.mlp.fc1.bias')
-        shard_last_dim(state_dict, f'transformer.layers.{i}.mlp.fc2.weight')
-        if rank != 0:
-            state_dict.pop(f'transformer.layers.{i}.mlp.fc2.bias')
     return state_dict
```

### Comparing `flash_attn-0.2.8/flash_attn/models/opt.py` & `flash_attn-1.0.0/flash_attn/models/opt.py`

 * *Files 3% similar despite different names*

```diff
@@ -7,15 +7,15 @@
 
 import torch
 import torch.nn.functional as F
 
 from transformers import GPT2Config, OPTConfig
 
 
-def remap_state_dict_opt(state_dict, config):
+def remap_state_dict_hf_opt(state_dict, config):
     def key_mapping_model(key):
         key = re.sub(r'^model.decoder.', 'transformer.', key)
         # The OPT-350m model uses '^decoder' instead of '^model.decoder'
         key = re.sub(r'^decoder.', 'transformer.', key)
         return key
     state_dict = OrderedDict((key_mapping_model(k), v) for k, v in state_dict.items())
     # Word embedding and position embedding
@@ -39,14 +39,16 @@
         word_embeddings, (0, 0, 0, vocab_size - word_embeddings.shape[0])
     )
     state_dict['lm_head.weight'] = state_dict['transformer.embeddings.word_embeddings.weight']
 
     # LayerNorm
     def key_mapping_ln(key):
         key = re.sub(r'^transformer.final_layer_norm.', r'transformer.ln_f.', key)
+        # The OPT-175B checkpoint calls this 'decoder.layer_norm' instead of 'decoder.final_layer_norm'
+        key = re.sub(r'^transformer.layer_norm.', r'transformer.ln_f.', key)
         key = re.sub(r'^transformer.layers.(\d+).self_attn_layer_norm.',
                      r'transformer.layers.\1.norm1.', key)
         key = re.sub(r'^transformer.layers.(\d+).final_layer_norm.',
                      r'transformer.layers.\1.norm2.', key)
         return key
     state_dict = OrderedDict((key_mapping_ln(k), v) for k, v in state_dict.items())
```

### Comparing `flash_attn-0.2.8/flash_attn/models/vit.py` & `flash_attn-1.0.0/flash_attn/models/vit.py`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/flash_attn/modules/block.py` & `flash_attn-1.0.0/flash_attn/modules/block.py`

 * *Files 27% similar despite different names*

```diff
@@ -14,14 +14,19 @@
 from flash_attn.modules.mlp import Mlp
 
 try:
     from flash_attn.ops.layer_norm import dropout_add_layer_norm
 except ImportError:
     dropout_add_layer_norm = None
 
+try:
+    from flash_attn.ops.layer_norm import dropout_add_layer_norm_parallel_residual
+except ImportError:
+    dropout_add_layer_norm_parallel_residual = None
+
 
 class Block(nn.Module):
 
     def __init__(self, dim, mixer_cls=None, mlp_cls=None, norm_cls=nn.LayerNorm,
                  dropout_cls=nn.Dropout, prenorm=True, resid_dropout1=0., resid_dropout2=0.,
                  drop_path1=0., drop_path2=0., fused_dropout_add_ln=False, return_residual=False,
                  residual_in_fp32=False, sequence_parallel=False, mark_shared_params=False):
@@ -60,15 +65,15 @@
         self.mlp = mlp_cls(dim)
         if not isinstance(self.mlp, nn.Identity):
             self.dropout2 = dropout_cls(resid_dropout2)
             self.drop_path2 = StochasticDepth(drop_path2, mode='row')
             self.norm2 = norm_cls(dim)
 
         if self.fused_dropout_add_ln:
-            assert dropout_add_layer_norm is not None, 'dropout_add_ln is not installed'
+            assert dropout_add_layer_norm is not None, 'dropout_layer_norm is not installed'
             assert isinstance(self.norm1, nn.LayerNorm) and isinstance(self.dropout1, nn.Dropout)
 
         # TD [2023-01-07]: TODO: During training, if sequence_parallel is False and dropout != 0.0,
         # then the input to each worker in the tensor parallel group will be different.
         # This would produce wrong outputs? Somehow we'd need to sync the RNG state across workers.
         # For now this is not an issue because we always use sequence_parallel=True during training
         # and only use sequence_parallel=False during inference.
@@ -186,7 +191,107 @@
                         )
                     hidden_states = dropout_add_layer_norm(
                         mlp_out, hidden_states, self.norm2.weight, self.norm2.bias,
                         self.dropout2.p if self.training else 0.0, self.norm2.eps,
                         rowscale=rowscale2, prenorm=False
                     )
             return hidden_states
+
+
+class ParallelBlock(nn.Module):
+    """The attention (mixer) and MLP blocks are done in parallel, similar to GPT-J, GPT-NeoX,
+    and PaLM.
+    """
+
+    def __init__(self, dim, mixer_cls=None, mlp_cls=None, norm_cls=nn.LayerNorm,
+                 dropout_cls=nn.Dropout, resid_dropout1=0., resid_dropout2=0.,
+                 tied_norm=False, fused_dropout_add_ln=False, residual_in_fp32=False,
+                 sequence_parallel=False, mark_shared_params=False):
+        """
+        This Block has a slightly different structure compared to a regular
+        prenorm Transformer block.
+        The standard block is: LN -> MHA / MLP -> Dropout -> Add.
+        [Ref: https://arxiv.org/abs/2002.04745]
+        Here we have: Dropout -> Add -> LN -> MHA / MLP, returning both
+        the hidden_states (output1 of the MHA / MLP) and the residual.
+        This is for performance reasons, as we can fuse the dropout, add and LayerNorm.
+        The residual needs to be provided (except for the very first block).
+        """
+        super().__init__()
+        self.tied_norm = tied_norm
+        self.fused_dropout_add_ln = fused_dropout_add_ln
+        self.residual_in_fp32 = residual_in_fp32
+        if mixer_cls is None:
+            mixer_cls = partial(MHA, num_heads=dim // 64)
+        if mlp_cls is None:
+            mlp_cls = partial(Mlp, hidden_features=4 * dim)
+        self.mixer = mixer_cls(dim)
+        self.dropout1 = dropout_cls(resid_dropout1)
+        self.norm1 = norm_cls(dim)
+        self.mlp = mlp_cls(dim)
+        self.dropout2 = dropout_cls(resid_dropout2)
+        if not self.tied_norm:
+            self.norm2 = norm_cls(dim)
+
+        if self.fused_dropout_add_ln:
+            assert dropout_add_layer_norm_parallel_residual is not None, 'dropout_layer_norm is not installed'
+            assert isinstance(self.norm1, nn.LayerNorm) and isinstance(self.dropout1, nn.Dropout)
+
+        # TD [2023-01-07]: TODO: During training, if sequence_parallel is False and dropout != 0.0,
+        # then the input to each worker in the tensor parallel group will be different.
+        # This would produce wrong outputs? Somehow we'd need to sync the RNG state across workers.
+        # For now this is not an issue because we always use sequence_parallel=True during training
+        # and only use sequence_parallel=False during inference.
+
+        # Mark the norm parameters as "sequence_parallel" so that we run all-reduce on their grads.
+        if sequence_parallel:
+            for p in self.norm1.parameters():
+                p._sequence_parallel = True
+            if hasattr(self, 'norm2'):
+                for p in self.norm2.parameters():
+                    p._sequence_parallel = True
+        # Mark the norm parameters as "shared_params" so that we sync their values at init.
+        if mark_shared_params:
+            for p in self.norm1.parameters():
+                p._shared_params = True
+            if hasattr(self, 'norm2'):
+                for p in self.norm2.parameters():
+                    p._shared_params = True
+
+    def forward(self, hidden_states1: Tensor, hidden_states2: Optional[Tensor] = None,
+                residual: Optional[Tensor] = None, mixer_kwargs=None):
+        r"""Pass the input through the encoder layer.
+
+        Args:
+            hidden_states1: the output of the previous attention (mixer) or embedding layer.
+            hidden_states2: the output of the previous MLP layer (if None, will use hidden_states1).
+            residual.
+        """
+        if not self.fused_dropout_add_ln:
+            dropped1 = self.dropout1(hidden_states1)
+            # For the very 1st block, we only want 1 dropout, not two different dropouts
+            if hidden_states2 is not None:
+                dropped2 = self.dropout2(hidden_states2)
+                residual = ((residual + dropped1 + dropped2)
+                            if residual is not None else dropped1 + dropped2)
+            else:
+                residual = (residual + dropped1) if residual is not None else dropped1
+            hidden_states1 = self.norm1(residual.to(dtype=self.norm1.weight.dtype))
+            hidden_states2 = (self.norm2(residual.to(dtype=self.norm2.weight.dtype))
+                              if not self.tied_norm else hidden_states1)
+            if self.residual_in_fp32:
+                residual = residual.to(torch.float32)
+        else:
+            weight2, bias2 = ((self.norm2.weight, self.norm2.bias)
+                              if not self.tied_norm else (None, None))
+            hidden_states1, hidden_states2, residual = dropout_add_layer_norm_parallel_residual(
+                hidden_states1, hidden_states2, residual, self.norm1.weight, self.norm1.bias,
+                weight2, bias2, self.dropout1.p if self.training else 0.0, self.norm1.eps,
+                prenorm=True, residual_in_fp32=self.residual_in_fp32
+            )
+            if self.tied_norm:
+                hidden_states2 = hidden_states1
+        if mixer_kwargs is None:
+            mixer_kwargs = {}
+        hidden_states1 = self.mixer(hidden_states1, **mixer_kwargs)
+        hidden_states2 = self.mlp(hidden_states2)
+        return hidden_states1, hidden_states2, residual
```

### Comparing `flash_attn-0.2.8/flash_attn/modules/embedding.py` & `flash_attn-1.0.0/flash_attn/modules/embedding.py`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/flash_attn/modules/mha.py` & `flash_attn-1.0.0/flash_attn/modules/mha.py`

 * *Files 3% similar despite different names*

```diff
@@ -343,17 +343,18 @@
         return kv
 
 
 class MHA(nn.Module):
     """Multi-head self-attention and cross-attention
     """
 
-    def __init__(self, embed_dim, num_heads, cross_attn=False, bias=True, dropout=0.0,
-                 softmax_scale=None, causal=False, layer_idx=None, dwconv=False, rotary_emb_dim=0,
-                 rotary_emb_scale_base=0,
+    def __init__(self, embed_dim, num_heads, cross_attn=False,
+                 qkv_proj_bias=True, out_proj_bias=True,
+                 dropout=0.0, softmax_scale=None, causal=False, layer_idx=None, dwconv=False,
+                 rotary_emb_dim=0, rotary_emb_scale_base=None, rotary_emb_interleaved=False,
                  fused_bias_fc=False, use_flash_attn=False, return_residual=False,
                  checkpointing=False, device=None, dtype=None) -> None:
         """
             return_residual: whether to return the input x along with the output. This is for
                 performance reason: for post-norm architecture, returning the input allows us
                 to fuse the backward of nn.Linear with the residual connection.
         """
@@ -373,48 +374,51 @@
         assert self.embed_dim % num_heads == 0, "self.kdim must be divisible by num_heads"
         self.head_dim = self.embed_dim // num_heads
 
         if self.rotary_emb_dim > 0:
             assert not cross_attn, 'MHA with rotary embedding does not support cross-attention yet'
             assert RotaryEmbedding is not None, 'rotary_emb is not installed'
             self.rotary_emb = RotaryEmbedding(self.rotary_emb_dim, scale_base=rotary_emb_scale_base,
-                                              device=device)
+                                              interleaved=rotary_emb_interleaved, device=device)
 
         if fused_bias_fc and FusedDense is None:
             raise ImportError('fused_dense is not installed')
         linear_cls = nn.Linear if not fused_bias_fc else FusedDense
         linear_resid_cls = (LinearResidual if not fused_bias_fc
                             else partial(FusedDense, return_residual=True))
         inner_attn_cls = FlashSelfAttention if use_flash_attn else SelfAttention
         inner_cross_attn_cls = FlashCrossAttention if use_flash_attn else CrossAttention
         if not self.cross_attn:
             if not self.return_residual:
-                self.Wqkv = linear_cls(embed_dim, 3 * embed_dim, bias=bias, **factory_kwargs)
+                self.Wqkv = linear_cls(embed_dim, 3 * embed_dim, bias=qkv_proj_bias,
+                                       **factory_kwargs)
             else:
-                self.Wqkv = linear_resid_cls(embed_dim, 3 * embed_dim, bias=bias, **factory_kwargs)
+                self.Wqkv = linear_resid_cls(embed_dim, 3 * embed_dim, bias=qkv_proj_bias,
+                                             **factory_kwargs)
             if self.dwconv:
                 self.dwconv_qkv = nn.Conv1d(3 * embed_dim, 3 * embed_dim, kernel_size=3, padding=2,
                                             groups=3 * embed_dim)
         else:
-            self.Wq = linear_cls(embed_dim, embed_dim, bias=bias, **factory_kwargs)
+            self.Wq = linear_cls(embed_dim, embed_dim, bias=qkv_proj_bias, **factory_kwargs)
             if not self.return_residual:
-                self.Wkv = linear_cls(embed_dim, 2 * embed_dim, bias=bias, **factory_kwargs)
+                self.Wkv = linear_cls(embed_dim, 2 * embed_dim, bias=qkv_proj_bias,
+                                      **factory_kwargs)
             else:
-                self.Wkv = linear_resid_cls(embed_dim, 2 * embed_dim, bias=bias, **factory_kwargs)
+                self.Wkv = linear_resid_cls(embed_dim, 2 * embed_dim, bias=qkv_proj_bias,
+                                            **factory_kwargs)
             if self.dwconv:
                 self.dwconv_q = nn.Conv1d(embed_dim, embed_dim, kernel_size=3, padding=2,
-                                        groups=embed_dim)
+                                          groups=embed_dim)
                 self.dwconv_kv = nn.Conv1d(2 * embed_dim, 2 * embed_dim, kernel_size=3, padding=2,
-                                        groups=2 * embed_dim)
+                                          groups=2 * embed_dim)
         self.inner_attn = inner_attn_cls(causal=causal, softmax_scale=softmax_scale,
                                          attention_dropout=dropout)
         self.inner_cross_attn = inner_cross_attn_cls(causal=causal, softmax_scale=softmax_scale,
                                                      attention_dropout=dropout)
-        # output projection always have the bias (for now)
-        self.out_proj = linear_cls(embed_dim, embed_dim, **factory_kwargs)
+        self.out_proj = linear_cls(embed_dim, embed_dim, bias=out_proj_bias, **factory_kwargs)
 
     def _update_kv_cache(self, kv, inference_params):
         """kv: (batch_size, seqlen, 2, nheads, head_dim) or (batch_size, 1, 2, nheads, head_dim)
         """
         assert not self.dwconv, 'Generation does not support dwconv yet'
         assert self.layer_idx is not None, 'Generation requires layer_idx in the constructor'
         return _update_kv_cache(kv, inference_params, self.layer_idx)
@@ -486,15 +490,16 @@
                 else:
                     assert inference_params.fused_ft_kernel
                     assert ft_attention is not None
                     context = ft_attention.single_query_attention(
                         *rearrange(qkv, 'b 1 three h d -> b three h d').unbind(dim=1),
                         *inference_params.key_value_memory_dict[self.layer_idx],
                         inference_params.lengths_per_sample, inference_params.sequence_len_offset,
-                        self.rotary_emb_dim
+                        self.rotary_emb_dim,
+                        not self.rotary_emb.interleaved  # neox_rotary_style
                     )
                     context = rearrange(context, 'b h d -> b 1 h d')
         else:
             if not self.return_residual:
                 q = self.Wq(x if mixer_subset is None else x[:, mixer_subset])
                 kv = self.Wkv(x_kv if x_kv is not None else x)
             else:
@@ -522,17 +527,18 @@
         return out if not self.return_residual else (out, x)
 
 
 class ParallelMHA(nn.Module):
     """Multi-head self-attention and cross-attention
     """
 
-    def __init__(self, embed_dim, num_heads, process_group, bias=True, dropout=0.0,
-                 softmax_scale=None, causal=False, layer_idx=None, rotary_emb_dim=0,
-                 rotary_emb_scale_base=0, use_flash_attn=False, checkpointing=False,
+    def __init__(self, embed_dim, num_heads, process_group, qkv_proj_bias=True, out_proj_bias=True,
+                 dropout=0.0, softmax_scale=None, causal=False, layer_idx=None,
+                 rotary_emb_dim=0, rotary_emb_scale_base=None, rotary_emb_interleaved=False,
+                 use_flash_attn=False, checkpointing=False,
                  sequence_parallel=True, device=None, dtype=None) -> None:
         factory_kwargs = {'device': device, 'dtype': dtype}
         super().__init__()
         self.embed_dim = embed_dim
         self.causal = causal
         self.layer_idx = layer_idx
         self.rotary_emb_dim = rotary_emb_dim
@@ -542,28 +548,29 @@
         self.num_heads = num_heads
         assert self.embed_dim % num_heads == 0, "self.kdim must be divisible by num_heads"
         self.head_dim = self.embed_dim // num_heads
 
         if self.rotary_emb_dim > 0:
             assert RotaryEmbedding is not None, 'rotary_emb is not installed'
             self.rotary_emb = RotaryEmbedding(self.rotary_emb_dim, scale_base=rotary_emb_scale_base,
-                                              device=device)
+                                              interleaved=rotary_emb_interleaved, device=device)
 
         if ColumnParallelLinear is None or RowParallelLinear is None:
             raise ImportError('fused_dense is not installed')
-        self.Wqkv = ColumnParallelLinear(embed_dim, 3 * embed_dim, process_group, bias=bias,
+        self.Wqkv = ColumnParallelLinear(embed_dim, 3 * embed_dim, process_group,
+                                         bias=qkv_proj_bias,
                                          sequence_parallel=sequence_parallel, **factory_kwargs)
         inner_attn_cls = FlashSelfAttention if use_flash_attn else SelfAttention
         inner_cross_attn_cls = FlashCrossAttention if use_flash_attn else CrossAttention
         self.inner_attn = inner_attn_cls(causal=causal, softmax_scale=softmax_scale,
                                          attention_dropout=dropout)
         self.inner_cross_attn = inner_cross_attn_cls(causal=causal, softmax_scale=softmax_scale,
                                                      attention_dropout=dropout)
-        # output projection always have the bias (for now)
         self.out_proj = RowParallelLinear(embed_dim, embed_dim, process_group,
+                                          bias=out_proj_bias,
                                           sequence_parallel=sequence_parallel, **factory_kwargs)
 
     def forward(self, x, seqlen=None, inference_params=None, **kwargs):
         """
         Arguments:
             x: (batch, seqlen, hidden_dim) (where hidden_dim = num heads * head dim) if seqlen=None.
                 If seqlen is not None, x is (batch * seqlen, hidden_dim). This is so that when we
@@ -597,15 +604,16 @@
             else:
                 assert inference_params.fused_ft_kernel
                 assert ft_attention is not None
                 context = ft_attention.single_query_attention(
                     *rearrange(qkv, 'b 1 three h d -> b three h d').unbind(dim=1),
                     *inference_params.key_value_memory_dict[self.layer_idx],
                     inference_params.lengths_per_sample, inference_params.sequence_len_offset,
-                    self.rotary_emb_dim
+                    self.rotary_emb_dim,
+                    not self.rotary_emb.interleaved  # neox_rotary_style
                 )
                 context = rearrange(context, 'b h d -> b 1 h d')
         if seqlen is None:
             context = rearrange(context, 'b s h d -> b s (h d)')
         else:
             context = rearrange(context, 'b s h d -> (b s) (h d)')
         out = self.out_proj(context)
```

### Comparing `flash_attn-0.2.8/flash_attn/modules/mlp.py` & `flash_attn-1.0.0/flash_attn/modules/mlp.py`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/flash_attn/ops/fused_dense.py` & `flash_attn-1.0.0/flash_attn/ops/fused_dense.py`

 * *Files 1% similar despite different names*

```diff
@@ -417,14 +417,16 @@
             2: recompute pre_act and gelu_out in the bwd
         heuristic:
             -1: don't fuse gemm + gelu (separate kernel)
             0..4: use this heuristic for the algo section in the fused gemm + gelu
             'auto': heuristic will be picked automatically:
                 For CUDA >= 11.8, we set heuristic=0 for both fp16 and bf16 for best perf.
                 For CUDA <= 11.7, we set heuristic=1 for fp16 and heuristic=-1 for bf16.
+                For H100, we set heuristic=-1 for both fp16 and bf16 as the fused cuBlasLt implementation
+                is slower than the unfused version.
         return_residual: whether to return the input x along with the output. This is for
             performance reason: for post-norm architecture, returning the input allows us
             to fuse the backward of nn.Linear with the residual connection.
         """
         assert checkpoint_lvl in [0, 1, 2]
         assert activation in ['gelu_approx', 'relu']
         factory_kwargs = {'device': device, 'dtype': dtype}
@@ -438,16 +440,19 @@
         self.fc1 = nn.Linear(in_features, hidden_features, bias=bias1, **factory_kwargs)
         self.fc2 = nn.Linear(hidden_features, out_features, bias=bias2, **factory_kwargs)
 
     def forward(self, x, process_group=None):
         dtype = x.dtype if not torch.is_autocast_enabled() else torch.get_autocast_gpu_dtype()
         if self.heuristic == 'auto':
             if self.activation == 'gelu_approx':
-                cuda_ver = tuple(map(int, torch.version.cuda.split('.')))
-                heuristic = 0 if cuda_ver >= (11, 8) else (1 if dtype == torch.float16 else -1)
+                if torch.cuda.get_device_capability('cuda') == (9, 0):
+                    heuristic = -1
+                else:
+                    cuda_ver = tuple(map(int, torch.version.cuda.split('.')))
+                    heuristic = 0 if cuda_ver >= (11, 8) else (1 if dtype == torch.float16 else -1)
             else:
                 heuristic = 0
         else:
             heuristic = self.heuristic
         out = fused_mlp_func(
             x, self.fc1.weight, self.fc2.weight, self.fc1.bias, self.fc2.bias,
             activation=self.activation, save_pre_act=self.training,
```

### Comparing `flash_attn-0.2.8/flash_attn/ops/gelu_activation.py` & `flash_attn-1.0.0/flash_attn/ops/gelu_activation.py`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/flash_attn/ops/layer_norm.py` & `flash_attn-1.0.0/flash_attn/ops/layer_norm.py`

 * *Files 15% similar despite different names*

```diff
@@ -95,14 +95,54 @@
     if colscale is None:
         return dx0mat, dresidualmat, dgamma, dbeta
     else:
         dcolscale = rest[0]
         return dx0mat, dresidualmat, dgamma, dbeta, dcolscale
 
 
+def _dropout_add_layer_norm_parallel_residual_forward(
+    x0, x1, residual, gamma0, beta0, gamma1, beta1, dropout_p,
+    epsilon, residual_in_fp32=False, is_rms_norm=False
+):
+    """ Assume that arguments are contiguous
+    """
+    hidden_size = gamma0.numel()
+    x0mat = x0.view((-1, hidden_size))
+    x1mat = x1.view((-1, hidden_size)) if x1 is not None else None
+    residualmat = residual.view((-1, hidden_size)) if residual is not None else None
+    z0mat, z1mat, xmat, dmask0, dmask1, mu, rsigma = dropout_layer_norm.dropout_add_ln_parallel_residual_fwd(
+        x0mat, x1mat, residualmat, gamma0, beta0, gamma1, beta1, dropout_p, epsilon,
+        None, residual_in_fp32, is_rms_norm
+    )
+    # dmask0 and dmask1 are None if dropout_p == 0.0
+    # xmat is None if dropout_p == 0.0 and residual is None and residual_dtype != input_dtype
+    return z0mat, z1mat, xmat if xmat is not None else x0mat, dmask0, dmask1, mu, rsigma
+
+
+def _dropout_add_layer_norm_parallel_residual_backward(
+    dz0, dz1, dx, x, dmask0, dmask1, mu, rsigma, gamma0, gamma1,
+    dropout_p, has_x1, has_residual, is_rms_norm=False
+):
+    """ Assume that arguments are contiguous
+    dx == None means that it was a post-norm architecture
+    (x = drop(x0) + residual was not returned in the fwd).
+    """
+    hidden_size = gamma0.numel()
+    xmat = x.view((-1, hidden_size))
+    dz0mat = dz0.view(xmat.shape)
+    dz1mat = dz1.view(xmat.shape) if dz1 is not None else None
+    dxmat = dx.view(xmat.shape) if dx is not None else None
+    dx0mat, dx1mat, dresidualmat, dgamma0, dbeta0, dgamma1, dbeta1, *rest = dropout_layer_norm.dropout_add_ln_parallel_residual_bwd(
+        dz0mat, dz1mat, dxmat, xmat, dmask0, dmask1, mu, rsigma, gamma0, gamma1,
+        dropout_p, has_x1, has_residual, is_rms_norm
+    )
+    # dresidualmat is None if not has_residual
+    return dx0mat, dx1mat, dresidualmat, dgamma0, dbeta0, dgamma1, dbeta1
+
+
 class DropoutAddLayerNormFn(torch.autograd.Function):
     @staticmethod
     def forward(ctx, x0, residual, gamma, beta, rowscale, colscale, dropout_p, epsilon,
                 residual_in_fp32=False, prenorm=False, is_rms_norm=False, return_dmask=False):
         x0 = x0.contiguous()
         residual = residual.contiguous() if residual is not None else None
         gamma = gamma.contiguous()
@@ -111,15 +151,15 @@
         colscale = colscale.contiguous() if colscale is not None else None
         zmat, xmat, dmask, mu, rsigma = _dropout_add_layer_norm_forward(
             x0, residual, gamma, beta, rowscale, colscale, dropout_p, epsilon,
             residual_in_fp32, is_rms_norm
         )
         # Only need to save x0 if we need to compute gradient wrt colscale
         x0_saved = x0 if colscale is not None else None
-        ctx.save_for_backward(xmat.view(x0.shape), x0, dmask, gamma, mu, rsigma, rowscale, colscale)
+        ctx.save_for_backward(xmat.view(x0.shape), x0_saved, dmask, gamma, mu, rsigma, rowscale, colscale)
         ctx.prenorm = prenorm
         ctx.dropout_p = dropout_p
         ctx.has_residual = residual is not None
         ctx.is_rms_norm = is_rms_norm
         ctx.has_beta = beta is not None
         if not return_dmask:
             return (zmat.view(x0.shape) if not prenorm
@@ -164,15 +204,15 @@
         zmat, xmat, dmask, mu, rsigma = _dropout_add_layer_norm_subset_forward(
             x0, residual, gamma, beta, colscale, x0_subset, out_subset, dropout_p, epsilon,
             rowscale_const, out_numrows, residual_in_fp32, is_rms_norm
         )
         # Only need to save x0 if we need to compute gradient wrt colscale
         x0_saved = x0 if colscale is not None else None
         x_shape = (-1, *x0.shape[1:])
-        ctx.save_for_backward(xmat.view(x_shape), x0, dmask, gamma, mu, rsigma, colscale,
+        ctx.save_for_backward(xmat.view(x_shape), x0_saved, dmask, gamma, mu, rsigma, colscale,
                               x0_subset, out_subset)
         ctx.prenorm = prenorm
         ctx.dropout_p = dropout_p
         ctx.rowscale_const = rowscale_const
         ctx.x0_numrows = x0.shape[:-1].numel()
         ctx.has_residual = residual is not None
         ctx.is_rms_norm = is_rms_norm
@@ -204,14 +244,68 @@
         dx0 = dx0mat.view(-1, *x.shape[1:])
         dresidual = dresidualmat.view(x.shape) if dresidualmat is not None else None
         dcolscale = rest[0] if colscale is not None else None
         return (dx0, dresidual, dgamma, dbeta if ctx.has_beta else None, dcolscale, None, None,
                 None, None, None, None, None, None, None, None)
 
 
+class DropoutAddLayerNormParallelResidualFn(torch.autograd.Function):
+    @staticmethod
+    def forward(ctx, x0, x1, residual, gamma0, beta0, gamma1, beta1, dropout_p, epsilon,
+                residual_in_fp32=False, prenorm=False, is_rms_norm=False, return_dmask=False):
+        x0 = x0.contiguous()
+        x1 = x1.contiguous() if x1 is not None else None
+        residual = residual.contiguous() if residual is not None else None
+        gamma0 = gamma0.contiguous()
+        beta0 = beta0.contiguous() if beta0 is not None else None
+        gamma1 = gamma1.contiguous() if gamma1 is not None else None
+        beta1 = beta1.contiguous() if beta1 is not None else None
+        z0mat, z1mat, xmat, dmask0, dmask1, mu, rsigma = _dropout_add_layer_norm_parallel_residual_forward(
+            x0, x1, residual, gamma0, beta0, gamma1, beta1, dropout_p, epsilon,
+            residual_in_fp32, is_rms_norm
+        )
+        ctx.save_for_backward(xmat.view(x0.shape), dmask0, dmask1, gamma0, gamma1, mu, rsigma)
+        ctx.prenorm = prenorm
+        ctx.dropout_p = dropout_p
+        ctx.has_x1 = x1 is not None
+        ctx.has_residual = residual is not None
+        ctx.is_rms_norm = is_rms_norm
+        ctx.has_beta = beta0 is not None
+        z = (z0mat.view(x0.shape), z1mat.view(x0.shape) if z1mat is not None else None)
+        if not return_dmask:
+            return z if not prenorm else (*z, xmat.view(x0.shape))
+        else:
+            dmask0 = (dmask0.view(x0.shape) if dropout_p > 0.
+                      else torch.ones(x0.shape, dtype=torch.uint8, device=x0.device))
+            dmask1 = (dmask1.view(x0.shape) if dropout_p > 0. and x1 is not None
+                      else torch.ones(x0.shape, dtype=torch.uint8, device=x0.device))
+            ctx.mark_non_differentiable(dmask0)
+            ctx.mark_non_differentiable(dmask1)
+            return (*z, dmask0, dmask1) if not prenorm else (*z, xmat.view(x0.shape), dmask0, dmask1)
+
+    @staticmethod
+    def backward(ctx, dz0, dz1, *args):
+        dz0 = dz0.contiguous()  # this happens!
+        dz1 = dz1.contiguous() if dz1 is not None else None
+        dx = args[0].contiguous() if ctx.prenorm else None
+        x, dmask0, dmask1, gamma0, gamma1, mu, rsigma = ctx.saved_tensors
+        dropout_p = ctx.dropout_p
+        has_x1 = ctx.has_x1
+        has_residual = ctx.has_residual
+        dx0mat, dx1mat, dresidualmat, dgamma0, dbeta0, dgamma1, dbeta1 = _dropout_add_layer_norm_parallel_residual_backward(
+            dz0, dz1, dx, x, dmask0, dmask1, mu, rsigma, gamma0, gamma1, dropout_p, has_x1,
+            has_residual, ctx.is_rms_norm
+        )
+        dx0 = dx0mat.view(x.shape)
+        dx1 = dx1mat.view(x.shape) if dx1mat is not None else None
+        dresidual = dresidualmat.view(x.shape) if dresidualmat is not None else None
+        return (dx0, dx1, dresidual, dgamma0, dbeta0 if ctx.has_beta else None, dgamma1,
+                dbeta1 if ctx.has_beta else None, None, None, None, None, None, None)
+
+
 def layer_norm(x, weight, bias, epsilon):
     return DropoutAddLayerNormFn.apply(x, None, weight, bias, None, None, 0.0, epsilon, False)
 
 
 def dropout_add_layer_norm(x0, residual, weight, bias, dropout_p, epsilon, rowscale=None,
                            layerscale=None, prenorm=False, residual_in_fp32=False,
                            return_dropout_mask=False):
@@ -233,14 +327,27 @@
     """
     return DropoutAddLayerNormSubsetFn.apply(
         x0, residual, weight, bias, layerscale, x0_subset, out_subset, dropout_p, epsilon,
         rowscale_const, out_numrows, residual_in_fp32, prenorm, False, return_dropout_mask
     )
 
 
+def dropout_add_layer_norm_parallel_residual(
+    x0, x1, residual, weight0, bias0, weight1, bias1, dropout_p, epsilon, prenorm=False,
+    residual_in_fp32=False, return_dropout_mask=False
+):
+    """residual_in_fp32 only has an effect if residual is None.
+    Otherwise residual dtype is residual.dtype.
+    """
+    return DropoutAddLayerNormParallelResidualFn.apply(
+        x0, x1, residual, weight0, bias0, weight1, bias1, dropout_p, epsilon, residual_in_fp32, prenorm,
+        False, return_dropout_mask
+    )
+
+
 class DropoutAddLayerNorm(torch.nn.Module):
     def __init__(self, hidden_size, prenorm=False, p=0.0, eps=1e-5, residual_in_fp32=False,
                  device=None, dtype=None):
         factory_kwargs = {'device': device, 'dtype': dtype}
         super().__init__()
         self.prenorm = prenorm
         self.p = p
```

### Comparing `flash_attn-0.2.8/flash_attn/ops/rms_norm.py` & `flash_attn-1.0.0/flash_attn/ops/rms_norm.py`

 * *Files 15% similar despite different names*

```diff
@@ -1,14 +1,15 @@
 # Copyright (c) 2022, Tri Dao.
 # Adapted from https://github.com/NVIDIA/apex/blob/master/apex/contrib/layer_norm/layer_norm.py
 
 import torch
 from torch.nn import init
 
 from flash_attn.ops.layer_norm import DropoutAddLayerNormFn, DropoutAddLayerNormSubsetFn
+from flash_attn.ops.layer_norm import DropoutAddLayerNormParallelResidualFn
 
 
 def rms_norm(x, weight, epsilon):
     return DropoutAddLayerNormFn.apply(x, None, weight, None, None, None, 0.0, epsilon, False,
                                        False, True)
 
 
@@ -33,14 +34,27 @@
     """
     return DropoutAddLayerNormSubsetFn.apply(
         x0, residual, weight, bias, layerscale, x0_subset, out_subset, dropout_p, epsilon,
         rowscale_const, out_numrows, residual_in_fp32, prenorm, True, return_dropout_mask
     )
 
 
+def dropout_add_rms_norm_parallel_residual(
+   x0, x1, residual, weight0, bias0, weight1, bias1,
+   dropout_p, epsilon, prenorm=False, residual_in_fp32=False, return_dropout_mask=False
+):
+    """residual_in_fp32 only has an effect if residual is None.
+    Otherwise residual dtype is residual.dtype.
+    """
+    return DropoutAddLayerNormParallelResidualFn.apply(
+        x0, x1, residual, weight0, bias0, weight1, bias1, dropout_p, epsilon, residual_in_fp32, prenorm,
+        True, return_dropout_mask
+    )
+
+
 class DropoutAddRMSNorm(torch.nn.Module):
     def __init__(self, hidden_size, prenorm=False, p=0.0, eps=1e-5, residual_in_fp32=False,
                  device=None, dtype=None):
         factory_kwargs = {'device': device, 'dtype': dtype}
         super().__init__()
         self.prenorm = prenorm
         self.p = p
```

### Comparing `flash_attn-0.2.8/flash_attn/rotary.py` & `flash_attn-1.0.0/flash_attn/rotary.py`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/flash_attn/triton/fused_attention.py` & `flash_attn-1.0.0/flash_attn/triton/fused_attention.py`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/flash_attn/utils/benchmark.py` & `flash_attn-1.0.0/flash_attn/utils/benchmark.py`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/flash_attn/utils/distributed.py` & `flash_attn-1.0.0/flash_attn/utils/distributed.py`

 * *Files identical despite different names*

### Comparing `flash_attn-0.2.8/flash_attn/utils/generation.py` & `flash_attn-1.0.0/flash_attn/utils/generation.py`

 * *Files 7% similar despite different names*

```diff
@@ -67,30 +67,33 @@
         else:
             logits_top = logits / temperature
             modify_logits_for_top_p_filtering(logits_top, top_p)
             return torch.multinomial(torch.softmax(logits_top, dim=-1), num_samples=1).squeeze(dim=-1)
 
 
 def decode(input_ids, model, max_length, top_k=1, top_p=0.0, temperature=1.0,
-           eos_token_id=None, vocab_size=None, tensor_parallel=1, fused_ft_kernel=False,
-           cg=False, timing=False):
+           eos_token_id=None, teacher_outputs=None, vocab_size=None, tensor_parallel=1,
+           fused_ft_kernel=False, cg=False, timing=False):
     """Decoding, either greedy or with top-k or top-p sampling.
     If top-k = 0, don't limit the number of candidates (pure sampling).
     Top-k and top-p can be used together. If top_k > 0 and top_p > 0, then top-k is applied first,
     then top-p.
     We assume that all sequences in the same batch have the same length.
 
     Arguments:
         input_ids: (batch, seq_len)
         max_length: int
+        teacher_outputs (optional): (batch, seq_len). If provided, instead of sampling from the
+            logits, the next token is taken from the teacher_outputs. Useful for testing.
     Returns: GreedySearchDecoderOnlyOutput or SampleDecoderOnlyOutput, with the following fields:
         sequences: (batch, max_length)
         scores: tuples of (batch, vocab_size)
     """
     batch_size, seqlen_og = input_ids.shape
+    teacher_output_len = teacher_outputs.shape[1] if teacher_outputs is not None else 0
     if cg:
         assert fused_ft_kernel
         if not hasattr(model, '_decoding_cache'):
             model._decoding_cache = None
         model._decoding_cache = update_graph_cache(
             model, model._decoding_cache, batch_size, seqlen_og, max_length,
             tensor_parallel=tensor_parallel
@@ -106,31 +109,37 @@
     with torch.inference_mode():
         logits = model(input_ids, inference_params=inference_params).logits[:, -1]
         if timing:
             torch.cuda.synchronize()
             start = time.time()
         if vocab_size is not None:
             logits = logits[..., :vocab_size]
-        scores.append(logits)
-        next_token = sample(logits, top_k=top_k, top_p=top_p, temperature=temperature)
+        scores.append(logits if not cg else logits.clone())
+        if teacher_outputs is None or teacher_output_len <= seqlen_og:
+            next_token = sample(logits, top_k=top_k, top_p=top_p, temperature=temperature)
+        else:
+            next_token = teacher_outputs[:, seqlen_og]
         sequences = [next_token]
         inference_params.sequence_len_offset = seqlen_og
         while True:
             position_ids = torch.full((batch_size, 1), inference_params.sequence_len_offset,
                                     dtype=torch.long, device=input_ids.device)
             if not cg:
                 logits = model(rearrange(next_token, 'b -> b 1'), position_ids=position_ids,
                                inference_params=inference_params).logits[:, -1]
             else:
                 logits = model._decoding_cache.run(rearrange(next_token, 'b -> b 1'), position_ids,
                                                    inference_params.sequence_len_offset)
             if vocab_size is not None:
                 logits = logits[..., :vocab_size]
-            scores.append(logits)
-            next_token = sample(logits, top_k=top_k, temperature=temperature)
+            scores.append(logits if not cg else logits.clone())
+            if teacher_outputs is None or teacher_output_len <= inference_params.sequence_len_offset + 1:
+                next_token = sample(logits, top_k=top_k, temperature=temperature)
+            else:
+                next_token = teacher_outputs[:, inference_params.sequence_len_offset + 1]
             sequences.append(next_token)
             inference_params.sequence_len_offset += 1
             if eos_token_id is not None and (next_token == eos_token_id).all():
                 break
             if inference_params.sequence_len_offset >= max_length - 1:
                 break
         if timing:
@@ -192,15 +201,15 @@
     mempool = None
     inference_params: Optional[InferenceParams] = None
     run: Optional[Callable] = None
 
 
 @torch.inference_mode()
 def update_graph_cache(model, cache, batch_size, seqlen_og, max_seqlen, tensor_parallel=1,
-                       dtype=None):
+                       dtype=None, n_warmups=2):
     if cache is None:
         cache = DecodingCGCache()
     param_example = next(iter(model.parameters()))
     device = param_example.device
     if dtype is None:
         dtype = param_example.dtype
     if ((device, dtype) != (cache.device, cache.dtype) or batch_size > cache.max_batch_size
@@ -224,40 +233,47 @@
             lengths_per_sample=lengths_per_sample
         )
         cache.mempool = torch.cuda.graphs.graph_pool_handle()
     for s_type in range(seqlen_to_seqlen_type(seqlen_og), seqlen_to_seqlen_type(max_seqlen) + 1):
         if s_type not in cache.callables:
             seqlen = min(max(seqlen_og, seqlen_type_to_seqlen(s_type)), max_seqlen)
             cache.callables[s_type] = capture_graph(
-                model, cache.inference_params, batch_size, seqlen_og, seqlen, mempool=cache.mempool
+                model, cache.inference_params, batch_size, seqlen_og, seqlen, mempool=cache.mempool,
+                n_warmups=n_warmups
             )
 
     def dispatch(input_ids, position_ids, seqlen):
         return cache.callables[seqlen_to_seqlen_type(seqlen)](input_ids, position_ids, seqlen)
 
     cache.run = dispatch
     cache.inference_params.sequence_length_offset = 0  # Reset so it's not confusing
     return cache
 
 
-def capture_graph(model, inference_params, batch_size, seqlen_og, max_seqlen, mempool=None):
+def capture_graph(model, inference_params, batch_size, seqlen_og, max_seqlen, mempool=None,
+                  n_warmups=2):
     assert max_seqlen >= seqlen_og
     device = next(iter(model.parameters())).device
     input_ids = torch.full((batch_size, 1), 0, dtype=torch.long, device=device)
     position_ids = torch.full((batch_size, 1), 0, dtype=torch.long, device=device)
     inference_params.lengths_per_sample[:] = seqlen_og
 
     # Warmup before capture
     s = torch.cuda.Stream()
     s.wait_stream(torch.cuda.current_stream())
     with torch.cuda.stream(s):
-        for _ in range(2):
+        for _ in range(n_warmups):
             logits = model(input_ids, position_ids=position_ids,
                            inference_params=inference_params).logits[:, -1]
         s.synchronize()
+        # This might be needed for correctness if we run with NCCL_GRAPH_MIXING_SUPPORT=0,
+        # which requires that graph launch and non-captured launch to not overlap (I think,
+        # that's how I interpret the documentation). I'm not sure if this is required.
+        if torch.distributed.is_initialized():
+            torch.distributed.barrier()
     torch.cuda.current_stream().wait_stream(s)
     # Captures the graph
     # To allow capture, automatically sets a side stream as the current stream in the context
     graph = torch.cuda.CUDAGraph()
     with torch.cuda.graph(graph, pool=mempool):
         logits = model(input_ids, position_ids=position_ids,
                         inference_params=inference_params).logits[:, -1]
```

### Comparing `flash_attn-0.2.8/flash_attn/utils/pretrained.py` & `flash_attn-1.0.0/flash_attn/utils/pretrained.py`

 * *Files 7% similar despite different names*

```diff
@@ -3,14 +3,16 @@
 from transformers.utils import WEIGHTS_NAME, WEIGHTS_INDEX_NAME
 from transformers.utils import is_remote_url
 from transformers.modeling_utils import load_state_dict
 from transformers.utils.hub import cached_file, get_checkpoint_shard_files
 
 
 def state_dict_from_pretrained(model_name, device=None, dtype=None):
+    # If not fp32, then we don't want to load directly to the GPU
+    mapped_device = 'cpu' if dtype not in [torch.float32, None] else device
     is_sharded = False
     resolved_archive_file = cached_file(model_name, WEIGHTS_NAME,
                                         _raise_exceptions_for_missing_entries=False)
     if resolved_archive_file is None:
         resolved_archive_file = cached_file(model_name, WEIGHTS_INDEX_NAME,
                                             _raise_exceptions_for_missing_entries=False)
         if resolved_archive_file is not None:
@@ -21,13 +23,15 @@
         # resolved_archive_file becomes a list of files that point to the different
         # checkpoint shards in this case.
         resolved_archive_file, sharded_metadata = get_checkpoint_shard_files(
             model_name, resolved_archive_file
         )
         state_dict = {}
         for sharded_file in resolved_archive_file:
-            state_dict.update(torch.load(sharded_file, map_location=device))
+            state_dict.update(torch.load(sharded_file, map_location=mapped_device))
     else:
         state_dict = torch.load(cached_file(model_name, WEIGHTS_NAME), map_location=device)
+    # Convert dtype before moving to GPU to save memory
     if dtype is not None:
-        state_dict = {k: v.to(dtype) for k, v in state_dict.items()}
+        state_dict = {k: v.to(dtype=dtype) for k, v in state_dict.items()}
+    state_dict = {k: v.to(device=device) for k, v in state_dict.items()}
     return state_dict
```

### Comparing `flash_attn-0.2.8/flash_attn.egg-info/PKG-INFO` & `flash_attn-1.0.0/PKG-INFO`

 * *Files 19% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
-Name: flash-attn
-Version: 0.2.8
+Name: flash_attn
+Version: 1.0.0
 Summary: Flash Attention: Fast and Memory-Efficient Exact Attention
 Home-page: https://github.com/HazyResearch/flash-attention
 Author: Tri Dao
 Author-email: trid@stanford.edu
 License: UNKNOWN
 Platform: UNKNOWN
 Classifier: Programming Language :: Python :: 3
@@ -51,17 +51,21 @@
 https://github.com/openai/triton/blob/master/python/tutorials/06-fused-attention.py  
 
 As Triton is a higher-level language than CUDA, it might be easier to understand
 and experiment with. The notations in the Triton implementation are also closer
 to what's used in our paper.
 
 
-## Beta release (0.2).
+## Installation and features
 
-To install (requiring CUDA 11, NVCC, and an Turing or Ampere GPU):
+Requirements:
+- CUDA 11.4 and above.
+- PyTorch 1.12 and above.
+
+To install:
 ```sh
 pip install flash-attn
 ```
 
 Alternatively you can compile from source:
 ```
 python setup.py install
@@ -71,29 +75,95 @@
 
 To run the benchmark against PyTorch standard attention: 
 ```
 PYTHONPATH=$PWD python benchmarks/benchmark_flash_attention.py
 ```
 
 FlashAttention currently supports:
-1. Turing or Ampere GPUs (e.g., A100, RTX 3090, T4, RTX 2080).
-2. fp16 and bf16 (bf16 requires Ampere GPUs).
-3. Head dimensions that are multiples of 8, up to 128 (e.g., 8, 16, 24, ..., 128). Head dim > 64 backward requires A100.
+1. Turing, Ampere, Ada, or Hopper GPUs (e.g., H100, A100, RTX 3090, T4, RTX 2080).
+2. fp16 and bf16 (bf16 requires Ampere, Ada, or Hopper GPUs).
+3. Head dimensions that are multiples of 8, up to 128 (e.g., 8, 16, 24, ...,
+   128). Head dim > 64 backward requires A100 or H100.
 
 Our tentative roadmap:
 1. ~~[Jun 2022] Make package pip-installable~~[Done, thanks to lucidrains].
 2. ~~[Jun 2022] Support SM86 GPUs (e.g., RTX 3080, 3090)~~[Done].
-3. [Jun 2022] Refactor to use Cutlass.
-4. ~~[Jun 2022] Support SM75 GPUs (e.g. T4)~~[Done].
-5. ~~[Jun 2022] Support bf16~~[Done].
-6. ~~[Jul 2022] Implement cross-attention~~[Done].
-7. ~~[Jul 2022] Support head dimension 128~~[Done].
-8. [Jul 2022] Support SM70 GPUs (V100).
-9. ~~[Aug 2022] Fuse rotary embedding~~[Done].
-10. [Aug 2022] Support attention bias (e.g. ALiBi, relative positional encoding).
+3. ~~[Jun 2022] Support SM75 GPUs (e.g. T4)~~[Done].
+4. ~~[Jun 2022] Support bf16~~[Done].
+5. ~~[Jul 2022] Implement cross-attention~~[Done].
+6. ~~[Jul 2022] Support head dimension 128~~[Done].
+7. ~~[Aug 2022] Fuse rotary embedding~~[Done].
+8. ~~[Mar 2023] Support SM90 GPUs (H100)~~[Done].
+9. [Apr 2023] Refactor to use Cutlass 3.x.
+10. [May 2023] Support attention bias (e.g. ALiBi, relative positional encoding).
+11. [Jun 2023] Support SM70 GPUs (V100).
+12. [Jun 2023] Support fp8 (H100).
+
+
+## How to use FlashAttention
+
+Here's a simple example:
+```python
+import torch
+from flash_attn.flash_attention import FlashMHA
+
+# Replace this with your correct GPU device
+device = "cuda:0"
+
+# Create attention layer. This is similar to torch.nn.MultiheadAttention,
+# and it includes the input and output linear layers
+flash_mha = FlashMHA(
+    embed_dim=128, # total channels (= num_heads * head_dim)
+    num_heads=8, # number of heads
+    device=device,
+    dtype=torch.float16,
+)
+
+# Run forward pass with dummy data
+x = torch.randn(
+    (64, 256, 128), # (batch, seqlen, embed_dim)
+    device=device,
+    dtype=torch.float16
+)
+
+output = flash_mha(x)[0]
+```
+
+Alternatively, you can import the inner attention layer only (so that the input
+and output linear layers are not included):
+```python
+from flash_attn.flash_attention import FlashAttention
+
+# Create the nn.Module
+flash_attention = FlashAttention()
+```
+
+Or, if you need more fine-grained control, you can import one of the lower-level
+functions (this is more similar to the `torch.nn.functional` style):
+```python
+from flash_attn.flash_attn_interface import flash_attn_unpadded_func
+
+# or
+
+from flash_attn.flash_attn_interface import flash_attn_unpadded_qkvpacked_split_func
+
+# etc.
+```
+
+There are also separate Python files with various FlashAttention extensions:
+```python
+# Import the triton implementation (torch.nn.functional version only)
+from flash_attn.flash_attn_triton import flash_attn_func
+
+# Import block sparse attention (nn.Module version)
+from flash_attn.flash_blocksparse_attention import FlashBlocksparseMHA, FlashBlocksparseAttention
+
+# Import block sparse attention (torch.nn.functional version)
+from flash_attn.flash_blocksparse_attn_interface import flash_blocksparse_attn_func
+```
 
 ## Speedup and Memory Savings
 
 We present expected speedup (combined forward + backward pass) and memory savings from using FlashAttention against PyTorch standard attention, depending on sequence length, on different GPUs (speedup depends on memory bandwidth - we see more speedup on slower GPU memory).
 
 We currently have benchmarks for these GPUs:
 * [A100](#a100)
@@ -193,9 +263,7 @@
 @inproceedings{dao2022flashattention,
   title={Flash{A}ttention: Fast and Memory-Efficient Exact Attention with {IO}-Awareness},
   author={Dao, Tri and Fu, Daniel Y. and Ermon, Stefano and Rudra, Atri and R{\'e}, Christopher},
   booktitle={Advances in Neural Information Processing Systems},
   year={2022}
 }
 ```
-
-
```

### Comparing `flash_attn-0.2.8/flash_attn.egg-info/SOURCES.txt` & `flash_attn-1.0.0/flash_attn.egg-info/SOURCES.txt`

 * *Files 2% similar despite different names*

```diff
@@ -1,14 +1,14 @@
 AUTHORS
 LICENSE
 MANIFEST.in
 README.md
 setup.py
+csrc/flash_attn/flash_api.cpp
 csrc/flash_attn/fmha_api.cpp
-csrc/flash_attn/rotary.cuh
 csrc/flash_attn/cutlass/cmake/nop.cu
 csrc/flash_attn/cutlass/examples/00_basic_gemm/basic_gemm.cu
 csrc/flash_attn/cutlass/examples/01_cutlass_utilities/cutlass_utilities.cu
 csrc/flash_attn/cutlass/examples/02_dump_reg_shmem/dump_reg_shmem.cu
 csrc/flash_attn/cutlass/examples/03_visualize_layout/options.h
 csrc/flash_attn/cutlass/examples/03_visualize_layout/register_layout.cu
 csrc/flash_attn/cutlass/examples/03_visualize_layout/register_layout.h
@@ -109,46 +109,59 @@
 csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/fmha_grouped.h
 csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/fmha_grouped_problem_visitor.h
 csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/fused_multihead_attention_fixed_seqlen.cu
 csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/fused_multihead_attention_variable_seqlen.cu
 csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/gemm_kernel_utils.h
 csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/kernel_forward.h
 csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/mma_from_smem.h
+csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/epilogue/epilogue_pipelined.h
+csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/epilogue/epilogue_rescale_output.h
+csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/epilogue/epilogue_thread_apply_logsumexp.h
 csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma.h
 csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma_base.h
 csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma_multistage.h
 csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/gemm/custom_mma_pipelined.h
+csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/gemm/find_default_mma.h
+csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/gemm/mma_accum_lambda_iterator.h
+csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/gemm/mma_from_smem.h
 csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/iterators/epilogue_predicated_tile_iterator.h
 csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/iterators/make_residual_last.h
 csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/iterators/predicated_tile_access_iterator_residual_last.h
 csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/iterators/predicated_tile_iterator_residual_last.h
-csrc/flash_attn/cutlass/examples/41_multi_head_attention/fused_multihead_attention.cu
-csrc/flash_attn/cutlass/examples/41_multi_head_attention/gemm_attention.h
-csrc/flash_attn/cutlass/examples/41_multi_head_attention/gemm_grouped_with_softmax_visitor.h
+csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/iterators/transpose_warp_iterator.h
+csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/iterators/warp_iterator_from_smem.h
+csrc/flash_attn/cutlass/examples/41_fused_multi_head_attention/transform/tile_smem_loader.h
 csrc/flash_attn/cutlass/examples/42_ampere_tensorop_group_conv/ampere_tensorop_group_conv.cu
 csrc/flash_attn/cutlass/examples/43_ell_block_sparse_gemm/ell_block_sparse_gemm.cu
 csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/leaky_bias.h
 csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/utils.h
 csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/default_bias_act_epilogue_tensor_op.h
 csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/default_thread_map_tensor_op_for_fused_bias.h
 csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/fused_bias_act_epilogue.h
 csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/threadblock/output_tile_thread_map_for_fused_bias.h
 csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/epilogue/warp/fused_bias_act_fragment_iterator_tensor_op.h
 csrc/flash_attn/cutlass/examples/44_multi_gemm_ir_and_codegen/fixed_impl/gemm/warp/mma_tensor_op_fragment_iterator_without_output_op.h
 csrc/flash_attn/cutlass/examples/45_dual_gemm/dual_gemm.cu
+csrc/flash_attn/cutlass/examples/45_dual_gemm/dual_gemm_common.h
 csrc/flash_attn/cutlass/examples/45_dual_gemm/dual_gemm_run.h
 csrc/flash_attn/cutlass/examples/45_dual_gemm/test_run.h
 csrc/flash_attn/cutlass/examples/45_dual_gemm/device/dual_gemm.h
 csrc/flash_attn/cutlass/examples/45_dual_gemm/kernel/dual_gemm.h
 csrc/flash_attn/cutlass/examples/45_dual_gemm/thread/left_silu_and_mul.h
 csrc/flash_attn/cutlass/examples/45_dual_gemm/threadblock/dual_epilogue.h
 csrc/flash_attn/cutlass/examples/45_dual_gemm/threadblock/dual_mma_base.h
 csrc/flash_attn/cutlass/examples/45_dual_gemm/threadblock/dual_mma_multistage.h
 csrc/flash_attn/cutlass/examples/46_depthwise_simt_conv2dfprop/depthwise_simt_conv2dfprop.cu
+csrc/flash_attn/cutlass/examples/47_ampere_gemm_universal_streamk/ampere_gemm_universal_streamk.cu
+csrc/flash_attn/cutlass/examples/48_hopper_warp_specialized_gemm/48_hopper_warp_specialized_gemm.cu
+csrc/flash_attn/cutlass/examples/49_hopper_gemm_schedules_with_collective_builder/49_hopper_gemm_schedules_with_collective_builder.cu
+csrc/flash_attn/cutlass/examples/50_hopper_gemm_with_epilogue_swizzle/50_hopper_gemm_with_epilogue_swizzle.cu
+csrc/flash_attn/cutlass/examples/60_cutlass_import/main.cpp
 csrc/flash_attn/cutlass/examples/common/helper.h
+csrc/flash_attn/cutlass/examples/cute/tutorial/sgemm_nt_1.cu
 csrc/flash_attn/cutlass/include/cutlass/aligned_buffer.h
 csrc/flash_attn/cutlass/include/cutlass/array.h
 csrc/flash_attn/cutlass/include/cutlass/array_planar_complex.h
 csrc/flash_attn/cutlass/include/cutlass/array_subbyte.h
 csrc/flash_attn/cutlass/include/cutlass/barrier.h
 csrc/flash_attn/cutlass/include/cutlass/bfloat16.h
 csrc/flash_attn/cutlass/include/cutlass/blas3.h
@@ -184,27 +197,29 @@
 csrc/flash_attn/cutlass/include/cutlass/tensor_view.h
 csrc/flash_attn/cutlass/include/cutlass/tensor_view_planar_complex.h
 csrc/flash_attn/cutlass/include/cutlass/tfloat32.h
 csrc/flash_attn/cutlass/include/cutlass/trace.h
 csrc/flash_attn/cutlass/include/cutlass/uint128.h
 csrc/flash_attn/cutlass/include/cutlass/wmma_array.h
 csrc/flash_attn/cutlass/include/cutlass/arch/arch.h
+csrc/flash_attn/cutlass/include/cutlass/arch/barrier.h
 csrc/flash_attn/cutlass/include/cutlass/arch/cache_operation.h
 csrc/flash_attn/cutlass/include/cutlass/arch/memory.h
 csrc/flash_attn/cutlass/include/cutlass/arch/memory_sm75.h
 csrc/flash_attn/cutlass/include/cutlass/arch/memory_sm80.h
 csrc/flash_attn/cutlass/include/cutlass/arch/mma.h
 csrc/flash_attn/cutlass/include/cutlass/arch/mma_sm50.h
 csrc/flash_attn/cutlass/include/cutlass/arch/mma_sm60.h
 csrc/flash_attn/cutlass/include/cutlass/arch/mma_sm61.h
 csrc/flash_attn/cutlass/include/cutlass/arch/mma_sm70.h
 csrc/flash_attn/cutlass/include/cutlass/arch/mma_sm75.h
 csrc/flash_attn/cutlass/include/cutlass/arch/mma_sm80.h
 csrc/flash_attn/cutlass/include/cutlass/arch/mma_sm90.h
 csrc/flash_attn/cutlass/include/cutlass/arch/mma_sparse_sm80.h
+csrc/flash_attn/cutlass/include/cutlass/arch/reg_reconfig.h
 csrc/flash_attn/cutlass/include/cutlass/arch/simd.h
 csrc/flash_attn/cutlass/include/cutlass/arch/simd_sm60.h
 csrc/flash_attn/cutlass/include/cutlass/arch/simd_sm61.h
 csrc/flash_attn/cutlass/include/cutlass/arch/wmma.h
 csrc/flash_attn/cutlass/include/cutlass/arch/wmma_sm70.h
 csrc/flash_attn/cutlass/include/cutlass/arch/wmma_sm72.h
 csrc/flash_attn/cutlass/include/cutlass/arch/wmma_sm75.h
@@ -543,15 +558,14 @@
 csrc/flash_attn/cutlass/include/cutlass/reduction/kernel/tensor_reduce_affine_contiguous.h
 csrc/flash_attn/cutlass/include/cutlass/reduction/kernel/tensor_reduce_affine_strided.h
 csrc/flash_attn/cutlass/include/cutlass/reduction/thread/reduce.h
 csrc/flash_attn/cutlass/include/cutlass/reduction/thread/reduction_operators.h
 csrc/flash_attn/cutlass/include/cutlass/thread/matrix.h
 csrc/flash_attn/cutlass/include/cutlass/transform/pitch_linear_thread_map.h
 csrc/flash_attn/cutlass/include/cutlass/transform/thread/transpose.h
-csrc/flash_attn/cutlass/include/cutlass/transform/thread/unaryOp.h
 csrc/flash_attn/cutlass/include/cutlass/transform/thread/unary_op.h
 csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/ell_iterator.h
 csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/ell_predicated_tile_access_iterator.h
 csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/ell_predicated_tile_iterator.h
 csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_scale_bias_vector_access_iterator.h
 csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_scale_bias_vector_iterator.h
 csrc/flash_attn/cutlass/include/cutlass/transform/threadblock/predicated_tile_access_iterator.h
@@ -637,15 +651,14 @@
 csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm75.cu
 csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_f16ndhwc_f16ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
 csrc/flash_attn/cutlass/test/unit/conv/device/conv3d_wgrad_implicit_gemm_tf32ndhwc_tf32ndhwc_f32ndhwc_tensor_op_f32_sm80.cu
 csrc/flash_attn/cutlass/test/unit/conv/device/depthwise_conv2d_direct_conv_testbed.h
 csrc/flash_attn/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_direct_conv_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu
 csrc/flash_attn/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_direct_conv_fixed_stride_dilation_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu
 csrc/flash_attn/cutlass/test/unit/conv/device/depthwise_conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu
-csrc/flash_attn/cutlass/test/unit/conv/device/depthwise_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_simt_f16_sm60.cu
 csrc/flash_attn/cutlass/test/unit/conv/device/group_conv2d_fprop_implicit_gemm_f16nhwc_f16nhwc_f16nhwc_tensor_op_f32_sm80.cu
 csrc/flash_attn/cutlass/test/unit/core/array.cu
 csrc/flash_attn/cutlass/test/unit/core/bfloat16.cu
 csrc/flash_attn/cutlass/test/unit/core/complex.cu
 csrc/flash_attn/cutlass/test/unit/core/float8.cu
 csrc/flash_attn/cutlass/test/unit/core/functional.cu
 csrc/flash_attn/cutlass/test/unit/core/half.cu
@@ -654,14 +667,32 @@
 csrc/flash_attn/cutlass/test/unit/core/numeric_conversion.cu
 csrc/flash_attn/cutlass/test/unit/core/predicate_vector.cu
 csrc/flash_attn/cutlass/test/unit/core/quaternion.cu
 csrc/flash_attn/cutlass/test/unit/core/tensor_ref.cu
 csrc/flash_attn/cutlass/test/unit/core/tensor_view.cu
 csrc/flash_attn/cutlass/test/unit/core/test_unit_core.cpp
 csrc/flash_attn/cutlass/test/unit/core/tfloat32.cu
+csrc/flash_attn/cutlass/test/unit/cute/ampere/cp_async.cu
+csrc/flash_attn/cutlass/test/unit/cute/ampere/ldsm.cu
+csrc/flash_attn/cutlass/test/unit/cute/core/bitfield.cpp
+csrc/flash_attn/cutlass/test/unit/cute/core/coalesce.cpp
+csrc/flash_attn/cutlass/test/unit/cute/core/compare.cpp
+csrc/flash_attn/cutlass/test/unit/cute/core/complement.cpp
+csrc/flash_attn/cutlass/test/unit/cute/core/composition.cpp
+csrc/flash_attn/cutlass/test/unit/cute/core/inverse_left.cpp
+csrc/flash_attn/cutlass/test/unit/cute/core/inverse_right.cpp
+csrc/flash_attn/cutlass/test/unit/cute/core/logical_divide.cpp
+csrc/flash_attn/cutlass/test/unit/cute/core/logical_product.cpp
+csrc/flash_attn/cutlass/test/unit/cute/core/mixedbits.cpp
+csrc/flash_attn/cutlass/test/unit/cute/core/transform.cpp
+csrc/flash_attn/cutlass/test/unit/cute/core/tuple.cpp
+csrc/flash_attn/cutlass/test/unit/cute/hopper/stsm.cu
+csrc/flash_attn/cutlass/test/unit/cute/hopper/tma_load.cu
+csrc/flash_attn/cutlass/test/unit/cute/hopper/tma_store.cu
+csrc/flash_attn/cutlass/test/unit/cute/layout/layout_operator.cu
 csrc/flash_attn/cutlass/test/unit/epilogue/thread/activation.cu
 csrc/flash_attn/cutlass/test/unit/epilogue/thread/linear_combination.cu
 csrc/flash_attn/cutlass/test/unit/epilogue/thread/linear_combination_planar_complex.cu
 csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/epilogue_planar_complex.cu
 csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/epilogue_simt.cu
 csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/epilogue_simt_sm60.cu
 csrc/flash_attn/cutlass/test/unit/epilogue/threadblock/epilogue_simt_sm61.cu
@@ -876,14 +907,35 @@
 csrc/flash_attn/cutlass/test/unit/gemm/device/simt_sgemm_tn_sm50.cu
 csrc/flash_attn/cutlass/test/unit/gemm/device/simt_sgemm_tn_sm80.cu
 csrc/flash_attn/cutlass/test/unit/gemm/device/simt_sgemm_tt_sm50.cu
 csrc/flash_attn/cutlass/test/unit/gemm/device/simt_zgemm_nn_sm50.cu
 csrc/flash_attn/cutlass/test/unit/gemm/device/simt_zgemm_nt_sm50.cu
 csrc/flash_attn/cutlass/test/unit/gemm/device/simt_zgemm_tn_sm50.cu
 csrc/flash_attn/cutlass/test/unit/gemm/device/simt_zgemm_tt_sm50.cu
+csrc/flash_attn/cutlass/test/unit/gemm/device/sm50_gemm_f32_f32_f32_simt.cu
+csrc/flash_attn/cutlass/test/unit/gemm/device/sm50_gemm_f64_f64_f64_simt.cu
+csrc/flash_attn/cutlass/test/unit/gemm/device/sm61_gemm_s8_s8_s32_simt.cu
+csrc/flash_attn/cutlass/test/unit/gemm/device/sm80_gemm_f16_f16_f32_tensor_op_f32.cu
+csrc/flash_attn/cutlass/test/unit/gemm/device/sm80_gemm_f32_f32_f32_simt.cu
+csrc/flash_attn/cutlass/test/unit/gemm/device/sm80_gemm_f64_f64_f64_simt.cu
+csrc/flash_attn/cutlass/test/unit/gemm/device/sm80_gemm_f64_f64_f64_tensor_op_f64.cu
+csrc/flash_attn/cutlass/test/unit/gemm/device/sm80_gemm_s8_s8_s32_tensor_op.cu
+csrc/flash_attn/cutlass/test/unit/gemm/device/sm80_gemm_tf32_tf32_f32_tensor_op_f32.cu
+csrc/flash_attn/cutlass/test/unit/gemm/device/sm90_gemm_bf16_bf16_bf16_alignx_tensor_op_f32.cu
+csrc/flash_attn/cutlass/test/unit/gemm/device/sm90_gemm_bf16_bf16_bf16_tensor_op_f32.cu
+csrc/flash_attn/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_alignx_tensor_op.cu
+csrc/flash_attn/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op.cu
+csrc/flash_attn/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_unspecialized.cu
+csrc/flash_attn/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized.cu
+csrc/flash_attn/cutlass/test/unit/gemm/device/sm90_gemm_f16_f16_f16_tensor_op_f32_cluster_warpspecialized_persistent.cu
+csrc/flash_attn/cutlass/test/unit/gemm/device/sm90_gemm_f32_f32_f32_tensor_op_f32.cu
+csrc/flash_attn/cutlass/test/unit/gemm/device/sm90_gemm_s8_s8_s8_alignx_tensor_op_s32.cu
+csrc/flash_attn/cutlass/test/unit/gemm/device/sm90_gemm_s8_s8_s8_tensor_op_s32.cu
+csrc/flash_attn/cutlass/test/unit/gemm/device/sm90_gemm_tf32_tf32_f32_alignx_tensor_op_f32.cu
+csrc/flash_attn/cutlass/test/unit/gemm/device/sm90_gemm_tf32_tf32_f32_tensor_op_f32.cu
 csrc/flash_attn/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_f32_ls_sm80.cu
 csrc/flash_attn/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_f32_rs_sm80.cu
 csrc/flash_attn/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_fast_f32_ls_sm80.cu
 csrc/flash_attn/cutlass/test/unit/gemm/device/symm_cf32n_cf32n_tensor_op_fast_f32_rs_sm80.cu
 csrc/flash_attn/cutlass/test/unit/gemm/device/symm_cf64_cf64_cf64_tensor_op_f64_sm90.cu
 csrc/flash_attn/cutlass/test/unit/gemm/device/symm_cf64n_cf64n_cf64n_tensor_op_ls_f64_gaussian_sm80.cu
 csrc/flash_attn/cutlass/test/unit/gemm/device/symm_cf64n_cf64n_cf64n_tensor_op_ls_f64_sm80.cu
@@ -1028,14 +1080,20 @@
 csrc/flash_attn/cutlass/test/unit/layout/tensor_nhwc.cu
 csrc/flash_attn/cutlass/test/unit/nvrtc/cutlass/nvrtc/environment.h
 csrc/flash_attn/cutlass/test/unit/nvrtc/kernel/thread/testbed_kernel.h
 csrc/flash_attn/cutlass/test/unit/nvrtc/stdlib/assert.h
 csrc/flash_attn/cutlass/test/unit/nvrtc/stdlib/stdint.h
 csrc/flash_attn/cutlass/test/unit/nvrtc/thread/gemm_nvrtc.cu
 csrc/flash_attn/cutlass/test/unit/nvrtc/thread/testbed.h
+csrc/flash_attn/cutlass/test/unit/pipeline/pipeline_async.cu
+csrc/flash_attn/cutlass/test/unit/pipeline/pipeline_tma_async.cu
+csrc/flash_attn/cutlass/test/unit/pipeline/pipeline_tma_async_warp_specialized.cu
+csrc/flash_attn/cutlass/test/unit/pipeline/pipeline_tma_async_warp_specialized_persistent.cu
+csrc/flash_attn/cutlass/test/unit/pipeline/sequence_barrier.cu
+csrc/flash_attn/cutlass/test/unit/pipeline/testbed.h
 csrc/flash_attn/cutlass/test/unit/reduction/device/tensor_reduce_contiguous.cu
 csrc/flash_attn/cutlass/test/unit/reduction/device/tensor_reduce_strided.cu
 csrc/flash_attn/cutlass/test/unit/reduction/kernel/reduce_splitk.cu
 csrc/flash_attn/cutlass/test/unit/reduction/kernel/reduce_splitk_testbed.h
 csrc/flash_attn/cutlass/test/unit/reduction/thread/reduction_thread.cu
 csrc/flash_attn/cutlass/test/unit/reduction/thread/testbed.h
 csrc/flash_attn/cutlass/test/unit/transform/threadblock/predicated_tile_iterator.cu
@@ -1046,14 +1104,15 @@
 csrc/flash_attn/cutlass/tools/library/include/cutlass/library/handle.h
 csrc/flash_attn/cutlass/tools/library/include/cutlass/library/library.h
 csrc/flash_attn/cutlass/tools/library/include/cutlass/library/manifest.h
 csrc/flash_attn/cutlass/tools/library/include/cutlass/library/operation_table.h
 csrc/flash_attn/cutlass/tools/library/include/cutlass/library/singleton.h
 csrc/flash_attn/cutlass/tools/library/include/cutlass/library/util.h
 csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/compiler.h
+csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/cute.cpp
 csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/cutlass.cpp
 csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/library.h
 csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/arch.h
 csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/swizzling.h
 csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/tensor_coord.h
 csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/tensor_ref_view.h
 csrc/flash_attn/cutlass/tools/library/scripts/pycutlass/src/cpp/include/types.h
@@ -1201,76 +1260,107 @@
 csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/tensor_elementwise.h
 csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/tensor_fill.h
 csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/tensor_foreach.h
 csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/tensor_norm.h
 csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/tensor_reduce.h
 csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/trmm.h
 csrc/flash_attn/cutlass/tools/util/include/cutlass/util/reference/host/trmm_complex.h
+csrc/flash_attn/src/block_info.h
+csrc/flash_attn/src/flash.h
+csrc/flash_attn/src/flash_bwd_hdim128.cu
+csrc/flash_attn/src/flash_bwd_hdim128_bf16_sm80.cu
+csrc/flash_attn/src/flash_bwd_hdim128_fp16_sm80.cu
+csrc/flash_attn/src/flash_bwd_hdim128_sm80_fp16.cu
+csrc/flash_attn/src/flash_bwd_hdim32.cu
+csrc/flash_attn/src/flash_bwd_hdim32_bf16_sm80.cu
+csrc/flash_attn/src/flash_bwd_hdim32_fp16_sm80.cu
+csrc/flash_attn/src/flash_bwd_hdim32_sm80_fp16.cu
+csrc/flash_attn/src/flash_bwd_hdim64.cu
+csrc/flash_attn/src/flash_bwd_hdim64_bf16_sm80.cu
+csrc/flash_attn/src/flash_bwd_hdim64_fp16_sm80.cu
+csrc/flash_attn/src/flash_bwd_hdim64_sm80_fp16.cu
+csrc/flash_attn/src/flash_bwd_hdim96.cu
+csrc/flash_attn/src/flash_bwd_hdim96_bf16_sm80.cu
+csrc/flash_attn/src/flash_bwd_hdim96_fp16_sm80.cu
+csrc/flash_attn/src/flash_bwd_hdim96_sm80_fp16.cu
+csrc/flash_attn/src/flash_bwd_kernel.h
+csrc/flash_attn/src/flash_bwd_kernel_bak.h
+csrc/flash_attn/src/flash_bwd_kernel_new.h
+csrc/flash_attn/src/flash_bwd_kernel_reverse.h
+csrc/flash_attn/src/flash_bwd_launch_template.h
+csrc/flash_attn/src/flash_fwd_hdim128.cu
+csrc/flash_attn/src/flash_fwd_hdim128_bf16_sm80.cu
+csrc/flash_attn/src/flash_fwd_hdim128_fp16_sm80.cu
+csrc/flash_attn/src/flash_fwd_hdim128_sm80_fp16.cu
+csrc/flash_attn/src/flash_fwd_hdim160.cu
+csrc/flash_attn/src/flash_fwd_hdim160_bf16_sm80.cu
+csrc/flash_attn/src/flash_fwd_hdim160_fp16_sm80.cu
+csrc/flash_attn/src/flash_fwd_hdim160_sm80_fp16.cu
+csrc/flash_attn/src/flash_fwd_hdim192.cu
+csrc/flash_attn/src/flash_fwd_hdim192_bf16_sm80.cu
+csrc/flash_attn/src/flash_fwd_hdim192_fp16_sm80.cu
+csrc/flash_attn/src/flash_fwd_hdim192_sm80_fp16.cu
+csrc/flash_attn/src/flash_fwd_hdim32.cu
+csrc/flash_attn/src/flash_fwd_hdim32_bf16_sm80.cu
+csrc/flash_attn/src/flash_fwd_hdim32_fp16_sm80.cu
+csrc/flash_attn/src/flash_fwd_hdim32_sm80_fp16.cu
+csrc/flash_attn/src/flash_fwd_hdim64.cu
+csrc/flash_attn/src/flash_fwd_hdim64_bf16_sm80.cu
+csrc/flash_attn/src/flash_fwd_hdim64_fp16_sm80.cu
+csrc/flash_attn/src/flash_fwd_hdim64_sm80_fp16.cu
+csrc/flash_attn/src/flash_fwd_hdim96.cu
+csrc/flash_attn/src/flash_fwd_hdim96_bf16_sm80.cu
+csrc/flash_attn/src/flash_fwd_hdim96_fp16_sm80.cu
+csrc/flash_attn/src/flash_fwd_hdim96_sm80_fp16.cu
+csrc/flash_attn/src/flash_fwd_kernel.h
+csrc/flash_attn/src/flash_fwd_kernel_old.h
+csrc/flash_attn/src/flash_fwd_launch_template.h
 csrc/flash_attn/src/fmha.h
 csrc/flash_attn/src/fmha_block_dgrad_fp16_kernel_loop.sm80.cu
 csrc/flash_attn/src/fmha_block_dgrad_kernel_1xN_loop.h
 csrc/flash_attn/src/fmha_block_fprop_fp16_kernel.sm80.cu
 csrc/flash_attn/src/fmha_block_fprop_kernel_1xN.h
 csrc/flash_attn/src/fmha_blockmask.h
 csrc/flash_attn/src/fmha_bwd_hdim128.cu
 csrc/flash_attn/src/fmha_bwd_hdim32.cu
 csrc/flash_attn/src/fmha_bwd_hdim64.cu
 csrc/flash_attn/src/fmha_bwd_launch_template.h
-csrc/flash_attn/src/fmha_dgrad_fp16_kernel_loop.sm80.cu
 csrc/flash_attn/src/fmha_dgrad_kernel_1xN_loop.h
-csrc/flash_attn/src/fmha_dgrad_launch_template.h
-csrc/flash_attn/src/fmha_fprop_fp16_kernel.sm80.cu
-csrc/flash_attn/src/fmha_fprop_hdim128.cu
-csrc/flash_attn/src/fmha_fprop_hdim32.cu
-csrc/flash_attn/src/fmha_fprop_hdim64.cu
 csrc/flash_attn/src/fmha_fprop_kernel_1xN.h
-csrc/flash_attn/src/fmha_fprop_kernel_dispatch.cu
-csrc/flash_attn/src/fmha_fprop_launch_template.h
 csrc/flash_attn/src/fmha_fwd_hdim128.cu
 csrc/flash_attn/src/fmha_fwd_hdim32.cu
 csrc/flash_attn/src/fmha_fwd_hdim64.cu
 csrc/flash_attn/src/fmha_fwd_launch_template.h
 csrc/flash_attn/src/fmha_kernel.h
 csrc/flash_attn/src/fmha_utils.h
-csrc/flash_attn/src/fp16_switch.h
-csrc/flash_attn/src/fprop_heuristic.cuh
+csrc/flash_attn/src/kernel_traits.h
+csrc/flash_attn/src/mask.h
 csrc/flash_attn/src/philox.cuh
+csrc/flash_attn/src/softmax.h
 csrc/flash_attn/src/static_switch.h
-csrc/flash_attn/src/fmha/epilogue.h
-csrc/flash_attn/src/fmha/epilogue_predicated_tile_iterator.h
+csrc/flash_attn/src/utils.h
 csrc/flash_attn/src/fmha/gemm.h
 csrc/flash_attn/src/fmha/gmem_tile.h
 csrc/flash_attn/src/fmha/kernel_traits.h
 csrc/flash_attn/src/fmha/mask.h
-csrc/flash_attn/src/fmha/mma_core_sm75.h
-csrc/flash_attn/src/fmha/regular_tile_access_iterator_tensor_op.h
 csrc/flash_attn/src/fmha/smem_tile.h
 csrc/flash_attn/src/fmha/softmax.h
-csrc/flash_attn/src/fmha/summary_stats.h
 csrc/flash_attn/src/fmha/utils.h
-csrc/flash_gen/bfloat16_fallback_kenrels.cuh
-csrc/flash_gen/cuda_bf16_wrapper.h
 csrc/flash_gen/decoder_masked_multihead_attention.cu
-csrc/flash_gen/decoder_masked_multihead_attention.h
-csrc/flash_gen/decoder_masked_multihead_attention_utils.h
-csrc/ft_attention/bfloat16_fallback.cuh
-csrc/ft_attention/bfloat16_fallback_kenrels.cuh
 csrc/ft_attention/cuda_bf16_fallbacks.cuh
 csrc/ft_attention/cuda_bf16_wrapper.h
 csrc/ft_attention/decoder_masked_multihead_attention.cu
 csrc/ft_attention/decoder_masked_multihead_attention.h
 csrc/ft_attention/decoder_masked_multihead_attention_utils.h
 csrc/ft_attention/ft_attention.cpp
 csrc/fused_dense_lib/fused_dense.cpp
 csrc/fused_dense_lib/fused_dense_cuda.cu
 csrc/fused_softmax/fused_softmax.cpp
-csrc/fused_softmax/scaled_masked_softmax.cpp
 csrc/fused_softmax/scaled_masked_softmax.h
 csrc/fused_softmax/scaled_masked_softmax_cuda.cu
-csrc/fused_softmax/scaled_upper_triang_masked_softmax.cpp
 csrc/fused_softmax/scaled_upper_triang_masked_softmax.h
 csrc/fused_softmax/scaled_upper_triang_masked_softmax_cuda.cu
 csrc/fused_softmax/type_shim.h
 csrc/layer_norm/ln.h
 csrc/layer_norm/ln_api.cpp
 csrc/layer_norm/ln_bwd_1024.cu
 csrc/layer_norm/ln_bwd_1280.cu
@@ -1279,36 +1369,75 @@
 csrc/layer_norm/ln_bwd_256.cu
 csrc/layer_norm/ln_bwd_2560.cu
 csrc/layer_norm/ln_bwd_3072.cu
 csrc/layer_norm/ln_bwd_4096.cu
 csrc/layer_norm/ln_bwd_512.cu
 csrc/layer_norm/ln_bwd_5120.cu
 csrc/layer_norm/ln_bwd_6144.cu
+csrc/layer_norm/ln_bwd_7168.cu
 csrc/layer_norm/ln_bwd_768.cu
+csrc/layer_norm/ln_bwd_8192.cu
 csrc/layer_norm/ln_bwd_kernels.cuh
-csrc/layer_norm/ln_bwd_semi_cuda_kernel.cu
 csrc/layer_norm/ln_bwd_semi_cuda_kernel_old.cu
 csrc/layer_norm/ln_fwd_1024.cu
+csrc/layer_norm/ln_fwd_10240.cu
+csrc/layer_norm/ln_fwd_12288.cu
 csrc/layer_norm/ln_fwd_128.cu
 csrc/layer_norm/ln_fwd_1280.cu
 csrc/layer_norm/ln_fwd_1536.cu
 csrc/layer_norm/ln_fwd_2048.cu
 csrc/layer_norm/ln_fwd_256.cu
 csrc/layer_norm/ln_fwd_2560.cu
 csrc/layer_norm/ln_fwd_3072.cu
 csrc/layer_norm/ln_fwd_384.cu
 csrc/layer_norm/ln_fwd_4096.cu
 csrc/layer_norm/ln_fwd_512.cu
 csrc/layer_norm/ln_fwd_5120.cu
 csrc/layer_norm/ln_fwd_6144.cu
+csrc/layer_norm/ln_fwd_7168.cu
 csrc/layer_norm/ln_fwd_768.cu
-csrc/layer_norm/ln_fwd_cuda_kernel.cu
+csrc/layer_norm/ln_fwd_8192.cu
+csrc/layer_norm/ln_fwd_9216.cu
 csrc/layer_norm/ln_fwd_cuda_kernel_old.cu
 csrc/layer_norm/ln_fwd_kernels.cuh
 csrc/layer_norm/ln_kernel_traits.h
+csrc/layer_norm/ln_parallel_bwd_1024.cu
+csrc/layer_norm/ln_parallel_bwd_1280.cu
+csrc/layer_norm/ln_parallel_bwd_1536.cu
+csrc/layer_norm/ln_parallel_bwd_2048.cu
+csrc/layer_norm/ln_parallel_bwd_256.cu
+csrc/layer_norm/ln_parallel_bwd_2560.cu
+csrc/layer_norm/ln_parallel_bwd_3072.cu
+csrc/layer_norm/ln_parallel_bwd_4096.cu
+csrc/layer_norm/ln_parallel_bwd_512.cu
+csrc/layer_norm/ln_parallel_bwd_5120.cu
+csrc/layer_norm/ln_parallel_bwd_6144.cu
+csrc/layer_norm/ln_parallel_bwd_7168.cu
+csrc/layer_norm/ln_parallel_bwd_768.cu
+csrc/layer_norm/ln_parallel_bwd_8192.cu
+csrc/layer_norm/ln_parallel_fwd_1024.cu
+csrc/layer_norm/ln_parallel_fwd_128.cu
+csrc/layer_norm/ln_parallel_fwd_1280.cu
+csrc/layer_norm/ln_parallel_fwd_1536.cu
+csrc/layer_norm/ln_parallel_fwd_2048.cu
+csrc/layer_norm/ln_parallel_fwd_256.cu
+csrc/layer_norm/ln_parallel_fwd_2560.cu
+csrc/layer_norm/ln_parallel_fwd_3072.cu
+csrc/layer_norm/ln_parallel_fwd_4096.cu
+csrc/layer_norm/ln_parallel_fwd_512.cu
+csrc/layer_norm/ln_parallel_fwd_5120.cu
+csrc/layer_norm/ln_parallel_fwd_6144.cu
+csrc/layer_norm/ln_parallel_fwd_7168.cu
+csrc/layer_norm/ln_parallel_fwd_768.cu
+csrc/layer_norm/ln_parallel_fwd_8192.cu
+csrc/layer_norm/ln_parallel_res_fwd_kernel.cuh
+csrc/layer_norm/ln_parallel_residual_bwd_512.cu
+csrc/layer_norm/ln_parallel_residual_bwd_kernels.cuh
+csrc/layer_norm/ln_parallel_residual_fwd_kernel.cuh
+csrc/layer_norm/ln_parallel_residual_fwd_kernels.cuh
 csrc/layer_norm/ln_utils.cuh
 csrc/layer_norm/static_switch.h
 csrc/rotary/rotary.cpp
 csrc/rotary/rotary_cuda.cu
 csrc/xentropy/interface.cpp
 csrc/xentropy/xentropy_kernel.cu
 flash_attn/__init__.py
@@ -1316,14 +1445,15 @@
 flash_attn/bert_padding.py
 flash_attn/flash_attention.py
 flash_attn/flash_attn_interface.py
 flash_attn/flash_attn_triton.py
 flash_attn/flash_attn_triton_og.py
 flash_attn/flash_attn_triton_single_query.py
 flash_attn/flash_attn_triton_tmp.py
+flash_attn/flash_attn_triton_tmp_og.py
 flash_attn/flash_attn_triton_varlen.py
 flash_attn/flash_blocksparse_attention.py
 flash_attn/flash_blocksparse_attn_interface.py
 flash_attn/fused_softmax.py
 flash_attn/rotary.py
 flash_attn.egg-info/PKG-INFO
 flash_attn.egg-info/SOURCES.txt
@@ -1336,14 +1466,17 @@
 flash_attn/losses/__init__.py
 flash_attn/losses/cross_entropy.py
 flash_attn/losses/cross_entropy_apex.py
 flash_attn/losses/cross_entropy_parallel.py
 flash_attn/models/__init__.py
 flash_attn/models/bert.py
 flash_attn/models/gpt.py
+flash_attn/models/gpt_j.py
+flash_attn/models/gpt_neox.py
+flash_attn/models/gptj.py
 flash_attn/models/opt.py
 flash_attn/models/vit.py
 flash_attn/modules/__init__.py
 flash_attn/modules/block.py
 flash_attn/modules/embedding.py
 flash_attn/modules/mha.py
 flash_attn/modules/mlp.py
```

### Comparing `flash_attn-0.2.8/setup.py` & `flash_attn-1.0.0/setup.py`

 * *Files 25% similar despite different names*

```diff
@@ -1,12 +1,13 @@
 # Adapted from https://github.com/NVIDIA/apex/blob/master/setup.py
 import sys
 import warnings
 import os
 from pathlib import Path
+from packaging.version import parse, Version
 
 from setuptools import setup, find_packages
 import subprocess
 
 import torch
 from torch.utils.cpp_extension import BuildExtension, CppExtension, CUDAExtension, CUDA_HOME
 
@@ -19,30 +20,27 @@
 this_dir = os.path.dirname(os.path.abspath(__file__))
 
 
 def get_cuda_bare_metal_version(cuda_dir):
     raw_output = subprocess.check_output([cuda_dir + "/bin/nvcc", "-V"], universal_newlines=True)
     output = raw_output.split()
     release_idx = output.index("release") + 1
-    release = output[release_idx].split(".")
-    bare_metal_major = release[0]
-    bare_metal_minor = release[1][0]
+    bare_metal_version = parse(output[release_idx].split(",")[0])
 
-    return raw_output, bare_metal_major, bare_metal_minor
+    return raw_output, bare_metal_version
 
 
 def check_cuda_torch_binary_vs_bare_metal(cuda_dir):
-    raw_output, bare_metal_major, bare_metal_minor = get_cuda_bare_metal_version(cuda_dir)
-    torch_binary_major = torch.version.cuda.split(".")[0]
-    torch_binary_minor = torch.version.cuda.split(".")[1]
+    raw_output, bare_metal_version = get_cuda_bare_metal_version(cuda_dir)
+    torch_binary_version = parse(torch.version.cuda)
 
     print("\nCompiling cuda extensions with")
     print(raw_output + "from " + cuda_dir + "/bin\n")
 
-    if (bare_metal_major != torch_binary_major) or (bare_metal_minor != torch_binary_minor):
+    if (bare_metal_version != torch_binary_version):
         raise RuntimeError(
             "Cuda extensions are being compiled with a version of Cuda that does "
             "not match the version used to compile Pytorch binaries.  "
             "Pytorch binaries were compiled with Cuda {}.\n".format(torch.version.cuda)
             + "In some cases, a minor-version mismatch will not cause later errors:  "
             "https://github.com/NVIDIA/apex/pull/323#discussion_r287021798.  "
             "You can try commenting out this check (at your own risk)."
@@ -56,41 +54,44 @@
         f"{global_option} was requested, but nvcc was not found.  Are you sure your environment has nvcc available?  "
         "If you're installing within a container from https://hub.docker.com/r/pytorch/pytorch, "
         "only images whose names contain 'devel' will provide nvcc."
     )
 
 
 def append_nvcc_threads(nvcc_extra_args):
-    _, bare_metal_major, bare_metal_minor = get_cuda_bare_metal_version(CUDA_HOME)
-    if int(bare_metal_major) >= 11 and int(bare_metal_minor) >= 2:
+    _, bare_metal_version = get_cuda_bare_metal_version(CUDA_HOME)
+    if bare_metal_version >= Version("11.2"):
         return nvcc_extra_args + ["--threads", "4"]
     return nvcc_extra_args
 
 
 if not torch.cuda.is_available():
     # https://github.com/NVIDIA/apex/issues/486
     # Extension builds after https://github.com/pytorch/pytorch/pull/23408 attempt to query torch.cuda.get_device_capability(),
     # which will fail if you are compiling in an environment without visible GPUs (e.g. during an nvidia-docker build command).
     print(
         "\nWarning: Torch did not find available GPUs on this system.\n",
         "If your intention is to cross-compile, this is not an error.\n"
-        "By default, We cross-compile for Volta (compute capability 7.0), "
-        "Turing (compute capability 7.5),\n"
+        "By default, Apex will cross-compile for Pascal (compute capabilities 6.0, 6.1, 6.2),\n"
+        "Volta (compute capability 7.0), Turing (compute capability 7.5),\n"
         "and, if the CUDA version is >= 11.0, Ampere (compute capability 8.0).\n"
         "If you wish to cross-compile for a single specific architecture,\n"
         'export TORCH_CUDA_ARCH_LIST="compute capability" before running setup.py.\n',
     )
-    if os.environ.get("TORCH_CUDA_ARCH_LIST", None) is None:
-        _, bare_metal_major, bare_metal_minor = get_cuda_bare_metal_version(CUDA_HOME)
-        if int(bare_metal_major) == 11:
-            os.environ["TORCH_CUDA_ARCH_LIST"] = "7.0;7.5;8.0"
-            if int(bare_metal_minor) > 0:
-                os.environ["TORCH_CUDA_ARCH_LIST"] = "7.0;7.5;8.0;8.6"
+    if os.environ.get("TORCH_CUDA_ARCH_LIST", None) is None and CUDA_HOME is not None:
+        _, bare_metal_version = get_cuda_bare_metal_version(CUDA_HOME)
+        if bare_metal_version >= Version("11.8"):
+            os.environ["TORCH_CUDA_ARCH_LIST"] = "6.0;6.1;6.2;7.0;7.5;8.0;8.6;9.0"
+        elif bare_metal_version >= Version("11.1"):
+            os.environ["TORCH_CUDA_ARCH_LIST"] = "6.0;6.1;6.2;7.0;7.5;8.0;8.6"
+        elif bare_metal_version == Version("11.0"):
+            os.environ["TORCH_CUDA_ARCH_LIST"] = "6.0;6.1;6.2;7.0;7.5;8.0"
         else:
-            os.environ["TORCH_CUDA_ARCH_LIST"] = "7.0;7.5"
+            os.environ["TORCH_CUDA_ARCH_LIST"] = "6.0;6.1;6.2;7.0;7.5"
+
 
 print("\n\ntorch.__version__  = {}\n\n".format(torch.__version__))
 TORCH_MAJOR = int(torch.__version__.split(".")[0])
 TORCH_MINOR = int(torch.__version__.split(".")[1])
 
 cmdclass = {}
 ext_modules = []
@@ -101,21 +102,24 @@
 torch_dir = torch.__path__[0]
 if os.path.exists(os.path.join(torch_dir, "include", "ATen", "CUDAGeneratorImpl.h")):
     generator_flag = ["-DOLD_GENERATOR_PATH"]
 
 raise_if_cuda_home_none("flash_attn")
 # Check, if CUDA11 is installed for compute capability 8.0
 cc_flag = []
-_, bare_metal_major, _ = get_cuda_bare_metal_version(CUDA_HOME)
-if int(bare_metal_major) < 11:
-    raise RuntimeError("FlashAttention is only supported on CUDA 11")
+_, bare_metal_version = get_cuda_bare_metal_version(CUDA_HOME)
+if bare_metal_version < Version("11.0"):
+    raise RuntimeError("FlashAttention is only supported on CUDA 11 and above")
 cc_flag.append("-gencode")
 cc_flag.append("arch=compute_75,code=sm_75")
 cc_flag.append("-gencode")
 cc_flag.append("arch=compute_80,code=sm_80")
+if bare_metal_version >= Version("11.8"):
+    cc_flag.append("-gencode")
+    cc_flag.append("arch=compute_90,code=sm_90")
 
 subprocess.run(["git", "submodule", "update", "--init", "csrc/flash_attn/cutlass"])
 ext_modules.append(
     CUDAExtension(
         name="flash_attn_cuda",
         sources=[
             "csrc/flash_attn/fmha_api.cpp",
@@ -154,15 +158,15 @@
             Path(this_dir) / 'csrc' / 'flash_attn' / 'cutlass' / 'include',
         ],
     )
 )
 
 setup(
     name="flash_attn",
-    version="0.2.8",
+    version="1.0.0",
     packages=find_packages(
         exclude=("build", "csrc", "include", "tests", "dist", "docs", "benchmarks", "flash_attn.egg-info",)
     ),
     author="Tri Dao",
     author_email="trid@stanford.edu",
     description="Flash Attention: Fast and Memory-Efficient Exact Attention",
     long_description=long_description,
```

